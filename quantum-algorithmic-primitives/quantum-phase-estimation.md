# Quantum phase estimation

## Rough overview (in words)

The quantum phase estimation (QPE) subroutine produces an estimate of an eigenvalue of a unitary operator. It is a cornerstone of quantum algorithms primitives and has numerous applications. For example, [Shor's algorithm](../areas-of-application/cryptanalysis/breaking-cryptosystems.md#breaking-cryptosystems) for factoring can be viewed as an application of QPE together with modular exponentiation. Similarly, when combined with [Hamiltonian simulation](../quantum-algorithmic-primitives/hamiltonian-simulation/introduction.md#hamiltonian-simulation), QPE can produce an estimate for an eigenvalue of a Hamiltonian (given an appropriate initial state), an important problem in areas such as [quantum chemistry](../areas-of-application/quantum-chemistry/introduction.md#quantum-chemistry). In this context, QPE is the quantum analogue of measuring the value of a real function $f$ of a random variable $x$, where in the quantum case, the function $f$ can include noncommuting terms, and the random variable $x$ is a vector in a Hilbert space.


## Rough overview (in math)

Let $U$ be a unitary with eigendecomposition $U=\sum_j e^{i2\pi\phi_j}|\psi_j\rangle \langle \psi_j|$. Given as input the state $|\psi_j\rangle$, the QPE subroutine produces an estimate $\smash{\hat{\phi}_j}$ for $\phi_j$. The algorithm requires the ability to apply controlled-$U^{2^p}$ for non-negative integers $p$. If $\phi_j$ is an exact multiple of $2^{-P}$, then an exact estimate of $\phi_j$ can be learned with certainty using only $p\in \{0,1,\ldots,P-1\}$. In general, an estimate $\smash{\hat{\phi}_j}$ of $\phi_j$ satisfying $\smash{|\phi_j-\hat{\phi}_j|\leq \epsilon}$ can be learned with high probability by taking the maximum value of $2^p$ on the order of $1/\epsilon$. The algorithm also requires application of an inverse [quantum Fourier transform](../quantum-algorithmic-primitives/quantum-fourier-transform.md#quantum-fourier-transform) to orchestrate the constructive interference near the estimate for $\phi_j$.


Phase estimation can also be applied coherently onto a superposition of eigenstates. Suppose that the input state is $|\psi \rangle = \sum_j\alpha_j|\psi_j\rangle$. By linearity, if each phase $\phi_j$ is a multiple of $2^{-P}$ and phase estimation is run with sufficient resolution, then QPE enacts the following unitary $$\begin{equation} \label{eq:coherent_QPE} |\psi \rangle |0\rangle \mapsto \sum_j \alpha_j |\psi_j \rangle |\phi_j \rangle, \end{equation}$$ where $\ket{\phi_j}$ holds a $P$-bit binary representation of $\phi_j$. If the auxiliary register is measured, then with probability $|\alpha_j|^2$ (consistent with the Born rule) the estimate $\phi_j$ is obtained and the state collapses to the corresponding eigenstate $|\psi_j\rangle$.[^1] If the phases $\phi_j$ are not multiples of $2^{-P}$, an approximate version of this operation can still be accomplished as long as the precision is sufficiently small to resolve the eigenvalues, subject to some caveats (discussed below).


![Quantum circuit implementation of QPE. The measurement outcomes on the $P$ ancilla qubits give a $P$-bit estimate of the phase $\phi_j$ (correct up to error $\mathcal{O}\left( 2^{-P} \right)$) with high probability.](../figures/qcirc/7.png)


## Dominant resource cost (gates/qubits)

The QPE subroutine is typically dominated by calls to the controlled unitary $U$. If resolution $\epsilon$ is desired, one must perform controlled-$U^{2^p}$ operations for $p\in \{0,1,\ldots, \lceil \log_2(1/\epsilon) \rceil + \mathcal{O}\left( 1 \right)\}$; thus, the number of calls to a controlled-$U$ oracle will be $\mathcal{O}\left( 1/\epsilon \right)$. This dependence on $\epsilon$ is optimal; the $\mathcal{O}\left( 1/\epsilon \right)$ scaling is known as the *Heisenberg limit*.


In the context of estimating the eigenenergy of a Hamiltonian $H$, one can choose $U = e^{iH}$, and then implement controlled-$U^t$, i.e., controlled-$e^{iHt}$, with [Hamiltonian simulation](../quantum-algorithmic-primitives/hamiltonian-simulation/introduction.md#hamiltonian-simulation). In this case, given the ability to prepare an eigenstate of $H$, an $\epsilon$-approximation of the eigenvalue requires values of $t$ up to $\mathcal{O}\left( 1/\epsilon \right)$.[^2] However, one must also factor in the error in the Hamiltonian simulation. In a typical setting, access to the $n$-qubit Hamiltonian is given through a [linear combination](../quantum-algorithmic-primitives/quantum-linear-algebra/manipulating-block-encodings.md#linear-combinations) of $L$ unitaries. Let $\lVert H \rVert_1$ denote the sum of the coefficients in the combination. Then, methods for Hamiltonian simulation based on [quantum signal processing](../quantum-algorithmic-primitives/quantum-linear-algebra/quantum-signal-processing.md#quantum-signal-processingqubitization) can approximate $e^{iHt}$ to error $\mathcal{O}\left( \epsilon \right)$ with $\mathcal{O}\left( nL(\lVert H \rVert_1 t + \log(1/\epsilon)) \right)$ gate complexity, whereas methods based on [product formulae](../quantum-algorithmic-primitives/hamiltonian-simulation/product-formulae.md#product-formulae) incur cost $\mathcal{O}\left( nL(\lVert H \rVert_1 t)^{1+1/2k}\epsilon^{-1/2k} \right)$ for $(2k)$th-order product formulas, although the actual cost can be lower after accounting for structure in the Hamiltonian terms. Balancing the error from phase estimation against the error from Hamiltonian simulation can cause sub-Heisenberg-limited performance, such as in the case of the product formulae approach. The overhead associated with imperfect Hamiltonian simulation can be avoided by applying QPE to different functions of $H$; for example, a promising choice is the [qubitization operator](../quantum-algorithmic-primitives/quantum-linear-algebra/qubitization.md#qubitization), which acts in a similar way to $U = e^{i \arccos(H)}$. The reason this is advantageous is that the qubitization operator can be implemented *exactly* given access to a [block-encoding](../quantum-algorithmic-primitives/quantum-linear-algebra/block-encodings.md#block-encodings) of $H$ [@low2016HamSimQubitization; @poulin2018SpectralQubitization; @berry2018ImprovedEigenstatesFermionic].


The number of qubits for QPE is simply the size of the register needed to hold the input state $\ket{\psi_j}$ plus the size of the register needed to hold the estimate $\hat{\phi}_j$ (that is, roughly $\lceil \log_2(1/\epsilon) \rceil$ bits). Additionally, QPE requires an inverse [quantum Fourier transform](../quantum-algorithmic-primitives/quantum-fourier-transform.md#quantum-fourier-transform) (QFT), which adds only $\smash{\mathcal{O}(\log^2(1/\epsilon))}$ additional gates to the protocol.


Another version of QPE [@kitaev2002ClassicalQuantumComputation] achieves the same task with only a single ancilla qubit, but, as a result, learns only one bit of the output at a time. Additionally, it requires an exact eigenstate as input. The latter problem can be avoided using a statistical approach [@lin2022HeisenbergLimited; @wan2021RandPhaseEst].


## Caveats

The main caveats of QPE are related to the fact that eigenphases are not always exact integer multiples of $2^{-P}$, resulting in noncertain outcomes of QPE, which can lead to complications in certain applications.


- Fat tails and boosting of success probability: Whenever the phases $\phi_j$ are not exact integer multiples of $2^{-P}$ for some integer $P$, phase estimation will not return the answer $\phi_j$ with certainty. Rather, there will be a distribution of possible estimates $\smash{\hat{\phi}_j}$ that is peaked near $\phi_j$. If one chooses $P = \lceil \log_2(1/\epsilon) \rceil + \mathcal{O}\left( 1 \right)$, then most of the probability mass of this distribution lies within $\epsilon$ of $\phi_j$. As $P$ is increased further, the distribution becomes more sharply peaked near $\phi_j$, and if an $\epsilon$-accurate estimate with $1-\delta$ probability is desired, one must take $P = \lceil \log_2(1/\epsilon) \rceil + \mathcal{O}\left( \log(1/\delta) \right)$, corresponding to a multiplicative $\mathcal{O}\left( 1/\delta \right)$ overhead in the query complexity to $U$ and $\mathcal{O}\left( \log(1/\delta) \right)$ additional ancilla qubits. This poor $\delta$ dependence is due to "fat tails" on the distribution of estimates of $\hat{\phi_j}$. One way to avoid this overhead is to take the median of estimates obtained from $\mathcal{O}\left( \log(1/\delta) \right)$ repetitions of QPE [@nagaj2009FastAmpQMA Lemma 1]. A downside of this approach is that it may be difficult to implement coherently on a superposition of eigenstates, in the sense of Eq. $\eqref{eq:coherent_QPE}$, since computing the median would require a coherent quantum sorting network. An alternative way to circumvent the fat tails problem is to modify the QPE protocol to have a nonuniform superposition in the register that controls applications of $U$; a judicious choice of superposition leads the distribution over estimates $\smash{\hat{\phi}_j}$ to be a Kaiser window distribution, which minimizes the probability of deviating from $\phi_j$ by more than $\epsilon$; boosting the success probability to $1-\delta$ incurs multiplicative $\mathcal{O}\left( \log(1/\delta) \right)$ cost, rather than $\mathcal{O}\left( 1/\delta \right)$ [@berry2022quantifyingTDA Appendix C]. See also [@chen2023QThermalStatePrep], where a Gaussian profile is used to suppress the tails.
- Performing coherent QPE: When $\phi_j$ are noninteger multiples of $2^{-P}$, the coherent operation in Eq. $\eqref{eq:coherent_QPE}$ cannot be straightforwardly performed with exact fidelity. This is because for each value of $j$, the second register will be in a superposition of many values of $\smash{\hat{\phi}_j}$ (most but not all of the amplitude will lie on estimates close to $\phi_j$). To restore coherence, one might try coherently rounding the estimate $\smash{\hat{\phi}_j}$ onto a coarser net of grid points (and then uncomputing the original estimate $\hat{\phi_j}$); however, there will always be edge cases where $\phi_j$ falls very near the midpoint between two grid points and rounding destroys some of the coherence in the input. This is true even as the precision of QPE is taken to zero ($\epsilon \rightarrow 0$). See [@Rall2021fastercoherent] for a discussion. One possible way to mitigate this issue is presented in the "consistent phase estimation" protocol of [@ta-shma2013InvertingLogSpace Section 5.2], where a random shift is applied to the grid points to avoid this situation for any particular eigenphase with high probability. However, this does not generically work simultaneously for all eigenphases. In [@Rall2021fastercoherent], it is shown that performing Eq. $\eqref{eq:coherent_QPE}$ is impossible without a "rounding promise" on the set of eigenphases $\{\phi_j\}$.
- Biased estimator: a further consequence of the noncertainty of the QPE output is that the estimate $\smash{\hat{\phi}_j}$ is *biased*; that is, its expectation value is not exactly equal to $\phi_j$. This issue can also be fixed with a random shift idea, yielding an unbiased (and symmetrically distributed) version of QPE [@linden2021AvgCaseQFTtoWorstCaseQFT; @apeldoorn2022TomographyStatePreparationUnitaries].


## Example use cases

- In [quantum chemistry](../areas-of-application/quantum-chemistry/introduction.md#quantum-chemistry) and [condensed matter physics](../areas-of-application/condensed-matter-physics/introduction.md#condensed-matter-physics), QPE is used to measure the eigenvalues (and especially the ground state energy) of the Hamiltonian $H$, which gives knowledge about reaction mechanisms, stable configurations, and other equilibrium properties. For QPE to succeed, a trial state $|\psi\rangle$ with substantial overlap with the eigenstate of interest must be input to QPE, which is challenging in the general case.
- In [Shor's algorithm](../areas-of-application/cryptanalysis/breaking-cryptosystems.md#breaking-cryptosystems), given a composite integer $N$ and a (randomly chosen) base $g < N$, QPE is used to determine the order of $g$, that is, the minimum integer $r$ for which $g^r \equiv 1 \mod N$, which is in turn used to infer the prime factors of $N$. Here, the unitary $U$ is the modular multiplication unitary that sends $\ket{x} \mapsto \ket{gx \mod N}$.
- In [amplitude estimation](../quantum-algorithmic-primitives/amplitude-amplification-and-estimation/amplitude-estimation.md#amplitude-estimation), given a unitary $U$ that prepares a state $U\ket{\psi_0} = a\ket{\psi_g} + b\ket{\psi_b}$, QPE is used to estimate $|a|$ or $|a|^2$.
- In the Monte Carloâ€“style quantum algorithms for [Gibbs sampling](../quantum-algorithmic-primitives/gibbs-sampling.md#gibbs-sampling), roughly speaking, the quantum state undergoes a random walk on the eigenbasis of the Hamiltonian. Steps of this random walk are accepted or rejected according to how much the energy changes at each step. The QPE subroutine is used to simultaneously (approximately) project onto the eigenbasis of the Hamiltonian and to produce an estimate of the energy, used to determine whether the step should be accepted or rejected. Early studies [@temme2011quantumMetropolis; @yung2010QuantumQuantumMetropolis; @wocjan2021Szegedy] of this approach were hampered by the caveats related to rejecting quantum states and imperfect energy estimates, but recent works [@Rall_thermal_22; @chen2023QThermalStatePrep] circumvent these problems (by randomizing the grid points or completely abandoning phase estimation).
- To follow the ground-state $|\psi_0(s)\rangle$ of a Hamiltonian $H(s)$ as some parameter $s$ is varied from 0 to 1, one can run the [adiabatic algorithm](../quantum-algorithmic-primitives/quantum-adiabatic-algorithm.md#quantum-adiabatic-algorithm). Alternatively, one can consider a discretization of steps $s_t \in \{s_0,\ldots,s_T\}$, where $0=s_0<s_1<s_2<\ldots<s_{T-1}<s_T=1$, and run QPE on $H(s_t)$ in succession, each time causing a measurement into the instantaneous eigenbasis of $H(s_t)$. Due to the quantum Zeno effect, as long as sufficiently small steps are taken, each projection will be onto the ground space with high probability (see, e.g., [@somma2007QuantumSimulatedAnnealing]). Larger steps can be tolerated if one boosts the probability that each step succeeds with [amplitude amplification](../quantum-algorithmic-primitives/amplitude-amplification-and-estimation/amplitude-amplification.md#amplitude-amplification) [@boixo2010FastQuantumAlgorithms]. This approach is similar to the idea in Hastings' short-path algorithm [@hastings2018ShortPathQuantum; @dalzell2022mindthegap], which solves [combinatorial optimization](../areas-of-application/combinatorial-optimization/introduction.md#combinatorial-optimization) problems.
- While state-of-the-art [quantum linear systems solvers (QLSS)](../quantum-algorithmic-primitives/quantum-linear-system-solvers.md#quantum-linear-system-solvers) do not explicitly use QPE, the original QLSS by Harrow, Hassidim, and Lloyd [@harrow2009QLinSysSolver] uses QPE to coherently measure the eigenvalues of a matrix $A$ into an auxiliary register. These eigenvalue estimates are subsequently inverted with coherent classical arithmetic in order to produce the state $A^{-1}\ket{b}$ corresponding to the solution to the system $Ax=b$.


## Further reading

- The standard circuit and analysis of QPE appears in Nielsen and Chuang [@nielsen2002QCQI]. See also [@cleve1997QAlgsRevisited].
- Many variants of the QPE algorithm have been explored, which can be superior to the standard version in certain settings. See, e.g., [@Rall2021fastercoherent; @lin2022HeisenbergLimited] for additional references and informative overviews of various methods, along with their advantages and drawbacks.
- Reference [@lin2022LectureNotes] contains a pedagogical overview of QPE including some of its variants and applications. 






[^1]: Alternatively, if $\phi_j$ is known ahead of time (to sufficient precision), QPE can be wrapped inside of [amplitude amplification](#prim:AmpAmp) and the state $\ket{\psi_j}$ can be prepared using $\mathcal{O}\left( |\alpha_j|^{-1} \right)$ applications of the QPE circuit, rather than $\mathcal{O}\left( |\alpha_j|^{-2} \right)$.


[^2]: The fact that learning energies to greater precision requires a proportionally greater amount of time $t$ is a manifestation of the energy-time Heisenberg uncertainty principle, and forms the origin of the term "Heisenberg limit."

