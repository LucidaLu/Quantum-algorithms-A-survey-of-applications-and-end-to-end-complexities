{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Abstract","text":"<p>The anticipated applications of quantum computers span across science and industry, ranging from quantum chemistry and many-body physics to optimization, finance, and machine learning. Proposed quantum solutions in these areas typically combine multiple quantum algorithmic primitives into an overall quantum algorithm, which must then incorporate the methods of quantum error correction and fault tolerance to be implemented correctly on quantum hardware. As such, it can be difficult to assess how much a particular application benefits from quantum computing, as the various approaches are often sensitive to intricate technical details about the underlying primitives and their complexities. Here we present a survey of several potential application areas of quantum algorithms and their underlying algorithmic primitives, carefully considering technical caveats and subtleties. We outline the challenges and opportunities in each area in an \u201cend-to-end\u201d fashion by clearly defining the problem being solved alongside the input-output model, instantiating all \u201coracles,\u201d and spelling out all hidden costs. We also compare quantum solutions against state-of-the-art classical methods and complexity-theoretic limitations to evaluate possible quantum speedups.</p><p>The survey is written in a modular, wiki-like fashion to facilitate navigation of the content. Each primitive and application area is discussed in a standalone section, with its own bibliography of references and embedded hyperlinks that direct to other relevant sections. This structure mirrors that of complex quantum algorithms that involve several layers of abstraction, and it enables rapid evaluation of how end-to-end complexities are impacted when subroutines are altered.</p>"},{"location":"authors/","title":"Authors","text":"Alexander\u00a0M.\u00a0Dalzell<sup>1</sup>AWS Center for Quantum Computing, Pasadena, CA, USA Sam\u00a0McArdle<sup>1</sup>AWS Center for Quantum Computing, Pasadena, CA, USA Mario\u00a0BertaAWS Center for Quantum Computing, Pasadena, CA, USAInstitute for Quantum Information, RWTH Aachen University, Aachen, GermanyImperial College London, London, UK Przemyslaw\u00a0BieniasAWS Center for Quantum Computing, Pasadena, CA, USA Chi-Fang\u00a0ChenAWS Center for Quantum Computing, Pasadena, CA, USAInstitute for Quantum Information and Matter, Caltech, Pasadena, CA, USA Andr\u00e1s\u00a0Gily\u00e9nAlfr\u00e9d R\u00e9nyi Institute of Mathematics, Budapest, Hungary Connor\u00a0T.\u00a0HannAWS Center for Quantum Computing, Pasadena, CA, USA Michael\u00a0J.\u00a0KastoryanoAWS Center for Quantum Computing, Pasadena, CA, USAIT University of Copenhagen, Copenhagen, Denmark Emil\u00a0T.\u00a0KhabiboullineAWS Center for Quantum Computing, Pasadena, CA, USADepartment of Physics, Harvard University, Cambridge, MA, USA Aleksander\u00a0KubicaAWS Center for Quantum Computing, Pasadena, CA, USA Grant\u00a0SaltonAWS Center for Quantum Computing, Pasadena, CA, USAInstitute for Quantum Information and Matter, Caltech, Pasadena, CA, USAAmazon Quantum Solutions Lab, Seattle, WA, USA Samson\u00a0WangAWS Center for Quantum Computing, Pasadena, CA, USAImperial College London, London, UK Fernando\u00a0G.\u00a0S.\u00a0L.\u00a0Brand\u00e3oAWS Center for Quantum Computing, Pasadena, CA, USAInstitute for Quantum Information and Matter, Caltech, Pasadena, CA, USA <ol> <li> <p>These authors contributed equally. Corresponding emails: dalzel@amazon.com, sammcard@amazon.com \u21a9\u21a9</p> </li> </ol>"},{"location":"introduction/","title":"Introduction","text":"<p>In 1985, Deutsch gave what was essentially the first quantum algorithm\u2014a simple procedure that, with just one black-box query, could accomplish a task that classically requires two queries. Over the next decade, larger black-box separations were discovered, such as the Deutsch\u2013Jozsa, Bernstein\u2013Vazirani, and Simon's algorithms. Then, in 1994, the first truly end-to-end quantum algorithm was developed: Shor's algorithm for factoring integers and computing discrete logarithms, bringing extensive ramifications for cryptography. This breakthrough demonstrated that quantum computers could not only speed up the solution of contrived black-box problems but, at least in theory, could provide faster solutions to important real-world problems. The discovery of Shor's algorithm transformed the field of quantum algorithms from a relatively niche topic into a major research area.</p><p>During the past three decades since Shor's seminal discovery, the field of quantum algorithms matured significantly. For example, our knowledge of upper and lower bounds on the quantum query complexity of black-box problems\u2014often deduced through sophisticated, nonconstructive mathematical arguments\u2014has been greatly expanded. Moreover, many additional quantum algorithms and subroutines\u2014for example, primitives for quantum simulation and linear algebra\u2014have been discovered, optimized, and subsequently generalized multiple times. Meanwhile, advances in hardware and the theory of fault-tolerant quantum computation have reached the point where it is conceivable that (some of) these algorithms might soon become implementable at scales large enough to surpass what can be done classically.</p><p>Nevertheless, the magnitude of available quantum speedups for real-world applications is often hard to assess and can be obscured by technical caveats, assumptions, and limitations in the underlying quantum algorithmic primitives. Despite being one of the oldest, Shor's algorithm for factoring arguably remains the cleanest example of a substantial quantum speedup with minimal caveats that targets a problem of significant real-world relevance. This survey aims to elucidate the true resource requirements of end-to-end quantum computing applications and thereby aid in identifying the most likely applications for fault-tolerant quantum computers. Through this distinct perspective, the survey is intended to complement the wealth of existing quantum algorithms resources, including a number of review articles, lecture notes, textbooks, and the quantum algorithms zoo.</p><p>We highlight both the opportunities and challenges of currently known quantum algorithms. To truly understand the potential advantage of a quantum algorithm, it is necessary to consider its resource requirements in an \"end-to-end\" fashion. By this, we mean the cost of solving the full problem of interest to the user, not only the cost of running a given quantum circuit that is a subroutine of the full solution. One must consider all quantum and classical overheads: keeping track of classical precomputation and postprocessing, explicitly instantiating quantum oracles and data access structures, and ideally computing the constant factors of all quantum subroutines (including those overheads associated with fault-tolerant protocols and quantum error correction). We note, however, that this task is a major undertaking for complex quantum algorithms, and so has only been achieved for a minority of quantum algorithms in the literature. In addition to studying end-to-end quantum complexities, it is also necessary to compare any quantum results to the state-of-the-art classical solutions of the same problem, as well as known complexity-theoretic limitations.</p><p>We summarize the end-to-end complexities of a number of leading quantum application proposals (by which we mean quantum algorithms applied to a well-defined real-world problem). The complexities of these applications are deduced from the complexities of their underlying primitives, which we review in detail. The modular structure of the survey aids the high-level understanding of the costs and tradeoffs coming from the various choices one makes when designing and compiling a quantum algorithm, as well as identifying the bottlenecks for a given application. On the technical front, this survey does not attempt to advance the state of the art; rather, it aims to collect, synthesize, and contextualize key results in the literature. We consider algorithms in the quantum circuit model, which is arguably the best-studied model for quantum computation, and renders the presented complexities hardware agnostic. In order to obtain concrete bounds we require oracles to be explicitly instantiated. We generally assume that quantum error correction of some form will be necessary, due to unavoidable imperfections inherent to all known quantum hardware modalities. As such, we typically consider the non-Clifford cost of quantum algorithms as the dominant cost, in keeping with leading quantum fault-tolerance schemes. Due to the general lack of application-scale experimental data, we focus on elucidating provable speedups, and only mention noisy, intermediate scale quantum (NISQ) algorithms in passing, where appropriate, since they are typically heuristic.</p><p>Throughout this survey, we attempt to be thorough, but not exhaustive in presentation; we only aim to give a representative collection of references, rather than providing a complete list. Generally, we try to explain how asymptotic complexity statements arise from their underlying primitives, but technical results are typically presented without explicit derivation or proofs, for which we refer the reader to the cited references. Additionally, we often quote resource estimates from the literature without covering all of the application-specific optimizations to the underlying primitives that are required to arrive at the reported constant factors. We survey a number of quantum applications, primitives, and fault-tolerance schemes, however the omission of other approaches does not indicate that they are unimportant. Also, the scope of this work excludes substantial topics, such as: quantum sensing or communications, measurement-based quantum computing, adiabatic quantum computing and quantum annealing, analog quantum simulators, quantum-inspired (\"dequantization\") methods, and tensor network algorithms.</p><p>An overarching takeaway of this survey is that the current literature generally lacks fully end-to-end analyses for concrete quantum applications. Consequently, in several parts of this survey, a fully satisfactory end-to-end accounting is not achieved. In part, this is due to certain technical aspects of the relevant quantum algorithms being underexplored, and in some cases also due to a lack of specific details on how the output of the quantum algorithm will integrate into concrete computational workflows for future quantum computing users. Quantum algorithms research often works upward from algorithmic primitives to identify computational tasks with maximal quantum speedups, but these may not align with the tasks most relevant to the user. On the other hand, potential users themselves may not yet know exactly how they would use a new capability to advance their high-level goals. Yet, we find ourselves at a point in the history of quantum computing at which it behooves us to fill in these details and adopt this end-to-end lens. As more end-to-end applications are found and with small fault-tolerant quantum computers now on the horizon, we expect the story to continue to evolve\u2014this survey provides a snapshot of the state of play in 2023. While improved quantum algorithms and approaches to quantum error correction and fault tolerance are likely to be discovered, classical computers continue to grow in scale and speed, and classical algorithms are also constantly refined and developed, thereby moving the goalposts for end-to-end quantum speedups. We hope the reader will find this survey a valuable guide for navigating this complex and dynamic landscape.</p>"},{"location":"introduction/#how-to-use-this-survey","title":"How to use this survey","text":"<p>This survey does not need to be read from cover to cover. Instead, it has a modular, wiki-like structure, which enables readers to directly explore the applications and primitives relevant for their use case. To the extent possible, each individual subsection has been written in a self-contained fashion and can be read independently from the rest of the document. Rather than scrolling through the survey to locate a certain section, readers are encouraged to utilize the hyperlinks embedded throughout the document as well as those in the header of every page, which direct back to the tables of contents. To facilitate usage of the survey in this fashion, we include an independent bibliography for each subsection of the document. A consolidated bibliography in alphabetical order appears at the end of the survey, along with back references to the pages in which each reference is cited.</p>"},{"location":"introduction/#acknowledgments","title":"Acknowledgments","text":"<p>We thank Joao Basso, J. Kyle Brubaker, Christopher Chamberland, Andrew Childs, Isabel Franco Garrido, Helmut G. Katzgraber, Eric M. Kessler, P\u00e9ter Kutas, Pavel Lougovski, Nicola Pancotti, John Preskill, Simone Severini, Sophia Simon, Yuan Su, James D. Whitfield, and Xiaodi Wu for helpful comments and conversations on various aspects of this survey. We are also grateful to the AWS Center for Quantum Computing and the Institute for Quantum Information and Matter, which is an NSF Physics Frontiers Center, for creating an environment that supported this work.</p>"},{"location":"areas-of-application/introduction/","title":"Areas of application","text":"<p>To provide benefit, quantum computers must solve computational problems where the solutions are simultaneously valuable to the user and also difficult to obtain classically. Simply developing a quantum algorithm with a theoretical quantum speedup is not sufficient to meet these criteria: we must directly compare the performance of classical and quantum algorithms for concrete problems of interest.</p><p>In this part, we survey a number of specific computational problems where quantum algorithms have been proposed, organized by application area. We present an overview of these algorithms through an end-to-end lens, noting clearly the actual end-to-end problem that is being solved and the dominant resource cost/complexity (derived from the algorithmic primitives that are being used), and emphasizing noteworthy caveats. We list known resource estimates for implementing these algorithms on fault-tolerant quantum computers (we also comment in passing on NISQ implementations), and we compare to classical complexities for the same problem, both in a practical and asymptotic sense. The list of applications presented is not exhaustive, but represents a broad spectrum of the most well studied applications proposed in the literature.</p>"},{"location":"areas-of-application/solving-differential-equations/","title":"Solving differential equations","text":""},{"location":"areas-of-application/solving-differential-equations/#overview","title":"Overview","text":"<p>Many applications in engineering and science rely on solving differential equations. Accordingly, this constitutes a large fraction of research-and-development high performance computing (HPC) workloads across a wide variety of industries. Unsurprisingly, there have been many proposals to speed up differential equation solving on a quantum computer. At this point, the consensus is that we lack compelling evidence for practical quantum speedup on industry-relevant problems. However, the field is progressing rapidly and could still provide some surprises.</p><p>Some of the main application areas that have been considered are:</p><ul> <li>Computational fluid dynamics (CFD), usually involving simulation of the Navier\u2013Stokes equation. The main industries relying on CFD simulations are: automotive, aerospace, civil engineering, wind energy, and defense. While most simulations focus on air or fluid flow on solid objects, other processes, such as foaming, are also important to model. Large CFD calculations are routinely in the petaflop regime and are run on millions of CPU cores. Specific quantum proposals include: [1, 2, 3, 4, 5, 6, 7, 8, 9].</li> <li>Geophysical modelling, involving simulation of the wave equation. The main industries are: oil and gas, hydro-electric, geophysics. Large seismic imaging simulations can easily be in the petaflop regime. Quantum proposals for simulating the wave equation include: [10, 11, 12].</li> <li>Finite element method (FEM) for studying structural properties of solid objects. The main industries are: civil engineering, manufacturing (including automotive), aerospace, defense. The simulations are typically slightly smaller in scale than CFD, though still requiring large HPC clusters. Quantum FEM proposals include: [13, 14, 15, 16].</li> <li>Maxwell and heat equation have applications to chip design and other electronic component design, as well as for navigation and radar technology. Specific quantum proposals include: [17, 13, 18]</li> <li>Risk modelling involving the simulation of stochastic differential equations (SDEs) are extensively used in finance (especially derivatives pricing), insurance, and energy markets. The largest risk modelling simulations can easily be in the petaflop regime, though typically more distributed than CFD calculations. Specific quantum proposals include: [19, 20, 21, 22, 23].</li> <li>Plasma physics involving the simulation of the Vlasov equation are widespread in nuclear fusion research. Quantum approaches include: [24, 25, 26].</li> </ul><p>Differential equations can be categorized according to a number of properties: (a) ordinary vs. partial depending on the number of differential variables, (b) stochastic vs. deterministic, depending on whether the function is a random variable or not, (c) linear vs. nonlinear. We will focus mainly on linear partial differential equations, which constitute the largest class for practical problems, and only comment in passing on stochastic, or nonlinear differential equations.</p><p>In order to solve a differential equation numerically, one needs to specify a discretization scheme. The two main classes are: (i) finite difference and its many variants, including the finite element (FEM) and the finite volume method (FVM) combined with various choices of support grids and preconditioning (see [27, 28] for an introduction). In the finite difference framework, the continuous space is discretized on a grid and the continuous operators are replaced by finite difference operations on neighboring grid points. Alternatively (ii), one can discretize space by expansion in a functional basis (Fourier, Hermite, etc.), and solve the discretized problem in this space. This second class is often referred to as spectral methods. Linear differential equations then map to a linear system of equations. In cases where one is interested in very high precision, requiring very fine discretization, then the linear system of equations can be too large for straightforward numerical solutions on a classical computer. In particular, if one wants high precision results integrated over time, and/or systems with many continuous variables, then the simulations can be challenging both in time and memory.</p>"},{"location":"areas-of-application/solving-differential-equations/#actual-end-to-end-problems-solved","title":"Actual end-to-end problem(s) solved","text":"<p>We are interested in solving a general linear partial differential equation of the form</p>\\[\\begin{equation} \\label{eqn:lindiffeq} \\mathcal{L}(u(x))=f(x)\\quad \\text{for}\\quad x\\in \\mathbb{C}^d, \\end{equation}\\]<p>where \\(\\mathcal{L}\\) is a linear differential operator acting on the function \\(u(x)\\), and \\(f(x) \\in \\mathbb{C}\\) specifies the \"geometry\" or some other form of constraint imposed by the particular problem at hand. The above form further encompasses ordinary differential equations and initial value problems. As an example, consider the Heat equation in \\(d+1\\) dimensions given by: </p>\\[\\begin{equation} -\\frac{\\partial u}{\\partial t}+\\frac{\\partial^2 u}{\\partial x^2_1}+\\cdots + \\frac{\\partial^2 u}{\\partial x^2_d}=0. \\end{equation}\\]<p>What does it mean to \"solve\" the differential equation? While closed-form solutions can be derived for some simple differential equations, this is not possible in general, and the solution typically must be computed numerically. Additionally, in a particular application, we may not need complete information about the function \\(u(x)\\). An end-to-end specification of the problem would be to estimate the value of some property \\(\\mathcal{P}[u] \\in \\mathbb{R}\\) up to specified additive error parameter \\(\\epsilon\\). A straightforward example is when the property \\(\\mathcal{P}\\) is simply the value of \\(u\\) at a specific point \\(x_0\\), i.e. \\(\\mathcal{P}[u] = u(x_0)\\). More generally, we restrict to the case where \\(\\mathcal{P}[u]\\) is a linear functional of \\(u\\), i.e. \\(\\mathcal{P}[u] = \\langle r, u\\rangle := \\int_{x \\in \\Omega} d\\Omega \\; r(x)u(x)\\) for some subset \\(\\Omega \\subset \\mathbb{R}^d\\) and function \\(r:\\Omega \\rightarrow \\mathbb{R}\\) for which \\(\\langle r, r \\rangle = 1\\) [14]. Indeed, in [17], a quantum algorithm for solving Maxwell's equations based on the FEM was given where the quantity of interest was not the electric field itself at any specific point, but rather the electromagnetic scattering cross section. In this case, the cross section was given by the square of a linear functional of \\(u\\).</p>"},{"location":"areas-of-application/solving-differential-equations/#dominant-resource-costcomplexity","title":"Dominant resource cost/complexity","text":"<p>For both quantum and classical algorithms, one needs to discretize the continuous degrees of freedom to numerically solve the differential equation. This can take many forms, and the choice of discretization will depend sensitively on the problem at hand. After appropriate discretization, the linear differential equation in Eq. \\(\\eqref{eqn:lindiffeq}\\) reduces to a matrix equation:</p>\\[\\begin{equation} L|u\\rangle=|f\\rangle. \\end{equation}\\]<p>From this point on, the linear PDE is typically solved on a quantum computer by applying the quantum linear system solver (QLSS), or some variant thereof. The QLSS subroutine prepares a quantum state approximating the solution vector \\(\\ket{u}/\\lVert u \\rVert\\) up to some specified precision \\(\\xi\\) in \\(\\ell_2\\) norm, where \\(\\lVert u \\rVert = \\sqrt{\\braket{u}{u}}\\). Assuming access to oracles that (coherently) query the matrix elements of \\(L\\) and prepare the state \\(\\ket{f}/\\lVert f \\rVert\\), the state-of-the-art QLSS [29] makes \\(\\mathcal{O}\\left( s \\kappa \\log(1/\\xi) \\right)\\) queries to these oracles, where \\(\\kappa\\) is the condition number of the matrix \\(L\\) (i.e. the ratio of the largest and smallest singular values), and \\(s\\) is the number of nonzero elements per row of \\(L\\) (\"sparsity\"). Additionally, learning an estimate for the norm \\(\\lVert u \\rVert\\) up to multiplicative error \\(\\xi\\) can be done in \\(\\mathcal{O}\\left( s \\kappa / \\xi \\right)\\) queries (note the worse \\(\\xi\\)-dependence) [30]. For simplicity, we assume that to achieve \\(\\epsilon\\) overall error on the end-to-end problem, it will suffice to take \\(\\xi = \\mathcal{O}\\left( \\epsilon \\right)\\), although there can also be factors that depend on the choice of discretization and norms of the solution \\(u\\) (see, e.g., [14]). The oracles for querying the matrix elements of the \\(s\\)-sparse \\(N \\times N\\) matrix \\(L\\) and for preparing the \\(N\\)-dimensional state \\(\\ket{f}/\\lVert f \\rVert\\) are assumed to have cost \\(\\mathrm{polylog}(N)\\); this is valid if the matrix elements can be efficiently computed \"on the fly,\" or more generally if one has access to a log-depth quantum random access memory; see loading classical data for more information.</p><p>With these assumptions, the QLSS portion of the quantum algorithm can be performed exponentially faster in \\(N\\), and with exponential savings in memory, than any classical method that manipulates vectors of size \\(N\\), which includes Gaussian elimination and iterative methods like conjugate gradient. The state-loading assumptions might be very difficult to satisfy in practice, as many practical applications of PDEs involve highly complex geometry in three spatial dimensions (CFD, FEM, seismic modelling).</p><p>Preparing the state \\(\\ket{u}/\\lVert u \\rVert\\) does not immediately yield an estimate for the property \\(\\mathcal{P}[u]\\). Indeed, reading out useful information from \\(\\ket{u}/\\lVert u \\rVert\\) represents a major bottleneck of the algorithm. In the case that \\(\\mathcal{P}[u] = u(x_0)\\) for a specific point \\(x_0\\), the estimation of \\(\\mathcal{P}[u]\\) is performed with amplitude estimation (here assuming that the choice of discretization encodes \\(u(x_0)\\) into an amplitude of \\(\\ket{u}\\)), which introduces multiplicative overhead \\(\\mathcal{O}\\left( \\lVert u \\rVert /\\epsilon \\right)\\). Note that, to read out all \\(N\\) amplitudes of the state \\(\\ket{u}\\) in this fashion, a linear factor of \\(N\\) would be reintroduced, although more advanced methods of pure state tomography can reduce this to \\(\\sqrt{N}\\) [31]. In the more general case that \\(\\mathcal{P}[u]\\) is a linear functional, the value of \\(\\mathcal{P}\\) can typically be approximately expressed as an overlap \\(\\braket{\\phi}{u}\\) between some preparable normalized state \\(\\ket{\\phi}\\) and the solution vector \\(\\ket{u}\\). Overlap estimation is then a straightforward application of amplitude estimation, and achieving precision \\(\\epsilon\\) introduces \\(\\mathcal{O}\\left( \\lVert u \\rVert /\\epsilon \\right)\\) multiplicative overhead. Thus, the overall scaling of the complexity is </p>\\[\\begin{equation} \\frac{s\\kappa \\lVert u \\rVert \\log(1/\\epsilon) }{\\epsilon} \\mathrm{polylog}(N). \\end{equation}\\]<p>The persisting \\(\\mathrm{polylog}(N)\\) dependence suggests an exponential speedup in \\(N\\) over classical methods, but this conclusion depends on the scaling of the parameters \\(s\\), \\(\\kappa\\), and \\(\\lVert u \\rVert\\) with \\(N\\). The sparsity \\(s\\) and condition number \\(\\kappa\\) depend on the differential equation and the choice of discretization, but can often be controlled as \\(s=\\mathcal{O}\\left( 1 \\right)\\) and \\(\\kappa = N^{2/d}\\) (e.g. [32, Theorem 9.7.1]). Additionally, heuristic preconditioning methods are very effective in practice and, in at least one case [17], have been shown to be compatible with the QLSS, which can often reduce the effective value of \\(\\kappa\\) to \\(\\mathcal{O}\\left( 1 \\right)\\). Finally, \\(N\\) and \\(\\epsilon\\) are not independent parameters: in general we are interested in simulating a PDE to a fixed precision, and adapt \\(N\\) to reach the desired precision. Using simple grid-based methods, achieving discretization error \\(\\mathcal{O}\\left( \\epsilon \\right)\\) for a problem in \\(d\\) spatial dimensions requires \\(N = (1/\\epsilon)^{\\Omega(d)}\\), with some caveats on solution norm and continuity [14]. Alternative sparse-grid or spectral methods can improve the \\(1/\\epsilon\\) dependence to logarithmic, but still scale exponentially with \\(d\\) [33]. A careful analysis of the problem [14] shows that for most properties of interest and a fixed precision \\(\\epsilon\\), the speedup\u2014irrespective of the discretization scheme\u2014from QLSS is at best polynomial in \\(1/\\epsilon\\), even assuming good control over the condition number \\(\\kappa\\). Indeed, when we assume \\(s,\\kappa = \\mathcal{O}\\left( 1 \\right)\\), in addition to the assumptions from above, the quantum complexity is </p>\\[\\begin{equation} \\widetilde{\\mathcal{O}}\\left( \\lVert u \\rVert/\\epsilon \\right)\\,. \\end{equation}\\]<p>Ultimately, this observation is traced back to the fact that the quantum solver produces a quantum state encoding the solution to the PDE, potentially exponentially faster than leading classical methods, such as conjugate gradient, but the exponential speedup is lost in the readout step. Moreover, this conclusion holds not just for \"bad\" observables (like full state tomography), but for any observable, due to the \\(\\Omega(1/\\epsilon)\\) cost of quantum readout.\\ A distinct approach to solving PDEs on a quantum computer is based on mapping the PDE directly to the Schr\u00f6dinger equation and performing the time evolution on a quantum computer (via Hamiltonian simulation) [34, 35]. This is also the typical approach employed for solving nonlinear differential equations [36, 37, 38, 39, 40]. In this approach, with appropriate assumptions on the initial state or boundary condition encoding, it is once again possible to obtain an exponential speedup in the time to prepare the time evolved state \\(|u(T)\\rangle\\). Moreover, this approach may avoid the condition number dependence that results from matrix inversion in the QLSS approach. Nevertheless, the same conclusions discussed above regarding readout still hold, restricting the quantum algorithm to a polynomial speedup for the practical task of measuring observables with respect to the solution of the differential equation (for constant dimension \\(d\\)).</p><p>Finally, we comment on two further classes of applications involving PDEs, but which typically have very different characteristics: The first is stochastic differential equations (SDEs) which are simulated extensively in computational finance and more generally in risk modeling. There, one typically samples trajectories of the SDE (via Monte Carlo methods), and evaluates observables stochastically. Quantum accelerated Monte Carlo has been worked on extensively (see the options pricing page). However, these algorithms involve very different tools from the ones discussed here. Alternatively, one could map a SDE to a Fokker\u2013Planck equation via the It\u00f4 calculus and solve the Fokker\u2013Planck PDE. This has been proposed in [41]. However, for most SDEs of interest in risk analysis, Monte Carlo simulation converges in a number of samples scaling linearly in the number of variables, leaving very little room for a quantum speedup in these applications given our current understanding.</p><p>The last class of problems to be mentioned are multi-particle Schr\u00f6dinger equations. They are (a) high dimensional, (b) complex, and (c) require high precision solutions for practical applications. Hence matching all of the criteria under which a quantum advantage might be expected. The second quantized approach to solving the full configuration interaction molecular Schr\u00f6dinger equation is a specific case of the spectral method. Unsurprisingly, this case has already gathered a lot of attention (see the application section quantum chemistry).</p>"},{"location":"areas-of-application/solving-differential-equations/#existing-error-corrected-resource-estimates","title":"Existing error corrected resource estimates","text":"<p>There do not exist many such resource estimates so far, though they should follow from similar estimates for the quantum linear system solver. See [29, 42] for a state-of-the-art analysis. Note, however, that much of the art in classical PDE solvers is to find appropriate preconditioning schemes to control the condition number. In [17], it was shown that one common class of preconditioners works within the framework of the quantum algorithm, but it is as of yet unclear if this is the case more generally.</p><p>One explicit resource estimate for the end-to-end problem discussed above was given in [43], which estimated that to beat the best classical solvers: \"a desired calculation accuracy \\(0.01\\) requires an approximate circuit width \\(340\\) and circuit depth of order \\(10^{25}\\) if oracle costs are excluded, and a circuit width and depth of order \\(10^8\\) and \\(10^{29}\\) if oracle costs are included.\" These estimates are not very encouraging, yet many orders of magnitude can be shaven off of them with more recent synthesis and simulation methods. We expect that using the state-of-the-art quantum linear system solver the Tofolli gate count can be brought down by orders of magnitude, likely in the vicinity of \\(10^{11-15}\\) depending upon the specific setting. Reliable estimates would require a more careful study.</p>"},{"location":"areas-of-application/solving-differential-equations/#caveats","title":"Caveats","text":"<p>An essential caveat is that the speedup for solving PDEs largely depends on what speedup one might obtain from the QLSS algorithm. This is very contentious, as quantum-inspired methods [44] are getting dangerously close to the same asymptotic scaling as the QLSS in many specific instances (see quantum machine learning section). Since the QLSS depends sensitively on the condition number, very careful analysis of the preconditioning scheme must be made on a case-by-case basis. Even if quantum-inspired methods cannot compete, classical iterative methods such as conjugate gradient, which also benefit from a small condition number, can be difficult to beat, especially when they are running on high performance computing hardware with many parallel CPUs.</p><p>Furthermore, incorporating highly complex geometry or boundary conditions into the problem, as is often necessary for CFD and finite element computations, might constitute a major state-loading bottleneck. Finally, the observables of interest in classical PDE problems might require near full tomography of the quantum solution state which in certain situations removes all quantum advantage [18].</p><p>In instances where these caveats can be overcome, the speedups are at best polynomial, with a larger speedup in a larger number of spatial dimensions. However, in many engineering applications, the number of dimensions is fixed to be fewer than four (three for space, one for time), limiting the advantage quantum methods can obtain.</p><p>Note that another approach for time evolving PDE based on time-stepping has been proposed recently, which might provide more advantage [34] (see also [35] for a query based model with exponential speedup in certain specific variables).</p>"},{"location":"areas-of-application/solving-differential-equations/#comparable-classical-complexity-and-challenging-instance-sizes","title":"Comparable classical complexity and challenging instance sizes","text":"<p>While the size and scale of PDE simulations vary widely, some of the largest and most costly are CFD simulations. CFD computations on a 3D grid with several billion mesh nodes (in finite volume discretization) running on tens of thousands of CPU cores are routine [9]. It is unclear what the main bottleneck for a quantum simulation of such a large system will be; the condition number and preconditioning, loading the geometry, or readout of the result? In any case, this scale seems well out of reach of the current fault-tolerant algorithmic projections.</p>"},{"location":"areas-of-application/solving-differential-equations/#speedup","title":"Speedup","text":"<p>In this section, we consider the complexity of either estimating a function of the PDE solution, or of outputting quantum states encoding the solution, to precision \\(\\epsilon\\) for a system in \\(d\\) spatial dimensions. Outputting a quantum state encoding the PDE solution will typically have a much more favorable quantum complexity, though it is not necessarily a fair comparison, as much of the speedup can be lost at readout.</p><p>Finite difference methods. Finite element, finite volume methods and their variants are the leading class of methods used in industry. These methods typically have a complexity/dimension scaling of \\({\\rm poly}(\\epsilon^{-d})\\). In [14] a quantum algorithm for the homogenous Poisson equation in \\(d\\) dimensions, with homogenous boundary conditions is found to have a complexity scaling as \\({\\rm poly}(d,1/\\epsilon)\\). In [45], a quantum algorithm for outputting the solution of a hyperbolic PDE in the finite volume discretization was proposed with a \\(d \\cdot {\\rm poly}(\\epsilon^{-1})\\) scaling.</p><p>Spectral methods. References [46, 33] explore the spectral method for ODEs and PDEs. Their quantum algorithm for outputting the solution of an elliptic PDE with Dirichlet boundary conditions scales as \\(d^2 \\cdot {\\rm polylog}(\\epsilon^{-1})\\) (note that an additional factor of \\(1/\\epsilon\\) for readout would be incurred to solve the fully end-to-end problem), compared to general classical spectral methods scaling as \\({\\rm poly}(\\epsilon^{-d})\\) [47].\\ The quoted scalings need to be considered with caution. Firstly, the quantum algorithms are not fully end-to-end but rather just output the quantum state representing the solution. Whether relevant functions (observables) of the solutions can be extracted efficiently from the quantum state will depend on the specific task at hand. Secondly, the condition number and the associated preconditioning scheme of the linear system under consideration is neither quoted in the classical nor in the quantum scalings. This could be the dominant cost of the algorithm in real settings. Thirdly, the scalings do not take state/geometry loading into account. This point is particularly sensitive, as industry-relevant problems often need just as high precision in geometry specification, as in solution quality. Capturing high precision geometry is often more challenging with spectral methods than with finite difference methods.</p><p>Nevertheless, the take-home message is that quantum algorithms can potentially outperform classical algorithms, but major gains are only to be expected when the number of dimensions is large. This intuition is corroborated by the analysis of quantum computing algorithms for ab initio chemistry, where the number of dimensions scales with the number of electrons. Substantial memory savings also seem likely in this setting.</p>"},{"location":"areas-of-application/solving-differential-equations/#nisq-implementations","title":"NISQ implementations","text":"<p>Various proposals at NISQ implementations of PDE solvers have been made; see [48] and references therein. The idea is to start from some discretization of the PDE \\(L|\\psi(\\theta)\\rangle = |b\\rangle\\), where \\(|\\psi(\\theta)\\rangle\\) is an appropriately chosen variational circuit, and optimize the parameters of the circuit. This is an example of a variational quantum algorithm. It is difficult to imagine that sufficient size and precision can be reached in the NISQ regime to be competitive with the best classical solvers.</p>"},{"location":"areas-of-application/solving-differential-equations/#outlook","title":"Outlook","text":"<p>While the simulation of PDEs is one of the most important large-scale computational tasks, constituting a sizable fraction of HPC workloads in industry, at present the benefit of quantum solvers is still too limited in dimensions up to four. To find a killer application of quantum algorithms for PDEs (beyond ab initio chemistry), one would need to find an important application of high dimensional PDEs, requiring very high precision solutions while involving relatively simple geometry or initial conditions, and that can't be solved accurately with any classical methods at present. There remains the possibility for substantial improvements in memory usage, but these are not currently a bottleneck in classical PDE solving. Recent progress [34, 35] suggests that in very specific scenarios, there might still be room for substantial gains on quantum hardware, but it is as yet unclear how practical or relevant these scenarios are.</p>"},{"location":"areas-of-application/solving-differential-equations/#bibliography","title":"Bibliography","text":"<ol> <li> <p>Xiangyu Li, Xiaolong Yin, Nathan Wiebe, Jaehun Chun, Gregory K Schenter, Margaret S Cheung, and Johannes M\u00fclmenst\u00e4dt. Potential quantum advantage for simulation of fluid dynamics. arXiv: https://arxiv.org/abs/2303.16550, 2023.</p> </li> <li> <p>Sauro Succi, Wael Itani, Katepalli R Sreenivasan, and Rene Steijl. Ensemble fluid simulations on quantum computers. arXiv: https://arxiv.org/abs/2304.05410, 2023.</p> </li> <li> <p>Wael Itani, Katepalli R Sreenivasan, and Sauro Succi. Quantum algorithm for lattice boltzmann (qalb) simulation of incompressible fluids with a nonlinear collision term. arXiv: https://arxiv.org/abs/2304.05915, 2023.</p> </li> <li> <p>Szabolcs J\u00f3czik, Zolt\u00e1n Zimbor\u00e1s, Tam\u00e1s Majoros, and Attila Kiss. A cost-efficient approach towards computational fluid dynamics simulations on quantum devices. Applied Sciences, 12(6):2873, 2022. URL: https://www.mdpi.com/2076-3417/12/6/2873, doi:doi.org/10.3390/app12062873.</p> </li> <li> <p>Furkan Oz, Rohit KSS Vuppala, Kursat Kara, and Frank Gaitan. Solving burgers' equation with quantum computing. Quantum Information Processing, 21:1\u201313, 2022. URL: https://doi.org/10.1007/s11128-021-03391-8, doi:10.1007/s11128-021-03391-8.</p> </li> <li> <p>Frank Gaitan. Finding solutions of the navier\u2013stokes equations through quantum computing\u2014recent progress, a generalization, and next steps forward. Advanced Quantum Technologies, 4(10):2100055, 2021. URL: https://doi.org/10.1002/qute.202100055, doi:10.1002/qute.202100055.</p> </li> <li> <p>Frank Gaitan. Finding flows of a navier\u2013stokes fluid through quantum computing. npj Quantum Information, 6(1):61, 2020. URL: https://doi.org/10.1038/s41534-020-00291-0, doi:10.1038/s41534-020-00291-0.</p> </li> <li> <p>Zhao-Yun Chen, Cheng Xue, Si-Ming Chen, Bing-Han Lu, Yu-Chun Wu, Ju-Chun Ding, Sheng-Hong Huang, and Guo-Ping Guo. Quantum approach to accelerate finite volume method on steady computational fluid dynamics problems. Quantum Information Processing, 21(4):137, 2022. URL: https://doi.org/10.1007/s11128-022-03478-w, doi:10.1007/s11128-022-03478-w.</p> </li> <li> <p>Leigh Lapworth. A hybrid quantum-classical cfd methodology with benchmark hhl solutions. arXiv: https://arxiv.org/abs/2206.00419, 2022.</p> </li> <li> <p>Shahpoor Moradi, Daniel Trad, and Kristopher A Innanen. Quantum computing in geophysics: algorithms, computational costs, and future applications. In 2018 SEG International Exposition and Annual Meeting. OnePetro, 2018. URL: https://doi.org/10.1190/segam2018-2998507.1, doi:10.1190/segam2018-2998507.1.</p> </li> <li> <p>Jessie M Henderson, Marianna Podzorova, M Cerezo, John K Golden, Leonard Gleyzer, Hari S Viswanathan, and Daniel O'Malley. Quantum algorithms for geologic fracture networks. Scientific Reports, 13(1):2906, 2023. arXiv: https://arxiv.org/abs/2210.11685. URL: https://doi.org/10.1038/s41598-023-29643-4, doi:10.1038/s41598-023-29643-4.</p> </li> <li> <p>M Dukalski. Toward an application of quantum computing in geophysics. In Fifth EAGE Workshop on High Performance Computing for Upstream, volume 2021, 1\u20135. EAGE Publications BV, 2021. doi:10.3997/2214-4609.2021612005.</p> </li> <li> <p>Shi Jin, Nana Liu, and Yue Yu. Time complexity analysis of quantum difference methods for linear high dimensional and multiscale partial differential equations. Journal of Computational Physics, 471:111641, 2022. arXiv: https://arxiv.org/abs/2202.04537. URL: https://doi.org/10.1016/j.jcp.2022.111641, doi:10.1016/j.jcp.2022.111641.</p> </li> <li> <p>Ashley Montanaro and Sam Pallister. Quantum algorithms and the finite element method. Physical Review A, 93(3):032324, 2016. arXiv: https://arxiv.org/abs/1512.05903. doi:10.1103/PhysRevA.93.032324.</p> </li> <li> <p>Dyon van Vreumingen, Florian Neukart, David Von Dollen, Carsten Othmer, Michael Hartmann, Arne-Christian Voigt, and Thomas B\u00e4ck. Quantum-assisted finite-element design optimization. arXiv: https://arxiv.org/abs/1908.03947, 2019.</p> </li> <li> <p>Jianan Zhang, Feng Feng, and QJ Zhang. Quantum method for finite element simulation of electromagnetic problems. In 2021 IEEE MTT-S International Microwave Symposium (IMS), 120\u2013123. IEEE, 2021. doi:10.1109/IMS19712.2021.9574852.</p> </li> <li> <p>B David Clader, Bryan C Jacobs, and Chad R Sprouse. Preconditioned quantum linear system algorithm. Physical Review Letters, 110(25):250504, 2013. arXiv: https://arxiv.org/abs/1301.2340. doi:10.1103/PhysRevLett.110.250504.</p> </li> <li> <p>Noah Linden, Ashley Montanaro, and Changpeng Shao. Quantum vs. classical algorithms for solving the heat equation. Communications in Mathematical Physics, 395(2):601\u2013641, 2022. arXiv: https://arxiv.org/abs/2004.06516. doi:10.1007/s00220-022-04442-6.</p> </li> <li> <p>Patrick Rebentrost and Seth Lloyd. Quantum computational finance: quantum algorithm for portfolio optimization. arXiv: https://arxiv.org/abs/1811.03975, 2018.</p> </li> <li> <p>Dong An, Noah Linden, Jin-Peng Liu, Ashley Montanaro, Changpeng Shao, and Jiasu Wang. Quantum-accelerated multilevel monte carlo methods for stochastic differential equations in mathematical finance. Quantum, 5:481, 2021. arXiv: https://arxiv.org/abs/2012.06283. doi:10.22331/q-2021-06-24-481.</p> </li> <li> <p>Sergi Ramos-Calderer, Adri\u00e1n P\u00e9rez-Salinas, Diego Garc\u00eda-Mart\u00edn, Carlos Bravo-Prieto, Jorge Cortada, Jordi Planaguma, and Jos\u00e9 I Latorre. Quantum unary approach to option pricing. Physical Review A, 103(3):032414, 2021. arXiv: https://arxiv.org/abs/1912.01618. doi:10.1103/PhysRevA.103.032414.</p> </li> <li> <p>Sergio Focardi, Frank J Fabozzi, and Davide Mazza. Quantum option pricing and quantum finance. The Journal of Derivatives, 2020. doi:10.3905/jod.2020.1.111.</p> </li> <li> <p>Yongming Li and Ariel Neufeld. Quantum monte carlo algorithm for solving black\u2013scholes pdes for high-dimensional option pricing in finance and its proof of overcoming the curse of dimensionality. arXiv: https://arxiv.org/abs/2301.09241, 2023.</p> </li> <li> <p>I. Novikau, E. A. Startsev, and I. Y. Dodin. Quantum signal processing for simulating cold plasma waves. Physical Review A, 105:062444, 6 2022. arXiv: https://arxiv.org/abs/2112.06086. URL: https://link.aps.org/doi/10.1103/PhysRevA.105.062444, doi:10.1103/PhysRevA.105.062444.</p> </li> <li> <p>Alexander Engel, Graeme Smith, and Scott E Parker. Quantum algorithm for the vlasov equation. Physical Review A, 100(6):062315, 2019. arXiv: https://arxiv.org/abs/1907.09418. doi:10.1103/PhysRevA.100.062315.</p> </li> <li> <p>Ilya Y Dodin and Edward A Startsev. On applications of quantum computing to plasma simulations. Physics of Plasmas, 28(9):092101, 2021. arXiv: https://arxiv.org/abs/2005.14369. doi:10.1063/5.0056974.</p> </li> <li> <p>Mats G Larson and Fredrik Bengzon. The finite element method: theory, implementation, and applications. Volume 10. Springer Science &amp; Business Media, 2013. doi:10.1007/978-3-642-33287-6.</p> </li> <li> <p>Ulrich Trottenberg, Cornelius W Oosterlee, and Anton Schuller. Multigrid. Elsevier, 2000.</p> </li> <li> <p>Pedro C.S. Costa, Dong An, Yuval R. Sanders, Yuan Su, Ryan Babbush, and Dominic W. Berry. Optimal scaling quantum linear-systems solver via discrete adiabatic theorem. PRX Quantum, 3:040303, 10 2022. arXiv: https://arxiv.org/abs/2111.08152. URL: https://link.aps.org/doi/10.1103/PRXQuantum.3.040303, doi:10.1103/PRXQuantum.3.040303.</p> </li> <li> <p>Shantanav Chakraborty, Andr\u00e1s Gily\u00e9n, and Stacey Jeffery. The power of block-encoded matrix powers: improved regression techniques via faster hamiltonian simulation. In Proceedings of the 46th International Colloquium on Automata, Languages, and Programming (ICALP), 33:1\u201333:14. 2019. arXiv: https://arxiv.org/abs/1804.01973. doi:10.4230/LIPIcs.ICALP.2019.33.</p> </li> <li> <p>Joran van Apeldoorn, Arjan Cornelissen, Andr\u00e1s Gily\u00e9n, and Giacomo Nannicini. Quantum tomography using state-preparation unitaries. In Proceedings of the 34th ACM-SIAM Symposium on Discrete Algorithms (SODA), 1265\u20131318. 2023. arXiv: https://arxiv.org/abs/2207.08800. doi:10.1137/1.9781611977554.ch47.</p> </li> <li> <p>Susanne C Brenner. The mathematical theory of finite element methods. Springer, 2008.</p> </li> <li> <p>Andrew M Childs, Jin-Peng Liu, and Aaron Ostrander. High-precision quantum algorithms for partial differential equations. Quantum, 5:574, 2021. arXiv: https://arxiv.org/abs/2002.07868. doi:10.22331/q-2021-11-10-574.</p> </li> <li> <p>Di Fang, Lin Lin, and Yu Tong. Time-marching based quantum solvers for time-dependent linear differential equations. Quantum, 7:955, 3 2023. arXiv: https://arxiv.org/abs/2208.06941. URL: https://doi.org/10.22331/q-2023-03-20-955, doi:10.22331/q-2023-03-20-955.</p> </li> <li> <p>Ryan Babbush, Dominic W Berry, Robin Kothari, Rolando D Somma, and Nathan Wiebe. Exponential quantum speedup in simulating coupled classical oscillators. arXiv: https://arxiv.org/abs/2303.13012, 2023.</p> </li> <li> <p>Sarah K Leyton and Tobias J Osborne. A quantum algorithm to solve nonlinear differential equations. arXiv: https://arxiv.org/abs/0812.4423, 2008.</p> </li> <li> <p>Seth Lloyd, Giacomo De Palma, Can Gokler, Bobak Kiani, Zi-Wen Liu, Milad Marvian, Felix Tennie, and Tim Palmer. Quantum algorithm for nonlinear differential equations. arXiv: https://arxiv.org/abs/2011.06571, 2020.</p> </li> <li> <p>Jin-Peng Liu, Herman \u00d8ie Kolden, Hari K. Krovi, Nuno F. Loureiro, Konstantina Trivisa, and Andrew M. Childs. Efficient quantum algorithm for dissipative nonlinear differential equations. Proceedings of the National Academy of Sciences, 118(35):e2026805118, 2021. arXiv: https://arxiv.org/abs/2011.03185. URL: https://www.pnas.org/doi/abs/10.1073/pnas.2026805118, arXiv:https://www.pnas.org/doi/pdf/10.1073/pnas.2026805118, doi:10.1073/pnas.2026805118.</p> </li> <li> <p>Dong An, Di Fang, Stephen Jordan, Jin-Peng Liu, Guang Hao Low, and Jiasu Wang. Efficient quantum algorithm for nonlinear reaction-diffusion equations and energy estimation. arXiv: https://arxiv.org/abs/2205.01141, 2022.</p> </li> <li> <p>Hari Krovi. Improved quantum algorithms for linear and nonlinear differential equations. Quantum, 7:913, 2023. arXiv: https://arxiv.org/abs/2202.01054. doi:10.22331/q-2023-02-02-913.</p> </li> <li> <p>Javier Gonzalez-Conde, \u00c1ngel Rodr\u00edguez-Rozas, Enrique Solano, and Mikel Sanz. Simulating option price dynamics with exponential quantum speedup. arXiv: https://arxiv.org/abs/2101.04023, 2021.</p> </li> <li> <p>David Jennings, Matteo Lostaglio, Sam Pallister, Andrew T. Sornborger, and Yigit Subasi. Efficient quantum linear solver algorithm with detailed running costs. arXiv: https://arxiv.org/abs/2305.11352, 2023.</p> </li> <li> <p>Artur Scherer, Beno\u00eet Valiron, Siun-Chuon Mau, Scott Alexander, Eric Van den Berg, and Thomas E Chapuran. Concrete resource analysis of the quantum linear-system algorithm used to compute the electromagnetic scattering cross section of a 2d target. Quantum Information Processing, 16(3):1\u201365, 2017. arXiv: https://arxiv.org/abs/1505.06552. doi:10.1007/s11128-016-1495-5.</p> </li> <li> <p>Ewin Tang. Quantum principal component analysis only achieves an exponential speedup because of its state preparation assumptions. Physical Review Letters, 127(6):060503, 2021. arXiv: https://arxiv.org/abs/1811.00414. doi:10.1103/PhysRevLett.127.060503.</p> </li> <li> <p>Fran\u00e7ois Fillion-Gourdeau and Emmanuel Lorin. Simple digital quantum algorithm for symmetric first-order linear hyperbolic systems. Numerical Algorithms, 82(3):1009\u20131045, 2019. arXiv: https://arxiv.org/abs/1705.09361. doi:10.1007/s11075-018-0639-3.</p> </li> <li> <p>Andrew M Childs and Jin-Peng Liu. Quantum spectral methods for differential equations. Communications in Mathematical Physics, 375(2):1427\u20131457, 2020. arXiv: https://arxiv.org/abs/1901.00961. doi:10.1007/s00220-020-03699-z.</p> </li> <li> <p>Jie Shen, Tao Tang, and Li-Lian Wang. Spectral methods: algorithms, analysis and applications. Volume 41. Springer Science &amp; Business Media, 2011. doi:10.1007/978-3-540-71041-7.</p> </li> <li> <p>Fong Yew Leong, Wei-Bin Ewe, and Dax Enshan Koh. Variational quantum evolution equation solver. Scientific Reports, 12(1):10817, 2022. arXiv: https://arxiv.org/abs/2204.02912. doi:10.1038/s41598-022-14906-3.</p> </li> </ol>"},{"location":"areas-of-application/combinatorial-optimization/beyond-quadratic-speedups-in-exact-combinatorial-optimization/","title":"Beyond quadratic speedups in exact combinatorial optimization","text":""},{"location":"areas-of-application/combinatorial-optimization/beyond-quadratic-speedups-in-exact-combinatorial-optimization/#overview","title":"Overview","text":"<p>The discovery of Grover's algorithm [1] (later generalized to amplitude amplification) has long been the source of enthusiasm that quantum algorithms can be advantageous for combinatorial optimization, as it leads to quadratic asymptotic speedups for many concrete end-to-end search problems in this area. However, resource estimates indicate that early and intermediate-term fault-tolerant devices will fail to deliver practical advantages when the available speedup is only quadratic, due to intrinsic overheads of quantum computation compared to classical computation (see, e.g., [2, 3]). Thus, identifying whether beyond-quadratic speedups are available is of principal importance for identifying end-to-end practical advantages in combinatorial optimization. Despite the fact that Grover's algorithm is optimal in the black-box (unstructured) setting, superquadratic speedups could be possible when the combinatorial optimization problem has a certain structure that can be better exploited by a quantum algorithm than a classical algorithm.</p><p>Unfortunately, many proposals that could conceivably deliver superquadratic speedups lack rigorous theoretical performance guarantees. This includes the quantum adiabatic algorithm and variational quantum algorithms such as the quantum approximate optimization algorithm (QAOA) [4], which is typically formulated to give approximate solutions, but at higher cost could also be used to find exact solutions. Limited analytic and numerical work provides some evidence (e.g. [5, 6]) that QAOA could outperform a vanilla application of Grover's algorithm to the \\(k\\)-\\(\\mathsf{SAT}\\) problem, but provides no definitive conclusion on the matter. Alternatively, a line of work in [7, 8] studies a different algorithm (related in certain aspects to the quantum adiabatic algorithm) and provide rigorous running time guarantees that slightly surpass Grover's algorithm.</p><p>However, while these algorithms may have a speedup over Grover's algorithm, this does not entail a superquadratic speedup over the best classical algorithm, which can often exploit structure in other ways to do much better than exhaustive search. Overall, it remains a wide open question whether quantum algorithms can provide superquadratic speedups for useful problems in exact combinatorial optimization.</p>"},{"location":"areas-of-application/combinatorial-optimization/beyond-quadratic-speedups-in-exact-combinatorial-optimization/#actual-end-to-end-problems-solved","title":"Actual end-to-end problem(s) solved","text":"<p>Combinatorial optimization problems ask to find which solution is optimal among a finite set of possible candidates. Here, we stick to binary optimization on \\(n\\) bits, where the universe of possible candidates are bit strings \\(z = (z_1,z_2,\\ldots,z_n) \\in \\{1,-1\\}^n\\). The input to the problem is a compact description of some cost function \\(C: \\{1,-1\\}^n \\rightarrow \\mathbb{R}\\), and the desired output is the string \\(z^*\\) for which \\(C\\) is minimized. Let \\(E^* = C(z^*)\\) denote the optimal value of the cost function. For simplicity we assume \\(z^*\\) is unique and \\(E^*\\) is known ahead of time.<sup>1</sup></p><p>Concrete examples can be formed by choosing the function \\(C(z)\\) to be a low-degree polynomial in the bits of \\(z\\). For example, if \\(C\\) is a degree-2 polynomial in \\(z\\), this is a Quadratic Unconstrained Binary Optimization (\\(\\mathsf{QUBO}\\)) problem. If furthermore every term of \\(C\\) has degree exactly 2 (no degree-1 or constant terms) and every coefficient is either \\(0\\) or \\(1\\), then the problem is equivalent to a \\(\\mathsf{MAX}\\)-\\(\\mathsf{CUT}\\)problem. Finally, if \\(C\\) is the sum of terms of the form </p>\\[\\begin{equation} z_az_bz_c + z_az_b+z_az_c +z_bz_c + z_a+z_b+z_c \\qquad \\text{where}\\qquad z_a,z_b,z_c \\in \\{z_1,-z_1,z_2,-z_2,\\ldots,z_n,-z_n\\} \\end{equation}\\]<p>then the problem is equivalent to a \\(\\mathsf{MAX}\\)-3-\\(\\mathsf{SAT}\\) instance, where the optimal solution represents the bit string that satisfies the most clauses of a satisfiability formula written in conjunctive normal form, where each clause involves three variables (this is easily generalized from \\(\\mathsf{MAX}\\)-3-\\(\\mathsf{SAT}\\) to \\(\\mathsf{MAX}\\)-\\(k\\)-\\(\\mathsf{SAT}\\)).</p><p>For a fixed instance \\(C\\), the quantum algorithms must find \\(z^*\\) with high probability over measurement outcomes. If it does so for every \\(C\\) chosen from some class of problem, we say it succeeds in the worst case. Alternatively, we can consider ensembles of instances chosen from some class of problem; if for a large fraction of instances from the ensemble, the algorithm finds \\(z^*\\) with high probability, then we say the algorithm succeeds in the average case.<sup>2</sup> A commonly considered average-case ensemble is the Sherrington\u2013Kirkpatrick (SK) model [9], defined as </p>\\[\\begin{equation} C(z) = \\sum_{i=1}^n\\sum_{j=i+1}^n J_{ij} z_i z_j \\quad \\text{where}\\quad J_{ij} \\sim \\mathcal{N}(0,1), \\end{equation}\\]<p>where the coefficients \\(J_{ij}\\) are drawn randomly from a standard Gaussian distribution \\(\\mathcal{N}(0,1)\\). The SK model is relevant in spin-glass theory, and can be generalized to higher-degree interactions, where it is referred to as the \\(p\\)-spin model [10]. Another ensemble is the random \\(\\mathsf{MAX}\\)-\\(k\\)-\\(\\mathsf{SAT}\\) ensemble, where \\(\\mathsf{MAX}\\)-\\(k\\)-\\(\\mathsf{SAT}\\) instances are generated by choosing each clause uniformly at random with some fixed clause-to-variable ratio (see, e.g., [11]).</p>"},{"location":"areas-of-application/combinatorial-optimization/beyond-quadratic-speedups-in-exact-combinatorial-optimization/#dominant-resource-costcomplexity","title":"Dominant resource cost/complexity","text":"<p>A vanilla application of Grover's algorithm to binary optimization problems achieves \\(\\mathcal{O}^*(2^{0.5n})\\) running time, where notation \\(\\mathcal{O}^*(2^{an})\\) is shorthand for \\(\\mathrm{poly}(n)2^{an}\\). We cover three approaches to solving binary optimization problems on a quantum computer that have some potential to improve upon this running time. Note that all of these algorithms require polynomial (in fact, linear \\(\\mathcal{O}\\left( n \\right)\\)) space. However, their running time is expected to scale exponentially in \\(n\\).</p><ul> <li>First, we consider variational quantum algorithms, using the QAOA [4] as a representative. These algorithms are typically studied as efficient (polynomial-time) quantum algorithms that produce approximate solutions, i.e. strings \\(z \\neq z^*\\) for which \\(C(z)\\) is small, but not optimal. However, they may also be viewed as exact algorithms, since, if repeated a sufficient number of times, they eventually produce the exactly optimal \\(z^*\\). The QAOA fixes a depth parameter \\(p\\) and variational parameters \\(\\gamma = (\\gamma_1,\\ldots,\\gamma_p)\\) and \\(\\beta = (\\beta_1,\\ldots,\\beta_p)\\) (sometimes these are set to some fixed instance-independent value, and sometimes they are variationally updated on subsequent repetitions of the algorithm). The QAOA starts in the \\(n\\)-qubit equal superposition state \\(\\ket{+}\\) and implements alternating rounds of rotations about the diagonal cost function \\(C\\) and a \"mixing\" operator \\(X = \\sum_i X_i\\), where \\(X_i\\) denotes the Pauli-\\(X\\) gate about qubit \\(i\\). The state produced by QAOA is thus given by  \\[\\begin{equation} \\ket{\\psi_{\\gamma,\\beta}} = e^{-i\\beta_p X}e^{-i\\gamma_p C}\\ldots e^{-i\\beta_2 X}e^{-i\\gamma_2 C}e^{-i\\beta_1X}e^{-i\\gamma_1 C}\\ket{+}\\,. \\end{equation}\\] <p>If one makes a computational basis measurement of \\(\\ket{\\psi_{\\gamma,\\beta}}\\), one obtains \\(z^*\\) with probability \\(|\\braket{z^*}{\\psi_{\\gamma,\\beta}}|^2\\). The expected number of repetitions required to obtain \\(z^*\\) is the inverse of this probability, and this running time can be quadratically sped up by performing amplitude amplification on top of the QAOA protocol; thus, the QAOA unitary is applied \\(\\mathcal{O}\\left( |\\braket{z^*}{\\psi_{\\gamma,\\beta}}|^{-1} \\right)\\) times. Implementing the QAOA unitary typically requires only \\(p \\cdot \\mathrm{poly}(n)\\) gates, as each of the rotations about \\(X\\) and \\(C\\) are efficient to implement. For hard combinatorial optimization problems such as typical \\(\\mathsf{MAX}\\)-\\(k\\)-\\(\\mathsf{SAT}\\) instances, the expectation is that the total running time required will be exponential. If the depth \\(p\\) is chosen to be constant or even \\(\\mathrm{poly}(n)\\), the dominant cost will come from the \\(\\mathcal{O}\\left( |\\braket{z^*}{\\psi_{\\gamma,\\beta}}|^{-1} \\right)\\) repetitions required to amplify the \\(\\ket{z^*}\\) state. Alternatively, one can reduce the number of repetitions needed to \\(\\mathcal{O}\\left( 1 \\right)\\) at the expense of taking \\(p\\) to be very large (at least exponentially large in \\(n\\)); indeed, for sufficiently large \\(p\\), the QAOA can be viewed as a Trotterized simulation of the adiabatic algorithm [4].   There is some analytic evidence that the QAOA may outperform Grover's algorithm at finding the exact solution for constant \\(p\\) in certain cases. Reference [5] studied the QAOA applied to hard (i.e. near the satisfiability threshold) \\(k\\)-\\(\\mathsf{SAT}\\) instances with instance-independent choice of \\(\\gamma\\), \\(\\beta\\) for constant \\(p\\), and developed an analytic formula for the expected success probability \\(|\\braket{z^*}{\\psi_{\\gamma,\\beta}}|^2\\) averaged over random instance in the limit \\(n \\rightarrow \\infty\\). This formula was evaluated numerically and suggested for example that the average success probability behaves as \\(2^{-0.33n}\\) for \\(p=10\\) on \\(8\\)-\\(\\mathsf{SAT}\\). One might be tempted to declare that this implies an overall average running time of \\(\\mathcal{O}^*(2^{0.33n/2})\\), substantially better than Grover, but such a conclusion is not analytically supported as the average of the inverse probability can be much larger than the inverse of the average probability. Nevertheless, it provides intriguing evidence in favor of such a conclusion. Further numerical evidence that QAOA may be effective as an exact algorithm was provided in [6], which numerically assessed the performance of QAOA on instances of the Low Autocorrelation Binary Sequences (LABS) problem up to \\(n=40\\), although compared to the best classical heuristic solver, the advantage appeared to be subquadratic. - Second, we consider the quantum adiabatic algorithm [12, 13]. The standard approach, as applied to binary optimization problems, is to start in the state \\(\\ket{+}\\) and evolve by a Hamiltonian that interpolates along a path \\(H(s)\\) parameterized by \\(s \\in [0,1]\\), given by </p> \\[\\begin{equation} \\label{eq:adiabatic_interpolation} H(s) = (1-s)(-X) + s C\\,. \\end{equation}\\] <p>It is important to note that the ground state of \\(H(0)\\) is \\(\\ket{+}\\) and the ground state of \\(H(1)\\) is \\(\\ket{z^*}\\). This evolution can be simulated on a fault-tolerant gate-based quantum computer using Hamiltonian simulation, and its running time is dominated by the inverse of the minimum spectral gap \\(\\Delta_{\\min}\\) of \\(H(s)\\). That is, the gate complexity to run the algorithm and produce \\(\\ket{z^*}\\) scales as at least \\(\\Delta_{\\min}^{-1}\\) and possibly a larger power of \\(\\Delta_{\\min}^{-1}\\). Much numerical work has been done on the performance of the adiabatic algorithm on small instances of combinatorial optimization problems, but it generally lacks analytical guarantees. The expectation is that \\(\\Delta_{\\min}\\) will be exponentially small [14, 15, 16] in \\(n\\) (or worse, see, e.g., [17, 18]), meaning the running time of the algorithm is exponentially large, but it remains possible that it surpasses the \\(\\mathcal{O}^*(2^{0.5n})\\) running time of Grover's algorithm in some cases, and could in principle deliver a superquadratic speedup. - Third, we consider the short-path algorithm studied in [7, 19, 20] and a dual version of the algorithm studied in [8]. The goal of these algorithms was to be able to provide a rigorous guarantee that the algorithm can find \\(z^*\\) in time \\(2^{(0.5-c)n}\\) for some value of \\(c&gt;0\\). Similar to the adiabatic algorithm, the short-path algorithm also considers a single-parameter family of Hamiltonians </p> \\[\\begin{equation} H(s) = (1-s) f_X\\left(-\\frac{X}{n}\\right) + s f_Z\\left(\\frac{C}{|E^*|}\\right)\\label{eq:short_path} \\end{equation}\\] <p>where \\(f_X, f_Z: \\mathbb{R} \\rightarrow \\mathbb{R}\\) are monotonic filter functions, and each term \\(X/n\\) and \\(C/|E^*|\\) are normalized to have minimum value \\(-1\\). The idea of the short-path algorithm is to, rather than evolve smoothly from \\(s=0\\) to \\(s=1\\), perform a pair of discrete \"jumps.\" The first jump goes from the ground state \\(\\ket{+}\\) at \\(s=0\\) to the ground state \\(\\ket{\\psi_b}\\) of an intermediate point with \\(s=b\\). The second jump goes from \\(\\ket{\\psi_b}\\) to the ground state \\(\\ket{z^*}\\) at \\(s=1\\). The jumps are accomplished with quantum phase estimation (or more advanced versions utilizing the quantum singular value transformation) of the Hamiltonian \\(H_b\\) combined with amplitude amplification. The running time of the algorithm is [8, Theorem 1] </p> \\[\\begin{equation} \\label{eq:short_path_runtime} \\mathrm{poly}(n) \\cdot \\frac{1}{\\Delta} \\cdot \\left(\\frac{1}{|\\braket{+}{\\psi_b}|} + \\frac{1}{|\\braket{\\psi_b}{z^*}|}\\right)\\,, \\end{equation}\\] <p>where \\(\\Delta\\) is the spectral gap of the Hamiltonian \\(H(b)\\). The \\(\\Delta^{-1}\\) factor comes from the need to perform phase estimation at \\(\\mathcal{O}\\left( \\Delta \\right)\\) resolution to successfully prepare \\(\\ket{\\psi_b}\\), and the two additive inverse overlap terms represent the number of rounds of amplitude amplification for the first and second jumps, respectively. In [7], filter functions \\(f_X(x) = x^K\\) for odd integers \\(K\\) (e.g. \\(K=3\\)) and \\(f_Z(x) = x\\) were chosen, and \\(b\\) was chosen close to 1, such that the first term of Eq. \\(\\eqref{eq:short_path}\\) could be viewed as a small perturbation of the second term. If \\(C\\) is an instance of \\(\\mathsf{MAX}\\)-\\(\\mathsf{E}k\\)-\\(\\mathsf{LIN2}\\), i.e. if it is a polynomial for which all monomials are degree exactly \\(k\\), then it was shown that certain conditions on the spectral density of \\(C\\) near the optimal cost value imply sufficient analytic control of \\(\\Delta\\) and the other parameters in Eq. \\(\\eqref{eq:short_path_runtime}\\) such that the algorithm runs in time \\(\\mathcal{O}^*(2^{(0.5-c)n})\\) for \\(c &gt; 0\\). However, it remained unclear when these conditions were met. Inspired by [7], [8] proposed using the filter functions \\(f_X(x) = x\\) and \\(f_Z(x) = \\min(0,(x+1-\\eta)/\\eta)\\) for a fixed choice of \\(\\eta \\in [0,1]\\), and chose a value of \\(s\\) close to 0 (rather than close to 1). In this sense, the algorithm in [8] is dual to that of [7]. These modifications allowed additional statements to be proved. For example, it was unconditionally shown that the algorithm solves \\(k\\)-\\(\\mathsf{SAT}\\) (whether or not a formula has a fully satisfiable solution) in time \\(\\mathcal{O}^*(2^{(0.5-c)n})\\) for a (small) constant \\(c &gt; 0\\), and that the same is true for typical instances of the SK model and its higher-body generalization (\\(p\\)-spin model), a polynomial speedup over Grover's algorithm and superquadratic advantage over classical exhaustive search.</p> </li> </ul>"},{"location":"areas-of-application/combinatorial-optimization/beyond-quadratic-speedups-in-exact-combinatorial-optimization/#existing-error-corrected-resource-estimates","title":"Existing error corrected resource estimates","text":"<p>Reference [21] compiled resource estimates for various primitive tasks related to combinatorial optimization. For example, it estimated that for an \\(n=512\\) instance of the SK model, implementing a single QAOA step \\(e^{-i\\beta_j X}e^{-i\\gamma_j C}\\) would require \\(577\\) logical qubits and \\(5.0 \\times 10^5\\) Toffoli gates. A similar estimate would hold for performing a single step of adiabatic evolution with a first-order product formula. The total logical estimate for finding \\(z^*\\) would be the product of the depth of the circuit and any number of repetitions / rounds of amplitude amplification. An error-corrected estimate could then be computed for a specific fault-tolerant architecture. Without knowing the number of repetitions, it is hard to give precise estimates, but a rough attempt was made in [3] for different speedup factors. There, under different possible assumptions on the amount of classical parallelism available, a breakeven point was estimated for different possible polynomial speedups (quadratic, cubic, quartic). It was found that with a quartic speedup, the breakeven point could be reasonable (on the order of seconds to hours) even assuming the availability of classical parallelism.</p>"},{"location":"areas-of-application/combinatorial-optimization/beyond-quadratic-speedups-in-exact-combinatorial-optimization/#caveats","title":"Caveats","text":"<p>There are several caveats. The most salient one is that for most of the algorithms above, there is no provable beyond-Grover advantage. Meanwhile, in the case of [8], the size of the provable beyond-Grover advantage is miniscule. The prospect of these algorithms is thus left to extrapolations from numerical simulations carried out at very small instance sizes and speculation based on physical principles.</p><p>A second important caveat is that to deliver practical superquadratic speedups, the performance of the quantum algorithm needs to be compared to the best classical algorithm, which is often substantially better than the \\(\\mathcal{O}^*(2^n)\\) running time of exhaustive enumeration. For example, \\(3\\)-\\(\\mathsf{SAT}\\) problems are classically solvable in \\(\\mathcal{O}^*(2^{0.39n})\\) time [22].</p><p>Along these lines, a third caveat is the existence of classical \"Quantum Monte Carlo\" algorithms (see, e.g., [23, 24, 25, 26, 27]), which can, under certain conditions, classically simulate the quantum algorithms described above. This is because the Hamiltonians in Eqs. \\(\\eqref{eq:adiabatic_interpolation}\\) and \\(\\eqref{eq:short_path}\\) are stoquastic Hamiltonians, defined by the property that their off-diagonal matrix elements are non-positive (when written in the computational basis). Stoquasticity implies that the ground state of the Hamiltonian can be written such that all amplitudes are non-negative real numbers [28], meaning that these Hamiltonians avoid the so-called \"sign problem\" enabling the potential application of Quantum Monte Carlo techniques. To be clear, it remains possible that quantum algorithms for these combinatorial optimization problems involving stoquastic Hamiltonians can evade classical simulation\u2014indeed, superpolynomial oracle separations have been shown between classical computation and adiabatic quantum computation restricted to stoquastic paths [29, 30]\u2014but it is something to keep in mind when designing algorithms based on stoquastic Hamiltonians.</p><p>A final caveat is that the quantum algorithms described here are typically not amenable to parallelization, although in principle QAOA could be parallelized if one opts not to use amplitude amplification (resulting in worse asymptotic complexity). This lies in stark contrast to many classical optimization algorithms for exact combinatorial optimization which are highly parallelizable, a feature that can be exploited to significantly reduce the runtime of these classical algorithms on high-performance computers, making achieving practical quantum advantage more difficult [3].</p>"},{"location":"areas-of-application/combinatorial-optimization/beyond-quadratic-speedups-in-exact-combinatorial-optimization/#comparable-classical-complexity-and-challenging-instance-sizes","title":"Comparable classical complexity and challenging instance sizes","text":"<p>For many binary optimization problems, there exist classical algorithms that exploit the structure of the problem to perform significantly better than exhaustive search. For example, the best 3-\\(\\mathsf{SAT}\\) algorithm runs in time \\(\\mathcal{O}^*(2^{0.39n})\\) and in general \\(k\\)-\\(\\mathsf{SAT}\\) can be solved in time \\(2^{(1-\\Omega(1/k))n}\\) [22]. This running time suggests the solution will be impractical once \\(n\\) is on the order of 100. The algorithm analyzed in [22] is designed for the worst case, and is likely not the best practical algorithm for typical instances. For random instances, the hardness of \\(k\\)-\\(\\mathsf{SAT}\\) depends sensitively on the clause-to-variable ratio \\(\\alpha\\). Remarkably, heuristic algorithms can succeed at finding a satisfiable solution for typical instances with thousands or even tens of thousands of variables even very close to the satisfiability threshold \\(\\alpha_c\\) where most instances become unsatisfiable (e.g., [31]). However, these algorithms are expected to fail sufficiently close to the satisfiability threshold and in the worst case.</p><p>Similarly, the SK model admits a classical branch-and-bound algorithm guaranteed to run in time \\(2^{0.45n}\\) (for a large fraction of instances) and likely better than that in practice [32]. However, once the interaction degree becomes larger than 2, the problem becomes significantly harder. The branch-and-bound algorithm is not known to generalize to the \\(p\\)-spin model, and for \\(p \\geq 3\\) there is no known classical algorithm that provably achieves \\(2^{(1-c)n}\\) for any constant \\(c\\) (although it has not garnered much attention, see [8]). Similarly, in contrast to \\(k\\)-\\(\\mathsf{SAT}\\), the \\(\\mathsf{MAX}\\)-\\(k\\)-\\(\\mathsf{SAT}\\) problem (i.e. the version of the problem that asks for the optimal assignment even if it does not satisfy all the clauses) only has a \\(\\mathcal{O}^*(2^{(1-c)n})\\) time algorithm for \\(k=2\\), and, notably, this algorithm requires exponential space [33].</p>"},{"location":"areas-of-application/combinatorial-optimization/beyond-quadratic-speedups-in-exact-combinatorial-optimization/#speedup","title":"Speedup","text":"<p>As there are generally no rigorous running time guarantees for the quantum algorithms, the speedup cannot be estimated. However, it is worth emphasizing that for hard combinatorial optimization problems, the speedup could be superquadratic, but it is not expected to be superpolynomial.</p><p>The rigorous results of [8] establish a beyond-Grover running time, but the only case in which the speedup is beyond quadratic when compared with the best known classical algorithm is the \\(p\\)-spin model with \\(p \\geq 3\\) (here, the comparison benefits from little work on classical algorithms for the problem).</p>"},{"location":"areas-of-application/combinatorial-optimization/beyond-quadratic-speedups-in-exact-combinatorial-optimization/#nisq-implementation","title":"NISQ implementation","text":"<p>The QAOA approach is amenable to NISQ implementation (assuming one opts not to apply amplitude amplification on top of it), since the quantum circuit one needs to implement is fairly shallow depth. In this case, the effect of uncorrected errors in the NISQ device may degrade the performance (and require more repetitions to extract the optimal bit string \\(z^*\\)). Similarly, on a NISQ quantum annealer [34, 13], one could run a noisy version of the quantum adiabatic algorithm and repeat until finding the optimal bit string \\(z^*\\).</p>"},{"location":"areas-of-application/combinatorial-optimization/beyond-quadratic-speedups-in-exact-combinatorial-optimization/#outlook","title":"Outlook","text":"<p>For quantum computers to be impactful for exact combinatorial optimization, one of two things must occur: (1) great advancements to the expected underlying clock speeds of quantum hardware and the overheads of fault-tolerant quantum computing, or (2) the development of quantum algorithms that go significantly beyond the quadratic speedup provided by Grover's algorithm. On the one hand, ideas have been proposed that could potentially deliver such a speedup, but on the other hand, in all cases there are no provable guarantees, or the provable guarantees are very small. Much more attention must be devoted to studying these quantum algorithms and developing new ones if we are to leverage them into actual practical advantages, especially given the extensive amount of work developing sophisticated classical algorithms for these problems.</p>"},{"location":"areas-of-application/combinatorial-optimization/beyond-quadratic-speedups-in-exact-combinatorial-optimization/#bibliography","title":"Bibliography","text":"<ol> <li> <p>Lov K. Grover. A fast quantum mechanical algorithm for database search. In Proceedings of the 28th ACM Symposium on the Theory of Computing (STOC), 212\u2013219. 1996. arXiv: https://arxiv.org/abs/quant-ph/9605043. doi:10.1145/237814.237866.</p> </li> <li> <p>Earl Campbell, Ankur Khurana, and Ashley Montanaro. Applying quantum algorithms to constraint satisfaction problems. Quantum, 3:167, 2019. arXiv: https://arxiv.org/abs/1810.05582. doi:10.22331/q-2019-07-18-167.</p> </li> <li> <p>Ryan Babbush, Jarrod R. McClean, Michael Newman, Craig Gidney, Sergio Boixo, and Hartmut Neven. Focus beyond quadratic speedups for error-corrected quantum advantage. PRX Quantum, 2(1):010103, 3 2021. arXiv: https://arxiv.org/abs/2011.04149. doi:10.1103/PRXQuantum.2.010103.</p> </li> <li> <p>Edward Farhi, Jeffrey Goldstone, and Sam Gutmann. A quantum approximate optimization algorithm. arXiv: https://arxiv.org/abs/1411.4028, 2014.</p> </li> <li> <p>Sami Boulebnane and Ashley Montanaro. Solving boolean satisfiability problems with the quantum approximate optimization algorithm. arXiv: https://arxiv.org/abs/2208.06909, 2022.</p> </li> <li> <p>Ruslan Shaydulin, Changhao Li, Shouvanik Chakrabarti, Matthew DeCross, Dylan Herman, Niraj Kumar, Jeffrey Larson, Danylo Lykov, Pierre Minssen, Yue Sun, Yuri Alexeev, Joan M. Dreiling, John P. Gaebler, Thomas M. Gatterman, Justin A. Gerber, Kevin Gilmore, Dan Gresh, Nathan Hewitt, Chandler V. Horst, Shaohan Hu, Jacob Johansen, Mitchell Matheny, Tanner Mengle, Michael Mills, Steven A. Moses, Brian Neyenhuis, Peter Siegfried, Romina Yalovetzky, and Marco Pistoia. Evidence of scaling advantage for the quantum approximate optimization algorithm on a classically intractable problem. arXiv: https://arxiv.org/abs/2308.02342, 2023.</p> </li> <li> <p>M. B. Hastings. A short path quantum algorithm for exact optimization. Quantum, 2:78, 7 2018. arXiv: https://arxiv.org/abs/1802.10124. URL: https://doi.org/10.22331/q-2018-07-26-78, doi:10.22331/q-2018-07-26-78.</p> </li> <li> <p>Alexander M. Dalzell, Nicola Pancotti, Earl T. Campbell, and Fernando G.S.L. Brand\u00e3o. Mind the gap: achieving a super-grover quantum speedup by jumping to the end. In Proceedings of the 55th ACM Symposium on the Theory of Computing (STOC), 1131\u20131144. New York, NY, USA, 2023. Association for Computing Machinery. arXiv: https://arxiv.org/abs/2212.01513. URL: https://doi.org/10.1145/3564246.3585203, doi:10.1145/3564246.3585203.</p> </li> <li> <p>David Sherrington and Scott Kirkpatrick. Solvable model of a spin-glass. Physical Review Letters, 35(26):1792, 1975. doi:10.1103/PhysRevLett.35.1792.</p> </li> <li> <p>B. Derrida. Random-energy model: limit of a family of disordered models. Physical Review Letters, 45:79\u201382, 7 1980. URL: https://link.aps.org/doi/10.1103/PhysRevLett.45.79, doi:10.1103/PhysRevLett.45.79.</p> </li> <li> <p>Don Coppersmith, David Gamarnik, MohammadTaghi Hajiaghayi, and Gregory B. Sorkin. Random max sat, random max cut, and their phase transitions. Random Structures &amp; Algorithms, 24(4):502\u2013545, 2004. Earlier version in *SODA'03*, arXiv: https://arxiv.org/abs/math/0306047. URL: https://onlinelibrary.wiley.com/doi/abs/10.1002/rsa.20015, arXiv:https://onlinelibrary.wiley.com/doi/pdf/10.1002/rsa.20015, doi:10.1002/rsa.20015.</p> </li> <li> <p>Edward Farhi, Jeffrey Goldstone, Sam Gutmann, and Michael Sipser. Quantum computation by adiabatic evolution. arXiv: https://arxiv.org/abs/quant-ph/0001106, 2000.</p> </li> <li> <p>Tameem Albash and Daniel A. Lidar. Adiabatic quantum computation. Reviews of Modern Physics, 90:015002, 1 2018. arXiv: https://arxiv.org/abs/1611.04471. doi:10.1103/RevModPhys.90.015002.</p> </li> <li> <p>Sergey Knysh and Vadim Smelyanskiy. On the relevance of avoided crossings away from quantum critical point to the complexity of quantum adiabatic algorithm. arXiv: https://arxiv.org/abs/1005.3011, 2010. doi:10.48550/arXiv.1005.3011.</p> </li> <li> <p>A. P. Young, S. Knysh, and V. N. Smelyanskiy. First-order phase transition in the quantum adiabatic algorithm. Physical Review Letters, 104:020502, 1 2010. arXiv: https://arxiv.org/abs/0910.1378. URL: https://link.aps.org/doi/10.1103/PhysRevLett.104.020502, doi:10.1103/PhysRevLett.104.020502.</p> </li> <li> <p>Itay Hen and A. P. Young. Exponential complexity of the quantum adiabatic algorithm for certain satisfiability problems. Physical Review E, 84:061152, 2011. arXiv: https://arxiv.org/abs/1109.6872. URL: https://link.aps.org/doi/10.1103/PhysRevE.84.061152, doi:10.1103/PhysRevE.84.061152.</p> </li> <li> <p>Boris Altshuler, Hari Krovi, and J\u00e9r\u00e9mie Roland. Anderson localization makes adiabatic quantum optimization fail. Proceedings of the National Academy of Sciences, 107:12446\u201312450, 2010. arXiv: https://arxiv.org/abs/0912.0746. doi:10.1073/pnas.1002116107.</p> </li> <li> <p>Dave Wecker, Matthew B. Hastings, and Matthias Troyer. Training a quantum optimizer. Physical Review A, 94:022309, 2016. arXiv: https://arxiv.org/abs/1605.05370. doi:10.1103/PhysRevA.94.022309.</p> </li> <li> <p>Matthew B Hastings. Weaker assumptions for the short path optimization algorithm. arXiv: https://arxiv.org/abs/1807.03758, 2018. doi:10.48550/arXiv.1807.03758.</p> </li> <li> <p>M. B. Hastings. The short path algorithm applied to a toy model. Quantum, 3:145, 5 2019. arXiv: https://arxiv.org/abs/1901.03884. URL: https://doi.org/10.22331/q-2019-05-20-145, doi:10.22331/q-2019-05-20-145.</p> </li> <li> <p>Yuval R. Sanders, Dominic W. Berry, Pedro C.S. Costa, Louis W. Tessler, Nathan Wiebe, Craig Gidney, Hartmut Neven, and Ryan Babbush. Compilation of fault-tolerant quantum heuristics for combinatorial optimization. PRX Quantum, 1(2):020312, 11 2020. arXiv: https://arxiv.org/abs/2007.07391. doi:10.1103/PRXQuantum.1.020312.</p> </li> <li> <p>Thomas Dueholm Hansen, Haim Kaplan, Or Zamir, and Uri Zwick. Faster \\(k\\)-sat algorithms using biased-ppsz. In Proceedings of the 51st ACM Symposium on the Theory of Computing (STOC), 578\u2013589. New York, NY, USA, 2019. Association for Computing Machinery. doi:10.1145/3313276.3316359.</p> </li> <li> <p>Edward Farhi, Jeffrey Goldstone, David Gosset, Sam Gutmann, Harvey B Meyer, and Peter Shor. Quantum adiabatic algorithms, small gaps, and different paths. Quantum Information and Computation, 2009. arXiv: https://arxiv.org/abs/0909.4766. doi:10.26421/QIC11.3-4-1.</p> </li> <li> <p>Sergey Bravyi. Monte carlo simulation of stoquastic hamiltonians. Quantum Information and Computation, 15:1122\u20131140, 2015. arXiv: https://arxiv.org/abs/1402.2295. doi:10.26421/QIC15.13-14-3.</p> </li> <li> <p>Michael Jarret, Stephen P. Jordan, and Brad Lackey. Adiabatic optimization versus diffusion monte carlo methods. Physical Review A, 94:042318, 10 2016. arXiv: https://arxiv.org/abs/1607.03389. URL: https://link.aps.org/doi/10.1103/PhysRevA.94.042318, doi:10.1103/PhysRevA.94.042318.</p> </li> <li> <p>Elizabeth Crosson and Aram W. Harrow. Simulated quantum annealing can be exponentially faster than classical simulated annealing. In Proceedings of the 57th IEEE Symposium on Foundations of Computer Science (FOCS), volume, 714\u2013723. 2016. arXiv: https://arxiv.org/abs/1601.03030. doi:10.1109/FOCS.2016.81.</p> </li> <li> <p>Elizabeth Crosson and Samuel Slezak. Classical simulation of high temperature quantum ising models. arXiv: https://arxiv.org/abs/2002.02232, 2020. doi:10.48550/arXiv.2002.02232.</p> </li> <li> <p>Sergey Bravyi and Barbara Terhal. Complexity of stoquastic frustration-free hamiltonians. SIAM Journal on Computing, 39(4):1462\u20131485, 2010. arXiv: https://arxiv.org/abs/0806.1746. doi:10.1137/08072689X.</p> </li> <li> <p>Matthew B. Hastings. The power of adiabatic quantum computation with no sign problem. arXiv: https://arxiv.org/abs/2005.03791, 2020.</p> </li> <li> <p>Andr\u00e1s Gily\u00e9n, Matthew B. Hastings, and Umesh Vazirani. (sub)exponential advantage of adiabatic quantum computation with no sign problem. In Proceedings of the 53rd ACM Symposium on the Theory of Computing (STOC), STOC 2021, 1357\u20131369. New York, NY, USA, 2021. Association for Computing Machinery. arXiv: https://arxiv.org/abs/2011.09495. URL: https://doi.org/10.1145/3406325.3451060, doi:10.1145/3406325.3451060.</p> </li> <li> <p>Raffaele Marino, Giorgio Parisi, and Federico Ricci-Tersenghi. The backtracking survey propagation algorithm for solving random k-sat problems. Nature Communications, 7(1):12996, 2016. arXiv: https://arxiv.org/abs/1508.05117. doi:10.1038/ncomms12996.</p> </li> <li> <p>Ashley Montanaro. Quantum speedup of branch-and-bound algorithms. Physical Review Research, 2(1):013056, 2020. arXiv: https://arxiv.org/abs/1906.10375. doi:10.1103/PhysRevResearch.2.013056.</p> </li> <li> <p>Ryan Williams. A new algorithm for optimal 2-constraint satisfaction and its implications. Theoretical Computer Science, 348(2):357\u2013365, 2005. Earlier version in ICALP'04. URL: https://www.sciencedirect.com/science/article/pii/S0304397505005438, doi:10.1016/j.tcs.2005.09.023.</p> </li> <li> <p>Tadashi Kadowaki and Hidetoshi Nishimori. Quantum annealing in the transverse ising model. Physical Review E, 58:5355\u20135363, 11 1998. arXiv: https://arxiv.org/abs/cond-mat/9804280. URL: https://link.aps.org/doi/10.1103/PhysRevE.58.5355, doi:10.1103/PhysRevE.58.5355.</p> </li> </ol> <ol> <li> <p>This assumption can often be relaxed at the expense of at most \\(\\mathrm{poly}(n)\\) overhead, e.g., by iterating over all possible values \\(E^*\\) might take, which fall within a \\(\\mathrm{poly}(n)\\) size range when the cost function consists of only \\(\\mathrm{poly}(n)\\) constant size (integer) terms.\u00a0\u21a9</p> </li> <li> <p>A more typical definition of the average-case complexity of an algorithm is the expected runtime required for it to find the solution \\(z^*\\), averaged over both choice of instance and internal algorithmic randomness (i.e., classical coin flips or quantum measurement outcomes). This definition is related to the convention we follow, but it is more coarse grained as it does not distinguish between the two types of randomness, the latter of which can be boosted by repetition.\u00a0\u21a9</p> </li> </ol>"},{"location":"areas-of-application/combinatorial-optimization/introduction/","title":"Combinatorial optimization","text":"<p>Combinatorial optimization problems are tasks where one seeks an optimal solution among a finite set of possible candidates. In industrial settings, combinatorial optimization arises via scheduling, routing, resource allocation, supply chain management, and other logistics problems, where it can be difficult to find optimal solutions that obey various desired constraints. The field of operations research\u2014which came to prominence after its application to logistics problems faced by WWII militaries\u2014applies methods of combinatorial optimization (as well as continuous optimization) to these problem areas for improved decision-making and efficiency in real-world problems.</p><p>Combinatorial optimization problems are also at the heart of classical theoretical computer science, where they are used to characterize and delineate complexity classes. Typical combinatorial optimization problems have limited structure to exploit, and therefore quantum computing most often only provides polynomial speedups. In fact, it came as a surprise in the early days of quantum computing research that for a wide variety of such problems quantum computers do offer up to quadratic speedups via Grover's search algorithm [1]. Subsequently, much effort was devoted to understanding how Grover's search and its generalization, amplitude amplification, offers speedups for various combinatorial optimization problems.</p><p>In this section, we cover several distinct approaches to solving combinatorial optimization problems. First, we look at combinatorial optimizations through its relation to search problems, where Grover's algorithm, or its generalizations, can be applied to give a quadratic or subquadratic speedup. Then, we cover several proposals\u2014variational algorithms (viewed as an exact algorithm), the adiabatic algorithm, and the \"short-path\" algorithm [2, 3]\u2014that have the potential to surpass the quadratic speedup of Grover's algorithm. We discuss the (limited, but existing) evidence that these approaches could generate significant advantages, as well as the associated caveats.</p><p>We do not specifically cover the large body of work on quantum approaches for approximate combinatorial optimization (typically variational quantum algorithms or quantum annealing). These algorithms usually translate the optimization problem to energy minimization of a spin system with a Hamiltonian that encodes the classical objective function. They apply some physically motivated heuristics to efficiently generate solutions that have low energy, and hopefully achieve a better objective value than could be generated classically in a comparable amount of time. An advantage of these approaches is that they are often more compatible with noisy near-term hardware. While approximate optimization remains an interesting direction, these quantum algorithms are heuristic and there is a general scarcity of concrete evidence that they will deliver practical advantages.</p>"},{"location":"areas-of-application/combinatorial-optimization/introduction/#bibliography","title":"Bibliography","text":"<ol> <li> <p>Lov K. Grover. A fast quantum mechanical algorithm for database search. In Proceedings of the 28th ACM Symposium on the Theory of Computing (STOC), 212\u2013219. 1996. arXiv: https://arxiv.org/abs/quant-ph/9605043. doi:10.1145/237814.237866.</p> </li> <li> <p>M. B. Hastings. A short path quantum algorithm for exact optimization. Quantum, 2:78, 7 2018. arXiv: https://arxiv.org/abs/1802.10124. URL: https://doi.org/10.22331/q-2018-07-26-78, doi:10.22331/q-2018-07-26-78.</p> </li> <li> <p>Alexander M. Dalzell, Nicola Pancotti, Earl T. Campbell, and Fernando G.S.L. Brand\u00e3o. Mind the gap: achieving a super-grover quantum speedup by jumping to the end. In Proceedings of the 55th ACM Symposium on the Theory of Computing (STOC), 1131\u20131144. New York, NY, USA, 2023. Association for Computing Machinery. arXiv: https://arxiv.org/abs/2212.01513. URL: https://doi.org/10.1145/3564246.3585203, doi:10.1145/3564246.3585203.</p> </li> </ol>"},{"location":"areas-of-application/combinatorial-optimization/search-algorithms-a-la-grover/","title":"Search algorithms \u00e0 la Grover","text":""},{"location":"areas-of-application/combinatorial-optimization/search-algorithms-a-la-grover/#overview","title":"Overview","text":"<p>Grover's search algorithm [1], and its generalizations, such as amplitude amplification, are essential sources of quantum speedups. A straightforward application of Grover search in the spirit of optimization is quantum minimum finding [2] that finds the minimizer of a function on a given set of elements with a quadratic speedup, and its natural generalization analogous to amplitude amplification can be found in [3].</p><p>As search is a very generic primitive, Grover's algorithm is extremely widely applicable and it can speed up many subroutines especially in algorithms for combinatorial optimization. In the early days of quantum computing, a plethora of such applications were found, and the list still keeps growing. We list a few such representative applications that demonstrate how Grover's algorithm may be applied to speed up combinatorial optimization.</p>"},{"location":"areas-of-application/combinatorial-optimization/search-algorithms-a-la-grover/#actual-end-to-end-problems-solved","title":"Actual end-to-end problem(s) solved","text":"<p>The goal is to solve a search problem, i.e., decide whether there is an element among a set of objects that satisfies some criterion, and if there is such an object, find one. Many combinatorial optimization problems are fundamentally search problems; a notable class of examples are graph problems, such as finding a maximal independent set, a \\(k\\)-coloring, a lowest weight Hamiltonian cycle (called the traveling salesperson problem), or the shortest path between two vertices.</p><p>For conceptual clarity, here, we focus on the prototypical Boolean satisfiability problem, i.e., \\(\\mathsf{SAT}\\) solving: given a Boolean formula in the so-called conjunctive normal form, decide whether it has a satisfying Boolean assignment (and if so, find one). A formula in this form consists of some constraints (called clauses) each containing the logical AND of some variables or their negation (called literals). We denote the number of Boolean variables by \\(n\\), while the total number of literals of the formula by \\(\\ell\\) (counted with multiplicity).</p>"},{"location":"areas-of-application/combinatorial-optimization/search-algorithms-a-la-grover/#dominant-resource-costcomplexity","title":"Dominant resource cost/complexity","text":"<p>If there are at least \\(m\\) marked elements among \\(N\\) possible ones, then the search problem can be solved with high probability by using \\(\\mathcal{O}\\left( \\sqrt{N/m} \\right)\\) Grover iterations. Each Grover iteration requires generating a uniform superposition over the \\(N\\) elements starting from the all \\(0\\) state, and to check whether an element is marked (in superposition), which can be implemented with gate cost \\(\\mathcal{O}\\left( \\ell+n \\right)\\). If the formula is satisfiable then there is at least one solution, thus \\(\\mathcal{O}\\left( \\sqrt{2^n} \\right)\\) Grover iterations suffice, giving an overall complexity of \\(\\mathcal{O}\\left( (\\ell+n)\\sqrt{2^n} \\right)\\).</p><p>In some applications, it is useful to consider a generalization of Grover search, amplitude amplification, which enables working with an arbitrary prior distribution on the elements, unlike Grover's algorithm which effectively uses a uniform prior. The relevance of this extension can be seen through the example of 3-\\(\\mathsf{SAT}\\), which is a restricted version of \\(\\mathsf{SAT}\\) where each clause has at most 3 literals. A clever application of amplitude amplification described by Ambainis [4] for solving 3-\\(\\mathsf{SAT}\\) more efficiently uses Sch\u00f6ning's algorithm [5] and thus generates a nontrivial prior distribution on the solutions.</p><p>The complexity of amplitude amplification is similar to that of Grover's search in general. If \\(\\ket{\\psi}\\) is the quantum state representing the prior distribution, so that measuring the state yields a marked element with probability at least \\(p\\), then \\(\\mathcal{O}\\left( \\sqrt{1/p} \\right)\\) \"Grover iterations\" suffice to find a marked element with high probability. The algorithm requires preparing the initial state \\(\\ket{\\psi}\\) and then each iteration consist of a reflection \\(2\\ketbra{\\psi}{\\psi}-I\\) around \\(\\ket{\\psi}\\) and checking whether an element is marked (in superposition). The former reflection can be implemented with two uses of the circuit that prepares \\(\\ket{\\psi}\\) from the all \\(0\\) state, and a reflection about the all \\(0\\) state.</p>"},{"location":"areas-of-application/combinatorial-optimization/search-algorithms-a-la-grover/#existing-error-corrected-resource-estimates","title":"Existing error corrected resource estimates","text":"<p>There are several studies on the resource estimation of Grover-type (sub)quadratic speedups. Due to the wide range of these problems, we do not focus on explicit gate counts on any particular problem/implementation variant, but rather list some prominent articles and illustrate their findings on a high level [6, 7, 8, 9, 10, 11]. Unfortunately, these recent studies revealed that quadratic or smaller speedups alone are unlikely to be useful probably even in the medium term, unless the large overheads of fault-tolerant quantum computing schemes can be greatly reduced. For example, [7] concluded that even if there is some reasonable advantage in quantum gate counts for solving the constraint satisfaction problems that they consider, the classical computation supporting the fault-tolerant quantum computation actually annihilates the speedup in practice. They state that \"Even when considering only problem instances that can be solved within one day, we find that there are potentially large quantum speedups available. \\(\\ldots\\) However, the number of physical qubits used is extremely large, \\(\\ldots\\) In particular, the quantum advantage disappears if one includes the cost of the classical processing power required to perform decoding of the surface code using current techniques.\" The most recent of the above quoted papers [11] estimates that getting a quantum advantage via a quadratic speedup requires at least a month-long computation already if each iteration contains at least one floating-point operation. The situation looks more promising for cubic and quartic speedups, but unfortunately such improvements seem to require techniques beyond Grover search.</p>"},{"location":"areas-of-application/combinatorial-optimization/search-algorithms-a-la-grover/#caveats","title":"Caveats","text":"<p>Grover originally described his result as \"A fast quantum mechanical algorithm for database search\" [1]. If we work in the circuit model of quantum computation, then strictly speaking Grover search gives a slowdown for database search, as every Grover iteration needs to \"touch\" every element in the database. If we anyway need to touch all \\(N\\) elements in the database, then the best we can do is to simply go over every element in linear time \\(\\mathcal{O}\\left( N \\right)\\). Grover's search circuit in this case would have gate complexity \\(\\widetilde{\\mathcal{O}}\\left( N^{3/2} \\right)\\), clearly worse than sequentially going through the entire dataset.</p><p>In the database scenario, we can only recover the quadratic speedup if we assume that we can use a quantum random access memory (QRAM), with constant (or logarithmic) cost for each database query. The analogous assumption regarding ordinary RAM is often made in classical computer science, simply because RAM calls are cheap in practice. However, since a RAM call should be able to touch every bit of the database, from a circuit complexity perspective a RAM call must have gate cost at least \\(N\\). On the other hand, this task can be parallelized very well, so with appropriate hardware it is reasonable to count a RAM call to have (time) complexity \\(\\log(N)\\). While QRAM can also be implemented with a quantum circuit of \\(\\mathcal{O}\\left( \\log(N) \\right)\\) depth, a similar accounting might not be fair in the case of QRAM if error correction is necessary, especially if one implements the entire QRAM circuit in a fault-tolerant fashion.</p><p>However, Grover's algorithm can provide a quadratic speedup without extra hardware assumptions when the elements of the list that we search over can be easily generated and checked \"on the fly.\" For example, in the case of \\(\\mathsf{SAT}\\), we search over the \\(2^n\\) possible truth assignments, yet we can easily check whether an individual assignment is satisfactory by simply substituting the assignment into the formula and evaluating the resulting Boolean expression.</p>"},{"location":"areas-of-application/combinatorial-optimization/search-algorithms-a-la-grover/#comparable-classical-complexity","title":"Comparable classical complexity","text":"<p>For the unstructured search problem, exhaustive search is essentially the best that can be done, with a running time \\(\\sim\\ell \\cdot 2^n\\). Of course, \\(\\mathsf{SAT}\\) seems to be far from unstructured, but under the Strong Exponential-Time Hypothesis [12, 13] the best classical algorithm for \\(\\mathsf{SAT}\\) has running time \\(2^{n-o(n)}\\).</p><p>A similar argument holds for the generalized problem considered in the setting of amplitude amplification: if we have some prior distribution, we can classically find a marked element by sampling from this distribution about \\(\\sim \\frac{1}{p}\\) times. Since unstructured search is a special case of this problem, we cannot hope for a better classical algorithm in general.</p>"},{"location":"areas-of-application/combinatorial-optimization/search-algorithms-a-la-grover/#speedup","title":"Speedup","text":"<p>The speedup is quadratic in terms of the number of required iterations if we compare to corresponding naive classical algorithms. It can be shown that this speedup is optimal in the black-box query model [14]. Moreover, we do not expect that there would be a bigger than quadratic speedup in gate complexity [15] in the general (non-black-box) case.</p>"},{"location":"areas-of-application/combinatorial-optimization/search-algorithms-a-la-grover/#outlook","title":"Outlook","text":"<p>We have discussed how Grover search provides a quadratic speedup for \\(\\mathsf{SAT}\\), and how amplitude amplification yields a quadratic speedup for 3-\\(\\mathsf{SAT}\\). Grover's algorithm can be used as a subroutine in several other combinatorial optimization problems as well, e.g., related to graphs. In the literature, these problems are most often studied in the query model, therefore here we also only discuss their speedup in terms of query complexity. Since these are (sub)quadratic speedups, we know that the fault-tolerant resource estimates will be unfavorable anyway, as discussed above.</p><p>For example, the problem of finding the shortest paths from a single source \\(s\\) in graph \\(G=(V,E)\\) to all other vertices \\(v\\in V\\) can be solved using Dijkstra's algorithm in time \\(\\mathcal{O}\\left( |E|+|V|\\log|V| \\right)\\) if the graph is provided with its adjacency list (and with query complexity \\(\\mathcal{O}\\left( |E| \\right)\\)), whereas the quantum query complexity of this problem is \\(\\widetilde{\\Theta}(\\sqrt{|V||E|})\\) [16]. The paper [16] determines the query complexity of several other graph problems such as deciding graph connectivity and strong connectivity as well as finding the minimum-weight spanning tree. For all of these problems, there is a similar moderate (sub)quadratic quantum speedup.</p><p>One graph problem that is often mentioned in connection to quantum computation is the (in)famous traveling salesperson problem. However, for this problem, the best provable speedup is only subquadratic. The naive classical problem runs in time \\(n!\\), and Grover's algorithm offers a quadratic speedup over it. Unfortunately, the best classical algorithm uses dynamic programming and runs in time \\(2^n\\). Ambainis et al. [17] showed how to obtain a speedup over this algorithm by combining classical precalculation with recursive applications of Grover's search resulting in time complexity \\(\\widetilde{\\mathcal{O}}\\left( 1.817^n \\right)\\) assuming that QRAM calls have unit costs. Considering the overheads coming from the implementation of QRAM and fault tolerance, the traveling salesperson problem seems to be one of the least likely candidates to achieve a practical quantum speedup.</p><p>Finally, let us mention quantum walk algorithms, which can also be viewed as a generalization of Grover's search. However, quantum walks are more distant relatives of Grover's search and can only be applied in more specific settings. They can be used for proving many nontrivial speedups in query complexity, however the resulting algorithms are often not practical due to high space and/or gate complexity overheads, as is the case for the prototypical Element Distinctness problem. The query reduction is moderate \\(N^2\\rightarrow N^{4/3}\\) in the number of elements \\(N\\), but the corresponding quantum algorithm [18] unfortunately uses a QRAM consisting of about \\(\\sim N^{4/3}\\) registers.</p><p>There are nevertheless more practical quantum walk algorithms applicable, e.g., to speed up backtracking algorithms [19, 20, 21, 22], which are among the most successful and widely used classical heuristics for solving \\(\\mathsf{SAT}\\) instances in practice. The quantum algorithm can achieve an essentially quadratic speedup compared to its classical backtracking variant. This approach is applicable to the traveling salesperson problem in the special case that the graph has degree at most 4 [23]. For resource estimates see the earlier quoted reference [6]. A further extension of this algorithm is applicable to branch-and-bound algorithms [24, 25], and in some cases yields running times that are substantially better than what we know can be achieved by naively using Grover's algorithm. For example, it can find exact ground states for most instances of the Sherrington\u2013Kirkpatrick model [26] in time \\(\\mathcal{O}\\left( 2^{0.226n} \\right)\\) [24], which means about a quadratic speedup compared to classical methods. Branch-and-bound-based speedups can also be applied to solve mixed-integer programs, which includes certain formulations of the portfolio optimization problem [25].</p><p>There is a plethora of other applications of quantum search speedups, ranging from machine learning [27] to dynamical programming solutions of other NP-hard problems [17], which we do not discuss here for length constraints and due to discouraging resource estimates for (sub)quadratic quantum speedups.</p>"},{"location":"areas-of-application/combinatorial-optimization/search-algorithms-a-la-grover/#bibliography","title":"Bibliography","text":"<ol> <li> <p>Lov K. Grover. A fast quantum mechanical algorithm for database search. In Proceedings of the 28th ACM Symposium on the Theory of Computing (STOC), 212\u2013219. 1996. arXiv: https://arxiv.org/abs/quant-ph/9605043. doi:10.1145/237814.237866.</p> </li> <li> <p>Christoph D\u00fcrr and Peter H\u00f8yer. A quantum algorithm for finding the minimum. arXiv: https://arxiv.org/abs/quant-ph/9607014, 1996.</p> </li> <li> <p>Joran van Apeldoorn, Andr\u00e1s Gily\u00e9n, Sander Gribling, and Ronald de Wolf. Quantum sdp-solvers: better upper and lower bounds. Quantum, 4:230, 2020. Earlier version in FOCS'17. arXiv: https://arxiv.org/abs/1705.01843. doi:10.22331/q-2020-02-14-230.</p> </li> <li> <p>A. Ambainis. Quantum search algorithms. SIGACT News, 35(2):22\u201335, 6 2004. arXiv: https://arxiv.org/abs/quant-ph/0504012. doi:10.1145/992287.992296.</p> </li> <li> <p>Uwe Sch\u00f6ning. A probabilistic algorithm for k-sat and constraint satisfaction problems. In Proceedings of the 40th IEEE Symposium on Foundations of Computer Science (FOCS), volume, 410\u2013414. 1999. doi:10.1109/SFFCS.1999.814612.</p> </li> <li> <p>Earl Campbell, Ankur Khurana, and Ashley Montanaro. Applying quantum algorithms to constraint satisfaction problems. Quantum, 3:167, 2019. arXiv: https://arxiv.org/abs/1810.05582. doi:10.22331/q-2019-07-18-167.</p> </li> <li> <p>Yuval R. Sanders, Dominic W. Berry, Pedro C.S. Costa, Louis W. Tessler, Nathan Wiebe, Craig Gidney, Hartmut Neven, and Ryan Babbush. Compilation of fault-tolerant quantum heuristics for combinatorial optimization. PRX Quantum, 1(2):020312, 11 2020. arXiv: https://arxiv.org/abs/2007.07391. doi:10.1103/PRXQuantum.1.020312.</p> </li> <li> <p>Ryan Babbush, Jarrod R. McClean, Michael Newman, Craig Gidney, Sergio Boixo, and Hartmut Neven. Focus beyond quadratic speedups for error-corrected quantum advantage. PRX Quantum, 2(1):010103, 3 2021. arXiv: https://arxiv.org/abs/2011.04149. doi:10.1103/PRXQuantum.2.010103.</p> </li> <li> <p>Chris Cade, Marten Folkertsma, Ido Niesen, and Jordi Weggemans. Quantifying grover speed-ups beyond asymptotic analysis. arXiv: https://arxiv.org/abs/2203.04975, 2022.</p> </li> <li> <p>Chris Cade, Marten Folkertsma, Ido Niesen, and Jordi Weggemans. Quantum algorithms for community detection and their empirical run-times. arXiv: https://arxiv.org/abs/2203.06208, 2022.</p> </li> <li> <p>Torsten Hoefler, Thomas H\u00e4ner, and Matthias Troyer. Disentangling hype from practicality: on realistically achieving quantum advantage. Commun. ACM, 66(5):82\u201387, 2023. doi:10.1145/3571725.</p> </li> <li> <p>Russell Impagliazzo, Ramamohan Paturi, and Francis Zane. Which problems have strongly exponential complexity? Journal of Computer and System Sciences, 63(4):512\u2013530, 2001. doi:https://doi.org/10.1006/jcss.2001.1774.</p> </li> <li> <p>Chris Calabro, Russell Impagliazzo, and Ramamohan Paturi. The complexity of satisfiability of small depth circuits. In Parameterized and Exact Computation, 75\u201385. Springer Berlin Heidelberg, 2009. doi:10.1007/978-3-642-11269-0\\_6.</p> </li> <li> <p>Charles H. Bennett, Ethan Bernstein, Gilles Brassard, and Umesh Vazirani. Strengths and weaknesses of quantum computing. SIAM Journal on Computing, 26(5):1510\u20131523, 1997. arXiv: https://arxiv.org/abs/quant-ph/9701001. doi:10.1137/S0097539796300933.</p> </li> <li> <p>Harry Buhrman, Subhasree Patro, and Florian Speelman. A framework of quantum strong exponential-time hypotheses. In Proceedings of the 38th Symposium on Theoretical Aspects of Computer Science (STACS), volume 187, 19:1\u201319:19. 2021. doi:10.4230/LIPIcs.STACS.2021.19.</p> </li> <li> <p>Christoph D\u00fcrr, Mark Heiligman, Peter H\u00f8yer, and Mehdi Mhalla. Quantum query complexity of some graph problems. SIAM Journal on Computing, 35(6):1310\u20131328, 2006. Earlier version in ICALP'04. arXiv: https://arxiv.org/abs/quant-ph/0401091. doi:10.1137/050644719.</p> </li> <li> <p>Andris Ambainis, Kaspars Balodis, J\u0101nis Iraids, Martins Kokainis, Kri\u0161j\u0101nis Pr\u016bsis, and Jevg\u0113nijs Vihrovs. Quantum speedups for exponential-time dynamic programming algorithms. In Proceedings of the 30th ACM-SIAM Symposium on Discrete Algorithms (SODA), 1783\u20131793. SIAM, 2019. arXiv: https://arxiv.org/abs/2104.14384. doi:10.1137/1.9781611975482.107.</p> </li> <li> <p>Andris Ambainis. Quantum walk algorithm for element distinctness. SIAM Journal on Computing, 37(1):210\u2013239, 2007. Earlier version in FOCS'04. arXiv: https://arxiv.org/abs/quant-ph/0311001. doi:10.1137/S0097539705447311.</p> </li> <li> <p>Ashley Montanaro. Quantum-walk speedup of backtracking algorithms. Theory of Computing, 14(15):1\u201324, 2018. arXiv: https://arxiv.org/abs/1509.02374. doi:10.4086/toc.2018.v014a015.</p> </li> <li> <p>Andris Ambainis and Martins Kokainis. Quantum algorithm for tree size estimation, with applications to backtracking and 2-player games. In Proceedings of the 49th ACM Symposium on the Theory of Computing (STOC), 989\u20131002. 2017. arXiv: https://arxiv.org/abs/1704.06774. doi:10.1145/3055399.3055444.</p> </li> <li> <p>Michael Jarret and Kianna Wan. Improved quantum backtracking algorithms using effective resistance estimates. Physical Review A, 97(2):022337, 2018. arXiv: https://arxiv.org/abs/1711.05295. doi:10.1103/PhysRevA.97.022337.</p> </li> <li> <p>Simon Martiel and Maxime Remaud. Practical implementation of a quantum backtracking algorithm. In Alexander Chatzigeorgiou, Riccardo Dondi, Herodotos Herodotou, Christos Kapoutsis, Yannis Manolopoulos, George A. Papadopoulos, and Florian Sikora, editors, SOFSEM 2020: Theory and Practice of Computer Science, 597\u2013606. Cham, 2020. Springer International Publishing. arXiv: https://arxiv.org/abs/1908.11291. doi:10.1007/978-3-030-38919-2\\_49.</p> </li> <li> <p>Alexandra E. Moylett, Noah Linden, and Ashley Montanaro. Quantum speedup of the traveling-salesman problem for bounded-degree graphs. Physical Review A, 95:032323, 3 2017. arXiv: https://arxiv.org/abs/1612.06203. URL: https://link.aps.org/doi/10.1103/PhysRevA.95.032323, doi:10.1103/PhysRevA.95.032323.</p> </li> <li> <p>Ashley Montanaro. Quantum speedup of branch-and-bound algorithms. Physical Review Research, 2(1):013056, 2020. arXiv: https://arxiv.org/abs/1906.10375. doi:10.1103/PhysRevResearch.2.013056.</p> </li> <li> <p>Shouvanik Chakrabarti, Pierre Minssen, Romina Yalovetzky, and Marco Pistoia. Universal quantum speedup for branch-and-bound, branch-and-cut, and tree-search algorithms. arXiv: https://arxiv.org/abs/2210.03210, 2022.</p> </li> <li> <p>David Sherrington and Scott Kirkpatrick. Solvable model of a spin-glass. Physical Review Letters, 35(26):1792, 1975. doi:10.1103/PhysRevLett.35.1792.</p> </li> <li> <p>Nathan Wiebe, Ashish Kapoor, and Krysta M. Svore. Quantum nearest-neighbor algorithms for machine learning. Quantum Information and Computation, 15(3&amp;4):318\u2013358, 2015. arXiv: https://arxiv.org/abs/1401.2142. doi:10.26421/QIC15.3-4.</p> </li> </ol>"},{"location":"areas-of-application/condensed-matter-physics/fermi-hubbard-model/","title":"Fermi\u2013Hubbard model","text":""},{"location":"areas-of-application/condensed-matter-physics/fermi-hubbard-model/#overview","title":"Overview","text":"<p>The Fermi\u2013Hubbard model was originally introduced as a simplified model of electrons in materials [1], closely related to the tight-binding model. It displays a wide range of behaviors including metallic, insulating, and antiferromagnetic phases. The model has more recently found applicability in studying high-temperature superconductivity. The 2D Fermi\u2013Hubbard model has a complex phase diagram that appears to reproduce universal (rather than chemical-specific) features of the phase diagram of cuprate high-temperature superconductors.</p><p>General analytic solutions are not known (beyond 1D chains or specific parameter regimes\u2014see [2] for a recent discussion), which has motivated the use of numerical methods to understand the physics of the Fermi\u2013Hubbard model. More recently, there has been increased interest in understanding the nonequilibrium properties of the model, for example its behavior following a quench.</p><p>Quantum simulation of Fermi\u2013Hubbard models, based on the current estimates, requires considerably fewer resources than simulations of molecules or solving optimization problems. This makes the Fermi\u2013Hubbard model a promising candidate for early demonstrations of quantum advantage.</p>"},{"location":"areas-of-application/condensed-matter-physics/fermi-hubbard-model/#actual-end-to-end-problems-solved","title":"Actual end-to-end problem(s) solved","text":"<p>The Fermi\u2013Hubbard Hamiltonian on \\(M/2\\) sites is given by </p>\\[\\begin{equation} \\label{hamiltonianHubbard} H= -t \\sum_{\\sigma \\in \\{\\uparrow,\\downarrow\\}}\\sum_{\\langle i,j\\rangle}^{M/2} (c_{i\\sigma}^\\dagger c_{j\\sigma}+c_{j\\sigma}^\\dagger c_{i\\sigma})+U \\sum_{i}^{M/2} n_{i\\uparrow} n_{i\\downarrow}\\,, \\end{equation}\\]<p>where \\(c_{i\\sigma}\\) are fermionic operators and \\(n_{i\\sigma} \\equiv c_{i\\sigma}^\\dagger c_{i\\sigma}\\) is the number operator, with \\(t\\) denoting the strength of the kinetic term, \\(U\\) the onsite interaction strength, and \\(\\langle i,j\\rangle\\) a sum over nearest-neighbor lattice sites, given a lattice geometry. It is also possible to consider longer-range hopping terms, the inclusion of site-dependent chemical potentials, or additional \"orbitals\" per site.</p><p>Quantum simulation provides insights into both equilibrium and nonequilibrium physics. With regards to equilibrium physics, the primary computational task is to resolve and probe the properties of the phase diagram of the Fermi\u2013Hubbard model, as a function of: lattice geometry, parameter values \\((t, U)\\), doping (the expected number of fermions divided by the number of sites), and temperature. This is achieved by preparing the thermal state \\(\\rho \\propto e^{-\\beta H}\\) (or at zero temperature, the ground state \\(\\ket{E_0}\\)) for the Fermi\u2013Hubbard Hamiltonian instantiated by the given parameters, and measuring the expectation values of a set of physical observables to error \\(\\epsilon\\). A thorough discussion of this end-to-end problem (at zero temperature) is provided in [3], where it is shown how to</p><ul> <li>Prepare mean-field states in a given phase (for example a BCS superconducting ground state).</li> <li>Adiabatically evolve from the mean-field Hamiltonian to the final Fermi\u2013Hubbard Hamiltonian. The absence of a phase transition confirms the predicted phase.</li> <li>Measure observables, including density correlation functions \\((n_{i \\uparrow} + n_{i \\downarrow})(n_{j \\uparrow} + n_{j \\downarrow})\\), pair correlation functions \\(c_{i \\sigma}^\\dag c_{j \\sigma'}^\\dag c_{k \\sigma'} c_{l \\sigma}\\), and dynamical correlation functions \\(\\bra{E_0} e^{iHt} A e^{-iHt}B \\ket{E_0}\\) (for operators \\(A,B\\) and ground state \\(\\ket{E_0}\\)).</li> </ul><p>The difficulty of this problem depends on the parameter regime under consideration. The ground state in the weak coupling regime of \\(U &lt; 4t\\) is well understood, but questions remain in the intermediate (\\(4t \\leq U \\leq 6t\\)) and strong (\\(U &gt; 6t\\)) regimes [4]. Challenges include precisely determining the phase boundaries and understanding the nature of the superconducting phase [5]. Progress has been made on this latter question in recent years, for example showing the absence of a superconducting phase at the physically relevant parameters of \\(U \\sim 8t\\) and \\(1/8\\)th doping (see [4] for a more detailed discussion). Calculations are made challenging by small energy differences between competing phases, as well as the need to extrapolate from finite simulations to the thermodynamic limit.</p><p>The simulation of nonequilibrium quantum dynamics is of interest for modeling materials driven by an external field (for example an ultrafast laser pulse or an applied voltage), or following a quench in the Hamiltonian. Classically simulating nonequilibrium quantum dynamics has so far proven challenging and is a less-well-studied problem than probing the equilibrium physics of the model. Example applications include as a model for ultrafast spintronics, whereby lasers are used to manipulate spin degrees of freedom to control and store information [6] to better understand photo-induced phase transitions [7], or to clarify the nature of thermalization in isolated quantum systems following a quench [8].</p>"},{"location":"areas-of-application/condensed-matter-physics/fermi-hubbard-model/#dominant-resource-costcomplexity","title":"Dominant resource cost/complexity","text":""},{"location":"areas-of-application/condensed-matter-physics/fermi-hubbard-model/#mapping-the-problem-to-qubits","title":"Mapping the problem to qubits:","text":"<p>Simulation of the Fermi\u2013Hubbard model is most naturally performed in the second-quantized representation, as the regime of interest is usually close to half-filling (c.f. simulation of molecules). The Jordan\u2013Wigner mapping between fermions and qubits is typically used (it has not yet been established if other mappings [9, 10], which preserve locality, provide concrete advantages in the fault-tolerant setting). For an \\(L \\times L\\) lattice, we require \\(M = 2L^2\\) qubits to simulate the spinful Fermi\u2013Hubbard model using the Jordan\u2013Wigner mapping.</p>"},{"location":"areas-of-application/condensed-matter-physics/fermi-hubbard-model/#accessing-the-hamiltonian","title":"Accessing the Hamiltonian:","text":"<p>Quantum algorithms for simulating the Fermi\u2013Hubbard model require access to the Hamiltonian. This is typically provided by block-encoding or Hamiltonian simulation. The structure in the Fermi\u2013Hubbard Hamiltonian reduces the costs of these subroutines. For example, performing a block-encoding using the linear combinations of unitaries technique requires access to a PREPARE unitary and a SELECT unitary. The PREPARE unitary requires preparing a quantum state from classical data. Because the Fermi\u2013Hubbard Hamiltonian has a small number of unique coefficients, the cost of this unitary can be reduced. Combining the results of [11, 12, 13] one can implement an \\((M(2t+U/8), \\mathcal{O}\\left( \\log(M) \\right), \\epsilon)\\)-block-encoding of the Fermi\u2013Hubbard Hamiltonian using </p>\\[\\begin{equation} \\mathcal{O}\\left( M + \\log(M/\\epsilon) \\right) \\end{equation}\\]<p>non-Clifford gates.</p><p>As another example, the costs of Trotter approaches for Hamiltonian simulation can exploit the fact that many terms in the Fermi\u2013Hubbard Hamiltonian commute, due to their locality. We will explicitly discuss these costs below.</p>"},{"location":"areas-of-application/condensed-matter-physics/fermi-hubbard-model/#state-preparation","title":"State preparation:","text":"<ul> <li>Eigenstate preparation: There exist quantum algorithms that can prepare energy eigenstates using QSVT-based eigenstate filtering [14] (cost scales as \\(1/\\gamma\\) with \\(\\gamma\\) the overlap of the initial state with the desired eigenstate) or adiabatic state preparation (scaling depends on the gap between energy levels along the adiabatic path). Adiabatic state preparation was proposed as a method of classifying the phase diagram of the Fermi\u2013Hubbard model [3]. A discrete version of the adiabatic approach, based on qubitization, was numerically investigated in the context of preparing ground states of the Fermi\u2013Hubbard model [15], and showed promising results for the small system sizes considered (see also [16]).</li> <li>Thermal states: A number of algorithms have been developed for preparation of thermal states. The most promising of these algorithms depend on the mixing time of a Markov chain (as in classical Monte Carlo approaches for preparing Gibbs states), which is currently undetermined for the Fermi\u2013Hubbard model.</li> <li>Time evolution: As discussed above, Trotter approaches for Hamiltonian simulation can exploit beneficial features of the Fermi\u2013Hubbard Hamiltonian, such as locality, fixed particle number, and commutativity of the terms [17, 18, 19]. For a Fermi\u2013Hubbard model with \\(\\eta\\) fermions on \\(M\\) spin-lattice-sites, \\(p\\)th-order Trotter methods can simulate time evolution for time \\(\\tau\\) up to error \\(\\epsilon\\) using  \\[\\begin{equation} \\mathcal{O}\\left( \\frac{5^p M \\eta^{1/p} \\tau^{1+1/p}}{\\epsilon^{1/p}} \\right) \\end{equation}\\] <p>gates. Explicit gate counts for Trotterization can be obtained from [20, 18, 13, 21], which have focused on constant factors for low-order formulae, rather than the asymptotic scaling.   Post-Trotter methods, such as [22], using quantum signal processing as a building block, can achieve similar scaling in \\(M\\) and \\(t\\). A suboptimal approach (i.e., not using the method of [22]) briefly discussed in [23] has a gate complexity of approximately </p> \\[\\begin{equation} 44 M^2 (2t + 3U/8)\\tau \\end{equation}\\] <p>\\(T\\) gates to simulate time evolution for time \\(\\tau\\) using quantum signal processing, neglecting logarithmic dependence on the error of the simulation.<sup>1</sup></p> </li> </ul>"},{"location":"areas-of-application/condensed-matter-physics/fermi-hubbard-model/#measuring-observables","title":"Measuring observables:","text":"<ul> <li>Energies: Quantum phase estimation can be used to measure the energy eigenvalues of the Fermi\u2013Hubbard Hamiltonian, given access to an initial state \\(\\ket{\\psi}\\) that has sufficient overlap \\(\\gamma = |\\braket{\\psi}{E_j}|\\) with the target eigenstate \\(\\ket{E_j}\\). We require \\(\\mathcal{O}\\left( \\gamma^{-2} \\epsilon^{-1} \\right)\\) calls to a unitary \\(U\\) encoding the spectrum of the Hamiltonian to measure the energy to precision \\(\\epsilon\\).<sup>2</sup> Successfully applying QPE projects the initial state into the target eigenstate, which enables the measurement of other observables with respect to the target eigenstate.   Using \\(U \\approx e^{iHt}\\) implemented via second-order product formulae (the approximation error must be balanced against the error from QPE) results in a \\(T\\) gate count of \\(\\mathcal{O}\\left( M^{3/2}/\\Delta E^{3/2} \\right)\\) to resolve the energy of the Fermi\u2013Hubbard model to precision \\(\\Delta E\\), neglecting the cost of initial state preparation [20, 13]. Performing QPE on a quantum walk operator \\(W\\) which acts like \\(e^{i\\arccos{H}}\\) and can be implemented via qubitization [24, 25] results in a \\(T\\) gate scaling of \\(\\mathcal{O}\\left( M^2/\\Delta E \\right)\\), also neglecting the cost of initial state preparation [11].</li> <li>Other observables: There have been few studies considering the costs of measuring observables other than the ground state energy using fault-tolerant quantum algorithms. In general, it is important to minimize the number of calls to the unitary \\(U_\\psi\\) that prepares the desired state, as this is typically considered the dominant cost. Reference [3] discussed methods for measuring density correlation functions \\((n_{i \\uparrow} + n_{i \\downarrow})(n_{j \\uparrow} + n_{j \\downarrow})\\), pair correlation functions \\(\\smash{c_{i \\sigma}^\\dag c_{j \\sigma'}^\\dag c_{k \\sigma'} c_{l \\sigma}}\\), and dynamical correlation functions \\(\\smash{\\bra{E_0} e^{iHt} A e^{-iHt}B \\ket{E_0}}\\) (for operators \\(A,B\\) and ground state \\(\\ket{E_0}\\)), including approaches for nondestructively measuring some of these observables. Some of these approaches can now be reframed as performing amplitude estimation [26] on \\(U_O\\), a unitary block-encoding of the observable \\(O\\) with subnormalization factor \\(\\alpha_O\\) [27].   A recent approach [28, 29] based on the quantum gradient estimation algorithm of [30] simultaneously computes the value of \\(M\\) (noncommuting) observables \\(O_j\\). The algorithm makes \\(\\widetilde{\\mathcal{O}}\\left( M^{1/2}/\\epsilon \\right)\\) calls to \\(U_\\psi, U_\\psi^\\dag\\) (or \\(R_\\psi = I - 2 \\ket{\\psi}\\bra{\\psi}\\)) and either \\(\\widetilde{\\mathcal{O}}\\left( M^{3/2}/\\epsilon \\right)\\) calls to gates of the form \\(e^{i x O_j}\\) [28] or \\(\\widetilde{\\mathcal{O}}\\left( M/\\epsilon \\right)\\) calls to a block-encoding of the observables [29]. The algorithm also requires \\(\\mathcal{O}\\left( M \\log(1/\\epsilon) \\right)\\) additional qubits. This approach has been considered in the context of measuring fermionic reduced density matrices and dynamic correlation functions [28].</li> </ul>"},{"location":"areas-of-application/condensed-matter-physics/fermi-hubbard-model/#existing-error-corrected-resource-estimates","title":"Existing error corrected resource estimates","text":"<p>There have been a number of fault-tolerant resource estimates for algorithms targeting both static and dynamic properties of the Fermi\u2013Hubbard model. In Table 1, we present approximate resource estimates for simulations of the 2D \\(10\\times 10\\) spinful Fermi\u2013Hubbard model. The table presents the number of logical qubits and gates required to run the algorithm; these can be converted into physical resource estimates via methods for fault-tolerant quantum computation.</p><p>References [11, 12] applied qubitization-based quantum phase estimation to calculate the ground state energy to constant additive error. For a lattice with \\(M\\) spin orbitals, using the compilation of [11], the number of \\(T\\) gates scales as roughly [11, Eq. (61)] </p>\\[\\begin{equation} \\# T \\propto \\frac{(4t + U)M^2}{\\Delta E} \\end{equation}\\]<p>and the number of logical qubits scales as approximately [11, Eq. (62)] </p>\\[\\begin{equation} \\# \\mathrm{Qubits} \\sim M + \\log\\left( \\frac{(2t + 0.5U)M^4}{\\Delta E} \\right). \\end{equation}\\]<p>References [20, 13] applied second-order Trotter-based quantum phase estimation to calculate the ground state energy, targeting relative error. Relative errors are appropriate when energy densities in the thermodynamic limit are of interest, and are better suited to the poorer error scaling of Trotter methods (compared to post-Trotter methods like qubitization). In both references, rigorous but potentially loose upper bounds on the Trotter error are computed. For a lattice with \\(M\\) spin orbitals, using the compilation of [13], the number of \\(T\\) gates scales as roughly [13, Eqs. (C3), (D6), (D10), (E17), (F10)] </p>\\[\\begin{equation} \\# T \\propto t\\sqrt{t+U} \\left(\\frac{M}{\\Delta E}\\right)^{3/2} \\end{equation}\\]<p>and the number of logical qubits scales as approximately [13, Table II] </p>\\[\\begin{equation} \\# \\mathrm{Qubits} \\sim (1 + \\kappa)M \\end{equation}\\]<p>where \\(\\kappa\\) is a free parameter that controls the number of ancilla qubits used for a compilation technique known as Hamming weight phasing (which reduces the cost of applying identical arbitrary angle rotation gates in parallel) [31, 20], set to \\(\\kappa=0.25\\) in [13] and in our Table 1.</p> <p></p> Problem and method #T gates qubits Parameters via qubitized QPE [11, 12] \\(\\sim 10^8\\) \\(\\sim 236\\) \\(U/t=4\\) and \\(\\Delta E = 0.01t\\) via Trotterized QPE \u00a0[13, 20] \\(\\sim 5 \\times 10^6\\) \\(\\sim 250\\) \\(U/t = 8\\) and \\(\\Delta E = 0.005 E_{\\rm tot}\\) via fourth-order Trotter\u00a0[23] \\(4.6\\times 10^5\\) \\(200\\) \\(T=10/t\\), \\(U=t\\), and \\(\\epsilon \\leq 1\\%\\) <p>Table 1: Fault-tolerant resource estimates for quantum phase estimation (QPE) and dynamics simulation applied to a 2D \\(10\\times 10\\) Fermi\u2013Hubbard model. The QPE circuits target an energy error of \\(\\Delta E\\). In the second row, \\(E_{\\rm tot}\\) denotes the ground state energy. The dynamics simulation runs for time \\(T\\), and targets an error of less than \\(1\\%\\) in a spatially averaged intensive observable, with Trotter errors bounded numerically via extrapolated small-scale simulations. The presented gate counts are for a single run of the circuit. For QPE, the number of required runs depends on the overlap between the initial state and the ground state. For dynamics simulations, the number of circuit repetitions depends on the precision to which one wants to estimate a given observable. The parameters for each problem vary between different rows of the table, and so cannot be directly compared (although the different methods for the same problem, e.g., ground state energy estimation, could be compared by changing the analyses in the original papers to the desired matching parameter values). </p> <p>The methods described above for encoding the Hamiltonian spectra (qubitization and Trotter) can also be used to simulate the dynamics of the Fermi\u2013Hubbard model. Trotter methods can be applied directly, while qubitization can be combined with quantum signal processing (QSP) to perform Hamiltonian simulation. In [23], a comparison was made between fourth-order Trotterization and qubitization\\(+\\)QSP for simulating time evolution of a \\(10 \\times 10\\) Fermi\u2013Hubbard model. Trotter was determined to be the more efficient method, although this conclusion hinges on a Trotter decomposition with large steps (justified via numerical simulations). We note that the Trotter decompositions and analyses in [13, 23] are different, which hampers an immediate comparison. It may also be fruitful to compare with Hamiltonian simulation algorithms designed explicitly for simulating local Hamiltonians [22] (see discussion in [11]).</p>"},{"location":"areas-of-application/condensed-matter-physics/fermi-hubbard-model/#caveats","title":"Caveats","text":"<p>In general, preparing the ground state of the Fermi\u2013Hubbard model is known to be a hard problem, even for a quantum computer. This task has been proven QMA-hard for the Fermi\u2013Hubbard model with a site dependent magnetic field [32] and for the Fermi\u2013Hubbard model with a site-dependent \\(t \\rightarrow t_{ij}\\) [33]. While the complexity class of the canonical Fermi\u2013Hubbard model is not yet known, when preparing the ground state via quantum phase estimation or eigenstate filtering methods, it is necessary to prepare an initial state with an overlap that decays no worse than polynomially with system size; otherwise, the overall complexity will be superpolynomial. While numerical simulations on small system sizes have shown encouraging results [16, 15], it is still an open question as to whether this property holds for sufficiently large system sizes to enable extrapolation to the thermodynamic limit.</p><p>It is also important to note that this extrapolation of measured properties, computed at a range of finite system sizes, to the thermodynamic limit, has been observed to contribute a significant proportion of the uncertainty and errors in classical methods [34], and will also afflict quantum simulations.</p><p>Finally, it will be necessary to repeat simulations a large number of times. In order to measure a single observable to precision \\(\\epsilon\\) we require \\(\\mathcal{O}\\left( 1/\\epsilon^2 \\right)\\) incoherent repetitions of the simulation, or \\(\\mathcal{O}\\left( 1/\\epsilon \\right)\\) using methods based on amplitude estimation. To map out and compute properties of the phase diagram or extract the phase following a quench, we may need to measure a large number of observables. In some cases, it may be necessary to re-prepare the initial state for each observable.</p>"},{"location":"areas-of-application/condensed-matter-physics/fermi-hubbard-model/#comparable-classical-complexity-and-challenging-instance-sizes","title":"Comparable classical complexity and challenging instance sizes","text":"<p>The Fermi\u2013Hubbard model has been a fertile environment for the development and testing of classical numerical methods for both static and dynamical properties. State-of-the-art methods for computing the phase diagram include: quantum Monte Carlo methods (determinantal QMC, diagrammatic MC, auxiliary-field QMC, diffusion MC), density matrix renormalization group (DMRG), coupled cluster methods, impurity methods (dynamical mean-field theory, density matrix embedding theory), among others. These methods typically have an approximation parameter (e.g., the excitation degree in coupled cluster or the bond dimension in DMRG) which influences the scaling of the algorithm and the accuracy of the simulation. Modern numerical studies of the Fermi\u2013Hubbard model typically cross-validate using a number of simulation methods [34, 35]. For example, [34] benchmarked a range of methods and performed sufficiently large and accurate simulations for extrapolation to the thermodynamic limit. That work concluded that \"the ground-state properties of a substantial part of the Hubbard model phase space are now under numerical control,\" but that some uncertainties still remain for \\(4t \\leq U \\leq 8\\) and dopings near half-filling. For a recent review of numerical simulations of the Fermi\u2013Hubbard model, we refer the reader to [4].</p><p>The simulation of dynamics of the Fermi\u2013Hubbard model appears to be more challenging for classical methods. For example, [36, 23] concluded that simulating the dynamics of a \\(10 \\times 10\\) lattice would be infeasible for tensor network techniques. Other classical approaches for simulating time evolution of the Fermi\u2013Hubbard model include nonequilibrium extensions of dynamical mean-field theory [37] or Floquet methods [7].</p>"},{"location":"areas-of-application/condensed-matter-physics/fermi-hubbard-model/#speedup","title":"Speedup","text":"<p>The speedup of quantum algorithms for computing static properties, such as the ground state energy, of the Fermi\u2013Hubbard model is difficult to determine. In general, we know that closely related models are QMA-hard (see Caveats) and so should be exponentially difficult for both classical and quantum computers. Assuming an initial state that has overlap with the target eigenstate that decays no faster than polynomially, then quantum phase estimation can be used to efficiently measure the eigenenergy and project into the desired eigenstate. It does so with cost \\(\\mathcal{O}\\left( M^2/\\Delta E \\right)\\) or \\(\\mathcal{O}((M/\\Delta E)^{3/2})\\), depending on the quantum algorithm used. Exact classical methods such as exact diagonalization have a cost that scales exponentially with \\(M\\) or \\(1/\\Delta E\\). Approximate classical methods scale with an approximation parameter (e.g., bond dimension, number of excitations) which will depend on both \\(M\\) and \\(\\Delta E\\). For example, [38, Fig. 4] shows the convergence of a tensor network (PEPS) calculation for the 2D Fermi\u2013Hubbard model as a function of bond dimension and system size. For the small systems studied (up to \\(16 \\times 4\\) sites) the plots are consistent with the bond dimension scaling polynomially in \\(1/\\Delta E\\), with a weak dependence on the system size. If this holds for larger system sizes and across a range of system parameters, this would suggest that quantum algorithms provide only a polynomial speedup for computing the ground state energy.</p><p>Simulating the dynamics of the Fermi\u2013Hubbard Hamiltonian requires polynomial resources using quantum algorithms, scaling almost linearly in \\(M\\) and \\(\\tau\\). In contrast, all known classical methods appear to scale exponentially in system size and simulation accuracy. For example, [23] used tensor network (matrix product state) approaches for simulating the dynamics of the Fermi\u2013Hubbard model following a quench. When truncating the bond dimension to facilitate efficient classical simulation, they found that errors in the observables grew exponentially with time. While this supports the conclusion of an exponential quantum speedup, we note that classical approaches will likely continue to improve and be applied to increasingly large system sizes. By using carefully engineered interactions (e.g., deviating significantly from a square lattice) it can be shown that simulating the dynamics of the Fermi\u2013Hubbard model on a planar graph is a BQP-complete problem, and so is expected to be hard for classical computers, in the worst case [39].</p>"},{"location":"areas-of-application/condensed-matter-physics/fermi-hubbard-model/#nisq-implementations","title":"NISQ implementations","text":"<p>There have been a number of proposals (and experimental demonstrations) of simulating the Fermi\u2013Hubbard model on NISQ hardware. Ground state calculations can be performed using the variational quantum eigensolver (VQE) [40, 41, 42, 43, 44], and experimental demonstrations have been carried out on lattices of size \\(1 \\times 8\\) and \\(2 \\times 4\\) using 16 superconducting qubits, yielding qualitative agreement with theoretical expectation [45].</p><p>Dynamics can be simulated using Hamiltonian simulation (typically Trotter methods) [18] and have been demonstrated for an \\(8 \\times 1\\) lattice on 16 superconducting qubits [46].</p><p>The simple Hamiltonian of the Fermi\u2013Hubbard model makes it well suited to realization in analog quantum simulators, including ultracold atoms in optical lattices, trapped ions, and neutral atom arrays. It has been argued that some local observables can be robust to errors in the simulation [47, 23], enabling analog simulations to already surpass classical methods for simulating dynamics. We refer the reader to [36, 48] for additional discussion on analog simulation.</p>"},{"location":"areas-of-application/condensed-matter-physics/fermi-hubbard-model/#outlook","title":"Outlook","text":"<p>The Fermi\u2013Hubbard model provides a longstanding and physically relevant computational challenge. The low gate counts and modest number of logical qubits required to compute ground state energies could make quantum algorithms competitive with leading classical approaches in challenging regimes. We note that further research is required to ascertain the costs for initial state preparation for these calculations. For the less-well-studied task of simulating the dynamics of the Fermi\u2013Hubbard model, quantum algorithms currently provide an exponential speedup over known classical algorithms. Nevertheless, as the Fermi\u2013Hubbard Hamiltonian is sufficiently simple to be realized in many controlled physical systems, future fault-tolerant quantum computers will also have to compete against analog quantum simulators.</p>"},{"location":"areas-of-application/condensed-matter-physics/fermi-hubbard-model/#bibliography","title":"Bibliography","text":"<ol> <li> <p>J. Hubbard and Brian Hilton Flowers. Electron correlations in narrow energy bands. Proceedings of the Royal Society A, 276(1365):238\u2013257, 1963. URL: https://royalsocietypublishing.org/doi/abs/10.1098/rspa.1963.0204, arXiv:https://royalsocietypublishing.org/doi/pdf/10.1098/rspa.1963.0204, doi:10.1098/rspa.1963.0204.</p> </li> <li> <p>Daniel P. Arovas, Erez Berg, Steven A. Kivelson, and Srinivas Raghu. The hubbard model. Annual Review of Condensed Matter Physics, 13:239\u2013274, 2022. arXiv: https://arxiv.org/abs/2103.12097. arXiv:2103.12097, doi:10.1146/annurev-conmatphys-031620-102024.</p> </li> <li> <p>Dave Wecker, Matthew B. Hastings, Nathan Wiebe, Bryan K. Clark, Chetan Nayak, and Matthias Troyer. Solving strongly correlated electron models on a quantum computer. Physical Review A, 92:062318, 12 2015. arXiv: https://arxiv.org/abs/1506.05135. URL: https://link.aps.org/doi/10.1103/PhysRevA.92.062318, doi:10.1103/PhysRevA.92.062318.</p> </li> <li> <p>Mingpu Qin, Thomas Schafer, Sabine Andergassen, Philippe Corboz, and Emanuel Gull. The hubbard model: a computational perspective. Annual Review of Condensed Matter Physics, 13:275\u2013302, 2022. arXiv: https://arxiv.org/abs/2104.00064. arXiv:2104.00064, doi:10.1146/annurev-conmatphys-090921-033948.</p> </li> <li> <p>Eduardo Fradkin, Steven A. Kivelson, and John M. Tranquada. Colloquium: theory of intertwined orders in high temperature superconductors. Reviews of Modern Physics, 87:457\u2013482, 5 2015. arXiv: https://arxiv.org/abs/1407.4480. URL: https://link.aps.org/doi/10.1103/RevModPhys.87.457, doi:10.1103/RevModPhys.87.457.</p> </li> <li> <p>Igor \u017duti\u0107, Jaroslav Fabian, and S. Das Sarma. Spintronics: fundamentals and applications. Reviews of Modern Physics, 76:323\u2013410, 4 2004. arXiv: https://arxiv.org/abs/cond-mat/0405528. URL: https://link.aps.org/doi/10.1103/RevModPhys.76.323, doi:10.1103/RevModPhys.76.323.</p> </li> <li> <p>Takashi Oka and Sota Kitamura. Floquet engineering of quantum materials. Annual Review of Condensed Matter Physics, 10(1):387\u2013408, 2019. arXiv: https://arxiv.org/abs/1804.03212. URL: https://doi.org/10.1146/annurev-conmatphys-031218-013423, arXiv:https://doi.org/10.1146/annurev-conmatphys-031218-013423, doi:10.1146/annurev-conmatphys-031218-013423.</p> </li> <li> <p>Anatoli Polkovnikov, Krishnendu Sengupta, Alessandro Silva, and Mukund Vengalattore. Colloquium: nonequilibrium dynamics of closed interacting quantum systems. Reviews of Modern Physics, 83:863\u2013883, 8 2011. arXiv: https://arxiv.org/abs/1007.5331. URL: https://link.aps.org/doi/10.1103/RevModPhys.83.863, doi:10.1103/RevModPhys.83.863.</p> </li> <li> <p>Frank Verstraete and J Ignacio Cirac. Mapping local hamiltonians of fermions to local hamiltonians of spins. Journal of Statistical Mechanics: Theory and Experiment, 2005(09):P09012, 2005. arXiv: https://arxiv.org/abs/cond-mat/0508353.</p> </li> <li> <p>Charles Derby, Joel Klassen, Johannes Bausch, and Toby Cubitt. Compact fermion to qubit mappings. Physical Review B, 104:035118, 7 2021. URL: https://link.aps.org/doi/10.1103/PhysRevB.104.035118, doi:10.1103/PhysRevB.104.035118.</p> </li> <li> <p>Ryan Babbush, Craig Gidney, Dominic W. Berry, Nathan Wiebe, Jarrod McClean, Alexandru Paler, Austin Fowler, and Hartmut Neven. Encoding electronic spectra in quantum circuits with linear t complexity. Physical Review X, 8(4):041015, 2018. arXiv: https://arxiv.org/abs/1805.03662. doi:10.1103/PhysRevX.8.041015.</p> </li> <li> <p>Nobuyuki Yoshioka, Tsuyoshi Okubo, Yasunari Suzuki, Yuki Koizumi, and Wataru Mizukami. Hunting for quantum-classical crossover in condensed matter problems. arXiv: https://arxiv.org/abs/2210.14109, 2022.</p> </li> <li> <p>Earl T Campbell. Early fault-tolerant simulations of the hubbard model. Quantum Science and Technology, 7(1):015007, 11 2021. arXiv: https://arxiv.org/abs/2012.09238. URL: https://dx.doi.org/10.1088/2058-9565/ac3110, doi:10.1088/2058-9565/ac3110.</p> </li> <li> <p>Lin Lin and Yu Tong. Near-optimal ground state preparation. Quantum, 4:372, 2020. arXiv: https://arxiv.org/abs/2002.12508. doi:10.22331/q-2020-12-14-372.</p> </li> <li> <p>Jessica Lemieux, Guillaume Duclos-Cianci, David S\u00e9n\u00e9chal, and David Poulin. Resource estimate for quantum many-body ground-state preparation on a quantum computer. Physical Review A, 103(5):052408, 2021. arXiv: https://arxiv.org/abs/2006.04650. arXiv:2006.04650, doi:10.1103/PhysRevA.103.052408.</p> </li> <li> <p>Norm M. Tubman, Carlos Mejuto-Zaera, Jeffrey M. Epstein, Diptarka Hait, Daniel S. Levine, William Huggins, Zhang Jiang, Jarrod R. McClean, Ryan Babbush, Martin Head-Gordon, and K. Birgitta Whaley. Postponing the orthogonality catastrophe: efficient state preparation for electronic structure simulations on quantum devices. arXiv: https://arxiv.org/abs/1809.05523, 2018.</p> </li> <li> <p>Andrew M Childs and Yuan Su. Nearly optimal lattice simulation by product formulas. Physical Review Letters, 123(5):050503, 2019. arXiv: https://arxiv.org/abs/1901.00564. arXiv:1901.00564, doi:10.1103/PhysRevLett.123.050503.</p> </li> <li> <p>Laura Clinton, Johannes Bausch, and Toby Cubitt. Hamiltonian simulation algorithms for near-term quantum hardware. Nature Communications, 12(1):4989, 8 2021. arXiv: https://arxiv.org/abs/2003.06886. URL: https://doi.org/10.1038/s41467-021-25196-0, doi:10.1038/s41467-021-25196-0.</p> </li> <li> <p>Yuan Su, Hsin Yuan Huang, and Earl T. Campbell. Nearly tight trotterization of interacting electrons. Quantum, 5(1):1\u201358, 2021. arXiv: https://arxiv.org/abs/2012.09194. arXiv:2012.09194, doi:10.22331/Q-2021-07-05-495.</p> </li> <li> <p>Ian D. Kivlichan, Craig Gidney, Dominic W. Berry, Nathan Wiebe, Jarrod McClean, Wei Sun, Zhang Jiang, Nicholas Rubin, Austin Fowler, Al\u00e1n Aspuru-Guzik, Hartmut Neven, and Ryan Babbush. Improved fault-tolerant quantum simulation of condensed-phase correlated electrons via trotterization. Quantum, 4:296, 7 2020. arXiv: https://arxiv.org/abs/1902.10673. URL: https://doi.org/10.22331/q-2020-07-16-296, doi:10.22331/q-2020-07-16-296.</p> </li> <li> <p>Ansgar Schubert and Christian B Mendl. Trotter error with commutator scaling for the fermi\u2013hubbard model. arXiv: https://arxiv.org/abs/2306.10603, 2023.</p> </li> <li> <p>Jeongwan Haah, Matthew B. Hastings, Robin Kothari, and Guang Hao Low. Quantum algorithm for simulating real time evolution of lattice hamiltonians. In Proceedings of the 59th IEEE Symposium on Foundations of Computer Science (FOCS), 350\u2013360. 2018. arXiv: https://arxiv.org/abs/1801.03922. doi:10.1109/FOCS.2018.00041.</p> </li> <li> <p>S Flannigan, N Pearson, G H Low, A Buyskikh, I Bloch, P Zoller, M Troyer, and A J Daley. Propagation of errors and quantitative quantum simulation with quantum advantage. Quantum Science and Technology, 7(4):045025, 8 2022. arXiv: https://arxiv.org/abs/2204.13644. URL: https://dx.doi.org/10.1088/2058-9565/ac88f5, doi:10.1088/2058-9565/ac88f5.</p> </li> <li> <p>David Poulin, Alexei Kitaev, Damian S. Steiger, Matthew B. Hastings, and Matthias Troyer. Quantum algorithm for spectral measurement with a lower gate count. Physical Review Letters, 121:010501, 7 2018. arXiv: https://arxiv.org/abs/1711.11025. URL: https://link.aps.org/doi/10.1103/PhysRevLett.121.010501, doi:10.1103/PhysRevLett.121.010501.</p> </li> <li> <p>Dominic W. Berry, M\u00e1ria Kieferov\u00e1, Artur Scherer, Yuval R. Sanders, Guang Hao Low, Nathan Wiebe, Craig Gidney, and Ryan Babbush. Improved techniques for preparing eigenstates of fermionic hamiltonians. npj Quantum Information, 4(1):22, 5 2018. arXiv: https://arxiv.org/abs/1711.10460. URL: https://doi.org/10.1038/s41534-018-0071-5, doi:10.1038/s41534-018-0071-5.</p> </li> <li> <p>Emanuel Knill, Gerardo Ortiz, and Rolando D. Somma. Optimal quantum measurements of expectation values of observables. Physical Review A, 75:012328, 1 2007. arXiv: https://arxiv.org/abs/quant-ph/0607019. URL: https://link.aps.org/doi/10.1103/PhysRevA.75.012328, doi:10.1103/PhysRevA.75.012328.</p> </li> <li> <p>Patrick Rall. Quantum algorithms for estimating physical quantities using block encodings. Physical Review A, 102:022408, 8 2020. arXiv: https://arxiv.org/abs/2004.06832. URL: https://link.aps.org/doi/10.1103/PhysRevA.102.022408, doi:10.1103/PhysRevA.102.022408.</p> </li> <li> <p>William J. Huggins, Kianna Wan, Jarrod McClean, Thomas E. O'Brien, Nathan Wiebe, and Ryan Babbush. Nearly optimal quantum algorithm for estimating multiple expectation values. Physical Review Letters, 129:240501, 12 2022. arXiv: https://arxiv.org/abs/2111.09283. URL: https://link.aps.org/doi/10.1103/PhysRevLett.129.240501, doi:10.1103/PhysRevLett.129.240501.</p> </li> <li> <p>Joran van Apeldoorn, Arjan Cornelissen, Andr\u00e1s Gily\u00e9n, and Giacomo Nannicini. Quantum tomography using state-preparation unitaries. In Proceedings of the 34th ACM-SIAM Symposium on Discrete Algorithms (SODA), 1265\u20131318. 2023. arXiv: https://arxiv.org/abs/2207.08800. doi:10.1137/1.9781611977554.ch47.</p> </li> <li> <p>Andr\u00e1s Gily\u00e9n, Srinivasan Arunachalam, and Nathan Wiebe. Optimizing quantum optimization algorithms via faster quantum gradient computation. In Proceedings of the 30th ACM-SIAM Symposium on Discrete Algorithms (SODA), 1425\u20131444. 2019. arXiv: https://arxiv.org/abs/1711.00465. doi:10.1137/1.9781611975482.87.</p> </li> <li> <p>Craig Gidney. Halving the cost of quantum addition. Quantum, 2:74, 2018. arXiv: https://arxiv.org/abs/1709.06648. arXiv:1709.06648, doi:10.22331/q-2018-06-18-74.</p> </li> <li> <p>Norbert Schuch and Frank Verstraete. Computational complexity of interacting electrons and fundamental limitations of density functionaltheory. Nature Physics, 5(10):732\u2013735, 2009. arXiv: https://arxiv.org/abs/0712.0483. arXiv:0712.0483, doi:10.1038/nphys1370.</p> </li> <li> <p>Bryan O'Gorman, Sandy Irani, James Whitfield, and Bill Fefferman. Intractability of electronic structure in a fixed basis. PRX Quantum, 3:020322, 5 2022. arXiv: https://arxiv.org/abs/2103.08215. URL: https://link.aps.org/doi/10.1103/PRXQuantum.3.020322, doi:10.1103/PRXQuantum.3.020322.</p> </li> <li> <p>J. P. F. LeBlanc, Andrey E. Antipov, Federico Becca, Ireneusz W. Bulik, Garnet Kin-Lic Chan, Chia-Min Chung, Youjin Deng, Michel Ferrero, Thomas M. Henderson, Carlos A. Jim\u00e9nez-Hoyos, E. Kozik, Xuan-Wen Liu, Andrew J. Millis, N. V. Prokof'ev, Mingpu Qin, Gustavo E. Scuseria, Hao Shi, B. V. Svistunov, Luca F. Tocchio, I. S. Tupitsyn, Steven R. White, Shiwei Zhang, Bo-Xiao Zheng, Zhenyue Zhu, and Emanuel Gull. Solutions of the two-dimensional hubbard model: benchmarks and results from a wide range of numerical algorithms. Physical Review X, 5:041041, 12 2015. arXiv: https://arxiv.org/abs/1505.02290. URL: https://link.aps.org/doi/10.1103/PhysRevX.5.041041, doi:10.1103/PhysRevX.5.041041.</p> </li> <li> <p>Thomas Sch\u00e4fer, Nils Wentzell, Fedor \u0160imkovic, Yuan-Yao He, Cornelia Hille, Marcel Klett, Christian J. Eckhardt, Behnam Arzhang, Viktor Harkov, Fran \u00e7 \u00e7ois-Marie Le R\u00e9gent, Alfred Kirsch, Yan Wang, Aaram J. Kim, Evgeny Kozik, Evgeny A. Stepanov, Anna Kauch, Sabine Andergassen, Philipp Hansmann, Daniel Rohe, Yuri M. Vilk, James P. F. LeBlanc, Shiwei Zhang, A.-M. S. Tremblay, Michel Ferrero, Olivier Parcollet, and Antoine Georges. Tracking the footprints of spin fluctuations: a multimethod, multimessenger study of the two-dimensional hubbard model. Physical Review X, 11:011058, 3 2021. arXiv: https://arxiv.org/abs/2006.10769. URL: https://link.aps.org/doi/10.1103/PhysRevX.11.011058, doi:10.1103/PhysRevX.11.011058.</p> </li> <li> <p>Andrew J. Daley, Immanuel Bloch, Christian Kokail, Stuart Flannigan, Natalie Pearson, Matthias Troyer, and Peter Zoller. Practical quantum advantage in quantum simulation. Nature, 607(7920):667\u2013676, 2022. doi:10.1038/s41586-022-04940-6.</p> </li> <li> <p>Hideo Aoki, Naoto Tsuji, Martin Eckstein, Marcus Kollar, Takashi Oka, and Philipp Werner. Nonequilibrium dynamical mean-field theory and its applications. Reviews of Modern Physics, 86:779\u2013837, 6 2014. arXiv: https://arxiv.org/abs/1310.5329. URL: https://link.aps.org/doi/10.1103/RevModPhys.86.779, doi:10.1103/RevModPhys.86.779.</p> </li> <li> <p>Seunghoon Lee, Joonho Lee, Huanchen Zhai, Yu Tong, Alexander M. Dalzell, Ashutosh Kumar, Phillip Helms, Johnnie Gray, Zhi-Hao Cui, Wenyuan Liu, Michael Kastoryano, Ryan Babbush, John Preskill, David R. Reichman, Earl T. Campbell, Edward F. Valeev, Lin Lin, and Garnet Kin-Lic Chan. Evaluating the evidence for exponential quantum advantage in ground-state quantum chemistry. Nature Communications, 14(1):1952, 2023. arXiv: https://arxiv.org/abs/2208.02199. URL: https://doi.org/10.1038/s41467-023-37587-6, doi:10.1038/s41467-023-37587-6.</p> </li> <li> <p>Ning Bao, Patrick Hayden, Grant Salton, and Nathaniel Thomas. Universal quantum computation by scattering in the fermi\u2013hubbard model. New Journal of Physics, 17(9):093028, 2015. arXiv: https://arxiv.org/abs/1409.3585.</p> </li> <li> <p>Zhang Jiang, Kevin J. Sung, Kostyantyn Kechedzhi, Vadim N. Smelyanskiy, and Sergio Boixo. Quantum algorithms to simulate many-body physics of correlated fermions. Physical Review Applied, 9(4):44036, 2018. arXiv: https://arxiv.org/abs/1711.05395. URL: https://doi.org/10.1103/PhysRevApplied.9.044036, arXiv:1711.05395, doi:10.1103/PhysRevApplied.9.044036.</p> </li> <li> <p>Jan Michael Reiner, Sebastian Zanker, Iris Schwenk, Juha Leppakangas, Frank Wilhelm-Mauch, Gerd Sch\u00f6n, and Michael Marthaler. Effects of gate errors in digital quantum simulations of fermionic systems. Quantum Science and Technology, 2018. arXiv: https://arxiv.org/abs/1804.06668. arXiv:1804.06668, doi:10.1088/2058-9565/aad5ba.</p> </li> <li> <p>Jan Michael Reiner, Frank Wilhelm-Mauch, Gerd Sch\u00f6n, and Michael Marthaler. Finding the ground state of the hubbard model by variational methods on a quantum computer with gate errors. Quantum Science and Technology, 2019. arXiv: https://arxiv.org/abs/1811.04476. arXiv:1811.04476, doi:10.1088/2058-9565/ab1e85.</p> </li> <li> <p>Zhenyu Cai. Resource estimation for quantum variational simulations of the hubbard model. Physical Review Applied, 14(1):1, 2020. arXiv: https://arxiv.org/abs/1910.02719. URL: https://doi.org/10.1103/PhysRevApplied.14.014059, arXiv:1910.02719, doi:10.1103/PhysRevApplied.14.014059.</p> </li> <li> <p>Chris Cade, Lana Mineh, Ashley Montanaro, and Stasja Stanisic. Strategies for solving the fermi\u2013hubbard model on near-term quantum computers. Physical Review B, 102:235122, 12 2020. arXiv: https://arxiv.org/abs/1912.06007. URL: https://link.aps.org/doi/10.1103/PhysRevB.102.235122, doi:10.1103/PhysRevB.102.235122.</p> </li> <li> <p>Stasja Stanisic, Jan Lukas Bosse, Filippo Maria Gambetta, Raul A. Santos, Wojciech Mruczkiewicz, Thomas E. O'Brien, Eric Ostby, and Ashley Montanaro. Observing ground-state properties of the fermi\u2013hubbard model using a scalable algorithm on a quantum computer. Nature Communications, 13(1):5743, 2022. arXiv: https://arxiv.org/abs/2112.02025. URL: https://doi.org/10.1038/s41467-022-33335-4, doi:10.1038/s41467-022-33335-4.</p> </li> <li> <p>Frank Arute, Kunal Arya, Ryan Babbush, Dave Bacon, Joseph C. Bardin, Rami Barends, Andreas Bengtsson, Sergio Boixo, Michael Broughton, Bob B. Buckley, David A. Buell, Brian Burkett, Nicholas Bushnell, Yu Chen, Zijun Chen, Yu-An Chen, Ben Chiaro, Roberto Collins, Stephen J. Cotton, William Courtney, Sean Demura, Alan Derk, Andrew Dunsworth, Daniel Eppens, Thomas Eckl, Catherine Erickson, Edward Farhi, Austin Fowler, Brooks Foxen, Craig Gidney, Marissa Giustina, Rob Graff, Jonathan A. Gross, Steve Habegger, Matthew P. Harrigan, Alan Ho, Sabrina Hong, Trent Huang, William Huggins, Lev B. Ioffe, Sergei V. Isakov, Evan Jeffrey, Zhang Jiang, Cody Jones, Dvir Kafri, Kostyantyn Kechedzhi, Julian Kelly, Seon Kim, Paul V. Klimov, Alexander N. Korotkov, Fedor Kostritsa, David Landhuis, Pavel Laptev, Mike Lindmark, Erik Lucero, Michael Marthaler, Orion Martin, John M. Martinis, Anika Marusczyk, Sam McArdle, Jarrod R. McClean, Trevor McCourt, Matt McEwen, Anthony Megrant, Carlos Mejuto-Zaera, Xiao Mi, Masoud Mohseni, Wojciech Mruczkiewicz, Josh Mutus, Ofer Naaman, Matthew Neeley, Charles Neill, Hartmut Neven, Michael Newman, Murphy Yuezhen Niu, Thomas E. O'Brien, Eric Ostby, B\u00e1lint Pat\u00f3, Andre Petukhov, Harald Putterman, Chris Quintana, Jan-Michael Reiner, Pedram Roushan, Nicholas C. Rubin, Daniel Sank, Kevin J. Satzinger, Vadim Smelyanskiy, Doug Strain, Kevin J. Sung, Peter Schmitteckert, Marco Szalay, Norm M. Tubman, Amit Vainsencher, Theodore White, Nicolas Vogt, Z. Jamie Yao, Ping Yeh, Adam Zalcman, and Sebastian Zanker. Observation of separated dynamics of charge and spin in the fermi\u2013hubbard model. arXiv: https://arxiv.org/abs/2010.07965, 2020. URL: http://arxiv.org/abs/2010.07965.</p> </li> <li> <p>Pablo M. Poggi. Analysis of lower bounds for quantum control times and their relation to the quantum speed limit. arXiv: https://arxiv.org/abs/2002.11147, 2020. URL: http://arxiv.org/abs/2002.11147, arXiv:2002.11147.</p> </li> <li> <p>Christian Gross and Immanuel Bloch. Quantum simulations with ultracold atoms in optical lattices. Science, 357(6355):995\u20131001, 2017. doi:10.1126/science.aal3837.</p> </li> </ol> <ol> <li> <p>Note that in [23], \\(M\\) is defined as the number of lattice sites, and so corresponds to \\(M/2\\) here.\u00a0\u21a9</p> </li> <li> <p>It is possible to improve the complexity to \\(\\mathcal{O}\\left( \\gamma^{-1} \\epsilon^{-1} \\right)\\) using amplitude amplification if a sufficiently precise estimate of the eigenvalue is known, or to \\(\\mathcal{O}\\left( \\gamma^{-2} \\Delta^{-1} + \\epsilon^{-1} \\right)\\) by exploiting knowledge of the gap \\(\\Delta\\) between the energy eigenstates to perform rejection sampling [25].\u00a0\u21a9</p> </li> </ol>"},{"location":"areas-of-application/condensed-matter-physics/introduction/","title":"Condensed matter physics","text":"<p>Condensed matter physics constructs and studies the behavior of simplified models designed to capture the universal physics of material systems. Phenomena of interest include: magnetism, phase transitions, superconductivity, frustrated systems, topological phases, and the interplay of thermalization and many-body localization in closed systems. While many seminal models can be studied analytically in certain limits (for example the 1D and 2D classical Ising model), a number of seemingly innocuous models have proven exceedingly difficult to solve. This has led to some models, such as the Fermi\u2013Hubbard model, becoming a proving ground for classical numerical methods. While there has been significant progress in recent decades in understanding the physics of these models through numerical simulation, it is still a challenging problem for many models and parameter regimes. As observed by Feynman [1], quantum computers have a natural advantage over their classical counterparts for simulating the simple Hamiltonians studied in condensed matter physics. While Feynman's proposal was more focused on analog simulation, digital quantum simulation of condensed matter systems has evolved into a major research direction. In this section, we focus on models whose end-to-end complexities have been well studied in the literature: the Fermi\u2013Hubbard model, the Sachdev\u2013Ye\u2013Kitaev (SYK) model, and spin models.</p>"},{"location":"areas-of-application/condensed-matter-physics/introduction/#bibliography","title":"Bibliography","text":"<ol> <li>Richard P. Feynman. Simulating physics with computers. International Journal of Theoretical Physics, 21(6-7):467\u2013488, 1982. doi:10.1007/BF02650179.</li> </ol>"},{"location":"areas-of-application/condensed-matter-physics/spin-models/","title":"Spin models","text":""},{"location":"areas-of-application/condensed-matter-physics/spin-models/#overview","title":"Overview","text":"<p>Classical and quantum spin systems are prototypical models for a wide range of physical phenomena including: magnetism, neuron activity, simplified models of materials and molecules, and networks. Studying the properties of spin Hamiltonians can also provide useful insights in quantum information science.</p><p>A number of scientific and industrial problems can be mapped onto finding the ground or thermal states of classical or quantum spin models, for example solving combinatorial optimization problems, training energy-based models in machine learning, and simulating low energy models of quantum chemistry [1].</p><p>Simulating the dynamics of quantum spin models is primarily of interest for quantum information science, and condensed matter physics or chemistry, for example interpreting nuclear magnetic resonance [2, 3] or related spectroscopy experiments [4, 5].</p><p>Because of the natural mapping between spin-\\(1/2\\) systems and qubits, as well as the locality of interactions commonly present, the resources required to simulate simple spin models using quantum algorithms can be much lower than for problems in areas like quantum chemistry or cryptography.</p><p>While our discussion will focus on quantum algorithms designed to be run on fault-tolerant quantum computers, the simple Hamiltonians of spin models are naturally realized in many physical systems. This has led to the use of analog simulators [6, 7], such as arrays of trapped ions or neutral atoms, for simulating the static and dynamic properties of interesting spin models. We will comment briefly on this below.</p>"},{"location":"areas-of-application/condensed-matter-physics/spin-models/#actual-end-to-end-problems-solved","title":"Actual end-to-end problem(s) solved","text":"<p>The most commonly studied spin models are those with pairwise interactions, referred to as \\(2\\)-local Hamiltonians. We note that the interactions are not necessarily geometrically local, although this will be present in many models of physical systems. Given a graph \\(\\mathcal{G}\\) with \\(N\\) vertices \\(\\{v_i\\}\\) and \\(L\\) edges \\(\\{E_{ij}\\}\\) we associate a classical or quantum spin with each vertex, and an interaction between spins with each edge. We can also add one-body interactions acting on individual spins. The Hamiltonian can then be written as </p>\\[\\begin{equation} \\label{Eq:SpinHamiltonian} H = \\sum_{v_i\\in V} \\sum_{\\alpha \\in \\{x,y,z\\}} B_i^\\alpha \\sigma_\\alpha^i + \\sum_{E_{ij} \\in E} \\sum_{\\alpha, \\beta \\in \\{x,y,z\\}} J_{ij}^{\\alpha \\beta} \\sigma_\\alpha^i \\sigma_\\beta^j \\end{equation}\\]<p>where \\(\\{\\sigma_x^i,\\sigma_y^i,\\sigma_z^i\\}\\) denote the Pauli operators \\(X_i,Y_i,Z_i\\) acting on site \\(i\\), and \\(\\{B_i^\\alpha\\}, \\{J_{ij}^{\\alpha \\beta}\\}\\) are coefficients. For classical spin Hamiltonians, the sums are restricted to \\(Z\\) operators. The Hamiltonian in Eq. \\(\\eqref{Eq:SpinHamiltonian}\\) encompasses a wide range of spin models, including: the classical Ising model </p>\\[\\begin{equation} H = \\sum_i B_i Z_i + \\sum_{ij} J_{ij} Z_i Z_j \\end{equation}\\]<p>which also describes the Hamiltonians arising from quadratic unconstrained binary optimization (QUBO) problems, the (quantum) transverse field Ising model (TFIM) </p>\\[\\begin{equation} H = B \\sum_i X_i + J \\sum_{ij} Z_i Z_j\\,, \\end{equation}\\]<p>and the Heisenberg model with a site-dependent magnetic field, defined in 1D with nearest-neighbor interactions by </p>\\[\\begin{equation} H = \\sum_j B_j Z_j + J^x X_j X_{j+1} + J^y Y_j Y_{j+1} + J^z Z_j Z_{j+1}. \\end{equation}\\]<p>Across the different models, we can vary the dimension, locality of interactions (e.g. nearest-neighbor vs. fully connected vs. power-law), and values of the site-dependent coefficients in comparison to the interaction terms. The models can be extended beyond 2-local by considering couplings of 3 or more spins\u2014see for example \\(p\\)-spin models, which are \\(p\\)-local [8]. The above definitions can be extended from spin-\\(1/2\\) systems to higher spin operators by generalizing the Pauli operators with their higher dimensional counterparts.</p><p>For classical spin models we seek to prepare the ground or thermal states of the model, as these may encode, for example, the solution to a combinatorial optimization problem, or a probability distribution that can be used for generative modelling. For quantum spin models, we similarly seek to compute ground or thermal states. However, because these are not classical states that can be easily extracted, we typically wish to sample observables with respect to these states. Examples include the energy, the magnetization of the system, or correlations between sites. In dynamical simulations of quantum systems, we seek to determine how observables of interest vary as a function of evolution time. Examples include the magnetization (used to infer the Hamiltonian in NMR [9] or related [10] experiments), or the growth of correlations between sites to probe thermalization. Hamiltonian simulation can efficiently access not only any feature that could be observed for simulated targets (e.g., solid-state materials of interest), but also additional features [11] which can lead to deeper understanding of the physics involved. Since studies of quench dynamics often require preparation of simple states (such as product states or the ground states of classically solvable Hamiltonians) and the measurement of local observables, propagation under the Hamiltonian typically dominates the simulation cost. For lattice systems with \\(N\\) spins in \\(D\\) dimensions, it is conventional to consider evolution times that scale as \\(\\Omega\\left(N^{1/D}\\right)\\), as the system must evolve for this long for self-thermalization to take place or even for information to propagate across the system due to the Lieb\u2013Robinson bound [12].</p>"},{"location":"areas-of-application/condensed-matter-physics/spin-models/#dominant-resource-costcomplexity","title":"Dominant resource cost/complexity","text":"<p>For a system of \\(N\\) spin-\\(1/2\\) particles, we require \\(N\\) qubits to represent the state of the system. For \\(N\\) spin-\\(S\\) particles, the problem can be mapped to qubits in different ways, for example using \\(N \\lceil \\log_2(2S+1)\\rceil\\) [13] qubits or using \\(2NS\\) qubits [5].</p><p>Quantum algorithms for preparing the ground or Gibbs states of classical spin systems are discussed in detail in the sections on combinatorial optimization, and energy-based machine learning models, respectively. We will restrict our discussion to the resources required for performing time evolution of quantum spin models. The reason for this is that quantum algorithms for preparing ground or thermal states require similar primitives for Hamiltonian access to algorithms for time evolution (e.g., block-encodings or Hamiltonian simulation itself) and use these in conjunction with either: eigenstate filtering approaches [14, 15] based on quantum singular value transformation, adiabatic state preparation, quantum phase estimation from a trial state, or quantum algorithms for thermal state preparation. More detailed discussions of these algorithms and their caveats can be found on the linked pages, as well as in the discussion of quantum algorithms for simulating molecules and materials or the Fermi\u2013Hubbard model, where preparing (approximate) eigenstates is the primary topic of interest. All of these algorithms depend on either an overlap between the trial state and the target state, the minimum gap along an adiabatic path, or the mixing time of a Markov chain\u2014all of which are difficult to bound in the general case.</p><p>When simulating the time evolution of spin systems, the most efficient algorithms exploit the locality of interactions in the Hamiltonian, and the resulting commutation structure. For \\(2\\)-local spin-\\(1/2\\) systems on a \\(D\\)-dimensional lattice with nearest-neighbor geometric locality, algorithms with almost optimal gate complexity are known for performing time evolution. Reference [16] showed that \\((2k)\\)th-order product formulae scale as \\(\\mathcal{O}\\left( (Nt)^{1+1/2k} / \\epsilon^{1/2k} \\right)\\) to simulate time evolution for time \\(t\\) to accuracy \\(\\epsilon\\), using a Hamiltonian given in the Pauli access model. Note that this expression suppresses the \\(5^{2k}\\) constant factor present in \\((2k)\\)th-order Trotter. Similarly, [17] gave an algorithm with complexity \\(\\mathcal{O}\\left( Nt \\cdot \\mathrm{polylog}(Nt/\\epsilon) \\right)\\) for Hamiltonians given in the sparse access model. In contrast, note that approaches that are asymptotically optimal in the black-box setting, such as quantum signal processing, have a gate complexity of \\(\\mathcal{O}\\left( N^2Dt + \\log(1/\\epsilon) \\right)\\) using a block-encoding based on linear combinations of unitaries (LCU).</p><p>Spin Hamiltonians with power-law interactions were studied in [18, 19], that is, where the interaction strength between spins \\(i\\) and \\(j\\) depends inversely on a power of the distance between the spins, denoted by \\(\\nrm{i-j}_2\\). For a \\(D\\)-dimensional lattice with \\(2\\)-local interactions with interaction strengths scaling as \\(1/\\nrm{i-j}_2^\\alpha\\), \\((2k)\\)th-order Trotter gives a scaling of (as above, suppressing the \\(5^{2k}\\) constant factor present in \\(2k\\)th-order Trotter) [19] </p>\\[\\begin{equation} \\widetilde{\\mathcal{O}}\\left( \\begin{array}{rcl} N^{3-\\frac{\\alpha}{D}(1+1/2k)+1/k} t^{1+1/2k}\\epsilon^{-1/2k} &amp; &amp; \\text{for } 0 \\leq \\alpha &lt; D, \\\\ N^{2+1/2k} t^{1+1/2k}\\epsilon^{-1/2k} &amp; &amp; \\alpha \\geq D\\end{array} \\right). \\end{equation}\\]<p>Focusing on the \\(D=1\\) case, if one were to directly apply quantum signal processing based on a block-encoding via the LCU approach, the scaling would be </p>\\[\\begin{equation} \\widetilde{\\mathcal{O}}\\left( N^2 t + \\log(1/\\epsilon) \\right) \\end{equation}\\]<p>These asymptotic complexities are complemented by the constant factor analyses discussed in the following section.</p><p>For estimating expectation values of observables to precision \\(\\epsilon\\), one can either consider directly sampling and then re-preparing the state of interest (scaling as \\(\\mathcal{O}\\left( 1/\\epsilon^2 \\right)\\)), or coherent approaches based on amplitude estimation scaling as \\(\\mathcal{O}\\left( 1/\\epsilon \\right)\\), but requiring a longer coherent circuit depth. Measurements of simple observables, such as the magnetization, can be obtained through the computational basis measurements on single qubits. For more complicated observables, one can consider the approaches in [20, 21, 22], discussed in more detail in the section on quantum chemistry.</p>"},{"location":"areas-of-application/condensed-matter-physics/spin-models/#existing-error-corrected-resource-estimates","title":"Existing error corrected resource estimates","text":"<p>A number of fault-tolerant resource estimates for simulating the dynamics of spin systems, or for finding their ground states via quantum phase estimation have been reported in the literature. In such calculations it is necessary to optimize the constant factor contributions from implementing the algorithmic primitives used. A detailed comparative study on simulating the dynamics of a 1D nearest-neighbor Heisenberg model was reported in [23], comparing the logical qubit and \\(T\\) gate counts of product formulae, Taylor series, and quantum signal processing. The two most efficient approaches are shown in the first two rows of Table 1.</p> <p></p> Problem Method #\u00a0Spins #\u00a0\\(T\\) gates Logical qubits Parameters 1D Heisenberg dyn. QSP \\(50\\) \\(2.4\\times 10^9\\) \\(67\\) \\(\\begin{gathered}B_j \\in [-1,1], J^x=J^y=J^z=1,\\\\t=N, \\epsilon=10^{-3}\\end{gathered}\\) \u00a0[23] 1D Heisenberg dyn. Trotter (6th order) \\(50\\) \\(1.8\\times 10^8\\) \\(50\\) \\(\\begin{gathered}B_j \\in [-1,1], J^x=J^y=J^z=1,\\\\t=N, \\epsilon=10^{-3}\\end{gathered}\\) [23] 2D NN TFIM<sup>1</sup> dyn. Trotter (4th order) \\(100\\) \\(1.7\\times 10^5\\) \\(100\\) \\(t=10/J, B=J, \\epsilon=10^{-2}\\) [24, 25] 2D \\(1/r^2\\) TFIM dyn. Trotter (4th order) \\(100\\) \\(1.5\\times 10^7\\) \\(100\\) \\(t=10/J, B=J, \\epsilon=10^{-2}\\) [24] 2D Heisenberg ground state with nearest- and next-nearest-neighbor interactions Qubitized QPE \\(100\\) \\(10^8\\) N.C.<sup>2</sup> \\(\\epsilon=10^{-2}, J_1=1, J_2=0.5, B_j=0\\) \u00a0 \u00a0 \u00a0 \u00a0 [26] <p>Table 1: Fault-tolerant resource estimates for quantum phase estimation (QPE) and dynamics simulation (dyn.) applied to different spin models. The presented gate counts are for a single run of the circuit. The results presented in rows 1 and 2 can be compared to each other, and both target an error of \\(\\epsilon=10^{-3}\\) in the operator norm distance between the ideal and implemented time evolution unitary. While [23] presents both analytic and empirical Trotter error bounds, the gate count presented in the table is that resulting from the empirical bound, though we remark that more recent analytic bounds are close to matching the empirical bounds [19]. The results presented in rows 3 and 4 can be compared to each other, and determine the number of Trotter steps used empirically by targeting an error of \\(\\epsilon=10^{-2}\\) in a particular spatially averaged local observable, and then extrapolating this behavior to larger system sizes. </p> <p>On a fault-tolerant quantum computer arbitrary angle rotation gates must be synthesized using a larger number of \\(T\\) and Clifford gates [27]. The number of \\(T\\) gates to synthesize a group of parallel rotation gates can be reduced if they share the same angle [28, 29]. This technique can be exploited in fault-tolerant compilations of algorithms simulating physical spin systems, which often exhibit features such as translational invariance.</p><p>In addition to the entries given in Table 1, fault-tolerant approaches to simulating NMR [3] and muon spectroscopy [5] experiments, which are effectively spin model simulations, have been considered.</p>"},{"location":"areas-of-application/condensed-matter-physics/spin-models/#caveats","title":"Caveats","text":"<p>The decision forms of the ground state problem for 2-local classical and quantum spin models are NP\u2013complete [30, 31] and QMA\u2013complete [32], respectively. As such, we do not expect quantum algorithms to provide efficient solutions to these problems in the general case. Nevertheless, given the success of classical heuristics for these problems, one may hope to observe a similar benefit from quantum heuristic algorithms, such as Monte Carlo\u2013style Gibbs sampling algorithms.</p><p>In contrast, simulating the dynamics of spin models is a BQP-complete problem [33], and is likely one of the most simple beyond-classical calculations that could be performed on a future fault-tolerant quantum computer. While such a computation would be of great scientific interest, providing new insights in quantum information and many-body physics, it is currently unclear whether dynamics simulations of large systems will have a direct impact on industrially relevant applications.</p>"},{"location":"areas-of-application/condensed-matter-physics/spin-models/#comparable-classical-complexity-and-challenging-instance-sizes","title":"Comparable classical complexity and challenging instance sizes","text":"<p>Exact classical simulations of quantum spin models are exponentially costly in system size. Exact simulations that consider a time evolution long enough for information to propagate across the system (as per the Lieb\u2013Robinson bound) are thus limited to around 50 spins using the largest classical supercomputers [34, 23].</p><p>Approximate classical algorithms for studying quantum spin systems include tensor network approaches and quantum Monte Carlo methods. These methods provide empirically accurate results for computing the ground states of physically motivated spin systems, in particular those with local interactions, in low dimensions. For example, the ground states of local, gapped 1D Hamiltonians have area law entanglement, and so can be efficiently represented by matrix product states. Similar statements can be made in 2D, using e.g. projected entangled pair states (PEPS).</p><p>In contrast, these methods are less accurate when performing simulations of quantum spin dynamics [35, 36]. In these systems the entanglement entropy grows linearly with time [37], resulting in a cost that grows exponentially with time for tensor network approaches targeting fixed accuracy. For example, it was claimed in [24] that simulations of the dynamics of the 2D TFIM for \\(N=100\\) spins would be far beyond the current capabilities of tensor network methods [24].</p><p>Many physical systems are subject to strong interactions with their environment which limits their coherence times. In these cases, the behavior of the system can often be reproduced by simulating a smaller number of spins (e.g. \\(\\leq 30\\)) and accounting for the interactions with the environment through physically motivated heuristics [38]. Such simulations (accessible via open source software libraries) are used to analyze NMR [9] and muon spectroscopy experiments [10].</p>"},{"location":"areas-of-application/condensed-matter-physics/spin-models/#speedup","title":"Speedup","text":"<p>The speedup for computing the ground states of quantum spin Hamiltonians over classical approximate methods (such as tensor networks or quantum Monte Carlo) is currently an open research question. A large speedup appears to require the availability of good initial states for quantum algorithms, without also being able to efficiently solve the problem classically [39].</p><p>The simulation of quantum spin dynamics appears to be exponentially costly using all known classical methods. As such, quantum algorithms for Hamiltonian simulation would provide an exponential speedup for this task. This would likely provide insights in quantum information and many\u2013body physics. As an example, such systems could study the competition and interplay between thermalization and many\u2013body localization in quantum systems.</p>"},{"location":"areas-of-application/condensed-matter-physics/spin-models/#nisq-implementations","title":"NISQ implementations","text":"<p>Quantum spin models are commonly used as benchmark systems for NISQ algorithms\u2014e.g. finding ground states [40], simulating dynamics [41], or probing thermalization [42].</p><p>The Hamiltonians of spin models are also naturally realized in a wide range of physical systems, including trapped ions or neutral atoms [6, 7]. For example, recent experiments in neutral atom systems have studied the dynamics of \\(\\mathcal{O}\\left( 200 \\right)\\) spins, which went beyond the capabilities of classical simulation via matrix product state approaches [43, 44]. Analog simulators are already an important tool providing new scientific insights, and they set a high bar for the future performance of fault-tolerant approaches to simulating spin systems.</p>"},{"location":"areas-of-application/condensed-matter-physics/spin-models/#outlook","title":"Outlook","text":"<p>Simulating the behavior of spin systems is arguably one of the most natural tasks for quantum computers, and is exponentially costly using all known classical methods. Such simulations can provide important insights into questions in quantum information and many-body physics, as well as acting as models for more complex systems in condensed matter physics and chemistry.</p><p>Fault-tolerant resource estimates for quantum algorithms simulating spin systems are among the lowest known for beyond-classical tasks. Nevertheless, analog quantum simulators are already able to natively simulate the dynamics of hundreds of spins. In order to surpass these capabilities, digital approaches may need to consider more complex observables, or target accuracies not available with error correction.</p><p>In addition, for many systems of scientific interest in related fields, such as chemistry or condensed matter physics, decoherence\u2013inducing interactions with the environment often limit the required simulation sizes. Identifying applications requiring accurate simulation of the dynamics of large spin models would increase the impact and applicability of quantum algorithms in this area.</p>"},{"location":"areas-of-application/condensed-matter-physics/spin-models/#bibliography","title":"Bibliography","text":"<ol> <li> <p>Ruslan N. Tazhigulov, Shi-Ning Sun, Reza Haghshenas, Huanchen Zhai, Adrian T.K. Tan, Nicholas C. Rubin, Ryan Babbush, Austin J. Minnich, and Garnet Kin-Lic Chan. Simulating models of challenging correlated molecules and materials on the sycamore quantum processor. PRX Quantum, 3:040318, 11 2022. arXiv: https://arxiv.org/abs/2203.15291. URL: https://link.aps.org/doi/10.1103/PRXQuantum.3.040318, doi:10.1103/PRXQuantum.3.040318.</p> </li> <li> <p>Dries Sels, Hesam Dashti, Samia Mora, Olga Demler, and Eugene Demler. Quantum approximate bayesian computation for nmr model inference. Nature Machine Intelligence, 2(7):396\u2013402, 7 2020. arXiv: https://arxiv.org/abs/1910.14221. URL: https://doi.org/10.1038/s42256-020-0198-x, doi:10.1038/s42256-020-0198-x.</p> </li> <li> <p>Thomas E. O'Brien, Lev B. Ioffe, Yuan Su, David Fushman, Hartmut Neven, Ryan Babbush, and Vadim Smelyanskiy. Quantum computation of molecular structure using data from challenging-to-classically-simulate nuclear magnetic resonance experiments. PRX Quantum, 3:030345, 9 2022. arXiv: https://arxiv.org/abs/2109.02163. URL: https://link.aps.org/doi/10.1103/PRXQuantum.3.030345, doi:10.1103/PRXQuantum.3.030345.</p> </li> <li> <p>A. Chiesa, F. Tacchino, M. Grossi, P. Santini, I. Tavernelli, D. Gerace, and S. Carretta. Quantum hardware simulating four-dimensional inelastic neutron scattering. Nature Physics, 15(5):455\u2013459, 5 2019. arXiv: https://arxiv.org/abs/1809.07974. URL: https://doi.org/10.1038/s41567-019-0437-4, doi:10.1038/s41567-019-0437-4.</p> </li> <li> <p>Sam McArdle. Learning from physics experiments with quantum computers: applications in muon spectroscopy. PRX Quantum, 2:020349, 6 2021. arXiv: https://arxiv.org/abs/2012.06602. URL: https://link.aps.org/doi/10.1103/PRXQuantum.2.020349, doi:10.1103/PRXQuantum.2.020349.</p> </li> <li> <p>Immanuel Bloch, Jean Dalibard, and Sylvain Nascimb\u00e8ne. Quantum simulations with ultracold quantum gases. Nature Physics, 8(4):267\u2013276, 4 2012. URL: http://www.nature.com/doifinder/10.1038/nphys2259, arXiv:nphys2259, doi:10.1038/nphys2259.</p> </li> <li> <p>I. M. Georgescu, S. Ashhab, and Franco Nori. Quantum simulation. Reviews of Modern Physics, 86(1):153\u2013185, 2014. arXiv: https://arxiv.org/abs/1308.6253. arXiv:1308.6253, doi:10.1103/RevModPhys.86.153.</p> </li> <li> <p>B. Derrida. Random-energy model: limit of a family of disordered models. Physical Review Letters, 45:79\u201382, 7 1980. URL: https://link.aps.org/doi/10.1103/PhysRevLett.45.79, doi:10.1103/PhysRevLett.45.79.</p> </li> <li> <p>H.J. Hogben, M. Krzystyniak, G.T.P. Charnock, P.J. Hore, and Ilya Kuprov. Spinach \u2013 a software library for simulation of spin dynamics in large spin systems. Journal of Magnetic Resonance, 208(2):179\u2013194, 2011. URL: https://www.sciencedirect.com/science/article/pii/S1090780710003575, doi:https://doi.org/10.1016/j.jmr.2010.11.008.</p> </li> <li> <p>Pietro Bonf\u00e0, Jonathan Frassineti, Muhammad Maikudi Isah, Ifeanyi John Onuorah, and Samuele Sanna. Undi: an open-source library to simulate muon-nuclear interactions in solids. Computer Physics Communications, 260:107719, 2021. URL: https://www.sciencedirect.com/science/article/pii/S0010465520303556, doi:https://doi.org/10.1016/j.cpc.2020.107719.</p> </li> <li> <p>Joana Fraxanet, Tymoteusz Salamon, and Maciej Lewenstein. The Coming Decades of Quantum Simulation, pages 85\u2013125. Springer International Publishing, Cham, 2023, arXiv: https://arxiv.org/abs/2204.08905. URL: https://doi.org/10.1007/978-3-031-32469-7\\_4, doi:10.1007/978-3-031-32469-7\\_4.</p> </li> <li> <p>Chi-Fang Chen, Andrew Lucas, and Chao Yin. Speed limits and locality in many-body quantum dynamics. arXiv: https://arxiv.org/abs/2303.07386, 2023.</p> </li> <li> <p>Nicolas PD Sawaya, Tim Menke, Thi Ha Kyaw, Sonika Johri, Al\u00e1n Aspuru-Guzik, and Gian Giacomo Guerreschi. Resource-efficient digital quantum simulation of d-level systems for photonic, vibrational, and spin-s hamiltonians. npj Quantum Information, 6(1):1\u201313, 2020. arXiv: https://arxiv.org/abs/1909.12847. doi:https://doi.org/10.1038/s41534-020-0278-0.</p> </li> <li> <p>Lin Lin and Yu Tong. Optimal polynomial based quantum eigenstate filtering with application to solving quantum linear systems. Quantum, 4:361, 2020. arXiv: https://arxiv.org/abs/1910.14596. doi:10.22331/q-2020-11-11-361.</p> </li> <li> <p>Lin Lin and Yu Tong. Near-optimal ground state preparation. Quantum, 4:372, 2020. arXiv: https://arxiv.org/abs/2002.12508. doi:10.22331/q-2020-12-14-372.</p> </li> <li> <p>Andrew M Childs and Yuan Su. Nearly optimal lattice simulation by product formulas. Physical Review Letters, 123(5):050503, 2019. arXiv: https://arxiv.org/abs/1901.00564. arXiv:1901.00564, doi:10.1103/PhysRevLett.123.050503.</p> </li> <li> <p>Jeongwan Haah, Matthew B. Hastings, Robin Kothari, and Guang Hao Low. Quantum algorithm for simulating real time evolution of lattice hamiltonians. In Proceedings of the 59th IEEE Symposium on Foundations of Computer Science (FOCS), 350\u2013360. 2018. arXiv: https://arxiv.org/abs/1801.03922. doi:10.1109/FOCS.2018.00041.</p> </li> <li> <p>Minh C. Tran, Andrew Y. Guo, Yuan Su, James R. Garrison, Zachary Eldredge, Michael Foss-Feig, Andrew M. Childs, and Alexey V. Gorshkov. Locality and digital quantum simulation of power-law interactions. Physical Review X, 9:031006, 7 2019. arXiv: https://arxiv.org/abs/1808.05225. URL: https://link.aps.org/doi/10.1103/PhysRevX.9.031006, doi:10.1103/PhysRevX.9.031006.</p> </li> <li> <p>Andrew M. Childs, Yuan Su, Minh C. Tran, Nathan Wiebe, and Shuchen Zhu. Theory of trotter error with commutator scaling. Physical Review X, 2 2021. arXiv: https://arxiv.org/abs/1912.08854. doi:10.1103/physrevx.11.011020.</p> </li> <li> <p>Patrick Rall. Quantum algorithms for estimating physical quantities using block encodings. Physical Review A, 102:022408, 8 2020. arXiv: https://arxiv.org/abs/2004.06832. URL: https://link.aps.org/doi/10.1103/PhysRevA.102.022408, doi:10.1103/PhysRevA.102.022408.</p> </li> <li> <p>William J. Huggins, Kianna Wan, Jarrod McClean, Thomas E. O'Brien, Nathan Wiebe, and Ryan Babbush. Nearly optimal quantum algorithm for estimating multiple expectation values. Physical Review Letters, 129:240501, 12 2022. arXiv: https://arxiv.org/abs/2111.09283. URL: https://link.aps.org/doi/10.1103/PhysRevLett.129.240501, doi:10.1103/PhysRevLett.129.240501.</p> </li> <li> <p>Joran van Apeldoorn, Arjan Cornelissen, Andr\u00e1s Gily\u00e9n, and Giacomo Nannicini. Quantum tomography using state-preparation unitaries. In Proceedings of the 34th ACM-SIAM Symposium on Discrete Algorithms (SODA), 1265\u20131318. 2023. arXiv: https://arxiv.org/abs/2207.08800. doi:10.1137/1.9781611977554.ch47.</p> </li> <li> <p>Andrew M. Childs, Dmitri Maslov, Yunseong Nam, Neil J. Ross, and Yuan Su. Toward the first quantum simulation with quantum speedup. Proceedings of the National Academy of Sciences, 115(38):9456\u20139461, 2018. arXiv: https://arxiv.org/abs/1711.10980. doi:10.1073/pnas.1801723115.</p> </li> <li> <p>S Flannigan, N Pearson, G H Low, A Buyskikh, I Bloch, P Zoller, M Troyer, and A J Daley. Propagation of errors and quantitative quantum simulation with quantum advantage. Quantum Science and Technology, 7(4):045025, 8 2022. arXiv: https://arxiv.org/abs/2204.13644. URL: https://dx.doi.org/10.1088/2058-9565/ac88f5, doi:10.1088/2058-9565/ac88f5.</p> </li> <li> <p>Michael E. Beverland, Prakash Murali, Matthias Troyer, Krysta M. Svore, Torsten Hoeffler, Vadym Kliuchnikov, Guang Hao Low, Mathias Soeken, Aarthi Sundaram, and Alexander Vaschillo. Assessing requirements to scale to practical quantum advantage. arXiv: https://arxiv.org/abs/2211.07629, 2022. URL: http://arxiv.org/abs/2211.07629.</p> </li> <li> <p>Nobuyuki Yoshioka, Tsuyoshi Okubo, Yasunari Suzuki, Yuki Koizumi, and Wataru Mizukami. Hunting for quantum-classical crossover in condensed matter problems. arXiv: https://arxiv.org/abs/2210.14109, 2022.</p> </li> <li> <p>A Yu Kitaev. Quantum computations: algorithms and error correction. Russian Mathematical Surveys, 52(6):1191, 1997. doi:10.1070/RM1997v052n06ABEH002155.</p> </li> <li> <p>Craig Gidney. Halving the cost of quantum addition. Quantum, 2:74, 2018. arXiv: https://arxiv.org/abs/1709.06648. arXiv:1709.06648, doi:10.22331/q-2018-06-18-74.</p> </li> <li> <p>Earl T Campbell. Early fault-tolerant simulations of the hubbard model. Quantum Science and Technology, 7(1):015007, 11 2021. arXiv: https://arxiv.org/abs/2012.09238. URL: https://dx.doi.org/10.1088/2058-9565/ac3110, doi:10.1088/2058-9565/ac3110.</p> </li> <li> <p>F Barahona. On the computational complexity of ising spin glass models. Journal of Physics A: Mathematical and Theoretical, 15(10):3241\u20133253, 10 1982. URL: https://doi.org/10.1088/0305-4470/15/10/028, doi:10.1088/0305-4470/15/10/028.</p> </li> <li> <p>Andrew Lucas. Ising formulations of many np problems. Frontiers in Physics, 2014. arXiv: https://arxiv.org/abs/1302.5843. URL: https://www.frontiersin.org/articles/10.3389/fphy.2014.00005, doi:10.3389/fphy.2014.00005.</p> </li> <li> <p>Julia Kempe, Alexei Kitaev, and Oded Regev. The complexity of the local hamiltonian problem. SIAM Journal on Computing, 35(5):1070\u20131097, 2006. Earlier version in FSTTCS'04. arXiv: https://arxiv.org/abs/quant-ph/0406180. doi:10.1137/S009753970444522.</p> </li> <li> <p>Seth Lloyd. Universal quantum simulators. Science, 273(5278):1073\u20131078, 1996. doi:10.1126/science.273.5278.1073.</p> </li> <li> <p>Thomas H\u00e4ner and Damian S Steiger. 0.5 petabyte simulation of a 45-qubit quantum circuit. In Proceedings of the International Conference for High Performance Computing, Networking, Storage and Analysis. New York, NY, USA, 2017. Association for Computing Machinery. arXiv: https://arxiv.org/abs/1704.01127. URL: https://doi.org/10.1145/3126908.3126947, doi:10.1145/3126908.3126947.</p> </li> <li> <p>Norbert Schuch, Michael M. Wolf, Frank Verstraete, and J. Ignacio Cirac. Entropy scaling and simulability by matrix product states. Physical Review Letters, 100(3):030504, 2008. arXiv: https://arxiv.org/abs/0705.0292. doi:10.1103/PhysRevLett.100.030504.</p> </li> <li> <p>Ulrich Schollw\u00f6ck. The density-matrix renormalization group in the age of matrix product states. Annals of Physics, 326(1):96\u2013192, 2011. arXiv: https://arxiv.org/abs/1008.3477. arXiv:1008.3477, doi:10.1016/j.aop.2010.09.012.</p> </li> <li> <p>Pasquale Calabrese and John Cardy. Evolution of entanglement entropy in one-dimensional systems. Journal of Statistical Mechanics: Theory and Experiment, pages 04010, 2005. arXiv: https://arxiv.org/abs/cond-mat/0503393. arXiv:0503393, doi:10.1088/1742-5468/2005/04/P04010.</p> </li> <li> <p>J. M. Wilkinson and S. J. Blundell. Information and decoherence in a muon-fluorine coupled system. Physical Review Letters, 125:087201, 8 2020. arXiv: https://arxiv.org/abs/2003.02762. URL: https://link.aps.org/doi/10.1103/PhysRevLett.125.087201, doi:10.1103/PhysRevLett.125.087201.</p> </li> <li> <p>Seunghoon Lee, Joonho Lee, Huanchen Zhai, Yu Tong, Alexander M. Dalzell, Ashutosh Kumar, Phillip Helms, Johnnie Gray, Zhi-Hao Cui, Wenyuan Liu, Michael Kastoryano, Ryan Babbush, John Preskill, David R. Reichman, Earl T. Campbell, Edward F. Valeev, Lin Lin, and Garnet Kin-Lic Chan. Evaluating the evidence for exponential quantum advantage in ground-state quantum chemistry. Nature Communications, 14(1):1952, 2023. arXiv: https://arxiv.org/abs/2208.02199. URL: https://doi.org/10.1038/s41467-023-37587-6, doi:10.1038/s41467-023-37587-6.</p> </li> <li> <p>Abhinav Kandala, Antonio Mezzacapo, Kristan Temme, Maika Takita, Markus Brink, Jerry M. Chow, and Jay M. Gambetta. Hardware-efficient variational quantum eigensolver for small molecules and quantum magnets. Nature, 549(7671):242\u2013246, 9 2017. arXiv: https://arxiv.org/abs/1704.05018. URL: https://doi.org/10.1038/nature23879, doi:10.1038/nature23879.</p> </li> <li> <p>Eliott Rosenberg, Trond Andersen, Rhine Samajdar, Andre Petukhov, Jesse Hoke, Dmitry Abanin, Andreas Bengtsson, Ilya Drozdov, Catherine Erickson, Paul Klimov, and others. Dynamics of magnetization at infinite temperature in a heisenberg spin chain. arXiv: https://arxiv.org/abs/2306.09333, 2023.</p> </li> <li> <p>X Mi, AA Michailidis, S Shabani, KC Miao, PV Klimov, J Lloyd, E Rosenberg, R Acharya, I Aleiner, TI Andersen, and others. Stable quantum-correlated many body states via engineered dissipation. arXiv: https://arxiv.org/abs/2304.13878, 2023.</p> </li> <li> <p>Sepehr Ebadi, Tout T. Wang, Harry Levine, Alexander Keesling, Giulia Semeghini, Ahmed Omran, Dolev Bluvstein, Rhine Samajdar, Hannes Pichler, Wen Wei Ho, Soonwon Choi, Subir Sachdev, Markus Greiner, Vladan Vuletic, and Mikhail D. Lukin. Quantum phases of matter on a 256-atom programmable quantum simulator. Nature, 595:227, 2021. arXiv: https://arxiv.org/abs/2012.12281. URL: http://arxiv.org/abs/2012.12281, arXiv:2012.12281, doi:10.1038/s41586-021-03582-4.</p> </li> <li> <p>Pascal Scholl, Michael Schuler, Hannah J. Williams, Alexander A. Eberharter, Daniel Barredo, Kai Niklas Schymik, Vincent Lienhard, Louis Paul Henry, Thomas C. Lang, Thierry Lahaye, Andreas M. L\u00e4uchli, and Antoine Browaeys. Quantum simulation of 2d antiferromagnets with hundreds of rydberg atoms. Nature, 595(7866):233\u2013238, 2021. arXiv: https://arxiv.org/abs/2012.12268. doi:10.1038/s41586-021-03585-1.</p> </li> </ol> <ol> <li> <p>2D nearest-neighbor transverse field Ising model.\u00a0\u21a9</p> </li> <li> <p>Not computed, scales as \\(\\mathcal{O}\\left( N+ \\log(N) + \\log(N/\\epsilon) \\right)\\).\u00a0\u21a9</p> </li> </ol>"},{"location":"areas-of-application/condensed-matter-physics/syk-model/","title":"SYK model","text":""},{"location":"areas-of-application/condensed-matter-physics/syk-model/#overview","title":"Overview","text":"<p>The Sachdev\u2013Ye\u2013Kitaev (SYK) model [1, 2] is a simplified model of a quantum black hole that is strongly coupled and \"maximally chaotic,\" but still solvable. This remarkable and, to date, unique combination of properties has led to great activity surrounding SYK. It has applications in high-energy physics through its connections to black holes and quantum gravity, and it has applications in condensed matter physics as a model of quantum chaos and scrambling, which sheds light on phases of matter in strongly coupled metals [3, 4]. While many interesting properties of the SYK model can be computed analytically in certain limits, not all properties qualify, and questions remain about the behavior of the model outside of these limits\u2014these questions can potentially be addressed numerically by a quantum computer.</p>"},{"location":"areas-of-application/condensed-matter-physics/syk-model/#actual-end-to-end-problems-solved","title":"Actual end-to-end problem(s) solved","text":"<p>The SYK model has many variants; a common version to consider is the four-body (\\(q=4\\)) Majorana fermion Hamiltonian with Gaussian coefficients </p>\\[\\begin{align} H_{\\rm SYK} = \\frac{1}{4\\times 4!}\\sum_{i,j,k,\\ell=1}^N g_{ijk\\ell} \\; \\chi_i\\chi_j \\chi_k \\chi_{\\ell} \\,, \\end{align}\\]<p>where \\(\\chi_i\\) denote Majorana fermion mode operators obeying the anticommutation relation \\(\\chi_i\\chi_j+\\chi_j\\chi_i = 2\\delta_{ij}\\), and \\(g_{ijk\\ell}\\) are coefficients drawn independently at random from a Gaussian distribution with zero mean and variance \\(\\sigma^2 = 3!g^2/N^3\\) (with \\(g\\) the tunable coupling strength).</p><p>In the limit of a large number of local degrees of freedom \\(N\\rightarrow \\infty\\) and at strong coupling \\(\\beta g \\gg 1\\) (where \\(\\beta\\) is the inverse of the temperature), the SYK model is exactly solvable (to physicists' rigor) for certain properties and provides insights into quantum gravity and quantum chaos. However, questions remain about the wealth of properties out of reach by taking limits or the nonasymptotic regime of parameters. For example, it has been challenging to rigorously calculate the density of states at a certain energy or the ground state energy of the four-body SYK model at the large-\\(N\\) limit [5, 6, 7]. These problems can potentially be probed numerically on a quantum computer.</p><p>Generally speaking, this often boils down to performing the following task on the quantum computer: given as input an instance of \\(H_{\\rm SYK}\\) (generated by choosing the couplings \\(g_{ijk\\ell}\\) at random) and an observable \\(O\\), estimate the expectation value \\(\\text{tr}(\\rho O)\\), where \\(\\rho\\) could be, for instance, (i) the ground state of \\(H_{\\rm SYK}\\), (ii) the thermal state \\(\\rho \\propto e^{-\\beta H_{\\rm SYK}}\\), or (iii) a time-evolved state \\(\\rho = e^{iH_{\\rm SYK}t}\\ket{0}\\bra{0}e^{-iH_{\\rm SYK}t}\\) from an easy-to-prepare initial state \\(\\ket{0}\\), among other possibilities. The observable \\(O\\) could be a local operator or even \\(H_{\\rm SYK}\\) itself. Another case is for \\(O\\) to be composed of \\(t\\)-dependent time-evolution unitaries \\(e^{iH_{\\rm SYK}t}\\).</p><p>For example, computing the ground state energy corresponds to taking \\(\\rho\\) to be the ground state of \\(H_{\\rm SYK}\\) and \\(O\\) to be \\(H_{\\rm SYK}\\), and computing a 4-point out-of-time-ordered correlation function corresponds to taking \\(\\rho\\) to be the thermal state at inverse temperature \\(\\beta\\) and \\(O\\) to be \\(Ae^{iH_{\\rm SYK}t}Be^{-iH_{\\rm SYK}t}Ae^{iH_{\\rm SYK}t}Be^{-iH_{\\rm SYK}t}\\), where \\(A\\) and \\(B\\) are few-body operators [8]. In another example, [9, 10] give a detailed proposal to \"simulate quantum gravity in the lab\" via computing expectation values of observables and states formed via simulation of the SYK model.</p><p>Depending on the ultimate end-to-end goal, one may need to repeat this calculation for many different \\(O\\) or for many instances of \\(H_{\\rm SYK}\\), e.g., to compute an ensemble average.</p>"},{"location":"areas-of-application/condensed-matter-physics/syk-model/#dominant-resource-costcomplexity","title":"Dominant resource cost/complexity","text":""},{"location":"areas-of-application/condensed-matter-physics/syk-model/#mapping-the-problem-to-qubits","title":"Mapping the problem to qubits:","text":"<p>To simulate the SYK model on a quantum computer, the Majorana operators are represented by strings of Pauli operators according to the Jordan\u2013Wigner representation (e.g., [11]). As a result, the Hamiltonian \\(H_{\\rm SYK}\\) on \\(N\\) Majoranas becomes a linear combination of multi-qubit Pauli operators over \\(N/2\\) qubits. Methods for Hamiltonian simulation in this Pauli access model typically have dependencies on the number of terms, \\(N^4\\), and on the 1-norm of Pauli coefficients, denoted by \\(\\lambda\\), which for typical SYK instances is seen to be \\(\\lambda = \\mathcal{O}\\left( gN^{5/2} \\right)\\) (see [6, Eq. (16)]).</p>"},{"location":"areas-of-application/condensed-matter-physics/syk-model/#state-preparation","title":"State preparation:","text":"<p>To solve the problem of estimating \\(\\text{tr}(\\rho O)\\), one must be able to prepare the \\((N/2)\\)-qubit state \\(\\rho\\). In some cases, \\(\\rho\\) could simply be a product state, which is trivial to prepare. If \\(\\rho\\) is the thermal state at inverse temperature \\(\\beta\\), then algorithms for Gibbs sampling would be used to prepare the state. Due to the chaotic properties of SYK and the fact that the system is expected to thermalize quickly in nature, one expects that Monte Carlo\u2013style Gibbs samplers (e.g., [12, 13, 14, 15, 16]) have a favorable \\(\\mathrm{poly}(N)\\) gate complexity, but the exact performance is unknown. If \\(\\rho\\) is the ground state of \\(H_{\\rm SYK}\\), there are several methods for preparing \\(\\rho\\), including projection onto \\(\\rho\\) by measuring (and postselecting) an ansatz state \\(\\phi\\) in the energy eigenbasis using quantum phase estimation (QPE), or by adiabatic state preparation. The cost of either of these methods is dependent on details such as which ansatz state is used (in particular, its overlap with \\(\\rho\\)), the adiabatic path, and the spectrum of \\(H_{\\rm SYK}\\)\u2014in both cases, in the absence of evidence to the contrary, the scaling can be exponential in \\(N\\). In [7], a \\(\\mathrm{poly}(N)\\)-time quantum algorithm for preparing states \\(\\rho\\) achieving a constant-factor approximation to the ground state energy of \\(H_{\\rm SYK}\\) was given, which could be used as \\(\\rho\\) to probe low-energy properties of the system.</p>"},{"location":"areas-of-application/condensed-matter-physics/syk-model/#time-evolution","title":"Time evolution:","text":"<p>The calculation also requires simulating time evolution by \\(H_{\\rm SYK}\\). This can be because \\(O\\) is a time-evolved operator, because the state \\(\\rho\\) corresponds to a time-evolved state, or simply as a subroutine for QPE or Gibbs sampling, mentioned above. Reference [11] proposed a scheme for simulating time evolution using a first-order product-formula approach to Hamiltonian simulation. That is, it implements the unitary \\(e^{iH_{\\rm SYK}t}\\) to precision \\(\\epsilon\\), with gate complexity \\(\\mathcal{O}(N^{10}g^2t^2/\\epsilon)\\). However, this steep scaling with \\(N\\) suggests that accessing large system sizes will be difficult with this method. Reference [6] later gave a method with better \\(N\\) dependence, achieving gate complexity \\(\\mathcal{O}(N^{7/2}gt +N^{5/2}gt\\,\\text{polylog}(N/\\epsilon))\\), leveraging qubitization with quantum signal processing. This gate complexity grows more slowly than the number of terms in \\(H_{\\rm SYK}\\) (\\(\\mathcal{O}\\left( N^4 \\right)\\)), a feat that is only possible because the simulation method generates the SYK coupling coefficients pseudorandomly: they perform the PREPARE step in the linear combination of unitaries with a shallow quantum circuit composed of \\(\\mathrm{polylog}(N)\\) random two-qubit gates, producing a state for which the \\(N^4\\) amplitudes are distributed approximately as independent Gaussians. Further reduction in the gate count would be bottlenecked by the 1-norm \\(\\lambda\\) of the coefficients of \\(H_{\\rm SYK}\\); however, recent work [17] suggests gravitational features may remain even if the Hamiltonian is substantially sparsified, which could reduce the number of terms and the value of \\(\\lambda\\).</p>"},{"location":"areas-of-application/condensed-matter-physics/syk-model/#measuring-observables","title":"Measuring observables:","text":"<p>Finally, given the ability to prepare a purification of \\(\\rho\\) and supposing \\(O\\) is unitary (if it is not, it could be decomposed into a sum of unitaries and each constituent computed separately), estimating the expectation value \\(\\text{tr}(\\rho O)\\) to precision \\(\\epsilon\\) can be done by overlap estimation, costing \\(\\mathcal{O}\\left( 1/\\epsilon \\right)\\) calls to the routine that prepares \\(\\rho\\) and to the routine that applies \\(O\\). If the purification of \\(\\rho\\) cannot be prepared, the cost is \\(\\mathcal{O}\\left( 1/\\epsilon^2 \\right)\\).</p>"},{"location":"areas-of-application/condensed-matter-physics/syk-model/#existing-error-corrected-resource-estimates","title":"Existing error corrected resource estimates","text":"<p>Reference [6] compiled the dominant contributions in their approach to Hamiltonian simulation into Clifford + \\(T\\) gates, and they found that at \\(N=100\\), implementing \\(e^{iHt}\\) requires fewer than \\(10^7 gt\\) \\(T\\) gates, and at \\(N=200\\), it requires fewer than \\(10^8 gt\\) \\(T\\) gates. The \\(T\\)-count can be turned into an estimate of the running time and number of physical qubits, see the discussion of fault-tolerant quantum computation.</p>"},{"location":"areas-of-application/condensed-matter-physics/syk-model/#caveats","title":"Caveats","text":"<p>Existing resource estimates only focus on simulating the dynamics of SYK models, but the proposed classically challenging problems involve static properties such as density of states and properties of thermal states. Probing these static properties in an end-to-end fashion would likely require preparing thermal states, ground states, or other kinds of low-energy states, in addition to being able to implement \\(e^{iHt}\\). The cost of preparing these states is unknown and difficult to assess analytically. Another caveat is that the gate counts quoted above do not take into account the \\(\\mathcal{O}\\left( 1/\\epsilon \\right)\\) scaling of reading out an observable to precision \\(\\epsilon\\), or any repetitions for different instances of \\(H_{\\rm SYK}\\) required for making inferences about the physics of SYK.</p>"},{"location":"areas-of-application/condensed-matter-physics/syk-model/#comparable-classical-complexity-and-challenging-instance-sizes","title":"Comparable classical complexity and challenging instance sizes","text":"<p>As mentioned above, one of the reasons that the SYK model is appealing is that many properties can be computed analytically in certain limits. Other properties that would be of interest to numerically compute on a quantum computer require poorly scaling classical methods. Exact diagonalization of systems consisting of more than roughly 50 fermions would be very challenging due to the exponential growth of the Hilbert space, which has dimension \\(2^{N/2}\\). For example, [5] and [18] gave a variety of numerical results based on exact diagonalization up to \\(N=34\\) and \\(N=36\\), respectively.</p>"},{"location":"areas-of-application/condensed-matter-physics/syk-model/#speedup","title":"Speedup","text":"<p>Hamiltonian simulation has \\(\\mathrm{poly}(N)\\) runtime, an exponential speedup over exact diagonalization, which is the go-to method for classical simulation of SYK-related problems. However, Hamiltonian simulation does not alone solve the same end-to-end problem as exact diagonalization; the persistence of the exponential speedup requires identifying specific interesting properties where the relevant initial states can also be prepared in \\(\\mathrm{poly}(N)\\) time, which is currently less clear.</p>"},{"location":"areas-of-application/condensed-matter-physics/syk-model/#nisq-implementations","title":"NISQ implementations","text":"<p>Experimental realizations of the SYK model have been proposed on several different experimental platforms [19, 20, 21]. However, even if these demonstrations can be realized, we do not expect this approach to scale in the absence of quantum error correction.</p>"},{"location":"areas-of-application/condensed-matter-physics/syk-model/#outlook","title":"Outlook","text":"<p>Simulating time evolution of the SYK model on a quantum computer has relatively mild gate cost, due to the model's straightforward mapping to a qubit Hamiltonian. At the same time, it is difficult to simulate the SYK model on a classical computer, owing to its chaotic and strongly coupled nature. However, further work is needed to understand the entire end-to-end pipeline. It has not yet been identified which properties would be most valuable to compute on a quantum computer and how costly they will be. Computing these properties will likely involve far more than a single run of time evolution on a single instance of the SYK model, so the overall cost is likely to be much larger than what initial gate counts in the literature suggest.</p>"},{"location":"areas-of-application/condensed-matter-physics/syk-model/#bibliography","title":"Bibliography","text":"<ol> <li> <p>Subir Sachdev and Jinwu Ye. Gapless spin-fluid ground state in a random quantum heisenberg magnet. Physical Review Letters, 70:3339\u20133342, 5 1993. arXiv: https://arxiv.org/abs/cond-mat/9212030. URL: https://link.aps.org/doi/10.1103/PhysRevLett.70.3339, doi:10.1103/PhysRevLett.70.3339.</p> </li> <li> <p>A. Kitaev. A simple model of quantum holography. 2015. Video of talk: part 1, part 2, accessed: 2023-09-30.</p> </li> <li> <p>Vladimir Rosenhaus. An introduction to the syk model. Journal of Physics A: Mathematical and Theoretical, 52(32):323001, 7 2019. arXiv: https://arxiv.org/abs/1807.03334. URL: https://dx.doi.org/10.1088/1751-8121/ab2ce1, doi:10.1088/1751-8121/ab2ce1.</p> </li> <li> <p>Xue-Yang Song, Chao-Ming Jian, and Leon Balents. Strongly correlated metal built from sachdev\u2013ye\u2013kitaev models. Physical Review Letters, 119:216601, 11 2017. arXiv: https://arxiv.org/abs/1705.00117. URL: https://link.aps.org/doi/10.1103/PhysRevLett.119.216601, doi:10.1103/PhysRevLett.119.216601.</p> </li> <li> <p>Jordan S Cotler, Guy Gur-Ari, Masanori Hanada, Joseph Polchinski, Phil Saad, Stephen H Shenker, Douglas Stanford, Alexandre Streicher, and Masaki Tezuka. Black holes and random matrices. Journal of High Energy Physics, 2017(5):1\u201354, 2017. arXiv: https://arxiv.org/abs/1611.04650. doi:10.1007/JHEP05(2017)118.</p> </li> <li> <p>Ryan Babbush, Dominic W. Berry, and Hartmut Neven. Quantum simulation of the sachdev\u2013ye\u2013kitaev model by asymmetric qubitization. Physical Review A, 99:040301, 4 2019. arXiv: https://arxiv.org/abs/1806.02793. URL: https://link.aps.org/doi/10.1103/PhysRevA.99.040301, doi:10.1103/PhysRevA.99.040301.</p> </li> <li> <p>Matthew B Hastings and Ryan O'Donnell. Optimizing strongly interacting fermionic hamiltonians. In Proceedings of the 54th ACM Symposium on the Theory of Computing (STOC), 776\u2013789. 2022. arXiv: https://arxiv.org/abs/2110.10701. doi:10.1145/3519935.3519960.</p> </li> <li> <p>Nicholas R Hunter-Jones. Chaos and randomness in strongly-interacting quantum systems. PhD thesis, California Institute of Technology, 2018. URL: https://resolver.caltech.edu/CaltechTHESIS:06012018-143029746, doi:10.7907/BHZ5-HV76.</p> </li> <li> <p>Adam R. Brown, Hrant Gharibyan, Stefan Leichenauer, Henry W. Lin, Sepehr Nezami, Grant Salton, Leonard Susskind, Brian Swingle, and Michael Walter. Quantum gravity in the lab. i. teleportation by size and traversable wormholes. PRX Quantum, 4:010320, 2 2023. arXiv: https://arxiv.org/abs/1911.06314. URL: https://link.aps.org/doi/10.1103/PRXQuantum.4.010320, doi:10.1103/PRXQuantum.4.010320.</p> </li> <li> <p>Sepehr Nezami, Henry W. Lin, Adam R. Brown, Hrant Gharibyan, Stefan Leichenauer, Grant Salton, Leonard Susskind, Brian Swingle, and Michael Walter. Quantum gravity in the lab. ii. teleportation by size and traversable wormholes. PRX Quantum, 4:010321, 2 2023. arXiv: https://arxiv.org/abs/2102.01064. URL: https://link.aps.org/doi/10.1103/PRXQuantum.4.010321, doi:10.1103/PRXQuantum.4.010321.</p> </li> <li> <p>L. Garcia-\u00c1lvarez, I. L. Egusquiza, L. Lamata, A. del Campo, J. Sonner, and E. Solano. Digital quantum simulation of minimal ads/cft. Physical Review Letters, 119:040501, 7 2017. arXiv: https://arxiv.org/abs/1607.08560. URL: https://link.aps.org/doi/10.1103/PhysRevLett.119.040501, doi:10.1103/PhysRevLett.119.040501.</p> </li> <li> <p>K. Temme, T. J. Osborne, K. G. Vollbrecht, D. Poulin, and F. Verstraete. Quantum metropolis sampling. Nature, 471(7336):87\u201390, 3 2011. arXiv: https://arxiv.org/abs/0911.3635. doi:10.1038/nature09770.</p> </li> <li> <p>Chi-Fang Chen and Fernando G. S. L. Brand\u00e3o. Fast thermalization from the eigenstate thermalization hypothesis. arXiv: https://arxiv.org/abs/2112.07646, 2021.</p> </li> <li> <p>Oles Shtanko and Ramis Movassagh. Algorithms for gibbs state preparation on noiseless and noisy random quantum circuits. arXiv: https://arxiv.org/abs/2112.14688, 2021.</p> </li> <li> <p>Patrick Rall, Chunhao Wang, and Pawel Wocjan. Thermal state preparation via rounding promises. arXiv: https://arxiv.org/abs/2210.01670, 2022.</p> </li> <li> <p>Chi-Fang Chen, Michael J. Kastoryano, Fernando G. S. L. Brand\u00e3o, and Andr\u00e1s Gily\u00e9n. Quantum thermal state preparation. arXiv: https://arxiv.org/abs/2303.18224, 2023.</p> </li> <li> <p>Shenglong Xu, Leonard Susskind, Yuan Su, and Brian Swingle. A sparse model of quantum holography. arXiv: https://arxiv.org/abs/2008.02303, 2020.</p> </li> <li> <p>Antonio M. Garc\u00eda-Garc\u00eda and Jacobus J. M. Verbaarschot. Spectral and thermodynamic properties of the sachdev\u2013ye\u2013kitaev model. Physical Review D, 94:126010, 12 2016. arXiv: https://arxiv.org/abs/1610.03816. URL: https://link.aps.org/doi/10.1103/PhysRevD.94.126010, doi:10.1103/PhysRevD.94.126010.</p> </li> <li> <p>Marcel Franz and Moshe Rozali. Mimicking black hole event horizons in atomic and solid-state systems. Nature Reviews Materials, 3(12):491\u2013501, 2018. arXiv: https://arxiv.org/abs/1808.00541. arXiv:1808.00541, doi:10.1038/s41578-018-0058-z.</p> </li> <li> <p>Armin Rahmani and Marcel Franz. Interacting majorana fermions. Reports on Progress in Physics, 82:084501, 2019. arXiv: https://arxiv.org/abs/1811.02593. doi:10.1088/1361-6633/ab28ef.</p> </li> <li> <p>Zhihuang Luo, Yi-Zhuang You, Jun Li, Chao-Ming Jian, Dawei Lu, Cenke Xu, Bei Zeng, and Raymond La. Quantum simulation of the non-fermi-liquid state of sachdev\u2013ye\u2013kitaev model. npj Quantum Information, pages 53, 2019. arXiv: https://arxiv.org/abs/1712.06458. doi:10.1038/s41534-019-0166-7.</p> </li> </ol>"},{"location":"areas-of-application/continuous-optimization/conic-programming-solving-lps-socps-and-sdps/","title":"Conic programming: Solving LPs, SOCPs, and SDPs","text":""},{"location":"areas-of-application/continuous-optimization/conic-programming-solving-lps-socps-and-sdps/#overview","title":"Overview","text":"<p>Conic programs are a specific subclass of convex optimization problems, where the objective function is linear and the convex constraints are restrictions to the intersection of affine spaces and certain cones within \\(\\mathbb{R}^n\\). Commonly considered cones are the positive orthant, the second-order cone (\"ice-cream cone\"), and the semidefinite cone, which give rise to linear programs (LPs), second-order cone programs (SOCPs), and semidefinite programs (SDPs), respectively. This framework remains quite general and many real-world problems can be reduced to a conic program. However, the additional structure of the program allows for more efficient classical and quantum algorithms, compared to completely general convex problems.</p><p>Algorithms for LPs, SOCPs, and SDPs have long been a topic of study. Today, the best classical algorithms are based on interior point methods (IPMs), but other algorithms based on the multiplicative weights update (MWU) method exist and can be superior in a regime where high precision is not required. Both of these approaches can be turned into quantum algorithms with potential to deliver asymptotic quantum speedup for general LPs, SOCPs, and SDPs. However, the runtime of the quantum algorithm typically depends on additional instance-specific parameters, which makes it difficult to produce a general apples-to-apples comparison with classical algorithms.</p>"},{"location":"areas-of-application/continuous-optimization/conic-programming-solving-lps-socps-and-sdps/#actual-end-to-end-problems-solved","title":"Actual end-to-end problem(s) solved","text":"<ul> <li>Linear programs (LPs) are the simplest convex program. An LP instance is specified by an \\(m \\times n\\) matrix \\(A\\), an \\(n\\)-dimensional vector \\(c\\) and an \\(m\\)-dimensional vector \\(b\\). The problem can then be written as  \\[\\begin{equation} \\label{eq:LP} \\begin{align} &amp; \\min_{x \\in \\mathbb{R}^n} \\langle c, x \\rangle \\\\   \\text{subject to } &amp; Ax=b \\\\   &amp; x_i \\geq 0 \\text{ for } i=1,\\ldots,n \\end{align} \\end{equation}\\] <p>where notation \\(\\langle u, v \\rangle\\) denotes the standard dot product of vectors \\(u\\) and \\(v\\). The function \\(\\langle c, x\\rangle\\), which is linear in \\(x\\), is called the objective function, and a point \\(x\\) is called feasible if it satisfies the linear equality<sup>1</sup> constraints \\(Ax=b\\) as well as the positivity constraints \\(x_i \\geq 0\\) for all \\(i\\). We denote the feasible point that optimizes the objective function by \\(x^*\\). Let \\(\\epsilon\\) be a precision parameter. The actual end-to-end problem solved is to take as input a classical description of the problem instance \\((c,A,b,\\epsilon)\\) and output a classical description of a point \\(x\\) for which \\(\\langle c, x \\rangle \\leq \\langle c, x^*\\rangle + \\epsilon\\). The set of points that obey the positivity constraints \\(x_i \\geq 0\\) forms the positive orthant of the vector space \\(\\mathbb{R}^n\\). This set meets the mathematical definition of a convex cone: for any points \\(u\\) and \\(v\\) in the set and any non-negative scalars \\(\\alpha,\\beta\\geq 0\\), the point \\(\\alpha u+\\beta v\\) is also in the set. - Second-order cone programs (SOCPs) are formed by replacing the positivity constraints in the definition of LPs with one or more second-order cone constraints, where the second-order cone of dimension \\(k\\) is defined to include points \\((x_0;x_1;\\ldots;x_{k-1}) \\in \\mathbb{R}^k\\) for which \\(x_0^2 \\geq x_1^2+\\ldots + x_{k-1}^2\\). - Semidefinite programs (SDPs) are formed by replacing the \\(n\\)-dimensional vector \\(x\\) in the definition of LPs with a \\(n \\times n\\) symmetric matrix \\(X\\) and replacing the positive orthant constraint with the conic constraint that \\(X\\) is a positive semidefinite matrix. Denote the set of \\(n \\times n\\) symmetric matrices by \\(\\mathbb{S}^n\\), and for any pair of matrices \\(U,V \\in \\mathbb{S}^n\\), define the notation \\(\\langle U, V\\rangle = \\text{tr}(UV)\\) (which generalizes the standard dot product). Then, an SDP instance is specified by matrices \\(C, A^{(1)},A^{(2)},\\ldots, A^{(m)} \\in \\mathbb{S}^n\\), as well as \\(b \\in \\mathbb{R}^m\\), and can be written as </p> \\[\\begin{equation} \\label{eq:SDP} \\begin{align} &amp; \\min_{X \\in \\mathbb{S}^n} \\langle C, X \\rangle \\\\   \\text{subject to } &amp; \\langle A^{(j)}, X\\rangle = b_j \\text{ for } j = 1,\\ldots,m \\\\   &amp; X \\succeq 0 \\end{align} \\end{equation}\\] <p>where \\(X\\succeq 0\\) denotes the constraint that \\(X\\) is positive semidefinite.</p> </li> </ul><p>In the LP or SDP case, we might also require as input parameters \\(R\\) and \\(r\\), where \\(R\\) is a known upper bound on the size of the solution in the sense that \\(\\sum_i |x_i| \\leq R\\) (LP) or \\(\\text{tr}(X) \\leq R\\) (SDP), and where \\(r\\) is an analogous upper bound on the size of the solution to the dual program (not written explicitly here, see [1]).</p>"},{"location":"areas-of-application/continuous-optimization/conic-programming-solving-lps-socps-and-sdps/#dominant-resource-costcomplexity","title":"Dominant resource cost/complexity","text":"<p>Two separate approaches to solving conic programs with quantum algorithms have been proposed in the literature. Both methods start with classical algorithms and replace some of the subroutines with quantum algorithms.</p><ol> <li>Quantum interior point methods (QIPMs) for LPs [2], SOCPs [3, 4], and SDPs [2, 5, 6] have been proposed. These methods start with classical interior point methods, for which the core step is solving a linear system, and simply replace the classical linear system solver with a quantum linear system solver (QLSS), combined with pure state quantum tomography. Given a linear system \\(Gu = v\\), the QLSS produces a quantum state \\(\\ket{u}\\), and quantum tomography is subsequently used to gain a classical estimate of the amplitudes of \\(\\ket{u}\\) in the computational basis. The QLSS ingredient introduces complexity dependence on a parameter \\(\\kappa=\\lVert G \\rVert \\lVert G^{-1}\\rVert\\), the condition number of \\(G\\), where \\(\\lVert \\cdot \\rVert\\) denotes the spectral norm. Additionally, the QLSS requires that the classical data defining \\(G\\) be loaded in the form of a block-encoding, for which the standard construction introduces a dependence on the factor \\(\\zeta = \\lVert G \\rVert_F \\lVert G \\rVert^{-1}\\), where \\(\\lVert \\cdot \\rVert_F\\) denotes the Frobenius norm. Finally, the tomography ingredient introduces a complexity dependence on a parameter \\(\\xi\\), defined as the precision to which the vector \\(u\\) must be classically learned, measured in \\(\\ell_2\\) norm. Assuming \\(m\\) is on the order of the number of degrees of freedom (i.e. \\(n\\) in the case of LP and SOCP, and \\(n^2\\) in the case of SDP), the number of queries the QIPM makes to block-encodings of the input matrices is  \\[\\begin{align} \\text{LP, SOCP \\cite{augustino2022inexact}:} &amp; \\qquad \\tilde{\\mathcal{O}}\\left(\\frac{n^{1.5}\\zeta \\kappa}{\\xi}\\log(1/\\epsilon)\\right) \\\\    \\text{SDP \\cite{kerenidis2018QIntPoint,augustino2021quantum}:} &amp; \\qquad \\tilde{\\mathcal{O}}\\left(\\frac{n^{2.5}\\zeta \\kappa}{\\xi}\\log(1/\\epsilon)\\right) \\end{align}\\] <p>where the \\(\\tilde{\\mathcal{O}}\\) notation hides logarithmic factors. Note that depending on how \\(\\xi\\) is defined, extra factors of \\(\\kappa\\) may be required. Moreover, note that the complexity statements in [5] go further and analyze the worst-case dependence of \\(\\xi\\) on the overall error \\(\\epsilon\\), and additionally make the worst-case replacement \\(\\zeta \\leq \\mathcal{O}\\left( n \\right)\\). The numerical values of \\(\\kappa\\), \\(\\zeta\\), and \\(\\xi\\) are generally difficult to determine in advance for a specific application. The block-encoding queries can be executed in circuit depth \\(\\mathrm{polylog}(n+m,1/\\epsilon)\\), which can also be absorbed into the \\(\\tilde{\\mathcal{O}}\\) notation (although it is important to note that the circuit size is generally \\(\\mathcal{O}\\left( n^2 \\right)\\)). If the input matrices are sparse or given in a form other than as a list of matrix entries, there may be other more efficient methods for block-encoding; in this case the parameter \\(\\zeta\\) might be replaced with another parameter \\(\\alpha &gt; 1\\), whose value would depend on the block-encoding method. 2. Quantum algorithms based on the multiplicative weights update (MWU) method have been proposed for SDP [7, 8, 9, 1] and LP [9, 10]. The quantum algorithm closely follows the classical algorithm based on MWU to iteratively update a candidate solution to the program. Each iteration is carried out using quantum subroutines, including Gibbs sampling, as well as Grover search and quantum minimum finding [11, 9] (a direct application of Grover search). Let \\(s\\) denote the sparsity, that is, the maximum number of nonzero entries in any row or column of the matrices composing the problem input (thus, \\(s \\leq \\max(m,n)\\)). Then, the runtime has been upper bounded by </p> \\[\\begin{align} \\text{LP \\cite{bouland2023zerosum}:} &amp; \\qquad \\tilde{\\mathcal{O}}\\left(\\sqrt{s}\\left(\\frac{rR}{\\epsilon}\\right)^{3.5}\\right) \\\\    \\text{SDP \\cite{apeldoorn2018ImprovedQSDPSolving}:} &amp; \\qquad \\tilde{\\mathcal{O}}\\left(s\\sqrt{m}\\left(\\frac{rR}{\\epsilon}\\right)^{4}+s\\sqrt{n}\\left(\\frac{rR}{\\epsilon}\\right)^5\\right) \\end{align}\\] <p>assuming sparse access to the input matrices, where \\(r,R\\) are the parameters related to the size of the primal and dual solutions, defined above. In [1], the input model was generalized to a \"quantum operator input model,\" based on block-encodings where \\(s\\) is replaced by the block-encoding normalization factor \\(\\alpha\\) in the runtime expressions. Note that it is possible the runtime for LP could be improved by applying the dynamic Gibbs sampling method of [12] together with the reduction from LP to zero-sum games in [10].</p> </li> </ol><p>The runtime expressions for the QIPM approach and the MWU approach are not directly comparable, as the former depends on instance-specific parameters \\(\\kappa\\), \\(\\zeta\\), and \\(\\xi\\), while the latter depends on instance-specific parameters \\(r\\) and \\(R\\). However, note that the explicit \\(n\\)-dependence is better in the case of MWU than QIPM, while the \\(\\epsilon\\)-dependence is worse.</p>"},{"location":"areas-of-application/continuous-optimization/conic-programming-solving-lps-socps-and-sdps/#existing-error-corrected-resource-estimates","title":"Existing error corrected resource estimates","text":"<p>Neither of the approaches for conic programs have garnered study at the level of error-corrected resource estimates. Reference [13] performed a resource analysis for a QIPM at the logical level, but did not analyze additional overheads due to error correction. The goal of that analysis was to completely compile the QIPM for SOCP into Clifford gates and \\(T\\) gates, and then to numerically estimate the parameters \\(\\kappa\\), \\(\\zeta\\), and \\(\\xi\\) for the particular use case of financial portfolio optimization, which can be reduced to SOCP. A salient feature of the QIPM is that \\(\\mathcal{O}\\left( n+m \\right) \\times \\mathcal{O}\\left( n+m \\right)\\) matrices of classical data must be repeatedly accessed by the QLSS via block-encoding, necessitating a large-scale quantum random access memory (QRAM) with \\(\\mathcal{O}\\left( n^2 \\right)\\) qubits. Accordingly, for SOCPs with \\(n=500\\) and \\(m=400\\) (which are still easily solved on classical computers) it was estimated that 8 million logical qubits would be needed. The total number of \\(T\\) gates needed for the same instance size was on the order of \\(10^{29}\\), which can be distributed over roughly \\(10^{24}\\) layers.</p><p>We are not aware of an analogous logical resource analysis for the MWU approach to conic programming. Such an analysis would be valuable and should ideally choose a specific use case to be able to evaluate the size of all parameters involved.</p>"},{"location":"areas-of-application/continuous-optimization/conic-programming-solving-lps-socps-and-sdps/#caveats","title":"Caveats","text":"<ul> <li>The QIPM approach requires a large-scale QRAM of size \\(\\mathcal{O}\\left( n^2 \\right)\\). This is a necessary ingredient to retain any hope of a speedup, and for relevant choice of \\(n\\) the associated hardware requirements could be prohibitively large.</li> <li>The QIPM approach has a weak case for a large asymptotic speedup: even under optimal circumstances, the asymptotic speedup over classical interior point methods is less than quadratic. See the article on the QIPM approach for more information.</li> <li>The QIPM approach has a large constant prefactor that is estimated to be on the order of \\(10^3\\) coming from state-of-the-art QLSS [14, 15]. (It is possible this could be improved using alternative approaches to QLSS such as variable-time amplitude amplification [16]. See also [15].)</li> <li>The MWU approach requires a medium-scale QRAM of size \\(\\mathcal{O}\\left( R^2r^2/\\epsilon^2 \\right)\\). This requirement can be avoided at the cost of an additional multiplicative overhead of \\(\\mathcal{O}\\left( R^2r^2/\\epsilon^2 \\right)\\).</li> <li>The MWU approach has poor dependence on error \\(\\epsilon\\); for SDPs it is \\(\\epsilon^{-5}\\). Even at modest choices of \\(\\epsilon\\), this may lead the algorithm to be impractical pending significant improvements.</li> <li>A general caveat that applies to both approaches is that the appearance of instance-specific parameters makes it difficult to predict the performance of these algorithms for more specific applications.</li> </ul>"},{"location":"areas-of-application/continuous-optimization/conic-programming-solving-lps-socps-and-sdps/#comparable-classical-complexity-and-challenging-instance-sizes","title":"Comparable classical complexity and challenging instance sizes","text":"<p>As in the quantum case, there are multiple distinct approaches in the classical case.</p><ol> <li>Classical interior point methods (CIPMs): There exist fast IPM-based software implementations for solving conic programs, such as ECOS [17] and MOSEK [18]. These solvers can solve instances with thousands of variables in a matter of seconds on a standard laptop [17]. However, the runtime scaling is poor and scaling too far beyond this regime leads the solvers to be far less practical. The runtime of the best provably correct classical IPMs for the regime where the number of constraints is roughly equal to the number of degrees of freedom is  \\[\\begin{align} \\text{LP \\cite{cohen2021LPsinMMtime}:} &amp; \\qquad \\tilde{\\mathcal{O}}\\left(n^{\\omega}\\log(1/\\epsilon)\\right) \\\\    \\text{SOCP \\cite{monteiro2000SOCP}:} &amp; \\qquad \\tilde{\\mathcal{O}}\\left(n^{\\omega+0.5}\\log(1/\\epsilon)\\right) \\\\    \\text{SDP \\cite{huang2022fasterIPM}:} &amp; \\qquad \\tilde{\\mathcal{O}}\\left( n^{2\\omega}\\log(1/\\epsilon)\\right) \\end{align}\\] <p>where \\(\\omega&lt;2.37\\) is the matrix multiplication exponent. It is plausible that, with some attention, the extra \\(n^{0.5}\\) factor for SOCP could be eliminated with modern techniques. Additionally, the runtime can be somewhat reduced when the number of constraints is much less than the number of degrees of freedom; for example, the \\(n\\)-dependence of the complexity of the CIPM for SDP in [19] can be as low as \\(\\tilde{\\mathcal{O}}(n^{2.5})\\) when there are few constraints. On practical instances, employing techniques for fast matrix multiplication is often not beneficial, and Gaussian Elimination-like methods are used, where \\(\\omega=3\\). Note that, alternatively, by using iterative classical linear systems solvers [20], each \\(n^{\\omega}\\) factor could be replaced by a factor of \\(n\\) at the cost of a linear dependence on \\((\\kappa \\zeta)^2\\), which could be superior if the matrices are well conditioned. 2. Classical MWU methods: a classical complexity statement for LPs is inferred from the reduction in [10] from LPs to zero-sum games and the classical analysis that appears there. For the SDP case, references in the classical literature appear only to examine specific subclasses of SDPs (e.g. [21, 22]). A general statement of the classical complexity for SDPs appears alongside the quantum algorithm in [9, Section 2.4]. </p> \\[\\begin{align} \\text{LP \\cite{apeldoorn2019QAlgorithmsForZeroSumGames}:} &amp; \\qquad \\tilde{\\mathcal{O}}\\left(s\\left(\\frac{rR}{\\epsilon}\\right)^{3.5}\\right) \\\\    \\text{SDP \\cite{apeldoorn2017QSDPSolvers}:} &amp; \\qquad \\tilde{\\mathcal{O}}\\left(s\\sqrt{nm}\\left(\\frac{rR}{\\epsilon}\\right)^{4}+sn\\left(\\frac{rR}{\\epsilon}\\right)^7\\right) \\end{align}\\] </li> <li>Cutting-plane methods: these classical methods are used for SDPs and can outperform IPMs when the number of constraints is small. The best algorithm, based on [23, 24], has runtime \\(\\mathcal{O}\\left( m(mn^2+n^{\\omega}+m^2)\\log(1/\\epsilon) \\right)\\), which can be as low as \\(\\mathcal{O}\\left( n^\\omega \\right)\\) when \\(m\\) is small.</li> </ol><p>It is important to note that the algorithms with the best provable complexities may not be the ones that are most useful in practice.</p>"},{"location":"areas-of-application/continuous-optimization/conic-programming-solving-lps-socps-and-sdps/#speedup","title":"Speedup","text":"<p>For both the IPM and the MWU approach, there can be at most a polynomial quantum speedup: upper and lower bounds scaling polynomially with \\(n\\) are known in both the classical and quantum cases [1]. The speedup of the QIPM method depends on the scaling of \\(\\kappa\\) with \\(n\\), but the speedup cannot be more than quadratic. The speedup of the MWU method with respect to the \\(n\\)-scaling could be as much as quadratic, assuming the sparsity is constant. There is a possibility that the speedup could be larger in practice if the Gibbs sampling routine is faster in practice than its worst-case upper bounds suggest, perhaps by utilizing Monte Carlo\u2013style approaches to Gibbs sampling.</p>"},{"location":"areas-of-application/continuous-optimization/conic-programming-solving-lps-socps-and-sdps/#outlook","title":"Outlook","text":"<p>It is very plausible that an asymptotic polynomial speedup can be obtained in problem size using the MWU method for solving LPs or SDPs, but the speedup appears only quadratic, and an assessment of practicality depends on the scaling of certain unspecified instance-specific parameters. Similarly, the QIPM method could bring a subquadratic speedup but only under certain assumptions about the condition number of certain matrices. These quadratic and subquadratic speedups alone might be regarded as unlikely to yield practical speedups after error correction overheads and slower quantum clock speeds are considered. Future work should aim to find additional asymptotic speedups while focusing on specific practically relevant use cases that allow the unspecified parameters to be evaluated.</p>"},{"location":"areas-of-application/continuous-optimization/conic-programming-solving-lps-socps-and-sdps/#bibliography","title":"Bibliography","text":"<ol> <li> <p>Joran van Apeldoorn and Andr\u00e1s Gily\u00e9n. Improvements in quantum sdp-solving with applications. In Proceedings of the 46th International Colloquium on Automata, Languages, and Programming (ICALP), 99:1\u201399:15. 2019. arXiv: https://arxiv.org/abs/1804.05058. doi:10.4230/LIPIcs.ICALP.2019.99.</p> </li> <li> <p>Iordanis Kerenidis and Anupam Prakash. A quantum interior point method for lps and sdps. ACM Transactions on Quantum Computing, 2020. arXiv: https://arxiv.org/abs/1808.09266. doi:10.1145/3406306.</p> </li> <li> <p>Iordanis Kerenidis, Anupam Prakash, and D\u00e1niel Szil\u00e1gyi. Quantum algorithms for second-order cone programming and support vector machines. Quantum, 5:427, 2021. arXiv: https://arxiv.org/abs/1908.06720. doi:10.22331/q-2021-04-08-427.</p> </li> <li> <p>Brandon Augustino, Tam\u00e1s Terlaky, and Luis F Zuluaga. An inexact-feasible quantum interior point method for second-order cone optimization. Technical Report 21T-009, Department of Industrial and Systems Engineering, Lehigh University, 2022.</p> </li> <li> <p>Brandon Augustino, Giacomo Nannicini, Tam\u00e1s Terlaky, and Luis F. Zuluaga. Quantum interior point methods for semidefinite optimization. Quantum, 7:1110, 9 2023. arXiv: https://arxiv.org/abs/2112.06025. URL: https://doi.org/10.22331/q-2023-09-11-1110, doi:10.22331/q-2023-09-11-1110.</p> </li> <li> <p>Baihe Huang, Shunhua Jiang, Zhao Song, Runzhou Tao, and Ruizhe Zhang. A faster quantum algorithm for semidefinite programming via robust ipm framework. arXiv: https://arxiv.org/abs/2207.11154, 2022.</p> </li> <li> <p>Fernando G. S. L. Brand\u00e3o and Krysta M. Svore. Quantum speed-ups for solving semidefinite programs. In Proceedings of the 58th IEEE Symposium on Foundations of Computer Science (FOCS), 415\u2013426. 2017. arXiv: https://arxiv.org/abs/1609.05537. URL: http://ieee-focs.org/FOCS-2017-Papers/3464a415.pdf, doi:10.1109/FOCS.2017.45.</p> </li> <li> <p>Fernando G. S. L. Brand\u00e3o, Amir Kalev, Tongyang Li, Cedric Yen-Yu Lin, Krysta M. Svore, and Xiaodi Wu. Quantum sdp solvers: large speed-ups, optimality, and applications to quantum learning. In Proceedings of the 46th International Colloquium on Automata, Languages, and Programming (ICALP), 27:1\u201327:14. 2019. arXiv: https://arxiv.org/abs/1710.02581. doi:10.4230/LIPIcs.ICALP.2019.27.</p> </li> <li> <p>Joran van Apeldoorn, Andr\u00e1s Gily\u00e9n, Sander Gribling, and Ronald de Wolf. Quantum sdp-solvers: better upper and lower bounds. Quantum, 4:230, 2020. Earlier version in FOCS'17. arXiv: https://arxiv.org/abs/1705.01843. doi:10.22331/q-2020-02-14-230.</p> </li> <li> <p>Joran van Apeldoorn and Andr\u00e1s Gily\u00e9n. Quantum algorithms for zero-sum games. arXiv: https://arxiv.org/abs/1904.03180, 2019.</p> </li> <li> <p>Christoph D\u00fcrr and Peter H\u00f8yer. A quantum algorithm for finding the minimum. arXiv: https://arxiv.org/abs/quant-ph/9607014, 1996.</p> </li> <li> <p>Adam Bouland, Yosheb Getachew, Yujia Jin, Aaron Sidford, and Kevin Tian. Quantum speedups for zero-sum games via improved dynamic gibbs sampling. arXiv: https://arxiv.org/abs/2301.03763, 2023.</p> </li> <li> <p>Alexander M Dalzell, B David Clader, Grant Salton, Mario Berta, Cedric Yen-Yu Lin, David A Bader, Nikitas Stamatopoulos, Martin J A Schuetz, Fernando G S L Brand\u00e3o, Helmut G Katzgraber, and others. End-to-end resource analysis for quantum interior point methods and portfolio optimization. PRX Quantum, pages to appear, 2023. arXiv: https://arxiv.org/abs/2211.12489.</p> </li> <li> <p>Pedro C.S. Costa, Dong An, Yuval R. Sanders, Yuan Su, Ryan Babbush, and Dominic W. Berry. Optimal scaling quantum linear-systems solver via discrete adiabatic theorem. PRX Quantum, 3:040303, 10 2022. arXiv: https://arxiv.org/abs/2111.08152. URL: https://link.aps.org/doi/10.1103/PRXQuantum.3.040303, doi:10.1103/PRXQuantum.3.040303.</p> </li> <li> <p>David Jennings, Matteo Lostaglio, Sam Pallister, Andrew T. Sornborger, and Yigit Subasi. Efficient quantum linear solver algorithm with detailed running costs. arXiv: https://arxiv.org/abs/2305.11352, 2023.</p> </li> <li> <p>Andris Ambainis. Variable time amplitude amplification and quantum algorithms for linear algebra problems. In Proceedings of the 29th Symposium on Theoretical Aspects of Computer Science (STACS), 636\u2013647. 2012. arXiv: https://arxiv.org/abs/1010.4458. doi:10.4230/LIPIcs.STACS.2012.636.</p> </li> <li> <p>Alexander Domahidi, Eric Chu, and Stephen Boyd. Ecos: an socp solver for embedded systems. In 2013 European Control Conference (ECC), volume, 3071\u20133076. 2013. doi:10.23919/ECC.2013.6669541.</p> </li> <li> <p>Erling D. Andersen and Knud D. Andersen. The Mosek Interior Point Optimizer for Linear Programming: An Implementation of the Homogeneous Algorithm, pages 197\u2013232. Springer US, Boston, MA, 2000. URL: https://doi.org/10.1007/978-1-4757-3216-0\\_8, doi:10.1007/978-1-4757-3216-0\\_8.</p> </li> <li> <p>Haotian Jiang, Tarun Kathuria, Yin Tat Lee, Swati Padmanabhan, and Zhao Song. A faster interior point method for semidefinite programming. In Proceedings of the 61st IEEE Symposium on Foundations of Computer Science (FOCS), volume, 910\u2013918. 2020. arXiv: https://arxiv.org/abs/2009.10217. doi:10.1109/FOCS46700.2020.00089.</p> </li> <li> <p>Thomas Strohmer and Roman Vershynin. A randomized kaczmarz algorithm with exponential convergence. Journal of Fourier Analysis and Applications, 15(2):262\u2013278, 2009. arXiv: https://arxiv.org/abs/math/0702226. doi:10.1007/s00041-008-9030-4.</p> </li> <li> <p>S. Arora, E. Hazan, and S. Kale. Fast algorithms for approximate semidefinite programming using the multiplicative weights update method. In Proceedings of the 46th IEEE Symposium on Foundations of Computer Science (FOCS), volume, 339\u2013348. 2005. doi:10.1109/SFCS.2005.35.</p> </li> <li> <p>Sanjeev Arora and Satyen Kale. A combinatorial, primal-dual approach to semidefinite programs. In Proceedings of the 39th ACM Symposium on the Theory of Computing (STOC), 227\u2013236. New York, NY, USA, 2007. Association for Computing Machinery. URL: https://doi.org/10.1145/1250790.1250823, doi:10.1145/1250790.1250823.</p> </li> <li> <p>Yin Tat Lee, Aaron Sidford, and Sam Chiu-wai Wong. A faster cutting plane method and its implications for combinatorial and convex optimization. In Proceedings of the 56th IEEE Symposium on Foundations of Computer Science (FOCS), 1049\u20131065. 2015. arXiv: https://arxiv.org/abs/1508.04874. doi:10.1109/FOCS.2015.68.</p> </li> <li> <p>Haotian Jiang, Yin Tat Lee, Zhao Song, and Sam Chiu-Wai Wong. An improved cutting plane method for convex optimization, convex-concave games, and its applications. In Proceedings of the 52nd ACM Symposium on the Theory of Computing (STOC), 944\u2013953. New York, NY, USA, 2020. Association for Computing Machinery. arXiv: https://arxiv.org/abs/2004.04250. URL: https://doi.org/10.1145/3357713.3384284, doi:10.1145/3357713.3384284.</p> </li> </ol> <ol> <li> <p>Inequality constraints of the form \\(Ax \\leq b\\) can be converted to linear equality constraints and positivity constraints by introducing a vector of slack variables \\(s\\) and imposing \\(Ax + s = b\\) and \\(s_i \\geq 0\\) for all \\(i\\). An analogous trick is possible for SOCP and SDP.\u00a0\u21a9</p> </li> </ol>"},{"location":"areas-of-application/continuous-optimization/general-convex-optimization/","title":"General convex optimization","text":""},{"location":"areas-of-application/continuous-optimization/general-convex-optimization/#overview","title":"Overview","text":"<p>A convex problem asks to optimize a convex function \\(f\\) over a convex set \\(K\\), where \\(K\\) is a subset of \\(\\mathbb{R}^n\\). Here we examine the situation where the value of \\(f(x)\\) and the membership of \\(x\\) in the set \\(K\\) can each be efficiently computed classically. However, we do not exploit/assume any additional structure that may be present in \\(f\\) or \\(K\\). This situation contrasts with that of solving conic programs, where \\(f\\) is linear and \\(K\\) is an intersection of convex cones and affine spaces, features that can be exploited to yield more efficient classical and quantum algorithms.</p><p>A so-called \"zeroth-order\" solution to this problem solves it simply by adaptively evaluating \\(f(x)\\) and \\(x \\in K\\) for different values of \\(x\\). For the zeroth-order approach, a quantum algorithm can obtain a quadratic speedup with respect to the number of times these functions are evaluated, reducing it from \\(\\tilde{\\mathcal{O}}(n^2)\\) to \\(\\tilde{\\mathcal{O}}(n)\\), where \\(\\tilde{\\mathcal{O}}\\) notation hides factors polylogarithmic in \\(n\\) and other parameters. This could lead to a practical speedup only if the cost to evaluate \\(f(x)\\) and \\(x\\in K\\) is large, and lack of structure rules out other, possibly faster, approaches to solving the problem.</p>"},{"location":"areas-of-application/continuous-optimization/general-convex-optimization/#actual-end-to-end-problems-solved","title":"Actual end-to-end problem(s) solved","text":"<p>Suppose we have classical algorithms \\(\\mathcal{A}_f\\) for computing \\(f(x)\\) and \\(\\mathcal{A}_K\\) for computing \\(x \\in K\\) (\"membership oracle\"), which require \\(C_f\\) and \\(C_K\\) gates to perform with a reversible classical circuit, respectively. Suppose further we have an initial point \\(x_0 \\in K\\) and that we have two numbers \\(r\\) and \\(R\\) for which we know that \\(B(x_0,r) \\subset K \\subset B(x_0,R)\\), where \\(B(y,t) = \\{z \\in \\mathbb{R}^n: \\lVert z-y \\rVert \\leq t\\}\\) denotes the ball of radius \\(t\\) centered at \\(y\\). Using \\(\\mathcal{A}_f\\), \\(\\mathcal{A}_K\\), \\(x_0\\), \\(r\\), \\(R\\), and \\(\\epsilon\\) as input, the output is a point \\(\\tilde{x}\\) that is \\(\\epsilon\\)-optimal, that is, it satisfies </p>\\[\\begin{equation} f(\\tilde{x}) \\leq \\min_{x \\in K}f(x) + \\epsilon\\,. \\end{equation}\\]"},{"location":"areas-of-application/continuous-optimization/general-convex-optimization/#dominant-resource-costcomplexity","title":"Dominant resource cost/complexity","text":"<p>The work of [1] and [2] independently establish that there is a quantum algorithm that solves this problem with gate complexity upper bounded by </p>\\[\\begin{equation} \\left[(C_f + C_K)n +n^3\\right]\\cdot \\text{polylog}(nR/r\\epsilon)\\,, \\end{equation}\\]<p>where the polylogarithmic factors were left unspecified. The rough idea behind the algorithm is to leverage the quantum gradient estimation algorithm to implement a separation oracle\u2014a routine that determines membership \\(x\\in K\\) and when \\(x \\not\\in K\\) outputs a hyperplane separating \\(x\\) from all points in \\(K\\)\u2014using only \\(\\mathcal{O}\\left( 1 \\right)\\) queries to algorithm \\(\\mathcal{A}_K\\) and \\(\\mathcal{A}_f\\). It had been previously established that \\(\\tilde{\\mathcal{O}}(n)\\) queries to a separation oracle then suffice to perform optimization [3], where \\(\\tilde{\\mathcal{O}}\\) denotes that logarithmic factors have been suppressed.</p>"},{"location":"areas-of-application/continuous-optimization/general-convex-optimization/#existing-error-corrected-resource-estimates","title":"Existing error corrected resource estimates","text":"<p>There have not been any such resource estimates for this algorithm. It may not make sense to perform such an estimate without a more concrete scenario in mind, as the estimate would highly depend on the complexity of performing the circuits for \\(\\mathcal{A}_f\\) and \\(\\mathcal{A}_K\\).</p>"},{"location":"areas-of-application/continuous-optimization/general-convex-optimization/#caveats","title":"Caveats","text":"<p>One caveat is that the quantum algorithm must coherently perform reversible implementations of the classical functions that compute \\(f(x)\\) and \\(x \\in K\\). Compared to a nonreversible classical implementation, this may cost additional ancilla qubits and gates. Another caveat relates to the scenario where \\(f(x)\\) and \\(x\\in K\\) are determined by classical data stored in a classical database. Such a situation may appear to be an appealing place to look for applications of this algorithm because when \\(f\\) and \\(K\\) are determined empirically rather than analytically, it becomes easier to argue that there is no structure that can be exploited. However, in such a situation, implementing \\(\\mathcal{A}_f\\) and \\(\\mathcal{A}_K\\) would require a large gate complexity \\(C_f\\) and \\(C_K\\) scaling with the size of the classical database. It would almost certainly be the case that a quantum random access memory (QRAM) admitting log-depth queries would be needed in order for the algorithm to remain competitive with classical implementations that have access to classical RAM, and the practical feasibility of building a large-scale log-depth QRAM has many additional caveats.</p><p>Another caveat is that there may not be many practical situations that are compatible with a quantum speedup by this algorithm. The source of the speedup in [1, 2] comes from a separation between the complexity of computing the gradient of \\(f\\) classically vs. quantumly using calls to the function \\(f\\). Classically, this requires at least linear-in-\\(n\\) number of calls. Quantumly, it can be done in \\(\\mathcal{O}\\left( 1 \\right)\\) calls using the quantum algorithm for gradient estimation. In both the classical and the quantum case, the gradient can subsequently be used to construct a \"separation\" oracle for the set \\(K\\), which is then used to solve the convex problem.</p><p>Thus, a speedup is only possible if there is no obvious way to classically compute the gradient of \\(f\\) other than to evaluate \\(f\\) at many points. This criterion is violated in many practical situations, which are often said to obey a \"cheap gradient principle\" [4, 5] that asserts that the gradient of \\(f\\) can be computed in time comparable to the time required to evaluate \\(f\\). For example, the fact that gradients are cheap is crucial for training modern machine learning models with a large number of parameters. When this is the case, the algorithms from [1, 2] do not offer a speedup. On the other hand, as observed in [2, Footnote 19] a nontrivial example of a problem where the cheap gradient principle may fail (enabling a possible advantage for these quantum algorithms) is the moment polytope problem, which has connections to quantum information [6].</p><p>When both the function \\(f\\) and the gradient of \\(f\\) can be evaluated at unit cost, this constitutes \"first-order\" optimization, which can be solved by gradient descent. However, gradient descent does not generally offer a quantum speedup, as general quantum lower bounds match classical upper bounds [7], although a quantum speedup could exist in specific cases.</p>"},{"location":"areas-of-application/continuous-optimization/general-convex-optimization/#comparable-classical-complexity","title":"Comparable classical complexity","text":"<p>The best classical algorithm [8] in the same setting has complexity </p>\\[\\begin{equation} \\left[(C'_f + C'_K)n^2 +n^3\\right]\\cdot \\text{polylog}(nR/r\\epsilon)\\,, \\end{equation}\\]<p>where \\(C_f'\\) and \\(C'_K\\) denote the classical complexity of evaluating \\(f\\) and querying membership in \\(K\\), respectively, without the restriction that the circuit be reversible.</p>"},{"location":"areas-of-application/continuous-optimization/general-convex-optimization/#speedup","title":"Speedup","text":"<p>The speedup is greatest when quantities \\(C_f\\) and \\(C_K\\) are large compared to \\(n\\) and roughly equal to \\(C'_f\\) and \\(C'_K\\). In this case, the quantum algorithm can provide an \\(\\mathcal{O}\\left( n \\right)\\) speedup, which is at best a polynomial speedup. The maximal power of the polynomial would be obtained if \\(C_f+C_K\\approx C'_f+C'_K\\) scales as \\(n^2\\), corresponding to a subquadratic speedup from \\(\\mathcal{O}\\left( n^4 \\right)\\) to \\(\\mathcal{O}\\left( n^3 \\right)\\).</p>"},{"location":"areas-of-application/continuous-optimization/general-convex-optimization/#outlook","title":"Outlook","text":"<p>The only analyses of this strategy are theoretical in nature, interested more so in the query complexity of solving this problem than any specific applications it might have. As such, the analysis is not sufficiently fine-grained to determine any impact from constant factors or logarithmic factors. While a quadratic speedup in query complexity is possible, the maximal speedup in gate complexity is smaller than quadratic. Moreover, there is a lack of concrete problems that fit into the paradigm of \"structureless\" quantum convex optimization. Together, these factors make it unlikely that a practical quantum advantage can be found in this instance.</p>"},{"location":"areas-of-application/continuous-optimization/general-convex-optimization/#bibliography","title":"Bibliography","text":"<ol> <li> <p>Shouvanik Chakrabarti, Andrew M. Childs, Tongyang Li, and Xiaodi Wu. Quantum algorithms and lower bounds for convex optimization. Quantum, 4:221, 2020. arXiv: https://arxiv.org/abs/1809.01731. doi:10.22331/q-2020-01-13-221.</p> </li> <li> <p>Joran van Apeldoorn, Andr\u00e1s Gily\u00e9n, Sander Gribling, and Ronald de Wolf. Convex optimization using quantum oracles. Quantum, 4:220, 2020. arXiv: https://arxiv.org/abs/1809.00643. doi:10.22331/q-2020-01-13-220.</p> </li> <li> <p>Yin Tat Lee, Aaron Sidford, and Sam Chiu-wai Wong. A faster cutting plane method and its implications for combinatorial and convex optimization. In Proceedings of the 56th IEEE Symposium on Foundations of Computer Science (FOCS), 1049\u20131065. 2015. arXiv: https://arxiv.org/abs/1508.04874. doi:10.1109/FOCS.2015.68.</p> </li> <li> <p>Andreas Griewank and Andrea Walther. Evaluating Derivatives: Principles and Techniques of Algorithmic Differentiation. SIAM, 2008. doi:10.1137/1.9780898717761.</p> </li> <li> <p>J\u00e9r\u00f4me Bolte, Ryan Boustany, Edouard Pauwels, and B\u00e9atrice Pesquet-Popescu. Nonsmooth automatic differentiation: a cheap gradient principle and other complexity results. arXiv: https://arxiv.org/abs/2206.01730, 2022.</p> </li> <li> <p>Peter B\u00fcrgisser, Cole Franks, Ankit Garg, Rafael Oliveira, Michael Walter, and Avi Wigderson. Efficient algorithms for tensor scaling, quantum marginals, and moment polytopes. In Proceedings of the 59th IEEE Symposium on Foundations of Computer Science (FOCS), 883\u2013897. 2018. arXiv: https://arxiv.org/abs/1804.04739. URL: http://ieee-focs.org/FOCS-2018-Papers/pdfs/59f883.pdf, doi:10.1109/FOCS.2018.00088.</p> </li> <li> <p>Ankit Garg, Robin Kothari, Praneeth Netrapalli, and Suhail Sherif. No quantum speedup over gradient descent for non-smooth convex optimization. In James R. Lee, editor, Proceedings of the 12th Innovations in Theoretical Computer Science Conference (ITCS), volume 185 of Leibniz International Proceedings in Informatics (LIPIcs), 53:1\u201353:20. Dagstuhl, Germany, 2021. Schloss Dagstuhl\u2013Leibniz-Zentrum f\u00fcr Informatik. arXiv: https://arxiv.org/abs/2010.01801. URL: https://drops.dagstuhl.de/opus/volltexte/2021/13592, doi:10.4230/LIPIcs.ITCS.2021.53.</p> </li> <li> <p>Yin Tat Lee, Aaron Sidford, and Santosh S. Vempala. Efficient convex optimization with membership oracles. In Proceedings of the 31st Conference On Learning Theory (COLT), 1292\u20131294. 2018. arXiv: https://arxiv.org/abs/1706.07357. URL: http://proceedings.mlr.press/v75/lee18a.html.</p> </li> </ol>"},{"location":"areas-of-application/continuous-optimization/introduction/","title":"Continuous optimization","text":"<p>Continuous optimization problems arise throughout science and industry. On their face, continuous optimization problems rarely seem quantum mechanical; nevertheless, quantum algorithms have been proposed for accelerating both convex and nonconvex continuous optimization. Most of the research on these algorithms thus far has been to develop and utilize the diverse set of primitive ingredients that give rise to potential quantum advantage in this space, without an eye toward the end-to-end practicality of the algorithms. Developing a better understanding of the practicality of these approaches should be a focus of future work.</p>"},{"location":"areas-of-application/continuous-optimization/nonconvex-optimization-escaping-saddle-points-and-finding-local-minima/","title":"Nonconvex optimization: Escaping saddle points and finding local minima","text":""},{"location":"areas-of-application/continuous-optimization/nonconvex-optimization-escaping-saddle-points-and-finding-local-minima/#overview","title":"Overview","text":"<p>Finding the global minimum of nonconvex optimization problems is challenging because local algorithms get stuck in local minima. Often, there are many local minima and they are each separated by large energy barriers. Accordingly, instead of finding the global minimum, one may settle for finding a local minimum: local minima can often still be used effectively in situations such as training machine learning models. An effective approach to finding a local minimum is gradient descent, but gradient descent can run into the problem of getting stuck near saddle points, which are not local minima but nonetheless have a vanishing gradient. Efficiently finding local minima thus requires methods for escaping saddle points. Limited work in this area suggests a potential polynomial quantum speedup [1] in the dimension dependence for finding local minima, using subroutines for Hamiltonian simulation and quantum gradient estimation.</p>"},{"location":"areas-of-application/continuous-optimization/nonconvex-optimization-escaping-saddle-points-and-finding-local-minima/#actual-end-to-end-problems-solved","title":"Actual end-to-end problem(s) solved","text":"<p>Suppose we have a classical algorithm \\(\\mathcal{A}_f\\) for (approximately) computing a function \\(f: \\mathbb{R}^n \\rightarrow \\mathbb{R}\\) which requires \\(C_f\\) gates to perform with a reversible classical circuit. The amount of error tolerable is specified later. Following [1], suppose further that \\(f\\) is \\(\\ell\\)-smooth and \\(\\rho\\)-Hessian Lipschitz, that is </p>\\[\\begin{align} \\lVert \\nabla f(x_1) - \\nabla f(x_2) \\rVert &amp; \\leq \\ell \\lVert x_1 - x_2 \\rVert \\qquad \\forall x_1, x_2 \\in \\mathbb{R}^n \\\\ \\lVert \\nabla^2 f(x_1) - \\nabla^2 f(x_2) \\rVert &amp; \\leq \\rho \\lVert x_1 - x_2 \\rVert \\qquad \\forall x_1, x_2 \\in \\mathbb{R}^n \\,, \\end{align}\\]<p>where \\(\\nabla f\\) denotes the gradient of \\(f\\) (a vector), \\(\\nabla^2 f\\) denotes the Hessian of \\(f\\) (a matrix), and \\(\\lVert \\cdot \\rVert\\) denotes the standard Euclidean norm for vector arguments, and the spectral norm for matrix arguments.</p><p>The end-to-end problem solved is to take as input a specification of the function \\(f\\), an initial point \\(x_0\\), and an error parameter \\(\\epsilon\\), and to output an \\(\\epsilon\\)-approximate second-order stationary point (i.e. approximate local minimum) \\(x\\), defined as satisfying </p>\\[\\begin{align} \\lVert \\nabla f(x) \\rVert \\leq \\epsilon \\qquad \\qquad \\lambda_{\\min}(\\nabla^2 f(x)) \\geq -\\sqrt{\\rho \\epsilon}\\,, \\end{align}\\]<p>where \\(\\lambda_{\\min}(\\cdot)\\) denotes the minimum eigenvalue of its argument. In other words, the gradient should be nearly zero, and the Hessian should be close to a positive-semidefinite matrix.</p>"},{"location":"areas-of-application/continuous-optimization/nonconvex-optimization-escaping-saddle-points-and-finding-local-minima/#dominant-resource-costcomplexity","title":"Dominant resource cost/complexity","text":"<p>Reference [1] gives a quantum algorithm that performs the \\(C_f\\)-gate quantum circuit for coherently computing \\(f\\) a number of times scaling as </p>\\[\\begin{equation} \\tilde{\\mathcal{O}}\\left(\\frac{\\log(n)(f(x_0)-f^*)}{\\epsilon^{1.75}}\\right) \\end{equation}\\]<p>where \\(x_0\\) is the initial point and \\(f^*\\) is the global minimum of \\(f\\). The evaluation of \\(f\\) must be correct up to precision \\(\\mathcal{O}\\left( \\epsilon^2/n^4 \\right)\\). Note that the work of [1] initially showed a \\(\\log^2(n)\\) dependence, which was later improved to \\(\\log(n)\\) using the improved simulation method of [2]. Any additional gate overhead is not quoted in [1].</p><p>The idea is to run normal gradient descent, which has gradient query cost independent of \\(n\\), until reaching an approximate saddle point. Classical algorithms typically apply random perturbations to detect a direction of negative curvature and continue the gradient descent. Instead, the quantum algorithm constructs a Gaussian wavepacket localized at the saddle point, and evolves according to the Schr\u00f6dinger equation </p>\\[\\begin{equation} \\label{eq:nonconvex_Ham} i\\frac{\\partial}{\\partial t}\\Phi = \\left(-\\frac{1}{2}\\Delta + f(x)\\right)\\Phi\\,, \\end{equation}\\]<p>where \\(\\Delta\\) denotes the Laplacian operator. The intuition is that, in the directions of positive curvature, the particle stays localized (as in a harmonic potential), while in the directions of negative curvature, the particle quickly disperses. Thus, when the position of the particle is measured, it is likely to have escaped the saddle point in a direction of negative curvature, and gradient descent can be continued. The other technical ingredient is the quantum gradient estimation algorithm, which uses a constant number of (coherent) queries to the function \\(f\\) to estimate \\(\\nabla f\\).</p><p>A similar approach was taken in [3] for analyzing the complexity of escaping a saddle point when one has access to noisy queries to the value of the function \\(f\\). Additionally, lower bounds on the \\(\\epsilon\\)-dependence of quantum algorithms for this problem are given in [4].</p>"},{"location":"areas-of-application/continuous-optimization/nonconvex-optimization-escaping-saddle-points-and-finding-local-minima/#existing-error-corrected-resource-estimates","title":"Existing error corrected resource estimates","text":"<p>This problem has received relatively little attention, and no resource estimates have been performed.</p>"},{"location":"areas-of-application/continuous-optimization/nonconvex-optimization-escaping-saddle-points-and-finding-local-minima/#caveats","title":"Caveats","text":"<p>Reference [1] gives the query complexity of the quantum algorithm but does not perform a full end-to-end resource analysis. (However, it does numerically study the performance of the quantum algorithm in a couple of toy examples.) Additionally, many practical scenarios are said to obey a \"cheap gradient principle\" [5, 6], which says that computing the gradient is almost as easy as computing the function itself, and in these scenarios, no significant quantum speedup is available. Finally, in the setting of variational quantum algorithms, this does not avoid the issue of barren plateaus, which refers to the situation where a large portion of the parameter space has a gradient (and Hessian) that vanishes exponentially with \\(n\\). These regions would be characterized as \\(\\epsilon\\)-approximate local minima unless \\(\\epsilon\\) is made exponentially small in \\(n\\).</p>"},{"location":"areas-of-application/continuous-optimization/nonconvex-optimization-escaping-saddle-points-and-finding-local-minima/#comparable-classical-complexity-and-challenging-instance-sizes","title":"Comparable classical complexity and challenging instance sizes","text":"<p>The best classical algorithm [7] for this problem makes </p>\\[\\begin{equation} \\tilde{\\mathcal{O}}\\left(\\frac{\\log(n)(f(x_0)-f^*)}{\\epsilon^{1.75}}\\right) \\end{equation}\\]<p>queries to the gradient of \\(f\\). Note that \\(\\text{poly}(n)\\) queries to the value of \\(f\\) would be needed to construct a query to the gradient. (When the quantum algorithm in [1] was first discovered, the best classical algorithm required \\(\\mathcal{O}\\left( \\log(n)^6 \\right)\\) gradient queries [8, Theorem 3], and this was later improved.)</p>"},{"location":"areas-of-application/continuous-optimization/nonconvex-optimization-escaping-saddle-points-and-finding-local-minima/#speedup","title":"Speedup","text":"<p>The quantum algorithm in [1] has the same query complexity as the classical algorithm in [7]; the difference is that the quantum algorithm makes (coherent) queries to an evaluation oracle, while the classical algorithm requires access to a gradient oracle. Thus, if classical gradient queries are available, there is no speedup, and if no gradient query is available, the speedup can be exponential.</p>"},{"location":"areas-of-application/continuous-optimization/nonconvex-optimization-escaping-saddle-points-and-finding-local-minima/#outlook","title":"Outlook","text":"<p>It is unclear whether the algorithm for finding local minima could lead to a practical speedup, as it depends highly on the (non)availability of an efficient classical procedure for implementing gradient oracles; a quantum speedup is possible only when such oracles are difficult to implement classically. However, the algorithm represents a useful end-to-end problem where the quantum gradient estimation primitive can be applied. It is also notable that the quantum algorithm employs Hamiltonian simulation, a primitive not used in most other approaches to continuous optimization. Relatedly, [9] proposes a quantum subroutine called \"quantum Hamiltonian descent\" which is a genuinely quantum counterpart to classical gradient descent, via Hamiltonian simulation of an equation similar to Eq. \\(\\eqref{eq:nonconvex_Ham}\\). Unlike classical gradient descent, it can exploit quantum tunneling to avoid getting stuck in local minima; thus, it can potentially find global minima of nonconvex functions. Establishing concrete end-to-end problems where quantum approaches based on Hamiltonian simulation yield an advantage in nonconvex optimization is an interesting direction for future work.</p>"},{"location":"areas-of-application/continuous-optimization/nonconvex-optimization-escaping-saddle-points-and-finding-local-minima/#bibliography","title":"Bibliography","text":"<ol> <li> <p>Chenyi Zhang, Jiaqi Leng, and Tongyang Li. Quantum algorithms for escaping from saddle points. Quantum, 5:529, 8 2021. arXiv: https://arxiv.org/abs/2007.10253. URL: https://doi.org/10.22331/q-2021-08-20-529, doi:10.22331/q-2021-08-20-529.</p> </li> <li> <p>Andrew M. Childs, Jiaqi Leng, Tongyang Li, Jin-Peng Liu, and Chenyi Zhang. Quantum simulation of real-space dynamics. Quantum, 6:860, 11 2022. arXiv: https://arxiv.org/abs/2203.17006. URL: https://doi.org/10.22331/q-2022-11-17-860, doi:10.22331/q-2022-11-17-860.</p> </li> <li> <p>Weiyuan Gong, Chenyi Zhang, and Tongyang Li. Robustness of quantum algorithms for nonconvex optimization. arXiv: https://arxiv.org/abs/2212.02548, 2022.</p> </li> <li> <p>Chenyi Zhang and Tongyang Li. Quantum lower bounds for finding stationary points of nonconvex functions. In Andreas Krause, Emma Brunskill, Kyunghyun Cho, Barbara Engelhardt, Sivan Sabato, and Jonathan Scarlett, editors, Proceedings of the 40th International Conference on Machine Learning (ICML), volume 202 of Proceedings of Machine Learning Research, 41268\u201341299. PMLR, 7 2023. arXiv: https://arxiv.org/abs/2212.03906. URL: https://proceedings.mlr.press/v202/zhang23u.html.</p> </li> <li> <p>Andreas Griewank and Andrea Walther. Evaluating Derivatives: Principles and Techniques of Algorithmic Differentiation. SIAM, 2008. doi:10.1137/1.9780898717761.</p> </li> <li> <p>J\u00e9r\u00f4me Bolte, Ryan Boustany, Edouard Pauwels, and B\u00e9atrice Pesquet-Popescu. Nonsmooth automatic differentiation: a cheap gradient principle and other complexity results. arXiv: https://arxiv.org/abs/2206.01730, 2022.</p> </li> <li> <p>Chenyi Zhang and Tongyang Li. Escape saddle points by a simple gradient-descent based algorithm. In M. Ranzato, A. Beygelzimer, Y. Dauphin, P.S. Liang, and J. Wortman Vaughan, editors, Advances in Neural Information Processing Systems 34 (NIPS), 8545\u20138556. Curran Associates, Inc., 2021. arXiv: https://arxiv.org/abs/2111.14069. URL: https://proceedings.neurips.cc/paper\\_files/paper/2021/file/47bd8ac1becf213f155a82244b4a696a-Paper.pdf.</p> </li> <li> <p>Chi Jin, Praneeth Netrapalli, and Michael I. Jordan. Accelerated gradient descent escapes saddle points faster than gradient descent. In S\u00e9bastien Bubeck, Vianney Perchet, and Philippe Rigollet, editors, Proceedings of the 31st Conference On Learning Theory (COLT), volume 75 of Proceedings of Machine Learning Research, 1042\u20131085. PMLR, 7 2018. arXiv: https://arxiv.org/abs/1711.10456. URL: https://proceedings.mlr.press/v75/jin18a.html.</p> </li> <li> <p>Jiaqi Leng, Ethan Hickman, Joseph Li, and Xiaodi Wu. Quantum hamiltonian descent. arXiv: https://arxiv.org/abs/2303.01471, 2023.</p> </li> </ol>"},{"location":"areas-of-application/continuous-optimization/zero-sum-games-computing-nash-equilibria/","title":"Zero-sum games: Computing Nash equilibria","text":""},{"location":"areas-of-application/continuous-optimization/zero-sum-games-computing-nash-equilibria/#overview","title":"Overview","text":"<p>In a two-player zero-sum game, each player independently chooses a strategy and then receives a \"payoff\" (such that the sum of the payoffs is always zero) that depends on which pair of strategies was chosen. A Nash equilibrium is the optimal way of probabilistically choosing a strategy that maximizes a player's worst-case payoff. The problem of computing a Nash equilibrium is, in a certain sense, equivalent to solving a Linear Program (LP): computing a Nash equilibrium is a special case of LP, and conversely any LP can be reduced to computing a Nash equilibrium at the expense of introducing dependencies on a certain instance-specific \"scale-invariant\" precision parameter [1]. However, the quantum approach to solving LPs based on the multiplicative weights update method [1] is more efficient in the special case of computing Nash equilibria, and has fewer caveats. It gives a potentially quadratic speedup over its classical counterpart.</p>"},{"location":"areas-of-application/continuous-optimization/zero-sum-games-computing-nash-equilibria/#actual-end-to-end-problems-solved","title":"Actual end-to-end problem(s) solved","text":"<p>A two-player zero-sum game is defined by an \\(n \\times m\\) matrix \\(A\\) called the \"payoff matrix,\" which specifies how much player 1 wins from player 2 when player 1 plays (pure) strategy \\(i \\in [n]\\) and player 2 plays (pure) strategy \\(j \\in [m]\\). A pure strategy is one in which the players use one fixed strategy in each game. By contrast, a mixed strategy is one in which players randomly choose a pure strategy, according to some probability distribution. Assume the entries of \\(A\\) are between \\(-1\\) and \\(1\\). A Nash equilibrium is an optimal (generally mixed) strategy that maximizes a player's worst-case payoff regardless of the other player's choice. That is, a distribution \\(y \\in \\Delta^m\\), where \\(\\Delta^m\\) denotes the \\(m\\)-dimensional probability simplex, is an optimal strategy for player 2 if it is the argument that optimizes the equation </p>\\[\\begin{equation} % \\begin{align} \\lambda^* = \\min_{y \\in \\Delta^m} \\max_{i \\in [n]} e_i^\\intercal A y % \\end{align} \\end{equation}\\]<p>where \\([n]\\) denotes the set of strategies available to player 1, and \\(e_i\\) denotes a basis state associated with strategy \\(i\\). The quantity \\(\\lambda^*\\) is the value of the game. This can be rewritten explicitly [1] as the following LP </p>\\[\\begin{align} &amp; \\min_{y \\in \\mathbb{R}^m} \\lambda \\\\ \\text{subject to }\\qquad &amp; Ay \\leq \\lambda \\mathbf{1}, \\qquad \\sum_j y_j = 1, \\qquad y_j \\geq 0\\;\\forall j \\end{align}\\]<p>where \\(\\mathbf{1}\\) is the all-ones vector. The dual LP for the above then corresponds to computing the Nash equilibrium for player 1.</p><p>The end-to-end problem solved is to, given access to the entries of the matrix \\(A\\) and an error parameter \\(\\epsilon\\), compute a probability vector \\(y\\) such that </p>\\[\\begin{equation} Ay \\leq (\\lambda^* + \\epsilon) \\mathbf{1}\\,. \\end{equation}\\]"},{"location":"areas-of-application/continuous-optimization/zero-sum-games-computing-nash-equilibria/#dominant-resource-costcomplexity","title":"Dominant resource cost/complexity","text":"<p>The quantum algorithm builds from a classical algorithm based on the multiplicative weights update method from [2]. With probability at least \\(1-\\delta\\), the classical algorithm finds a solution \\(y\\) that approximates the Nash equilibrium to error \\(\\epsilon\\) after \\(\\lceil 16 \\ln(nm/\\delta)/\\epsilon^2)\\rceil\\) iterations, where each iteration can be accomplished using \\(n+m\\) queries to the entries of the matrix \\(A\\) and \\(\\mathcal{O}\\left( n+m \\right)\\) total time. An important subroutine of each iteration is a Gibbs sampling step for a diagonal matrix (a special case of the general quantum Gibbs sampling problem in which any Hermitian matrix is allowable). When the matrix \\(A\\) is sparse, the number of queries can be reduced to \\(2s\\), where \\(s\\) is the maximum number of nonzero entries in a row or column of \\(A\\), and the total time can be reduced to \\(\\mathcal{O}\\left( s\\ln(mn) \\right)\\).</p><p>The quantum algorithm assumes coherent access to the matrix entries of \\(A\\). Through amplitude amplification and the related subroutines of amplitude estimation and minimum finding, the quantum algorithm of [1] speeds up the Gibbs sampling task and reduces the maximum cost of an iteration to \\(\\tilde{\\mathcal{O}}(\\sqrt{n+m}/\\epsilon)\\) queries to the matrix elements of \\(A\\) and an equal amount of time complexity, where \\(\\tilde{\\mathcal{O}}\\) notation suppresses logarithmic factors. In the case that the matrices are sparse, the maximum cost of an iteration is reduced to \\(\\tilde{\\mathcal{O}}(\\sqrt{s}/\\epsilon^{1.5})\\). The work of [3] introduces a technique called dynamic Gibbs sampling, which exploits the fact that the distribution to be sampled changes slowly from iteration to iteration, and further reduces the iteration cost to \\(\\tilde{\\mathcal{O}}(\\sqrt{n+m}/\\epsilon^{1/2} +1/\\epsilon)\\) in the dense case. This gives a total query and time complexity roughly given by </p>\\[\\begin{align} \\text{dense:} \\;\\;\\; &amp; \\left(\\frac{16\\ln(nm)}{\\epsilon^2} \\text{ iterations}\\right)\\times \\left(\\tilde{\\mathcal{O}}\\left(\\frac{\\sqrt{n+m}}{\\sqrt{\\epsilon}} + \\frac{1}{\\epsilon}\\right) \\text{ per iteration}\\right) = \\tilde{\\mathcal{O}}\\left(\\frac{\\sqrt{n+m}}{\\epsilon^{2.5}} + \\frac{1}{\\epsilon^3}\\right) \\\\ \\text{sparse:} \\;\\;\\; &amp; \\left(\\frac{16\\ln(nm)}{\\epsilon^2} \\text{ iterations}\\right)\\times \\left(\\tilde{\\mathcal{O}}\\left(\\frac{\\sqrt{s}}{\\epsilon^{1.5}}\\right) \\text{ per iteration}\\right) = \\tilde{\\mathcal{O}}\\left(\\frac{\\sqrt{s}}{\\epsilon^{3.5}}\\right) &amp; \\end{align}\\]<p>This complexity assumes access to a quantum random access memory (QRAM). Without a QRAM, the cost per iteration increases by a factor \\(\\tilde{\\mathcal{O}}(1/\\epsilon^2)\\).</p><p>See also [4], which independently from [1] gave a quantum algorithm that solves zero-sum games with slightly worse \\(\\epsilon\\) dependence, as well as [5], which gave quantum algorithms for generalizations of zero-sum games to other vector norms.</p>"},{"location":"areas-of-application/continuous-optimization/zero-sum-games-computing-nash-equilibria/#existing-error-corrected-resource-estimates","title":"Existing error corrected resource estimates","text":"<p>There are no existing error corrected resource estimates for this algorithm.</p>"},{"location":"areas-of-application/continuous-optimization/zero-sum-games-computing-nash-equilibria/#caveats","title":"Caveats","text":"<ul> <li>Due to poor dependence of the complexity on the error \\(\\epsilon\\), this algorithm is only likely to be useful in situations where it is not necessary to learn the optimal strategy to high precision. It is unclear when such situations arise in practice.</li> <li>As mentioned above, if no QRAM is available, the runtime suffers a \\(\\tilde{\\mathcal{O}}(1/\\epsilon^2)\\) time slowdown.</li> <li>A fully end-to-end analysis should also consider the exact way that the queries to the matrix entries of \\(A\\) are implemented. If they are given in a classical database, a large \\(\\mathcal{O}\\left( nm \\right)\\)-size QRAM may also be required to implement the queries in \\(\\text{polylog}(mn)\\) time. Note that this would be separate from the \\(\\tilde{\\mathcal{O}}(1/\\epsilon^2)\\)-size QRAM the algorithm uses to reduce the time complexity. To avoid the QRAM requirement for implementing a query, it must be the case that the matrix entries are efficiently computable in some other way.</li> </ul>"},{"location":"areas-of-application/continuous-optimization/zero-sum-games-computing-nash-equilibria/#comparable-classical-complexity-and-challenging-instance-sizes","title":"Comparable classical complexity and challenging instance sizes","text":"<p>The classical version of the quantum algorithm has time and query complexity given by [1, Section 2] </p>\\[\\begin{align} \\text{dense:} \\;\\;\\; &amp; \\left(\\frac{16\\ln(nm)}{\\epsilon^2} \\text{ iterations}\\right)\\times \\left(\\mathcal{O}\\left( n+m \\right) \\text{ per iteration}\\right) = \\tilde{\\mathcal{O}}\\left(\\frac{n+m}{\\epsilon^2}\\right) \\\\ \\text{sparse:} \\;\\;\\; &amp; \\left(\\frac{16\\ln(nm)}{\\epsilon^2} \\text{ iterations}\\right)\\times \\left(\\tilde{\\mathcal{O}}(s) \\text{ per iteration}\\right) = \\tilde{\\mathcal{O}}\\left(\\frac{s}{\\epsilon^{2}}\\right) &amp; \\end{align}\\]<p>Alternatively, the problem could be solved using other approaches for solving the associated LP. Classical interior point methods for LPs can achieve \\(\\mathcal{O}\\left( n^{\\omega}\\log(1/\\epsilon) \\right)\\) runtime in the common case that \\(m=\\mathcal{O}\\left( n \\right)\\) [6], where \\(\\omega &lt; 2.37\\) is the matrix-multiplication exponent. This runtime exhibits better \\(\\epsilon\\) dependence at the expense of worse \\(n\\) dependence. Note that quantum interior point methods have also been proposed for conic programs like LPs, but whether they could yield a speedup over classical interior point methods would depend on the scaling of certain instance-specific parameters.</p>"},{"location":"areas-of-application/continuous-optimization/zero-sum-games-computing-nash-equilibria/#speedup","title":"Speedup","text":"<p>The quantum complexity has a quadratic improvement in complexity with respect to the parameter \\(n+m\\), and a polynomial slowdown with respect to the parameter \\(\\epsilon\\).</p>"},{"location":"areas-of-application/continuous-optimization/zero-sum-games-computing-nash-equilibria/#outlook","title":"Outlook","text":"<p>It is difficult to assess whether a practical advantage could be obtained in the setting of zero-sum games without further investigation of how queries to matrix elements are accomplished, an assessment of constant factors involved in the algorithm, and consideration of any additional overheads from fault-tolerant quantum computation. The theoretical speedup available is quadratic and may require a medium or large-scale QRAM. This speedup may not be sufficiently large to overcome these overheads in practice.</p><p>It is perhaps instructive to compare the outlook of zero-sum games to conic programming more generally. On the one hand, unlike the algorithm for general SDPs and LPs, the algorithm for zero-sum games does not have a complexity dependence on instance-specific parameters denoting the size of the primal and dual solutions. This makes it easier to evaluate the runtime of the algorithm and more likely that it can be an effective algorithm. On the other hand, a core subroutine of the quantum algorithm is to perform classical Gibbs sampling quadratically faster than a classical computer can using techniques like amplitude amplification. However, it is not clear how the speedup could be made greater than quadratic, even in special cases. A similar subroutine is required in the multiplicative weights approach to solving SDPs, but in that case, the Gibbs state to be sampled is a truly quantum state (i.e. nondiagonal in the computational basis), rather than a classical state. Using more advanced methods for Gibbs sampling, it is possible that in some special cases there could be a superquadratic quantum speedup for SDPs that would not be available for the simpler case of LPs and zero-sum games.</p>"},{"location":"areas-of-application/continuous-optimization/zero-sum-games-computing-nash-equilibria/#bibliography","title":"Bibliography","text":"<ol> <li> <p>Joran van Apeldoorn and Andr\u00e1s Gily\u00e9n. Quantum algorithms for zero-sum games. arXiv: https://arxiv.org/abs/1904.03180, 2019.</p> </li> <li> <p>Michael D. Grigoriadis and Leonid G. Khachiyan. A sublinear-time randomized approximation algorithm for matrix games. 18(2):53\u201358, 1995. doi:10.1016/0167-6377(95)00032-0.</p> </li> <li> <p>Adam Bouland, Yosheb Getachew, Yujia Jin, Aaron Sidford, and Kevin Tian. Quantum speedups for zero-sum games via improved dynamic gibbs sampling. arXiv: https://arxiv.org/abs/2301.03763, 2023.</p> </li> <li> <p>Tongyang Li, Shouvanik Chakrabarti, and Xiaodi Wu. Sublinear quantum algorithms for training linear and kernel-based classifiers. In Kamalika Chaudhuri and Ruslan Salakhutdinov, editors, Proceedings of the 36th International Conference on Machine Learning (ICML), volume 97 of Proceedings of Machine Learning Research, 3815\u20133824. PMLR, 6 2019. arXiv: https://arxiv.org/abs/1904.02276. URL: https://proceedings.mlr.press/v97/li19b.html.</p> </li> <li> <p>Tongyang Li, Chunhao Wang, Shouvanik Chakrabarti, and Xiaodi Wu. Sublinear classical and quantum algorithms for general matrix games. In Proceedings of the 35th AAAI Conference on Artificial Intelligence, volume 35, 8465\u20138473. 5 2021. arXiv: https://arxiv.org/abs/2012.06519. URL: https://ojs.aaai.org/index.php/AAAI/article/view/17028, doi:10.1609/aaai.v35i10.17028.</p> </li> <li> <p>Michael B. Cohen, Yin Tat Lee, and Zhao Song. Solving linear programs in the current matrix multiplication time. Journal of the ACM, 1 2021. arXiv: https://arxiv.org/abs/1810.07896. URL: https://doi.org/10.1145/3424305, doi:10.1145/3424305.</p> </li> </ol>"},{"location":"areas-of-application/cryptanalysis/breaking-cryptosystems/","title":"Breaking cryptosystems","text":""},{"location":"areas-of-application/cryptanalysis/breaking-cryptosystems/#overview","title":"Overview","text":"<p>Much of modern cryptography relies on computational assumptions.<sup>1</sup> A cryptosystem is considered secure if, assuming that a particular mathematical problem is hard to solve, an adversary cannot learn more than a negligible amount of information about what is being encrypted. The earliest such cryptosystems used particular problems from number theory, and variants are widely deployed to this day [1]. These cryptosystems are in the class of public-key cryptography, which enables any user to perform tasks like encryption, in contrast to symmetric cryptography, in which users have to pre-share a secret key.</p><p>Quantum computers use quantum algorithms to solve computational problems, and in some cases they provide a speedup over the best known classical techniques. When they are applied to the underlying computational task in a cryptosystem, a large speedup over classical methods can break the cryptosystem, in that an adversary efficiently learns the encrypted information to a non-negligible degree. One of the first discovered and most famous applications of quantum computing is Shor's algorithm [2], which breaks common methods of public-key cryptography based on number theory, including factoring, discrete logarithm, and elliptic curves. The applications of these public-key cryptosystems include encryption to hide the contents of a message, signatures that prevent tampering and impersonation, and key exchange to generate a key for symmetric cryptography [3]. In this section, we restrict our focus to two of the most widely used cryptosystems: Rivest\u2013Shamir\u2013Adleman (RSA) and elliptic curves.</p>"},{"location":"areas-of-application/cryptanalysis/breaking-cryptosystems/#actual-end-to-end-problems-solved","title":"Actual end-to-end problem(s) solved","text":"<p>The RSA cryptosystem [4] relies on a user choosing a large number \\(N\\) that is the product of two prime numbers; arithmetic is done modulo \\(N\\). Denote by \\(n=\\lceil \\log_2(N) \\rceil\\) the number of bits specifying \\(N\\). The two prime numbers are kept private, but their product is publicly revealed, along with an exponent \\(e\\). A message \\(m\\) is encrypted as \\(m^e \\bmod N\\). By construction, using tricks from number theory, there exists \\(d\\) such that \\((m^e)^d \\bmod N = m \\bmod N\\). That is, exponentiating with \\(d\\) performs decryption. The user efficiently solves for the necessary value of \\(d\\) using the Euclidean algorithm, by knowing the prime factors of \\(N\\), along with \\(e\\). However, if an adversary is able to find the factors of \\(N\\) after the construction by the user, they can also solve for \\(d\\) and thereby decrypt messages. The security of the cryptosystem comes from the difficulty of factoring large numbers, i.e., finding the two primes that multiply to \\(N\\).</p><p>A similar cryptosystem is based on elliptic curves, which has the advantage that classical algorithms attacking it are even less successful than for RSA, so the ratio of bits of security (quantifying the number of attacks needed to learn the encrypted information; see section on weakening cryptosystems for details) relative to key size is larger. Consequently, fewer resources (e.g., communication, complexity of encryption and decryption) are required to implement elliptic curve cryptography. Instead of using the multiplicative group of a finite field, consider points on an elliptic curve [5, 6]: </p>\\[\\begin{equation} y^2=x^3+ax+b\\,,\\quad a,b\\in K\\,, \\end{equation}\\]<p>where \\(K\\) is a field. A special group operation can be defined over points \\((x,y)\\) lying on the elliptic curve. Then, given a secret number \\(c\\) and a point \\(P = (x,y)\\), the point \\(P\\) can be added to itself under this operation \\(c\\) times, yielding the point \\(P'=cP\\), which can be efficiently computed from \\(c\\) and \\(P\\). Multiplication by \\(c\\) is analogous to the exponentiation in RSA, above. The assumption of hardness is in the following problem, known as the elliptic curve discrete logarithm problem (ECDLP): For two points \\(P,P'\\) on an elliptic curve, find an integer \\(c\\) such that \\(P'=cP\\). As an example of this cryptosystem, for a publicly known point \\(P\\), a receiver chooses a secret \\(c\\) and publishes \\(cP\\). The sender chooses a random integer \\(d\\) and encrypts the message \\(m\\) as \\(m+ d(cP)\\), also sending \\(dP\\). Since group multiplication is commutative, to decrypt the message, the receiver multiplies \\(dP\\) by \\(c\\) and subtracts the product from the encrypted message.</p>"},{"location":"areas-of-application/cryptanalysis/breaking-cryptosystems/#dominant-resource-costcomplexity","title":"Dominant resource cost/complexity","text":"<p>Shor's algorithm [2] solves the number-theoretic problem of order finding: given \\(n\\)-bit positive integer \\(N\\) and \\(x\\) coprime to \\(N\\), find the smallest integer \\(r\\) such that \\(x^r=1 \\bmod N\\). Factoring was shown to reduce to order finding. In particular, there is an efficient, otherwise classical algorithm, of classical complexity \\(\\mathcal{O}\\left( n^3 \\right)\\) [7], that uses order finding as a quantum subroutine. To describe the quantum algorithm for order finding, let the function \\(f\\) denote modular exponentiation, i.e., \\(f(e) = x^e \\bmod N\\), and note that \\(f\\) is periodic with (unknown) period \\(r\\). Also, let \\(L\\) be a large integer such that an interval of length \\(L\\) contains many periods, i.e., \\(L \\gg r\\). It can be shown that \\(L \\geq N^2\\) is sufficient. There are three steps. First, an equal superposition over the numbers \\(\\{0,\\ldots,L-1\\}\\) is formed and the function \\(f\\) is computed into an ancilla register yielding the state \\(L^{-1/2}\\sum_{e=0}^{L-1} \\ket{e}\\ket{f(e)}\\). Second, a measurement is performed on the ancilla register, which, due to the periodicity of the function \\(f\\), yields a state \\((\\lceil L/r \\rceil)^{-1/2} \\sum_{j=0}^{\\lfloor L/r \\rfloor}\\ket{rj + y}\\) for \\(0\\leq y&lt;r\\) a random and unknown integer.<sup>2</sup> Third, a quantum Fourier transform is performed. In the case that \\(L\\) is a multiple of \\(r\\), the result is </p>\\[\\begin{equation} \\frac{\\sqrt{r}}{L}\\sum_{j=0}^{L/r} \\sum_{z=0}^{L-1}e^{2\\pi i z(rj+y)/L} \\ket{z} = \\frac{1}{\\sqrt{r}}\\sum_{\\ell=0}^{r-1}e^{2\\pi i \\ell y/r} \\ket{\\ell L/r } \\,, \\end{equation}\\]<p>where the equality follows since coefficients of \\(\\ket{z}\\) for which \\(z\\) is not equal to \\(\\ell L/r\\) for some integer \\(\\ell\\) vanish due to destructive interference. Measurement of this state then produces an outcome \\(\\ell L/r\\) for a random choice of \\(\\ell\\). The value of \\(r\\) can be classically computed by dividing the measurement outcome by \\(L\\) and determining the value of the denominator of the rational number that results; repetition may be required since \\(\\ell\\) and \\(r\\) could have common divisors. If \\(L/r\\) is not an integer, the measurement outcome is (with high probability) an integer close to \\(\\ell L / r\\) for some integer \\(\\ell\\). One can deduce the rational number \\(\\ell/r\\) (which allows for the determination of \\(r\\)) from the estimate of \\(\\ell L /r\\) by writing it as a continued fractions expansion, with classical complexity \\(\\mathcal{O}\\left( n^3 \\right)\\) [7].</p><p>This entire procedure can alternatively be viewed as quantum phase estimation applied to the unitary \\(U\\) that sends \\(\\ket{y}\\mapsto \\ket{xy \\bmod N}\\) for all \\(y\\) relatively prime to \\(N\\), performed with at least \\(2n\\) bits of precision.</p><p>The number of qubits for order finding is \\(\\mathcal{O}\\left( n \\right)\\), which stems from the number of bits specifying the problem: the first register has size \\(2n\\), and the ancilla register holding the result \\(f(e)\\) has size \\(n\\). Naively, the number of operations is \\(\\mathcal{O}\\left( n^2 \\right)\\) for the quantum Fourier transform and \\(\\mathcal{O}\\left( n^3 \\right)\\) for implementing the coherent modular exponentiation \\(\\ket{e}\\ket{0} \\mapsto \\ket{e}\\ket{x^e \\bmod N}\\). The bottleneck in the complexity is thus from reversible circuits for modular arithmetic. These circuits are closely related to those in classical computing that have been optimized. The best scaling in theory is achieved with algorithms that have large prefactors in their complexity, making them impractical to implement except for large numbers: \\(\\mathcal{O}\\left( n^2\\log(n) \\right)\\) is possible asymptotically, using integer multiplication with \\(\\mathcal{O}\\left( n\\log(n) \\right)\\) scaling [8]. Alternatively, optimization may be performed to, e.g., increase qubit count and decrease gate count. For example, an approximate version of the quantum Fourier transform is implemented with \\(\\mathcal{O}\\left( n\\log(n) \\right)\\) gates and allows factoring with \\(\\mathcal{O}\\left( \\log (n) \\right)\\)-depth quantum circuits [9], at the cost of extra overhead in number of qubits and gates; allowing for \\(\\mathcal{O}\\left( \\log^2 (n) \\right)\\)-depth preserves the circuit size \\(\\mathcal{O}\\left( n^3 \\right)\\).</p><p>A related approach proposed by Regev [10] for quantum factoring has quantum circuit size of only \\(\\widetilde{\\mathcal{O}}\\left( n^{3/2} \\right)\\) gates but the circuit has to be run \\(\\mathcal{O}\\left( n^{1/2} \\right)\\) times. Furthermore, the algorithm relies on a plausible number-theoretic assumption. The reduction in quantum circuit size may lead to more favorable resource counts in practice.</p><p>Essentially the same quantum algorithm of Shor is readily applied to elliptic curves, as well as the discrete logarithm problem (i.e., find \\(r\\) such that \\(a^r=b\\) for \\(a,b\\in G\\) where \\(G\\) is a group) that also is used as a computationally hard problem for cryptography. These applications are all instances of the hidden subgroup problem: Find the generators for subgroup \\(K\\) of a finite group \\(G\\), given a quantum oracle performing \\(U\\ket{g}\\ket{h}=\\ket{g}\\ket{h \\oplus f(g)}\\), where \\(f:G\\to X\\) (\\(X\\) is a finite set) is a function that is promised to be constant on the cosets of \\(K\\) and take unique values on each coset. In the case of period finding, \\(G\\) is the group \\(\\mathbb{Z}/L\\mathbb{Z}\\) under addition, and the hidden subgroup is \\(K = \\{0,r,2r,\\ldots,L-r\\}\\) (technically a subgroup only if \\(r\\) divides \\(L\\)); one can verify that \\(f(g) = x^g \\bmod N\\) is constant on each coset of \\(K\\). The procedure outlined above for period finding can be applied to other groups, where it is called \"the standard method\" [11] (which requires generalizing the quantum Fourier transform to arbitrary groups). For abelian groups, the hidden subgroup \\(K\\) can be determined with \\(\\mathrm{polylog}(|G|)\\) queries to \\(f\\), but the method does not work for nonabelian groups, such as the symmetric group and the dihedral group.</p>"},{"location":"areas-of-application/cryptanalysis/breaking-cryptosystems/#existing-error-corrected-resource-estimates","title":"Existing error corrected resource estimates","text":"<p>The minimum recommended key size for RSA is 2048 bits [12]. Optimizations in the circuits [13, 14] and incorporation of hardware constraints [15] have led to decreasing but also more realistic resource estimates. For key size 2048, assuming nearest-neighbor connectivity, about \\(14000\\) logical qubits (which includes space for routing and distillation; see sections on quantum error correction and lattice surgery) and \\(3\\times 10^9\\) Toffoli gates are necessary [16].</p><p>For elliptic curve cryptography, the minimum recommended key size to ensure 128-bit security, is 256 bits [12] (achieving the same level of security with RSA requires a key size of 3072 bits [17, 18]). For breaking 256-bit elliptic curve cryptography, it is estimated that around three times fewer logical qubits, and 100 times fewer Toffoli gates are required (compared to 3072-bit RSA) [18]. Similar to factoring, improvements have been made in circuit compilation [19] and hardware considerations [20], resulting in an estimate of 2871 logical qubits and \\(5.76\\times 10^9\\) \\(T\\) gates (note that one Toffoli gate costs around 4 \\(T\\) gates). As a conclusion, breaking elliptic curve cryptography is easier than factoring for quantum computers in practice [21], relative to their practical difficulty on classical computers.</p><p>In both cases (2048-bit RSA [16, 22] and 256-bit elliptic curves [20]), given current hardware schemes based on surface codes, the number of physical qubits is estimated to be on the order of \\(10\\) million and the computation runs for around \\(10\\) hours. For a discussion on how to convert between logical and physical resources, see the section on fault-tolerant quantum computation. Optimization based on the particular architecture can give improvements to these estimates. For example, assuming a logarithmic number of nonlocal links, as in photonic implementations, enables breaking elliptic curves around 200 times faster [23]. The algorithms considered in the resource estimates above do not achieve the best known asymptotic scaling, which comes at the cost of large constant prefactors.</p>"},{"location":"areas-of-application/cryptanalysis/breaking-cryptosystems/#caveats","title":"Caveats","text":"<p>While the popular cryptosystems based on number-theoretic problems are rendered insecure for public-key cryptography, there exist alternatives that are believed to be secure against quantum computers: e.g., based on error-correcting codes or lattices [3]. These alternative computational problems are believed to be hard for both classical and quantum computers. The National Institute of Standards and Technology (NIST) of the United States plans to provide standards by 2024 to prompt implementation [24]. The class of symmetric cryptography (see a standard text [1] for details) involves computations that do not have much structure, and also is not broken by quantum computers. Instead, the number of bits of security is reduced.</p><p>Prior experimental demonstrations of Shor's algorithm have used knowledge of the answer in order to optimize the circuit and thus lead to sizes that are experimentally feasible on non-error-corrected devices. Meaningful demonstration should avoid such shortcuts [25], which are not available in realistic cryptographic scenarios.</p>"},{"location":"areas-of-application/cryptanalysis/breaking-cryptosystems/#comparable-classical-complexity-and-challenging-instance-sizes","title":"Comparable classical complexity and challenging instance sizes","text":"<p>The best known classical algorithm for factoring is the number field sieve, which has time complexity super-polynomial in number of bits \\(n\\): namely, it scales as \\(\\mathcal{O}\\left( \\exp(p\\cdot n^{1/3}\\log^{2/3}(n)) \\right)\\), where \\(p&gt;1.9\\). With a hybrid quantum-classical algorithm applying amplitude amplification on the number field sieve, \\(p= 1.387\\) can be achieved using a number of qubits scaling only as \\(\\mathcal{O}\\left( n^{2/3} \\right)\\) [26]. Classically, problems of size 795 bits have been factored, taking 76 computer core-years, which distributed in parallel over a cluster took 12 days; the same team then extended the record to 829 bits [17].</p><p>Several algorithms attacking elliptic curve cryptography have complexity \\(\\mathcal{O}\\left( 2^{n/2} \\right)\\) [27], leading to the recommended doubling of key size compared to bits of security. In practice, a problem of size 117 bits was solved [28].</p>"},{"location":"areas-of-application/cryptanalysis/breaking-cryptosystems/#speedup","title":"Speedup","text":"<p>The number of gates to implement Shor's algorithm is \\(\\widetilde{\\mathcal{O}}\\left( n^2 \\right)\\) asymptotically using fast multiplication on large numbers [29]. More practically, without incurring the time overhead and additional storage space of fast multiplication, the scaling is \\(\\mathcal{O}\\left( n^3 \\right)\\). Assuming classical and quantum gates are polynomially related in time complexity, the speedup is super-polynomial. However, there are no tight lower bounds on the classical complexity of factoring or ECDLP; it remains possible that more efficient classical algorithms could be discovered.</p>"},{"location":"areas-of-application/cryptanalysis/breaking-cryptosystems/#nisq-implementations","title":"NISQ implementations","text":"<p>The large circuit depth, complicated operations, and high number of qubits needed to implement Shor's algorithm make faithful NISQ implementation challenging. However, there have been several attempts to ease implementation at the expense of losing the guarantees of Shor's algorithm, in the hope that the output is still correct with some nonzero probability, which could be vanishing.</p><p>One approach [30] is to simplify several operations and make them approximate. The outcome is that the circuit depth is \\(\\mathcal{O}\\left( n^2 \\right)\\), saving a factor of \\(n\\) [14]. The depth is then about \\(10^8\\) to factor a 1024-bit instance of RSA, so for relevant sizes, error correction is still required. Implementation of the approximate algorithm, including experimentally, allowed for the successful factorization of larger problem instances than had been possible before. This approximate version is not NISQ in the usual sense of involving noisy circuits, but rather introduces some uncontrolled approximation error in return for reducing the depth, for the possibility of a useful result. Another approach is to encode the factoring problem in a variational optimization circuit. Again, performance is not guaranteed; moreover, variational optimization applied to generic problems is expected to have, at best, a quadratic improvement compared to classical methods, leaving no hope for breaking cryptography. Classical simulation on small problem sizes shows that the algorithm can succeed [31], as does experimental implementation on a superconducting quantum processor [32]. We emphasize that, generally, these NISQ approaches have no evidence or arguments for scaling to cryptographically relevant system sizes.</p>"},{"location":"areas-of-application/cryptanalysis/breaking-cryptosystems/#outlook","title":"Outlook","text":"<p>The existence of Shor's algorithm implies common RSA and elliptic curve schemes are theoretically not secure, and resource estimates have made clear what scale of quantum hardware would break them. While such hardware does not exist currently, progress towards such a device can be used to inform the speed of transitioning to quantum-resistant encryption [33]. Currently, from a hardware perspective, the field of quantum computing is far from implementing algorithms that would break encryption schemes used in practice. The estimates above suggest that the resources required would be millions of physical qubits performing billions of Toffoli gates running on the timescale of days. In contrast, current state-of-the-art is on the order of one hundred noisy physical qubits, with progress towards demonstration of a single logical qubit. Running fault-tolerant quantum computation requires extra overhead, such as magic state factories (see the sections on quantum error correction and lattice surgery). Thus, the gap between state-of-the-art hardware and the requirements for breaking cryptosystems is formidable. Moreover, a linear increase in key size will increase, e.g., the number of Toffoli gates by a power of three, which can be substantial. Therefore, considering the experimental challenges, likely only the most sensitive data will be at risk first, rather than common transactions. Consequently, these highly confidential communications will likely adopt post-quantum cryptography first to avoid being broken. However, insecure protocols often linger in practice, so quantum computers can exploit any vulnerabilities in deployed systems that have not been addressed. For example, RSA keys of size 768 bits have been found in commercial devices (note that such key sizes can already be broken classically [17]). In addition, intercepted messages, encrypted with RSA or elliptic curves, can be stored now and decrypted later, once large-scale quantum computers become available.</p><p>The resilience of candidates for post-quantum cryptography is under active investigation. In particular, specialized quantum attacks [34] can reduce the number of bits of security, weakening the cryptosystem. Classical attacks have even broken certain cryptosystems [35]. Note that these attacks affect the feasibility of particular proposals, but there exist other post-quantum candidates that have no known weaknesses.</p><p>A sensitive area that warrants additional discussion is cryptocurrency, since much of the encryption relies on the compromised, number-theoretic, public-key cryptography. Moreover, changing the cryptographic protocol of the currency requires that most of the users reach a consensus to do so, which can be challenging to coordinate, even if the technical hurdles of adopting post-quantum encryption are overcome. Cryptocurrency wallets that have revealed their public key (for example, via a transaction reusing a public key assigned to that wallet previously) can be broken using Shor's algorithm. An attack is also possible during the short time-window in which the key is revealed during a single transaction [36]. Different cryptocurrencies have different levels of susceptibility to these types of attacks [37, 38]. Nevertheless, the mining of cryptocurrency is not broken, but only weakened by quantum computers.</p>"},{"location":"areas-of-application/cryptanalysis/breaking-cryptosystems/#bibliography","title":"Bibliography","text":"<ol> <li> <p>Jonathan Katz and Yehuda Lindell. Introduction to Modern Cryptography: Third Edition. CRC Press, Boca Raton, FL, 2021.</p> </li> <li> <p>Peter W. Shor. Polynomial-time algorithms for prime factorization and discrete logarithms on a quantum computer. SIAM Journal on Computing, 26(5):1484\u20131509, 1997. Earlier version in *FOCS'94*. arXiv: https://arxiv.org/abs/quant-ph/9508027. doi:10.1137/S0097539795293172.</p> </li> <li> <p>Daniel J. Bernstein and Tanja Lange. Post-quantum cryptography. Nature, 549(7671):188\u2013194, 9 2017. ePrint: https://eprint.iacr.org/2017/314. URL: https://doi.org/10.1038/nature23461, doi:10.1038/nature23461.</p> </li> <li> <p>R. L. Rivest, A. Shamir, and L. Adleman. A method for obtaining digital signatures and public-key cryptosystems. Communications of the ACM, 21(2):120\u2013126, 2 1978. URL: https://doi.org/10.1145/359340.359342, doi:10.1145/359340.359342.</p> </li> <li> <p>Neal Koblitz. Elliptic curve cryptosystems. Mathematics of Computation, 48(177):203\u2013209, 1 1987. doi:10.2307/2007884.</p> </li> <li> <p>Victor S. Miller. Use of elliptic curves in cryptography. In Hugh C. Williams, editor, Advances in Cryptology \u2013 CRYPTO 1985, 417\u2013426. Berlin, Heidelberg, 1986. Springer Berlin Heidelberg. doi:10.1007/3-540-39799-X\\_31.</p> </li> <li> <p>Michael A. Nielsen and Isaac L. Chuang. Quantum computation and quantum information. Cambridge University Press, 2000. doi:10.1017/CBO9780511976667.</p> </li> <li> <p>David Harvey and Joris van der Hoeven. Integer multiplication in time \\(o(n\\mathrm log\\, n)\\). Annals of Mathematics, 193(2):563 \u2013 617, 2021. URL: https://doi.org/10.4007/annals.2021.193.2.4, doi:10.4007/annals.2021.193.2.4.</p> </li> <li> <p>R. Cleve and J. Watrous. Fast parallel circuits for the quantum fourier transform. In Proceedings of the 41st IEEE Symposium on Foundations of Computer Science (FOCS), volume, 526\u2013536. 2000. arXiv: https://arxiv.org/abs/quant-ph/0006004. doi:10.1109/SFCS.2000.892140.</p> </li> <li> <p>Oded Regev. An efficient quantum factoring algorithm. arXiv: https://arxiv.org/abs/2308.06572, 2023.</p> </li> <li> <p>Andrew M. Childs and Wim van Dam. Quantum algorithms for algebraic problems. Reviews of Modern Physics, 82:1\u201352, 1 2010. arXiv: https://arxiv.org/abs/0812.0380. URL: https://link.aps.org/doi/10.1103/RevModPhys.82.1, doi:10.1103/RevModPhys.82.1.</p> </li> <li> <p>Elaine Barker and Quynh Dang. Recommendation for key management, part 3: application-specific key management guidance. Technical Report SP 800-57 Part 3 Rev. 1, National Institute of Standards and Technology, Gaithersburg, MD, 2015. doi:10.6028/NIST.SP.800-57pt3r1.</p> </li> <li> <p>Stephane Beauregard. Circuit for shor's algorithm using 2n+3 qubits. Quantum Information and Computation, 3(2):175\u2013185, 3 2003. arXiv: https://arxiv.org/abs/quant-ph/0205095. doi:10.26421/QIC3.2-8.</p> </li> <li> <p>Thomas H\u00e4ner, Martin Roetteler, and Krysta M. Svore. Factoring using 2n + 2 qubits with toffoli based modular multiplication. Quantum Information and Computation, 17(7\u20138):673\u2013684, 6 2017. arXiv: https://arxiv.org/abs/1611.07995. doi:10.26421/QIC17.7-8-7.</p> </li> <li> <p>Austin G. Fowler, Matteo Mariantoni, John M. Martinis, and Andrew N. Cleland. Surface codes: towards practical large-scale quantum computation. Physical Review A, 86:032324, 9 2012. arXiv: https://arxiv.org/abs/1208.0928. URL: https://link.aps.org/doi/10.1103/PhysRevA.86.032324, doi:10.1103/PhysRevA.86.032324.</p> </li> <li> <p>Craig Gidney and Martin Eker\u00e5. How to factor 2048 bit rsa integers in 8 hours using 20 million noisy qubits. Quantum, 5:433, 4 2021. arXiv: https://arxiv.org/abs/1905.09749. URL: https://doi.org/10.22331/q-2021-04-15-433, doi:10.22331/q-2021-04-15-433.</p> </li> <li> <p>Fabrice Boudot, Pierrick Gaudry, Aurore Guillevic, Nadia Heninger, Emmanuel Thom\u00e9, and Paul Zimmermann. Comparing the difficulty of factorization and discrete logarithm: a 240-digit experiment. In Daniele Micciancio and Thomas Ristenpart, editors, Advances in Cryptology \u2013 CRYPTO 2020, 62\u201391. Cham, 2020. Springer International Publishing. arXiv: https://arxiv.org/abs/2006.06197. doi:10.1007/978-3-030-56880-1\\_3.</p> </li> <li> <p>Martin Roetteler, Michael Naehrig, Krysta M. Svore, and Kristin Lauter. Quantum resource estimates for computing elliptic curve discrete logarithms. In Tsuyoshi Takagi and Thomas Peyrin, editors, Advances in Cryptology \u2013 ASIACRYPT 2017, 241\u2013270. Cham, 2017. Springer International Publishing. arXiv: https://arxiv.org/abs/1706.06752. doi:10.1007/978-3-319-70697-9\\_9.</p> </li> <li> <p>Thomas H\u00e4ner, Samuel Jaques, Michael Naehrig, Martin Roetteler, and Mathias Soeken. Improved quantum circuits for elliptic curve discrete logarithms. In Jintai Ding and Jean-Pierre Tillich, editors, Post-Quantum Cryptography, 425\u2013444. Cham, 2020. Springer International Publishing. arXiv: https://arxiv.org/abs/2001.09580. doi:10.1007/978-3-030-44223-1\\_23.</p> </li> <li> <p>Mark Webber, Vincent Elfving, Sebastian Weidt, and Winfried K. Hensinger. The impact of hardware specifications on reaching quantum advantage in the fault tolerant regime. AVS Quantum Science, 4(1):013801, 2022. arXiv: https://arxiv.org/abs/2108.12371. URL: https://doi.org/10.1116/5.0073075, arXiv:https://doi.org/10.1116/5.0073075, doi:10.1116/5.0073075.</p> </li> <li> <p>John Proos and Christof Zalka. Shor's discrete logarithm quantum algorithm for elliptic curves. Quantum Information and Computation, 3(4):317\u2013344, 7 2003. arXiv: https://arxiv.org/abs/0301141.</p> </li> <li> <p>Jinyoung Ha, Jonghyun Lee, and Jun Heo. Resource analysis of quantum computing with noisy qubits for shor's factoring algorithms. Quantum Information Processing, 21(2):60, 1 2022. URL: https://doi.org/10.1007/s11128-021-03398-1, doi:10.1007/s11128-021-03398-1.</p> </li> <li> <p>Daniel Litinski. How to compute a 256-bit elliptic curve private key with only 50 million toffoli gates. arXiv: https://arxiv.org/abs/2306.08585, 2023. arXiv:2306.08585.</p> </li> <li> <p>Gorjan Alagic, Daniel Apon, David Cooper, Quynh Dang, Thinh Dang, John Kelsey, Jacob Lichtinger, Carl Miller, Dustin Moody, Rene Peralta, Ray Perlner, Angela Robinson, Daniel Smith-Tone, and Yi-Kai Liu. Status report on the third round of the nist post-quantum cryptography standardization process. Technical Report NISTIR 8413, National Institute of Standards and Technology, Gaithersburg, MD, 2022. doi:10.6028/NIST.IR.8413-upd1.</p> </li> <li> <p>John A. Smolin, Graeme Smith, and Alexander Vargo. Oversimplifying quantum factoring. Nature, 499(7457):163\u2013165, 2013. URL: https://doi.org/10.1038/nature12290, doi:10.1038/nature12290.</p> </li> <li> <p>Daniel J. Bernstein, Jean-Fran\u00e7ois Biasse, and Michele Mosca. A low-resource quantum factoring algorithm. In Tanja Lange and Tsuyoshi Takagi, editors, Post-Quantum Cryptography, 330\u2013346. Cham, 2017. Springer International Publishing. ePrint: https://eprint.iacr.org/2017/352. doi:10.1007/978-3-319-59879-6\\_19.</p> </li> <li> <p>Lawrence C. Washington. Elliptic Curves: Number Theory and Cryptography, Second Edition. Chapman and Hall/CRC, 2008.</p> </li> <li> <p>Daniel J. Bernstein, Susanne Engels, Tanja Lange, Ruben Niederhagen, Christof Paar, Peter Schwabe, and Ralf Zimmermann. Faster elliptic-curve discrete logarithms on fpgas. ePrint: https://eprint.iacr.org/2016/382, 2016.</p> </li> <li> <p>David Beckman, Amalavoyal N. Chari, Srikrishna Devabhaktuni, and John Preskill. Efficient networks for quantum factoring. Physical Review A, 54:1034\u20131063, 8 1996. arXiv: https://arxiv.org/abs/quant-ph/9602016. URL: https://link.aps.org/doi/10.1103/PhysRevA.54.1034, doi:10.1103/PhysRevA.54.1034.</p> </li> <li> <p>Martina Rossi, Luca Asproni, Davide Caputo, Stefano Rossi, Alice Cusinato, Remo Marini, Andrea Agosti, and Marco Magagnini. Using shor's algorithm on near term quantum computers: a reduced version. Quantum Machine Intelligence, 4(2):18, 7 2022. arXiv: https://arxiv.org/abs/2112.12647. URL: https://doi.org/10.1007/s42484-022-00072-2, doi:10.1007/s42484-022-00072-2.</p> </li> <li> <p>Eric Anschuetz, Jonathan Olson, Al\u00e1n Aspuru-Guzik, and Yudong Cao. Variational quantum factoring. In Quantum Technology and Optimization Problems, 74\u201385. Springer, 2019. arXiv: https://arxiv.org/abs/1808.08927. URL: https://link.springer.com/chapter/10.1007/978-3-030-14082-3\\_7, doi:10.1007/978-3-030-14082-3\\_7.</p> </li> <li> <p>Amir H. Karamlou, William A. Simon, Amara Katabarwa, Travis L. Scholten, Borja Peropadre, and Yudong Cao. Analyzing the performance of variational quantum factoring on a superconducting quantum processor. npj Quantum Information, 7(1):156, 10 2021. arXiv: https://arxiv.org/abs/2012.07825. URL: https://doi.org/10.1038/s41534-021-00478-z, doi:10.1038/s41534-021-00478-z.</p> </li> <li> <p>Lily Chen, Stephen Jordan, Yi-Kai Liu, Dustin Moody, Rene Peralta, Ray Perlner, and Daniel Smith-Tone. Report on post-quantum cryptography. Technical Report NISTIR 8105, National Institute of Standards and Technology, Gaithersburg, MD, 2016. doi:10.6028/NIST.IR.8105.</p> </li> <li> <p>Chris Peikert. He gives c-sieves on the csidh. In Advances in Cryptology \u2013 EUROCRYPT 2020, 463\u2013492. Berlin, Heidelberg, 2020. Springer-Verlag. ePrint: https://eprint.iacr.org/2019/725. URL: https://doi.org/10.1007/978-3-030-45724-2\\_16, doi:10.1007/978-3-030-45724-2\\_16.</p> </li> <li> <p>Wouter Castryck and Thomas Decru. An efficient key recovery attack on sidh. In Carmit Hazay and Martijn Stam, editors, Advances in Cryptology \u2013 EUROCRYPT 2023, 423\u2013447. Cham, 2023. Springer Nature Switzerland. ePrint: https://eprint.iacr.org/2022/975. doi:10.1007/978-3-031-30589-4\\_15.</p> </li> <li> <p>Divesh Aggarwal, Gavin Brennen, Troy Lee, Miklos Santha, and Marco Tomamichel. Quantum attacks on bitcoin, and how to protect against them. Ledger, 8 2018. arXiv: https://arxiv.org/abs/1710.10377. URL: https://ledger.pitt.edu/ojs/ledger/article/view/127, doi:10.5195/ledger.2018.127.</p> </li> <li> <p>Itan Barmes and Bram Bosch. Quantum computers and the bitcoin blockchain. 2019. https://www2.deloitte.com/nl/nl/pages/innovatie/artikelen/quantum-computers-and-the-bitcoin-blockchain.html, accessed: 2023-09-30. URL: https://www2.deloitte.com/nl/nl/pages/innovatie/artikelen/quantum-computers-and-the-bitcoin-blockchain.html.</p> </li> <li> <p>Itan Barmes, Bram Bosch, and Marc Verdonk. Quantum risk to the ethereum blockchain - a bump in the road or a brick wall? 2022. https://www2.deloitte.com/nl/nl/pages/risk/articles/quantum-risk-to-the-ethereum-blockchain.html, accessed: 2023-09-30.</p> </li> </ol> <ol> <li> <p>An example of a cryptosystem not requiring computational assumptions is the one-time pad.\u00a0\u21a9</p> </li> <li> <p>If \\(r\\lfloor L/r \\rfloor+y \\geq L\\), then the \\(j = \\lfloor L/r \\rfloor\\) term does not appear in the expression.\u00a0\u21a9</p> </li> </ol>"},{"location":"areas-of-application/cryptanalysis/introduction/","title":"Cryptanalysis","text":"<p>Computation and communication are secured by cryptography. For example, a user's data can be made private, along with messages that they send or receive, from malicious agents who interfere to try to learn the sensitive information. A set of algorithms collectively called a cryptosystem endows the security. The attempt to break security is known as cryptanalysis, which has its own set of algorithms. Historically, both cryptography and cryptanalysis considered classical, polynomial-time algorithms as the only realistic ones. The advent of quantum computation forces us to consider attacks via quantum algorithms. Generally, we want to know what is the best algorithm for cryptanalysis, in order to understand the effect on the cryptosystem in the worst case. The effect of quantum attacks can be to void the security of a set of widely used cryptosystems (section on breaking cryptosystems). More broadly, quantum cryptanalysis can reduce a cryptosystem's security (section on weakening cryptosystems), such that it becomes more expensive to implement in a secure manner. While the properties of quantum mechanics can also be used to devise more secure cryptosystems (e.g., quantum key distribution) [1, 2, 3], we consider this area of cryptography to be outside the scope of the present discussion on quantum algorithms.</p>"},{"location":"areas-of-application/cryptanalysis/introduction/#bibliography","title":"Bibliography","text":"<ol> <li> <p>Charles H. Bennett and Gilles Brassard. Quantum cryptography: public key distribution and coin tossing. Theoretical Computer Science, 560:7\u201311, 2014. arXiv: https://arxiv.org/abs/2003.06557. URL: https://www.sciencedirect.com/science/article/pii/S0304397514004241, doi:10.1016/j.tcs.2014.05.025.</p> </li> <li> <p>S. Pirandola, U. L. Andersen, L. Banchi, M. Berta, D. Bunandar, R. Colbeck, D. Englund, T. Gehring, C. Lupo, C. Ottaviani, J. L. Pereira, M. Razavi, J. Shamsul Shaari, M. Tomamichel, V. C. Usenko, G. Vallone, P. Villoresi, and P. Wallden. Advances in quantum cryptography. Adv. Opt. Photon., 12(4):1012\u20131236, 12 2020. arXiv: https://arxiv.org/abs/1906.01645. URL: https://opg.optica.org/aop/abstract.cfm?URI=aop-12-4-1012, doi:10.1364/AOP.361502.</p> </li> <li> <p>Feihu Xu, Xiongfeng Ma, Qiang Zhang, Hoi-Kwong Lo, and Jian-Wei Pan. Secure quantum key distribution with realistic devices. Reviews of Modern Physics, 92:025002, 5 2020. arXiv: https://arxiv.org/abs/1903.09051. URL: https://link.aps.org/doi/10.1103/RevModPhys.92.025002, doi:10.1103/RevModPhys.92.025002.</p> </li> </ol>"},{"location":"areas-of-application/cryptanalysis/weakening-cryptosystems/","title":"Weakening cryptosystems","text":""},{"location":"areas-of-application/cryptanalysis/weakening-cryptosystems/#overview","title":"Overview","text":"<p>The discovery of Shor's algorithm (see Breaking cryptosystems) prompted interest in post-quantum cryptography, the study of cryptosystems assuming the presence of large-scale, working quantum computers [1]. While some existing systems retained confidence in their security, others that were broken by quantum algorithms were superseded by those that accomplish the same task, but are believed to maintain a high level of security against quantum attacks.</p><p>Even if a cryptosystem is not broken altogether, its degree of security can be weakened by quantum algorithms. The strength of a cryptosystem is typically quantified by the number of bits of security, i.e., \\(n\\) bits corresponds to guessing the desired information with probability \\(1/2^n\\) and accessing what is being protected. Breaking a cryptosystem means only an efficient number of attempts (i.e., \\(\\mathrm{poly}(n)\\)) are needed, while an attack that weakens a cryptosystem still takes \\(2^m &gt; \\mathrm{poly}(n)\\) attempts, for some \\(m&lt;n\\).</p><p>In contrast to public-key cryptosystems, symmetric-key cryptography was discovered earlier and has fewer capabilities. However, it relies less on the presumed hardness of underlying mathematical problems, and correspondingly has only been weakened by quantum cryptanalysis, as discussed in more detail below.</p>"},{"location":"areas-of-application/cryptanalysis/weakening-cryptosystems/#actual-end-to-end-problems-solved","title":"Actual end-to-end problem(s) solved","text":"<p>In symmetric-key cryptography, two communicating parties share the same key \\(K\\), which is used both in encryption \\(\\mathit{Enc}_K\\) and decryption \\(\\mathit{Dec}_K\\). As usual, the cryptographic algorithm \\((\\mathit{Enc}_K,\\mathit{Dec}_K)\\) is known to everyone, including adversaries. Then, the task of the adversary is to learn the key, given access to \\(r\\) pairs of plaintext (the message \\(m\\)) and corresponding ciphertext \\(c\\) (its encryption). Such a pair can be accessed by, e.g., forcing a certain test message to be transmitted. Precisely, an input \\(K\\) is sought for which the following function outputs 1: </p>\\[\\begin{equation} f(K) = (\\mathit{Enc}_K(m_1)=c_1 \\land \\ldots \\land \\mathit{Enc}_K(m_r)=c_r) \\,, \\end{equation}\\]<p>i.e., find a key such that all the messages encrypt correctly. A straightforward attack is to use brute force and test every key; in practice, sophisticated classical attacks do not perform better than this approach in asymptotic scaling.</p>"},{"location":"areas-of-application/cryptanalysis/weakening-cryptosystems/#dominant-resource-costcomplexity","title":"Dominant resource cost/complexity","text":"<p>The main, generic quantum attack is to use amplitude amplification: given a classical algorithm with success probability \\(\\mathcal{O}\\left( 2^{-n} \\right)\\) of finding a solution, the probability is increased quadratically to \\(\\mathcal{O}\\left( 2^{-n/2} \\right)\\). Thus, applying amplitude amplification to the task of solving for the key, the security of cryptosystems goes from \\(n\\) bits to \\(n/2\\).</p><p>The function queried in superposition must be efficient to evaluate with a quantum circuit, which is often the case in cryptography [1]. However, the operations are typically long sequences of Boolean arithmetic. As such, a universal gate set and fault-tolerant computation are still required. To store the key, \\(\\mathcal{O}\\left( n \\right)\\) register qubits are needed, and many more ancilla qubits are used for the reversible arithmetic.</p>"},{"location":"areas-of-application/cryptanalysis/weakening-cryptosystems/#existing-error-corrected-resource-estimates","title":"Existing error corrected resource estimates","text":"<p>Consider the Advanced Encryption Standard (AES) [2], a symmetric encryption algorithm that is widely used in cryptosystems, e.g., for encrypting web traffic. At a high level, it mixes the plaintext and adds it to the key to obtain the ciphertext. An attack based on amplitude amplification needs around 3000\u20137000 logical qubits [3] for AES-\\(k\\), where \\(k\\) denotes key size in bits, and \\(k\\in \\{128,192,256\\}\\). For these sizes, the number of necessary problem instances \\(r\\) is three to five. While the number of logical qubits roughly doubles going from AES-128 to AES-256, the number of \\(T\\) gates goes from \\(2^{86} \\approx 10^{25}\\) to \\(2^{151} \\approx 10^{45}\\).</p>"},{"location":"areas-of-application/cryptanalysis/weakening-cryptosystems/#caveats","title":"Caveats","text":"<p>Since the quantum attack only halves the exponent in the complexity, a simple fix is to double the key length, e.g., adopting AES-256 instead of AES-128. This modification results in increased, but usually tolerable, cost in implementation (i.e., complexity of encryption and communication resources). In addition, there exist cryptosystems with an information-theoretic security guarantee, assuming adversaries with unlimited computational power, which covers against quantum attacks [1].</p><p>Furthermore, it is important to note that to realize the full quadratic benefit of amplitude amplification, the \\(2^{n/2}\\) function queries must be performed in series. In contrast, classical brute-force attacks can exploit the parallelism available in high-performance classical computers, potentially increasing the value of \\(n\\) for which a quantum approach would be advantageous over classical methods.</p>"},{"location":"areas-of-application/cryptanalysis/weakening-cryptosystems/#comparable-classical-complexity-and-challenging-instance-sizes","title":"Comparable classical complexity and challenging instance sizes","text":"<p>Classical algorithmic attacks on AES have reduced the security by only a few bits [4]. More practical are side-channel attacks, which make use of physical byproducts, such as energy consumption. For example, when comparing bits between a key and another string, a flipped value can result in logic that increases energy consumption, compared to the same value where nothing happens. The two cases are distinguished and information about the key is learned. 128 bits of security is currently about the minimum recommended amount [5].</p>"},{"location":"areas-of-application/cryptanalysis/weakening-cryptosystems/#speedup","title":"Speedup","text":"<p>The basic speedup is quadratic: \\(\\mathcal{O}\\left( \\sqrt{N} \\right)\\) function evaluations compared to \\(\\mathcal{O}\\left( N \\right)\\) classically, where \\(N\\) denotes the number of possibilities for the key; i.e., \\(n=\\lceil \\log_2(N) \\rceil\\). However, the function queries in amplitude amplification cannot be parallelized. Then, the evaluation time of the function sets a bottleneck [1]. That is, the problem size is limited by the number of function evaluations \\(T\\) that can be run in an acceptable period of time. For \\(\\sqrt{N}&gt;T\\), employing \\(p\\) parallel quantum processors, each executes \\(T=\\sqrt{N/p}\\) evaluations. Then, \\(p=\\mathcal{O}\\left( N/T^2 \\right)\\) and the total number of evaluations is \\(pT=\\mathcal{O}\\left( N/T \\right)\\), whereas classically, the number of processors is \\(\\mathcal{O}\\left( N/T \\right)\\) and total evaluations is \\(\\mathcal{O}\\left( N \\right)\\). The advantage is a factor of \\(T\\), which is the bottleneck, rather than the larger \\(\\sqrt{N}\\). However, the advantage can be overshadowed by faster or cheaper classical processing. That is, if classical computers evaluate the function \\(T\\) times faster than quantum processors, there is no time-advantage with using the quantum device. Furthermore, this argument assumes the same cost of parallelization for classical and quantum, which is optimistic for quantum devices. An example of this effect is in mining cryptocurrency [6]: while a quantum computer needs quadratically fewer attempts to succeed, the development of fast, specialized, classical hardware negates the advantage.</p>"},{"location":"areas-of-application/cryptanalysis/weakening-cryptosystems/#nisq-implementations","title":"NISQ implementations","text":"<p>The key can be encoded as the ground state of a Hamiltonian, and then variational methods are applied to solve for it. The scaling is expected to be the same as amplitude amplification. However, since the variational algorithm does not have a set time-complexity, the solution may be found much slower or faster [7]. If the fluctuations are large enough, they can potentially pose a challenge to cryptography, which makes worst-case guarantees. However, there is no reason to expect that the success probability will scale favorably with key size and compromise security in practice. Another approach is to use amplitude amplification, but adapt it to near-term devices, so that the NISQ-optimized versions perform better in real experiments [8].</p>"},{"location":"areas-of-application/cryptanalysis/weakening-cryptosystems/#outlook","title":"Outlook","text":"<p>Here, we focused on the example of symmetric-key encryption. Nonetheless, the effect of amplitude amplification to halve the effective bits of security is generic for computational problems, assuming efficient construction of the oracle. From the cryptographic standpoint, this attack is mild and can be counteracted by doubling the number of bits of security in the scheme. In practice, the increase in key size can be unwieldy in certain applications, such as cryptocurrencies, but fundamental security is not threatened.</p>"},{"location":"areas-of-application/cryptanalysis/weakening-cryptosystems/#bibliography","title":"Bibliography","text":"<ol> <li> <p>Daniel J. Bernstein and Tanja Lange. Post-quantum cryptography. Nature, 549(7671):188\u2013194, 9 2017. ePrint: https://eprint.iacr.org/2017/314. URL: https://doi.org/10.1038/nature23461, doi:10.1038/nature23461.</p> </li> <li> <p>Information Technology Laboratory. Advanced encryption standard (aes). Technical Report FIPS 197, National Institute of Standards and Technology, Gaithersburg, MD, 2001. doi:10.6028/NIST.FIPS.197-upd1.</p> </li> <li> <p>Markus Grassl, Brandon Langenberg, Martin Roetteler, and Rainer Steinwandt. Applying grover's algorithm to aes: quantum resource estimates. In Tsuyoshi Takagi, editor, Post-Quantum Cryptography, 29\u201343. Cham, 2016. Springer International Publishing. arXiv: https://arxiv.org/abs/1512.04965. doi:10.1007/978-3-319-29360-8\\_3.</p> </li> <li> <p>Andrey Bogdanov, Dmitry Khovratovich, and Christian Rechberger. Biclique cryptanalysis of the full aes. In Dong Hoon Lee and Xiaoyun Wang, editors, Advances in Cryptology \u2013 ASIACRYPT 2011, 344\u2013371. Berlin, Heidelberg, 2011. Springer Berlin Heidelberg. ePrint: https://eprint.iacr.org/2011/449. doi:10.1007/978-3-642-25385-0\\_19.</p> </li> <li> <p>Elaine Barker. Recommendation for key management: part 1 - general. Technical Report SP 800-57 Part 1 Rev. 5, National Institute of Standards and Technology, Gaithersburg, MD, 2020. doi:10.6028/NIST.SP.800-57pt1r5.</p> </li> <li> <p>Divesh Aggarwal, Gavin Brennen, Troy Lee, Miklos Santha, and Marco Tomamichel. Quantum attacks on bitcoin, and how to protect against them. Ledger, 8 2018. arXiv: https://arxiv.org/abs/1710.10377. URL: https://ledger.pitt.edu/ojs/ledger/article/view/127, doi:10.5195/ledger.2018.127.</p> </li> <li> <p>Zeguo Wang, Shijie Wei, Gui-Lu Long, and Lajos Hanzo. Variational quantum attacks threaten advanced encryption standard based symmetric cryptography. Science China Information Sciences, 65(10):200503, 7 2022. arXiv: https://arxiv.org/abs/2205.03529. URL: https://doi.org/10.1007/s11432-022-3511-5, doi:10.1007/s11432-022-3511-5.</p> </li> <li> <p>K. Zhang, K. Yu, and V. Korepin. Quantum search on noisy intermediate-scale quantum devices. Europhysics Letters, 140(1):18002, 9 2022. arXiv: https://arxiv.org/abs/2202.00122. URL: https://dx.doi.org/10.1209/0295-5075/ac90e6, doi:10.1209/0295-5075/ac90e6.</p> </li> </ol>"},{"location":"areas-of-application/finance/introduction/","title":"Finance","text":"<p>While several industries stand to benefit from quantum computing, the financial services industry has historically been an early adopter of quantum technology by investing in research and development efforts in the area of quantum finance. Finance has the distinct feature that more powerful and more accurate simulations can lead to direct competitive advantage, in a way that is harder to identify in other industries. In this application area, researchers strive to find quantum speedups for use cases of interest to financial services. A number of use cases have been proposed as candidates for quantum solutions, such as:</p><ul> <li>Derivative pricing (such as options [1], and collateralized debt obligations (CDO) [2]). Derivatives are financial instruments that are built upon an underlying asset (or assets) that can depend on the value of the asset in potentially complicated ways. In the derivative pricing problem, one needs to determine a fair price of the financial instrument, which typically depends on an expected value of the underlying assets at some later date. A similar and related problem is known as computing the Greeks [3]. The Greeks of a financial derivative are quantities that determine the sensitivity of the derivative to various parameters in the problem. For example, the Greeks of an option are given by the derivative of the value of the option with respect to some parameter, e.g., \\(\\Delta:=\\partial V/\\partial X\\), where \\(V\\) is the value of the option and \\(X\\) is the price of the underlying asset.</li> <li>Credit valuation adjustments (CVA) [4]. CVA is the problem of determining the fair price of a derivative, portfolio, or other financial instrument that is extended to a purchaser on credit, and that takes into account the purchaser's (potentially poor) credit rating, and the risk of default. CVA is typically given by the difference between the risk-free portfolio and the value of the portfolio taking into account the possibility of default.</li> <li>Value at risk (VaR) [5]. Many forms of risk analysis can be considered, with VaR being a common example. VaR measures the total value a financial instrument (such as a portfolio) might lose over a predefined time interval within a fixed confidence interval. For example, the VaR of a portfolio might indicate that, with 95% probability, the portfolio will not lose more than \\(\\$Y\\). A similar technique works as well for the related Credit Value at Risk (CVaR) problem.</li> <li>Portfolio optimization [6]. The goal of portfolio optimization is to determine the optimal allocation of funds into a universe of investable assets such that the resulting portfolio maximizes returns and minimizes risk, while also respecting other constraints.</li> </ul><p>While there are are many more use cases and several approaches for generating quantum speedups, broadly speaking, many uses cases stem from one of two paths to quantum improvements: quantum enhancements to Monte Carlo methods (for simulating stochastic processes), and constrained optimization. In the first case, the approach generally involves encoding a relevant, problem-specific function into a quantum state, and then using quantum amplitude estimation to sample from the distribution quadratically fewer times than classical Monte Carlo methods [7]. In the second case, a financial use case is reduced to a constrained optimization problem, and a quantum algorithm for optimization is used to solve the problem.</p><p>Among the use cases studied in these two areas, option pricing and portfolio optimization often serve as archetypal examples of Monte Carlo and constrained optimization problems, respectively, and their associated quantum algorithms have the most follow-up work. Moreover, these two classes of problems comprise a considerable fraction of the classical compute used in the financial services industry. For these reasons, we will focus on these two use cases in this section, though the approaches, caveats, and complexities can (usually) be readily carried over to other relevant use cases.</p><p>In addition to the use cases described above, other areas of interest to the financial services industry include post-quantum cryptography, quantum-secure networking and quantum key distribution, etc. However, many of these topics or their proposed quantum implementations are outside the scope of this document. Quantum machine learning is yet another popular use case within quantum finance, but oftentimes these results are quantum approaches to standard machine learning problems, which are then applied to a financial application. As such, we will also not study machine learning in this finance-specific section, and we instead refer interested readers to any of the excellent review articles on quantum finance (e.g., [8, 9]) for more details.</p>"},{"location":"areas-of-application/finance/introduction/#bibliography","title":"Bibliography","text":"<ol> <li> <p>Nikitas Stamatopoulos, Daniel J Egger, Yue Sun, Christa Zoufal, Raban Iten, Ning Shen, and Stefan Woerner. Option pricing using quantum computers. Quantum, 4:291, 2020. arXiv: https://arxiv.org/abs/1905.02666. doi:10.22331/q-2020-07-06-291.</p> </li> <li> <p>Hao Tang, Anurag Pal, Tian-Yu Wang, Lu-Feng Qiao, Jun Gao, and Xian-Min Jin. Quantum computation for pricing the collateralized debt obligations. Quantum Engineering, 3(4):e84, 2021. arXiv: https://arxiv.org/abs/2008.04110. doi:10.1002/que2.84.</p> </li> <li> <p>Nikitas Stamatopoulos, Guglielmo Mazzola, Stefan Woerner, and William J Zeng. Towards quantum advantage in financial market risk using quantum gradient algorithms. Quantum, 6:770, 2022. arXiv: https://arxiv.org/abs/2111.12509. doi:10.22331/q-2022-07-20-770.</p> </li> <li> <p>Jeong Yu Han and Patrick Rebentrost. Quantum advantage for multi-option portfolio pricing and valuation adjustments. arXiv: https://arxiv.org/abs/2203.04924, 2022.</p> </li> <li> <p>Stefan Woerner and Daniel J Egger. Quantum risk analysis. npj Quantum Information, 5(1):15, 2019. arXiv: https://arxiv.org/abs/1806.06893. doi:10.1038/s41534-019-0130-6.</p> </li> <li> <p>Patrick Rebentrost and Seth Lloyd. Quantum computational finance: quantum algorithm for portfolio optimization. arXiv: https://arxiv.org/abs/1811.03975, 2018.</p> </li> <li> <p>Ashley Montanaro. Quantum speedup of monte carlo methods. Proceedings of the Royal Society A, 2015. arXiv: https://arxiv.org/abs/1504.06987. doi:10.1098/rspa.2015.0301.</p> </li> <li> <p>Dylan Herman, Cody Googin, Xiaoyuan Liu, Yue Sun, Alexey Galda, Ilya Safro, Marco Pistoia, and Yuri Alexeev. Quantum computing for finance. Nature Reviews Physics, 2023. arXiv: https://arxiv.org/abs/2201.02773. URL: https://doi.org/10.1038/s42254-023-00603-1, doi:10.1038/s42254-023-00603-1.</p> </li> <li> <p>Adam Bouland, Wim van Dam, Hamed Joorati, Iordanis Kerenidis, and Anupam Prakash. Prospects and challenges of quantum finance. arXiv: https://arxiv.org/abs/2011.06492, 2020.</p> </li> </ol>"},{"location":"areas-of-application/finance/monte-carlo-methods-option-pricing/","title":"Monte Carlo methods: Option pricing","text":""},{"location":"areas-of-application/finance/monte-carlo-methods-option-pricing/#overview","title":"Overview","text":"<p>Many financial instruments require an estimate of the average of some function of a stochastic variable within a window of time. To compute this average, one can use Monte Carlo methods to perform many simulations of the stochastic process over the time window, evaluate the function (which can potentially depend on the path taken by the stochastic variable during the entire window), and numerically estimate the average. While the setup and details of the problems may vary from one use case to another, the underlying methods are often quite similar. As an archetypal example of this problem, we will focus on the problem of pricing derivatives, such as options, but we remark that many of these results can be carried over to other use cases, such as computing Greeks, credit valuation adjustments, value at risk, etc.</p><p>Derivatives are financial instruments that, roughly speaking, allow the parties involved to benefit when an asset (such as a stock) increases or decreases in value, but without having to already hold the asset itself. One type of derivative\u2014called an \"option\"\u2014is a contract that permits the holder to either purchase (\"call option\") or sell (\"put option\") an underlying asset at a fixed, predetermined price (the \"strike price\") at or prior to some predetermined time in the future (\"the exercise window\"). The seller of the option is obligated to either sell or buy the asset, should the holder choose to exercise the option.</p><p>How, then, should one decide on a price for the option (i.e., the amount the holder must pay for the contract, not the strike price)? The well-known Black\u2013Scholes (or Black\u2013Scholes\u2013Merton) model provides one approach to pricing options, making a few assumptions about the underlying assets and the rules of the contract. More complicated options can be considered that include, for example, multiple assets in the contract (e.g., basket options), multiple possible exercise windows (e.g., Bermudan or American options), etc.</p><p>Typically, options are priced by running Monte Carlo sampling on the value of the underlying asset(s) and determining the expected profit or loss from a given position, which can be translated into a price that the purchaser must pay. Options with a larger potential downside for the seller should cost a larger amount to purchase. For more information on options and Monte Carlo methods in the context of computational finance, see [1, 2].</p>"},{"location":"areas-of-application/finance/monte-carlo-methods-option-pricing/#actual-end-to-end-problems-solved","title":"Actual end-to-end problem(s) solved","text":"<p>Suppose you want to price an option based on an underlying asset. The price of the asset is a random variable \\(X\\) that follows a known (or assumed) stochastic process that models the market market for the underlying asset. The option has a known payoff function \\(f(X)\\) (e.g., the difference between the price of the asset at each time step minus the strike price over the trajectory, or zero, whichever is larger). For options that depend on more than one underlying asset or on asset prices at multiple distinct points in time, the random variable \\(X\\) would represent a vector of data containing all information needed to compute the payoff. Given these inputs, the end-to-end problem is to compute the an estimate of the expected payoff \\(\\mathbb{E}_{X}(f(X))\\) that lies within a certain error tolerance \\(\\epsilon\\) with high probability. This quantity is then used to determine a price to charge for the option.</p><p>Using the assumed stochastic model for the price of the asset, one can develop a stochastic differential equation for the average payoff of the option. In limited cases, one can compute the average payoff analytically, as in the case of the famous Black\u2013Scholes formula for the price of European call options, for which the 1997 Nobel Prize in economics was awarded. The Black\u2013Scholes differential equation for the price of an asset at time \\(t\\) is given by </p>\\[\\begin{equation} d X_t = X_t \\alpha dt + X_t \\sigma d W_t, \\end{equation}\\]<p>where \\(X_t\\) is the price of the underlying asset at time \\(t\\), \\(\\alpha\\) is a parameter known as the \"drift\" of the asset, \\(\\sigma\\) is the volatility (the standard deviation of the underlying returns), and \\(d W_t\\) is an increment of an accompanying Brownian motion \\(W_t\\). Using It\u00f4's lemma, one can derive a differential equation for the payoff function of the option at time \\(t\\) and, in limited cases (with several assumptions), one can solve the differential equation analytically. In practice, however, different types of contract have more complex definitions and fewer assumptions and, as a consequence, the differential equation cannot be solved analytically. Quantum approaches to numerically solving the stochastic differential equation have been proposed, including finite difference methods [3], Hamiltonian simulation [4], and quantum random walks [5], etc. For more detail on quantum approaches to solving differential equations, see the differential equations section of this document. In many real-world derivative pricing use cases, the underlying differential equation becomes intractable. Thus, the most common classical method of computing the average payoff of an option is not through solving the stochastic differential equation, but rather through Monte Carlo sampling the random process \\(X\\) directly. To do so, one generates a large number of price trajectories over the chosen time range, and the average payoff is computed numerically. In what follows, we will focus on quantum approaches to Monte Carlo estimation, which was pioneered in [6] and subsequently applied to several problems in finance (e.g., [7, 8, 9, 10, 11]). However, we remark that other approaches to solving this problem that do not make use of Monte Carlo methods have also been proposed (e.g., [12]), and that this is an area of active research.</p><p>If a different financial instrument is desired, such as value at risk or credit valuation adjustments, the function to be computed may be quite different, but the approach is often the same: simulate the underlying stochastic evolution several times, and estimate the desired quantity numerically.</p>"},{"location":"areas-of-application/finance/monte-carlo-methods-option-pricing/#dominant-resource-costcomplexity","title":"Dominant resource cost/complexity","text":"<p>In [7, 8], the quantum speedup of Monte Carlo estimation from [6] is applied to solve the option pricing problem. We briefly explain the method and its dominant cost. First of all, this requires discretizing the set of values the random variable \\(X\\) can take, which we index by the label \\(x\\). Let \\(N\\) denote the number of values and \\(n = \\lceil \\log_2(N) \\rceil\\) denote the number of qubits needed to hold the state \\(\\ket{x}\\). The first step is to load the probabilities for the future prices of the asset into the amplitudes of a quantum state, that is, the state </p>\\[\\begin{equation} \\sum_x \\sqrt{p_x} \\ket{x} \\end{equation}\\]<p>where \\(p_x\\) is the probability that \\(x\\) is observed in the corresponding classical Monte Carlo simulation.</p><p>Second, a subroutine is employed that computes information about the payoff function into an ancilla register using coherent arithmetic. More precisely, the angle \\(\\theta_x\\) is computed (rounded to some finite number of bits of precision), where \\(\\sin(\\theta_x) = \\sqrt{f(x)}\\). (For simplicity, here we assume \\(0 \\leq f(x) \\leq 1\\) for all \\(x\\), but we revisit this point later.) This yields </p>\\[\\begin{equation} \\sum_x \\sqrt{p_x} \\ket{x}\\ket{\\theta_x}\\,. \\end{equation}\\]<p>Third, the amplitude \\(\\sqrt{f(x)}\\) is loaded into the amplitude of an ancilla register by applying the map \\(\\ket{\\theta}\\ket{0} \\mapsto \\ket{\\theta}(\\sin(\\theta) \\ket{0} + \\cos(\\theta)\\ket{1})\\). This gives </p>\\[\\begin{equation} \\label{eq:option_pricing_state} \\left(\\sum_x \\sqrt{p_xf(x)} \\ket{x}\\ket{\\theta_x}\\right)\\ket{0} + \\left(\\sum_x \\sqrt{p_x(1-f(x))} \\ket{x}\\ket{\\theta_x}\\right)\\ket{1}\\,. \\end{equation}\\]<p>The probability of measuring the final ancilla in \\(\\ket{0}\\) is precisely \\(\\mathbb{E}_X(f(X))\\). Thus, the final step is to apply quantum amplitude estimation (which requires many calls to the unitary that produces the state above) to obtain an estimate to error \\(\\epsilon\\).</p><p>If \\(0 \\leq f(x) \\leq 1\\) does not hold, the above approach needs to be modified for example by shifting and rescaling \\(f\\) over a sequence of intervals of increasing length, as discussed in [6, 7]. To fit the range of \\(f\\) into the interval \\([0,1]\\), we should expect the function \\(f\\) will need to be scaled down by a factor on the order of the standard deviation \\(\\sigma = \\sqrt{\\mathbb{E}_X(f(X)^2)-(\\mathbb{E}f(x))^2}\\). Thus, to achieve error \\(\\epsilon\\), QAE must be performed to precision \\(\\epsilon/\\sigma\\) instead of \\(\\epsilon\\).</p><p>There are three components to the algorithm that each contribute to the resource cost:</p><ul> <li>Loading the distribution with amplitudes \\(\\sqrt{p_x}\\). The gate complexity of this step is roughly the same as the time complexity of classically drawing a Monte Carlo sample, although for certain distributions it could be faster (e.g. a quadratic quantum speedup can be obtained if \\(p_x\\) is the stationary distribution of a Markov process [13]). Alternatively, if a functional form for \\(p_x\\) is known, the methods of [14] could be used to approximately prepare the state. Finally, [8] proposes using a quantum Generative Adversarial Network (qGAN), a variational ansatz, which could reduce the resources but requires a training phase.</li> <li>Coherent arithmetic to compute the rotation angle \\(\\theta_x\\). This depends on the complexity of the function \\(f\\), but can generally be accomplished in comparable gate complexity as classical arithmetic, i.e. \\(\\mathrm{poly}(n)\\). In [15], it was shown how the payoff can instead be put directly into the amplitude, without ever computing \\(\\theta_x\\), using quantum signal processing methods [14].</li> <li>Quantum amplitude estimation to precision \\(\\epsilon/\\sigma\\), which requires \\(\\widetilde{\\mathcal{O}}\\left( \\sigma/\\epsilon \\right)\\) repetitions of the above two costs to achieve an \\(\\epsilon\\)-estimate on the quantity \\(\\mathbb{E}_X f(X)\\).</li> </ul><p>Overall, from [6, Theorem 2.5] the complexity is </p>\\[\\begin{equation} \\frac{\\sigma}{\\epsilon}\\log^{3/2}(\\sigma/\\epsilon)\\log(\\log(\\sigma/\\epsilon)) \\cdot \\mathrm{poly}(n)\\,, \\end{equation}\\]<p>with the \\(\\mathrm{poly}(n)\\) factor generally on the same order as the time required to draw and process a single classical Monte Carlo sample.</p><p>One can also consider approaches to solving this problem that rely on quantum techniques for solving differential equations, though we refer the reader to that section for more details.</p>"},{"location":"areas-of-application/finance/monte-carlo-methods-option-pricing/#existing-error-corrected-resource-estimates","title":"Existing error corrected resource estimates","text":"<p>Detailed resource estimations for benchmark option-pricing problems (known as autocallable and Target Accrual Redemption Forward, or TARF) were studied in [16]. The authors studied real-world use cases and problem sizes that are relevant to current financial institutions, but on the more challenging side for classical methods. For a basket autocallable with 3 underlying assets, 5 payment days, and a knock-in put option with 20 barrier dates, the authors found that one would need about \\(8000\\) logical qubits, a \\(T\\)-depth of \\(5.4\\times 10^7\\), and a \\(T\\)-count of about \\(1.2\\times 10^{10}\\), using the most efficient methods they studied. For a TARF with 1 underlying and 26 payment dates, one needs about \\(1.2 \\times 10^4\\) logical qubits, a \\(T\\)-depth of about \\(8.2\\times 10^7\\), and a \\(T\\)-count of about \\(9.8\\times 10^9\\). A follow up analysis [15] involving a quantum signal processing approach subsequently reduced these estimates to \\(4.7 \\times 10^3\\) logical qubits, \\(4.5 \\times 10^7\\) \\(T\\)-depth, and \\(2.4 \\times 10^9\\) \\(T\\)-count. For comparison, classical Monte Carlo methods are roughly estimated to require 1\u201310 seconds and \\(4 \\times 10^4\\) samples to achieve the same accuracy on these examples.</p><p>Similar analyses were performed in [9] for the computation of \"the Greeks\", which are quantities that measure the sensitivity of a derivative to various parameters. To compute the Greeks of an option, one needs to compute the derivative of the payoff function with respect to, for example, the price of the underlying. To to do this on a quantum computer, one needs to be able to estimate both the expectation of the payoff function, and have a way of computing gradients. The authors apply several quantum methods of computing gradients in order to calculate the Greeks, in addition to the quantum approaches to Monte Carlo methods used. Using a quantum gradient method to compute Greeks of an option, the authors estimate that one would need about \\(1.2 \\times 10^4\\) logical qubits and a \\(T\\)-depth of around \\(10^8\\).</p>"},{"location":"areas-of-application/finance/monte-carlo-methods-option-pricing/#caveats","title":"Caveats","text":"<p>There are many types of options and derivatives that may not be accurately captured by these simple models. Some payoff functions are path-dependent, and hence one cannot simply use the asset value at some fixed time to compute the cost, but rather the cost depends on the trajectory the random variable takes in each Monte Carlo sample.</p><p>Moreover, classical approaches to Monte Carlo sampling often allow for massive parallelization, as each simulation of the underlying asset can be done independently. By contrast, quantum algorithms for this problem require a serial approach, as the subroutines in the quantum algorithm must be run one after another without measurement and restart if the quadratic advantage is to be realized. When the slower clock speeds found in quantum devices is also taken into account, the requirements for a quantum speedup over classical methods become more stringent, as much larger problem sizes are required to achieve practical advantage. For further reading, see [17, Sec. 2.3], for example.</p><p>It is worth noting that in certain cases the number of classical samples needed to achieve error \\(\\epsilon\\) can be reduced from the naive \\(\\mathcal{O}\\left( \\sigma^2/\\epsilon^2 \\right)\\), cutting into the quadratic quantum speedup. In particular, quasi\u2013Monte Carlo methods, which sample possible trajectories of the underlying assets nonrandomly can achieve a nearly quadratic speedup compared to traditional classical Monte Carlo methods, but gain an exponential dependence on the number of underlying assets (\"curse of dimensionality\") see [2, Chapter 5], which limits their use. The number of samples can also potentially be reduced classically via multilevel Monte Carlo methods [18]. However, when and how these methods work is delicate and must be evaluated on a case-by-case basis.</p>"},{"location":"areas-of-application/finance/monte-carlo-methods-option-pricing/#comparable-classical-complexity-and-challenging-instance-sizes","title":"Comparable classical complexity and challenging instance sizes","text":"<p>Classical approaches to option pricing comprise some of the largest computational costs incurred by financial institutions. In the traditional approach to solving the option pricing problem, Monte Carlo sampling is required to simulate the evolution of the underlying asset over the time horizon of the option, and it can be slow to converge. In particular, denote the expectation value of \\(f(X)\\) by \\(V:=\\mathbb{E}_{X}(f(X))\\), and the variance of \\(f(X)\\) by \\(\\sigma^2\\). Classical Monte Carlo methods computes an estimate \\(\\hat{V}\\) for \\(V\\) formed by averaging \\(f(X)\\) for \\(M\\) independent samples of \\(X\\). By Chebyshev's inequality, </p>\\[\\begin{equation} \\mathrm{Pr}(|V-\\hat{V}|\\geq \\epsilon)\\leq \\frac{\\sigma^2}{M\\epsilon^2}. \\end{equation}\\]<p>Thus, classically one needs \\(M\\sim\\mathcal{O}(\\sigma^2/\\epsilon^2)\\) samples to find an estimate \\(\\hat{V}\\) within a 99% confidence interval [6].</p><p>In typical industrial scenarios, options can be priced to sufficient operational precision after roughly a few seconds of runtime, sampling as many as tens of thousands of Monte Carlo trajectories.</p><p>Alternatively, a tensor-network-based classical approach to option pricing was proposed by [19] that could lead to significant advantages over traditional classical methods in some cases.</p>"},{"location":"areas-of-application/finance/monte-carlo-methods-option-pricing/#speedup","title":"Speedup","text":"<p>The classical algorithm requires \\(M = \\mathcal{O}\\left( \\sigma^2/\\epsilon^2 \\right)\\) samples whereas the quantum algorithm requires only \\(\\widetilde{\\mathcal{O}}\\left( \\sqrt{M} \\right) = \\widetilde{\\mathcal{O}}\\left( \\sigma/\\epsilon \\right)\\) samples. The gate cost of a sample is roughly the same classically and quantumly, and thus the speedup is (nearly) quadratic, inherited from the quadratic speedup of QAE.</p>"},{"location":"areas-of-application/finance/monte-carlo-methods-option-pricing/#outlook","title":"Outlook","text":"<p>In [16], the authors place an upper bound on the resources required for pricing options on quantum computers, and they provide a goalpost for quantum hardware development to be able to outperform classical Monte Carlo methods. In particular, the authors estimate that a quantum device would need to be able to execute about \\(10^7\\) layers of \\(T\\)-gates per second. Moreover, the code distance for fault-tolerant implementation would need to be chosen large enough to support \\(10^{10}\\) total error-free logical operations. These requirements translate to a logical clock rate of about \\(50\\)MHz that would be needed in order to compete with current classical Monte Carlo methods. This clock speed is orders of magnitude faster than what is foreseeably possible given the current status of physical hardware and currently known methods for performing logical gates in the surface code.</p><p>While the resource requirements for pricing of derivatives are quite stringent, this is nevertheless an area of active research. For example, a new \"analog\" quantum representation of stochastic processes was developed in [20] that can compute \\(\\epsilon\\)-accurate estimates of time averages (over \\(T\\) timesteps) of certain functions of stochastic processes in time \\(O(\\mathrm{polylog}(T)\\epsilon^{-c})\\), where \\(3/2 &lt; c &lt;2\\), an exponential speedup over classical methods in the parameter \\(T\\). The analog nature of their method leads to additional caveats, and finding concrete applications of this method remains an interesting open question.</p>"},{"location":"areas-of-application/finance/monte-carlo-methods-option-pricing/#bibliography","title":"Bibliography","text":"<ol> <li> <p>J. Hull. Options, Futures, and Other Derivatives. Pearson, 2017. ISBN 9781292212890.</p> </li> <li> <p>Paul Glasserman. Monte Carlo methods in financial engineering. Volume 53. Springer, 2004. doi:10.1007/978-0-387-21617-1.</p> </li> <li> <p>Koichi Miyamoto and Kenji Kubo. Pricing multi-asset derivatives by finite-difference method on a quantum computer. IEEE Transactions on Quantum Engineering, 3:1\u201325, 2021. arXiv: https://arxiv.org/abs/2109.12896. doi:10.1109/TQE.2021.3128643.</p> </li> <li> <p>Javier Gonzalez-Conde, \u00c1ngel Rodr\u00edguez-Rozas, Enrique Solano, and Mikel Sanz. Simulating option price dynamics with exponential quantum speedup. arXiv: https://arxiv.org/abs/2101.04023, 2021.</p> </li> <li> <p>Noah Linden, Ashley Montanaro, and Changpeng Shao. Quantum vs. classical algorithms for solving the heat equation. Communications in Mathematical Physics, 395(2):601\u2013641, 2022. arXiv: https://arxiv.org/abs/2004.06516. doi:10.1007/s00220-022-04442-6.</p> </li> <li> <p>Ashley Montanaro. Quantum speedup of monte carlo methods. Proceedings of the Royal Society A, 2015. arXiv: https://arxiv.org/abs/1504.06987. doi:10.1098/rspa.2015.0301.</p> </li> <li> <p>Patrick Rebentrost, Brajesh Gupt, and Thomas R. Bromley. Quantum computational finance: monte carlo pricing of financial derivatives. Physical Review A, 98:022321, 8 2018. arXiv: https://arxiv.org/abs/1805.00109. URL: https://link.aps.org/doi/10.1103/PhysRevA.98.022321, doi:10.1103/PhysRevA.98.022321.</p> </li> <li> <p>Nikitas Stamatopoulos, Daniel J Egger, Yue Sun, Christa Zoufal, Raban Iten, Ning Shen, and Stefan Woerner. Option pricing using quantum computers. Quantum, 4:291, 2020. arXiv: https://arxiv.org/abs/1905.02666. doi:10.22331/q-2020-07-06-291.</p> </li> <li> <p>Nikitas Stamatopoulos, Guglielmo Mazzola, Stefan Woerner, and William J Zeng. Towards quantum advantage in financial market risk using quantum gradient algorithms. Quantum, 6:770, 2022. arXiv: https://arxiv.org/abs/2111.12509. doi:10.22331/q-2022-07-20-770.</p> </li> <li> <p>Jeong Yu Han and Patrick Rebentrost. Quantum advantage for multi-option portfolio pricing and valuation adjustments. arXiv: https://arxiv.org/abs/2203.04924, 2022.</p> </li> <li> <p>Stefan Woerner and Daniel J Egger. Quantum risk analysis. npj Quantum Information, 5(1):15, 2019. arXiv: https://arxiv.org/abs/1806.06893. doi:10.1038/s41534-019-0130-6.</p> </li> <li> <p>Patrick Rebentrost, Alessandro Luongo, Samuel Bosch, and Seth Lloyd. Quantum computational finance: martingale asset pricing for incomplete markets. arXiv: https://arxiv.org/abs/2209.08867, 2022.</p> </li> <li> <p>M\u00e1ri\u00f3 Szegedy. Quantum speed-up of markov chain based algorithms. In Proceedings of the 45th IEEE Symposium on Foundations of Computer Science (FOCS), 32\u201341. 2004. arXiv: https://arxiv.org/abs/quant-ph/0401053. doi:10.1109/FOCS.2004.53.</p> </li> <li> <p>Sam McArdle, Andr\u00e1s Gily\u00e9n, and Mario Berta. Quantum state preparation without coherent arithmetic. arXiv: https://arxiv.org/abs/2210.14892, 2022.</p> </li> <li> <p>Nikitas Stamatopoulos and William J. Zeng. Derivative pricing using quantum signal processing. arXiv: https://arxiv.org/abs/2307.14310, 2023.</p> </li> <li> <p>Shouvanik Chakrabarti, Rajiv Krishnakumar, Guglielmo Mazzola, Nikitas Stamatopoulos, Stefan Woerner, and William J Zeng. A threshold for quantum advantage in derivative pricing. Quantum, 5:463, 2021. arXiv: https://arxiv.org/abs/2012.03819. doi:10.22331/q-2021-06-01-463.</p> </li> <li> <p>Adam Bouland, Wim van Dam, Hamed Joorati, Iordanis Kerenidis, and Anupam Prakash. Prospects and challenges of quantum finance. arXiv: https://arxiv.org/abs/2011.06492, 2020.</p> </li> <li> <p>Michael B. Giles. Multilevel monte carlo methods. Acta Numerica, 24:259\u2013328, 2015. arXiv: https://arxiv.org/abs/1304.5472. doi:10.1017/S096249291500001X.</p> </li> <li> <p>Michael Kastoryano and Nicola Pancotti. A highly efficient tensor network algorithm for multi-asset fourier options pricing. arXiv: https://arxiv.org/abs/2203.02804, 2022.</p> </li> <li> <p>Adam Bouland, Aditi Dandapani, and Anupam Prakash. A quantum spectral method for simulating stochastic processes, with applications to monte carlo. arXiv: https://arxiv.org/abs/2303.06719, 2023.</p> </li> </ol>"},{"location":"areas-of-application/finance/portfolio-optimization/","title":"Portfolio optimization","text":""},{"location":"areas-of-application/finance/portfolio-optimization/#overview","title":"Overview","text":"<p>Given a set of possible assets into which one can invest, the problem of portfolio optimization (PO) involves finding the optimal allocation of funds into these assets so as to maximize returns while minimizing risk. The Markowitz model, as it is commonly called, is widely used in the financial industry, owing to its simplicity and broad applicability. Sophisticated constraints, transaction cost functions, and modifications to the problem can be used to model realistic, modern portfolio optimization problems. Numerically solving these optimization problems is a routine part of existing workflows in financial services operations. Several quantum approaches to solving the portfolio optimization problem have been proposed, each with their own advantages and drawbacks.</p>"},{"location":"areas-of-application/finance/portfolio-optimization/#actual-end-to-end-problems-solved","title":"Actual end-to-end problem(s) solved","text":"<p>Consider a set of \\(n\\) investable assets with a fixed total budget. Define \\(w_i \\in \\mathbb{R}\\) to be the fraction of the total budget that is invested into asset \\(i\\). Thus, the \\(n\\)-dimensional vector \\(w\\) defines a portfolio. Let \\(r\\) be a known \\(n\\)-dimensional vector denoting the expected return for each of the available assets, i.e. the percentage by which the value of each asset is expected to grow over some defined time period. Let \\(\\Sigma\\in\\mathbb{R}^{n\\times n}\\) be the covariance matrix governing the random (and possibly correlated) fluctuations in the asset returns away from their mean \\(r\\). In practice, the input parameters \\(\\Sigma\\) and \\(r\\) can be inferred from historical stock price data, or through more sophisticated analyses. The covariance matrix can be used to define a portfolio's \"risk\" \\(w^\\intercal \\Sigma w\\), which is precisely the variance in the returns it generates, assuming the underlying model is accurate. Denote the all-ones vector by \\(\\mathbf{1}\\), and for any pair of vectors \\(u,v\\) let \\(\\langle u,v\\rangle\\) denote the standard inner product between \\(u\\) and \\(v\\). The goal of the Markowitz formulation of portfolio optimization is to find the optimal portfolio (i.e., vector of weights \\(w\\)) that either:</p><ul> <li>maximizes the expected return subject to a fixed risk parameter \\(\\sigma_0^2\\) \\[\\begin{align} \\max_{w}\\; &amp; \\langle w,r\\rangle \\\\   \\mathrm{s.t.}\\quad w^\\intercal \\Sigma w &amp; =\\sigma_0^2 \\\\   \\quad \\langle \\mathbf{1}, w\\rangle &amp; =1 \\end{align}\\] </li> <li>minimizes risk subject to a fixed return parameter \\(r_0\\) \\[\\begin{align}\\label{eq:PO_fixed_return} \\min_{w}\\; &amp; w^\\intercal \\Sigma w \\\\   \\mathrm{s.t.}\\quad \\langle w,r\\rangle &amp; =r_0 \\\\   \\langle \\mathbf{1}, w\\rangle &amp; =1 \\end{align}\\] </li> <li>maximizes return and minimizes risk with a tradeoff determined by a parameter known as the \"risk aversion parameter\" \\(\\lambda\\):  \\[\\begin{equation} \\label{eq:quadratic_objective} \\begin{align} \\max_{w}\\; \\langle w,r \\rangle- \\lambda &amp; w^\\intercal \\Sigma w \\\\   \\mathrm{s.t.}\\quad \\langle\\mathbf{1}, w\\rangle &amp; =1 \\end{align} \\end{equation}\\] <p>or the alternative for the square root of risk (standard deviation rather than variance) </p> \\[\\begin{align} \\max_{w}\\; \\langle w,r\\rangle- q &amp; \\sqrt{w^\\intercal \\Sigma w} \\\\   \\mathrm{s.t.}\\quad \\langle\\mathbf{1}, w\\rangle &amp; =1, \\end{align}\\] <p>where \\(q\\) plays the same role as \\(\\lambda\\).</p> </li> </ul><p>Typically, it is satisfactory to find a vector that optimizes the objective function up to additive error \\(\\epsilon\\), for some prespecified value of \\(\\epsilon\\).</p><p>When solving the above Markowitz model formulations of PO, the absence of inequality constraints leads to simpler optimization problems that can be solved with simpler approaches. For example, the optimization problem in Eq. \\(\\eqref{eq:PO_fixed_return}\\) is a simple quadratic program without complicated constraints, for which one can derive a closed-form expression for \\(w\\) using Lagrange multipliers [1]. More general portfolio optimization problems that include practically relevant constraints (such as the simple \"long-only\" constraint \\(w_i\\geq 0\\), which contrasts \"short\" positions in which \\(w_i\\) can be less than zero) cannot generically be solved analytically, and one needs to employ more sophisticated numerical solvers. Real-world portfolio optimization problems include a number of possible constraints (see [2] for a discussion), including, but not limited to:</p><ul> <li>Long only \u2014 \\(w_j\\geq 0, \\quad \\forall j\\)</li> <li>Investment bands \u2014 \\(w_j\\in [w_j^{\\mathrm{min}}, w_j^{\\mathrm{max}}]\\)</li> <li>Turnover constraints \u2014 \\(|\\Delta w_j|\\leq U_j\\) for some fixed fraction \\(U_j\\), where \\(\\Delta w_j\\) represents the change in holdings of asset \\(w_j\\) from one portfolio to the next.</li> <li>Cardinality constraints \u2014 minimum, maximum, or exact number of nonzero assets in the portfolio</li> <li>Sector constraints \u2014 specified minimum and/or maximum allocations to groups of assets (e.g., the energy or healthcare sectors)</li> <li>Transaction costs \u2014 typically represented as a function of \\(|\\Delta w_j|\\), and often added as a term in the objective function rather than as a constraint</li> </ul><p>As is often the case with optimization problems, the problem formulation strongly affects the solution strategy and the problem \"hardness.\" If the PO problem is unconstrained and continuous (i.e., each \\(w_i\\) is a real number), then the problem is relatively easy. If convex inequality constraints, such as the long-only or turnover constraints, are imposed, the problem is harder, but can still be tackled by relatively efficient methods for convex optimization. By contrast, if one discretizes the problem (so that \\(w\\) now represents an integer number of asset shares or lots being traded), or if one applies some of the constraints above (such as integer-valued constraints like cardinality), then the problem becomes nonconvex and considerably harder to solve. In general, with discrete constraints, the problem can be formulated as an instance of mixed-integer program (MIP), which is NP-complete and therefore intractable to solve in polynomial-time (in \\(n\\)) under widely believed assumptions. Alternatively, by encoding the integer variables in binary, it can be formulated as a quadratic unconstrained binary optimization (QUBO) instance. These formulations allow quantum algorithms for combinatorial optimization to be employed; for example, the MIP formulation can be solved with a branch-and-bound approach [3], and the QUBO formulation can be solved via Grover-type methods, or heuristically through (NISQ-friendly) quantum annealing approaches (e.g., [4]).</p>"},{"location":"areas-of-application/finance/portfolio-optimization/#dominant-resource-costcomplexity","title":"Dominant resource cost/complexity","text":"<p>An early approach to solving this optimization problem using a quantum algorithm was presented in [5], in which the Markowitz problem is written as minimizing risk with fixed return (Eq. \\(\\eqref{eq:PO_fixed_return}\\)), and without other complicated constraints. This simple optimization problem boils down to an equality constrained convex program; it can be solved by introducing Lagrange multipliers and solving a linear system involving the input data \\(r\\) and \\(\\Sigma\\) [5]. The approach of [5] is to use a quantum linear system solver (QLSS) and prepare the quantum state \\(\\ket{w}\\) whose amplitudes are proportional to the optimal weights \\(w_i\\). The complexity to do so to error \\(\\epsilon\\) is \\(\\widetilde{\\mathcal{O}}\\left( \\kappa\\zeta\\log(1/\\epsilon) \\right)\\), where \\(\\kappa\\) is the condition number of the matrix \\(G\\) being inverted and \\(\\zeta = \\lVert G \\rVert_F/\\lVert G \\rVert\\) is the ratio of its Frobenius norm to its spectral norm. The \\(\\tilde{\\mathcal{O}}\\) suppresses logarithmic factors, including a factor coming from applying unitaries that block-encode the matrix \\(G\\) in \\(\\mathrm{polylog}(n)\\) depth, essentially equivalent to the assumption that log-depth quantum random access memory (QRAM) is available. It is a priori unclear what the value of \\(\\kappa\\) and \\(\\zeta\\) would be for actual PO instances and whether they depend on \\(n\\), but the explicit logarithmic dependence of this complexity on \\(n\\) is appealing. However, a drawback of this approach is that it produces the quantum state \\(\\ket{w}\\) rather than an estimate for the optimal portfolio \\(w\\). Learning the \\(n\\) entries of \\(w\\) to precision \\(\\epsilon\\) in 2-norm incurs multiplicative overhead of \\(\\widetilde{\\mathcal{O}}\\left( n/\\epsilon \\right)\\) using quantum pure-state tomography [6] for total time complexity \\(\\widetilde{\\mathcal{O}}\\left( n\\kappa\\zeta/\\epsilon \\right)\\).<sup>1</sup></p><p>When convex linear inequality constraints, such as long-only or turnover constraints, are included, the above approach will not work. However, a more sophisticated method can be applied, which first maps the PO instance to a convex program (specifically, a second-order cone program (SOCP)) and then makes use of interior point methods to solve the program. These interior point methods can be quantized, forming quantum interior point methods (QIPMs) [7, 8]. The QIPM is an iterative method, where each iteration involves solving a linear equation with a QLSS and classically reading out the solution with tomography. Thus, the procedure within each iteration is similar to the procedure above for solving the unconstrained PO problem, but the linear system to be solved is different (and changes with each iteration). A preliminary study of the effectiveness of this approach for PO was given by [9], and a more extensive study later appeared in [10]. The QIPM produces an \\(\\epsilon\\)-optimal classical estimate for \\(w\\), and has time complexity \\(\\tilde{\\mathcal{O}}(n^{1.5}\\frac{\\zeta\\kappa}{\\xi}\\log(1/\\epsilon))\\), where \\(\\kappa\\) and \\(\\zeta\\) are the maximum condition number and Frobenius-to-spectral-norm ratio for the matrices that must be inverted over the course of the algorithm, respectively, and \\(\\xi\\) is the precision to which tomography must be performed. Note that in principle \\(\\xi\\) can stay constant even as the overall precision estimate \\(\\epsilon \\rightarrow 0\\) [10].</p><p>With the addition of discrete constraints, PO is instead formulated as a nonconvex MIP. MIPs are typically solved with a branch-and-bound approach (for a summary in a financial context, see, e.g., [11, Chapter 11]). Key to this approach is the ability to solve convex relaxations of the MIP where the discrete constraints are dropped in \\(\\mathrm{poly}(n)\\) time (perhaps via classical or quantum interior point methods for SOCPs, as above). To impose the discrete constraints, a tree is constructed and explored, where generating the children of a given node in the tree requires solving one of these relaxations. Thus, the number of convex relaxations that must be solved is proportional to the tree size \\(T\\), which is generally exponentially large in \\(n\\). Reference [3] (extending prior work of [12]) showed that a quantum algorithm can produce the same output while exploring quadratically fewer nodes, solving roughly \\(\\tilde{\\mathcal{O}}(\\sqrt{T})\\) convex relaxations (but doing so coherently, which could introduce overheads), for a total complexity of \\(\\tilde{\\mathcal{O}}(\\sqrt{T}) \\cdot \\mathrm{poly}(n)\\). The value of \\(T\\) is instance dependent and requires empirical estimation: a preliminary numerical analysis of the value of \\(T\\) for a certain ensemble of PO instances up to \\(n=56\\) found that \\(T\\sim 2^{0.14n}\\) to \\(2^{0.20n}\\) [3].</p><p>The assessment of the number of qubits used by these algorithms requires a nuanced discussion of data loading. A key feature of all of the approaches above is that they require (repeatedly) accessing the classical data representing the historical stock information (i.e., the returns \\(r\\) and the covariance matrix \\(\\Sigma\\)) into the quantum algorithm. The size of this data is typically \\(\\mathcal{O}\\left( n^2 \\right)\\). Loading can be performed using block-encodings and QRAM, which achieves \\(\\mathcal{O}\\left( \\log(n) \\right)\\) depth (time), at the expense of \\(\\mathcal{O}\\left( n^2 \\right)\\) space. Here, several caveats are inherited from the QRAM primitive. Moreover, for practical values of \\(n\\), this \\(\\mathcal{O}\\left( n^2 \\right)\\) space cost could be prohibitively large, although it is possible this space cost could manifest as a dedicated QRAM hardware element of the device, rather than as part of the main processor. If log-depth QRAM of sufficient size is not desired or not available, the data could instead be loaded with only \\(\\mathcal{O}\\left( \\log(n) \\right)\\) space and in \\(\\mathcal{O}\\left( n^2 \\right)\\) time, but this overhead in time would likely preclude the possibility of quantum speedup at least in the first two cases, where the formulation is convex and classical \\(\\mathrm{poly}(n)\\)-time algorithms exist.</p>"},{"location":"areas-of-application/finance/portfolio-optimization/#existing-error-corrected-resource-estimates","title":"Existing error corrected resource estimates","text":"<p>A detailed, end-to-end resource analysis of the PO problem using QIPMs was performed in [10]. The authors followed the approach of [9] and performed a careful accounting of all quantum resources, including constant prefactors. The authors found that one needs \\(800n^2\\) logical qubits, a \\(T\\)-depth of </p>\\[\\begin{equation} (2\\times 10^8)\\kappa\\zeta n^{1.5}\\xi^{-2}\\log_2(n)\\log_2(\\epsilon^{-1})\\log_2(\\kappa\\zeta n^{14/27}\\xi^{-1}), \\end{equation}\\]<p>and a \\(T\\)-count of </p>\\[\\begin{equation} (7\\times 10^{11})\\kappa\\zeta n^{3.5}\\xi^{-2}\\log_2(n)\\log_2(\\epsilon^{-1})\\log_2(\\kappa\\zeta \\xi^{-1}), \\end{equation}\\]<p>where \\(\\kappa\\) is the maximum condition number encountered in the algorithm, \\(\\zeta\\) is the maximum Frobenius-to-spectral-norm ratio, and \\(\\xi\\) is the minimum tomographic precision required. The \\(\\xi^{-2}\\) dependence can asymptotically be improved to \\(\\xi^{-1}\\) at the expense of a more sophisticated protocol for tomography [6]. Note also that this calculation incorporated optimized circuits for block-encoding with \\(\\mathcal{O}\\left( \\log(n) \\right)\\) \\(T\\)-depth but \\(\\mathcal{O}\\left( n^2 \\right)\\) \\(T\\)-count [13], leading to the large discrepancy between those two quantities. The authors performed numerical simulations of portfolio optimization instances to determine the instance-specific quantities. Using numerically determined values for \\(\\kappa\\zeta\\) and \\(\\xi\\), and using realistic values of \\(\\epsilon=10^{-7}\\) and \\(n=100\\), these resource counts imply that one would need \\(8\\times 10^6\\) logical qubits, \\(2\\times 10^{24}\\) \\(T\\)-depth, and \\(8\\times 10^{29}\\) \\(T\\)-count. These logical estimates for the number of non-Clifford gates could in principle be turned into estimates for the number of physical qubits and runtime on actual hardware, using the methods discussed in the page on fault-tolerant quantum computation. However, the authors of [10] did not do so, in part because the logical costs were sufficiently high that the qualitative conclusion about the practicality of the algorithm was already clear.</p>"},{"location":"areas-of-application/finance/portfolio-optimization/#caveats","title":"Caveats","text":"<p>The quantum algorithms for PO discussed above inherit many of the caveats of their underlying primitives, namely QLSS, tomography, and classical data loading. One salient caveat is that the QLSS-based approaches depend on a number of instance-specific parameters \\(\\kappa, \\zeta,\\xi\\), which are difficult to predict without running numerical simulations. The asymptotic speedup is subject to assumptions about the scaling of these parameters. Additionally, for a speedup to be possible, log-depth QRAM must be available on large datasets, which, while theoretically possible, presents practical challenges.</p><p>The branch-and-bound approach does not require log-depth QRAM to achieve its nearly quadratic speedup since the runtime will be dominated by the exponential tree-size factor (although it would help to have fast QRAM to reduce by \\(\\mathrm{poly}(n)\\) factors the time needed to solve the convex relaxations at each step). However, a caveat to that approach is that to obtain the quadratic speedup, the convex relaxations of the MIP (which would be SOCPs), would need to be solved coherently. In principle, this is always possible, but it would likely require a substantial amount of coherent classical arithmetic and additional \\(\\mathrm{poly}(n)\\) overheads in time and space.</p>"},{"location":"areas-of-application/finance/portfolio-optimization/#comparable-classical-complexity-and-challenging-instance-sizes","title":"Comparable classical complexity and challenging instance sizes","text":"<p>Convex formulations of the PO problem are typically solved classically via mapping to SOCP. Optimized software packages can solve these SOCPs efficiently, and many are based on interior point methods. These interior point methods have theoretical runtime complexity of roughly \\(\\tilde{O}(n^{\\omega+0.5}\\log(1/\\epsilon))\\), where \\(\\omega\\approx 2.373\\) is the matrix multiplication exponent, although for practical instance sizes, the effective value of \\(\\omega\\) is typically closer to 3. Note that the example PO problem with 100 assets solved in [10] and described above can typically be solved within seconds on a laptop using traditional classical methods. Problem sizes found in the financial services industry can include as many as tens of thousands of assets.</p><p>In the MIP formulation of PO, classical solutions will have complexity exponential in \\(n\\). As a point of reference, the numerical experiments reported in [3] classically solved hundreds of PO instances up to size \\(n=56\\) (and likely could have gone significantly higher).</p>"},{"location":"areas-of-application/finance/portfolio-optimization/#speedup","title":"Speedup","text":"<p>Recall that the QIPMs used to solve the SOCP for constrained PO are virtually identical to their classical counterpart; they differ by their use of a quantum subroutine to solve linear systems. Thus, any speedup obtained by the quantum approach to solving the SOCP will necessarily come from speedups from the QLSS plus tomography approach to solving a linear system. The approach for unconstrained PO was also based on the same primitives. The performance of the quantum method is often compared against classical Gaussian elimination. However, since the quantum approach necessarily produces an approximate solver (due to tomography), another valid comparison to make is against approximate classical solvers, such as the randomized Kaczmarz method [14]. In this case, the classical complexity for solving an \\(L\\times L\\) linear system to precision \\(\\xi\\) scales as \\(\\mathcal{O}(L\\kappa^2 \\zeta^2\\log(\\xi^{-1}))\\) (where \\(\\kappa\\) is the condition number and \\(\\zeta\\) the Frobenius-to-spectral norm ratio) compared to \\(\\mathcal{O}(L^3)\\) for Gaussian elimination (asymptotically \\(\\mathcal{O}(L^{\\omega})\\)). Thus, the quantum method provides the greatest speedup when \\(\\kappa\\zeta\\propto L\\) and \\(\\xi=\\mathcal{O}\\left( 1 \\right)\\), in which case the QIPM for constrained PO runtime scales as \\(\\widetilde{\\mathcal{O}}\\left( n^{2.5} \\right)\\), whereas the classical runtimes scales as \\(\\widetilde{\\mathcal{O}}\\left( n^{3.5} \\right)\\), where \\(n\\) is the number of stocks in the portfolio (see [10, Table XI] for a more complete discussion). For unconstrained PO, which only requires solving one linear system, the comparison would be \\(\\widetilde{\\mathcal{O}}\\left( n^2 \\right)\\) vs. \\(\\widetilde{\\mathcal{O}}\\left( n^3 \\right)\\). In either case, the speedup is subquadratic. Moreover, the numerical simulations in [10] were not consistent with these optimistic assumptions on \\(\\kappa \\zeta\\) and \\(\\xi\\), suggesting, rather, that the QIPM would have minimal if any speedup over classical IPMs, albeit based on small instance sizes up to \\(n=120\\).</p><p>The speedup for the branch-and-bound approach to the MIP formulation of PO is quadratic (up to log factors), although, as mentioned, in contrast to the convex formulations, both the quantum and classical algorithms generally have runtime exponential in \\(n\\).</p>"},{"location":"areas-of-application/finance/portfolio-optimization/#nisq-implementations","title":"NISQ implementations","text":"<p>Several alternative approaches to portfolio optimization using quantum solutions have been proposed.</p><ul> <li>NISQ-HHL [15]. This work generalizes the algorithm of [5], described above, by employing mid-circuit measurements and conditional logic to obtain a NISQ version of the QLSS that readily solves the PO problem.</li> <li>QAOA approaches: [16, 17, 18]   . These approaches typically use the quadratic objective function from Eq. \\(\\eqref{eq:quadratic_objective}\\), but instead consider \\(w_i \\in \\{0,1\\}\\) as binary variables indicating whether or not an asset is part of the portfolio (a substantial deviation from the normal formulation). Constraints are dealt with by adding penalties to the objective function. Alternatively, constraints are enforced by choosing clever versions of the ansatz [19] or by making measurements to project into the feasible space [17].</li> <li>Quantum annealing approaches: [20, 21, 22, 23, 4]. As in the previous case, these approaches require the problem to be formulated as a binary optimization problem. However, in this case, they typically take the MIP formulation and encode integers in binary through one of several possible encodings [20] (thus, the number of binary variables will be greater than \\(n\\)). Constraints in the PO problem can also be included in the objective function using a variety of tricks, resulting in the desired QUBO, which can then be solved using a quantum annealer.</li> </ul>"},{"location":"areas-of-application/finance/portfolio-optimization/#outlook","title":"Outlook","text":"<p>The QIPM approach (and QLSS-based techniques more generally) for continuous formulations of PO have the potential to offer polynomial (but subquadratic) speedups for the PO problem. However, these speedups are subject to conjectures about the scaling of certain instance-specific parameters and preliminary empirical estimates are not suggestive of a maximal speedup. In any regard, the resource estimates of [10] illustrate that the non-Clifford resources required to implement the QIPM for this use case are prohibitive, even at problem sizes that are trivial to solve with classical computers. An asymptotic quantum advantage for this problem could exist for sufficiently large sets of assets, but without drastic improvements to the quantum algorithm and the underlying primitives (e.g., QRAM, QLSS), it is unlikely this approach will be fruitful. Even if such improvements are made, the algorithm only provides a polynomial speedup that is subquadratic, at best, greatly limiting the upside potential of this approach.</p><p>The branch-and-bound approach for discrete formulations has a possible for a larger quadratic speedup, but, as has been observed (see, e.g., [24, 25]) in the context of Grover-like quadratic speedups in combinatorial optimization, it is unclear whether the quadratic speedup is sufficient to overcome the inherently slower quantum clock speeds and overheads due to fault-tolerant quantum computation for practical instance sizes.</p>"},{"location":"areas-of-application/finance/portfolio-optimization/#bibliography","title":"Bibliography","text":"<ol> <li> <p>Robert C Merton. An analytic derivation of the efficient portfolio frontier. Journal of Financial and Quantitative Analysis, 7(4):1851\u20131872, 1972. doi:10.2307/2329621.</p> </li> <li> <p>MOSEK ApS. Mosek portfolio optimization cookbook: release 1.3.0. 11 2023. https://docs.mosek.com/MOSEKPortfolioCookbook-a4paper.pdf, accessed: 2023-10-04.</p> </li> <li> <p>Shouvanik Chakrabarti, Pierre Minssen, Romina Yalovetzky, and Marco Pistoia. Universal quantum speedup for branch-and-bound, branch-and-cut, and tree-search algorithms. arXiv: https://arxiv.org/abs/2210.03210, 2022.</p> </li> <li> <p>Samuel Mugel, Carlos Kuchkovsky, Escolastico Sanchez, Samuel Fernandez-Lorenzo, Jorge Luis-Hita, Enrique Lizaso, and Roman Orus. Dynamic portfolio optimization with real datasets using quantum processors and quantum-inspired tensor networks. Physical Review Research, 4(1):013006, 2022. arXiv: https://arxiv.org/abs/2007.00017. doi:10.1103/PhysRevResearch.4.013006.</p> </li> <li> <p>Patrick Rebentrost and Seth Lloyd. Quantum computational finance: quantum algorithm for portfolio optimization. arXiv: https://arxiv.org/abs/1811.03975, 2018.</p> </li> <li> <p>Joran van Apeldoorn, Arjan Cornelissen, Andr\u00e1s Gily\u00e9n, and Giacomo Nannicini. Quantum tomography using state-preparation unitaries. In Proceedings of the 34th ACM-SIAM Symposium on Discrete Algorithms (SODA), 1265\u20131318. 2023. arXiv: https://arxiv.org/abs/2207.08800. doi:10.1137/1.9781611977554.ch47.</p> </li> <li> <p>Iordanis Kerenidis, Anupam Prakash, and D\u00e1niel Szil\u00e1gyi. Quantum algorithms for second-order cone programming and support vector machines. Quantum, 5:427, 2021. arXiv: https://arxiv.org/abs/1908.06720. doi:10.22331/q-2021-04-08-427.</p> </li> <li> <p>Brandon Augustino, Tam\u00e1s Terlaky, and Luis F Zuluaga. An inexact-feasible quantum interior point method for second-order cone optimization. Technical Report 21T-009, Department of Industrial and Systems Engineering, Lehigh University, 2022.</p> </li> <li> <p>Iordanis Kerenidis, Anupam Prakash, and D\u00e1niel Szil\u00e1gyi. Quantum algorithms for portfolio optimization. In Proceedings of the 1st ACM Conference on Advances in Financial Technologies, AFT '19, 147\u2013155. New York, NY, USA, 2019. Association for Computing Machinery. arXiv: https://arxiv.org/abs/1908.08040. URL: https://doi.org/10.1145/3318041.3355465, doi:10.1145/3318041.3355465.</p> </li> <li> <p>Alexander M Dalzell, B David Clader, Grant Salton, Mario Berta, Cedric Yen-Yu Lin, David A Bader, Nikitas Stamatopoulos, Martin J A Schuetz, Fernando G S L Brand\u00e3o, Helmut G Katzgraber, and others. End-to-end resource analysis for quantum interior point methods and portfolio optimization. PRX Quantum, pages to appear, 2023. arXiv: https://arxiv.org/abs/2211.12489.</p> </li> <li> <p>Gerard Cornuejols and Reha T\u00fct\u00fcnc\u00fc. Optimization methods in finance. Volume 5. Cambridge University Press, 2006.</p> </li> <li> <p>Ashley Montanaro. Quantum speedup of branch-and-bound algorithms. Physical Review Research, 2(1):013056, 2020. arXiv: https://arxiv.org/abs/1906.10375. doi:10.1103/PhysRevResearch.2.013056.</p> </li> <li> <p>B. David Clader, Alexander M. Dalzell, Nikitas Stamatopoulos, Grant Salton, Mario Berta, and William J. Zeng. Quantum resources required to block-encode a matrix of classical data. IEEE Transactions on Quantum Engineering, 3:1\u201323, 2022. arXiv: https://arxiv.org/abs/2206.03505. doi:10.1109/TQE.2022.3231194.</p> </li> <li> <p>Thomas Strohmer and Roman Vershynin. A randomized kaczmarz algorithm with exponential convergence. Journal of Fourier Analysis and Applications, 15(2):262\u2013278, 2009. arXiv: https://arxiv.org/abs/math/0702226. doi:10.1007/s00041-008-9030-4.</p> </li> <li> <p>Romina Yalovetzky, Pierre Minssen, Dylan Herman, and Marco Pistoia. Nisq-hhl: portfolio optimization for near-term quantum hardware. arXiv: https://arxiv.org/abs/2110.15958, 2021.</p> </li> <li> <p>Sebastian Brandhofer, Daniel Braun, Vanessa Dehn, Gerhard Hellstern, Matthias H\u00fcls, Yanjun Ji, Ilia Polian, Amandeep Singh Bhatia, and Thomas Wellens. Benchmarking the performance of portfolio optimization with qaoa. Quantum Information Processing, 22(1):1\u201327, 2023. arXiv: https://arxiv.org/abs/2207.10555. doi:10.1007/s11128-022-03766-5.</p> </li> <li> <p>Dylan Herman, Ruslan Shaydulin, Yue Sun, Shouvanik Chakrabarti, Shaohan Hu, Pierre Minssen, Arthur Rattew, Romina Yalovetzky, and Marco Pistoia. Portfolio optimization via quantum zeno dynamics on a quantum processor. arXiv: https://arxiv.org/abs/2209.15024, 2022.</p> </li> <li> <p>Jack S Baker and Santosh Kumar Radha. Wasserstein solution quality and the quantum approximate optimization algorithm: a portfolio optimization case study. arXiv: https://arxiv.org/abs/2202.06782, 2022.</p> </li> <li> <p>Pradeep Niroula, Ruslan Shaydulin, Romina Yalovetzky, Pierre Minssen, Dylan Herman, Shaohan Hu, and Marco Pistoia. Constrained quantum optimization for extractive summarization on a trapped-ion quantum computer. Scientific Reports, 12(1):1\u201314, 2022. arXiv: https://arxiv.org/abs/2206.06290. doi:10.1038/s41598-022-20853-w.</p> </li> <li> <p>Gili Rosenberg, Poya Haghnegahdar, Phil Goddard, Peter Carr, Kesheng Wu, and Marcos L\u00f3pez de Prado. Solving the optimal trading trajectory problem using a quantum annealer. IEEE Journal of Selected Topics in Signal Processing, 10(6):1053\u20131060, 2016. Earlier version in WHPCF'15, arXiv: https://arxiv.org/abs/1508.06182. doi:10.1109/JSTSP.2016.2574703.</p> </li> <li> <p>Samuel Palmer, Konstantinos Karagiannis, Adam Florence, Asier Rodriguez, Roman Orus, Harish Naik, and Samuel Mugel. Financial index tracking via quantum computing with cardinality constraints. arXiv: https://arxiv.org/abs/2208.11380, 2022.</p> </li> <li> <p>Samuel Palmer, Serkan Sahin, Rodrigo Hernandez, Samuel Mugel, and Roman Orus. Quantum portfolio optimization with investment bands and target volatility. arXiv: https://arxiv.org/abs/2106.06735, 2021.</p> </li> <li> <p>Erica Grant, Travis S Humble, and Benjamin Stump. Benchmarking quantum annealing controls with portfolio optimization. Physical Review Applied, 15(1):014012, 2021. arXiv: https://arxiv.org/abs/2007.03005. doi:10.1103/PhysRevApplied.15.014012.</p> </li> <li> <p>Earl Campbell, Ankur Khurana, and Ashley Montanaro. Applying quantum algorithms to constraint satisfaction problems. Quantum, 3:167, 2019. arXiv: https://arxiv.org/abs/1810.05582. doi:10.22331/q-2019-07-18-167.</p> </li> <li> <p>Ryan Babbush, Jarrod R. McClean, Michael Newman, Craig Gidney, Sergio Boixo, and Hartmut Neven. Focus beyond quadratic speedups for error-corrected quantum advantage. PRX Quantum, 2(1):010103, 3 2021. arXiv: https://arxiv.org/abs/2011.04149. doi:10.1103/PRXQuantum.2.010103.</p> </li> <li> <p>Emanuel Knill, Gerardo Ortiz, and Rolando D. Somma. Optimal quantum measurements of expectation values of observables. Physical Review A, 75:012328, 1 2007. arXiv: https://arxiv.org/abs/quant-ph/0607019. URL: https://link.aps.org/doi/10.1103/PhysRevA.75.012328, doi:10.1103/PhysRevA.75.012328.</p> </li> </ol> <ol> <li> <p>Reference [5] suggests several possible nonstandard problems that can be solved with \\(\\ket{w}\\) without actually learning the entries of \\(w\\), such as sampling values of \\(i\\) with large \\(|w_i|\\), and estimating overlaps \\(\\langle \\tilde{w}, w \\rangle\\) with hypothesized portfolios \\(\\tilde{w}\\). In general, inner products \\(\\langle u, w \\rangle\\) of arbitrary normalized vectors \\(u\\) with \\(w\\) can be learned to precision \\(\\epsilon\\) using overlap estimation [26] (an application of amplitude estimation), incurring multiplicative overhead of \\(\\mathcal{O}\\left( 1/\\epsilon \\right)\\), but no explicit linear-in-\\(n\\) dependence. However, the practical utility of such tasks within the existing workflows of financial institutions is unclear.\u00a0\u21a9</p> </li> </ol>"},{"location":"areas-of-application/machine-learning-with-classical-data/introduction/","title":"Machine learning with classical data","text":"<p>There has been significant recent interest in exploring the interplay between quantum computing and machine learning. Quantum resources and quantum algorithms have been studied in all major parts of the traditional machine learning pipeline: (1) the data set; (2) data processing and analysis; (3) the machine learning model leading to a hypothesis family; and (4) the learning algorithm (see [1, 2, 3] for reviews). In this section we predominantly focus on quantum approaches for the latter three categories\u2014that is, here we mostly consider quantum algorithms applied to classical data. These approaches include algorithms hinging on the quantum linear system solver (or quantum linear algebra more generally) as the source for possible quantum speedup over classical learning algorithms. These also include quantum neural networks (using the framework of variational quantum algorithms) and quantum kernels, where the classical machine learning model is replaced with a quantum model. Additionally, in this section we discuss quantum algorithms that aim to speed up data analysis tasks, namely tensor principal component analysis (TPCA) and topological data analysis.</p><p>Quantum machine learning is an active area of research. As such, we expect the conclusions made in this section to evolve over time, as new results are discovered. At present, our evaluation suggests that few of the considered quantum machine learning algorithms show any promise of quantum advantage in the intermediate future. This conclusion stems from a number of factors, including issues of loading classical data into the quantum device and extracting classical data via tomography, and the success of classical \"dequantized\\\" algorithms [4]. More specialized tasks, such as tensor PCA and topological data analysis may provide larger polynomial speedups (i.e., better than quadratic) in some regimes, but their application scope is less broad. Finally, other techniques such as quantum neural networks and quantum kernel methods contain heuristic elements which make it challenging to perform concrete analytic end-to-end resource estimates [5].</p>"},{"location":"areas-of-application/machine-learning-with-classical-data/introduction/#bibliography","title":"Bibliography","text":"<ol> <li> <p>Jacob Biamonte, Peter Wittek, Nicola Pancotti, Patrick Rebentrost, Nathan Wiebe, and Seth Lloyd. Quantum machine learning. Nature, 549:195\u2013202, 2017. arXiv: https://arxiv.org/abs/1611.09347. doi:10.1038/nature23474.</p> </li> <li> <p>M Cerezo, Guillaume Verdon, Hsin-Yuan Huang, Lukasz Cincio, and Patrick J Coles. Challenges and opportunities in quantum machine learning. Nature Computational Science, 2(9):567\u2013576, 2022. arXiv: https://arxiv.org/abs/2303.09491. doi:https://doi.org/10.1038/s43588-022-00311-3.</p> </li> <li> <p>Carlo Ciliberto, Mark Herbster, Alessandro Davide Ialongo, Massimiliano Pontil, Andrea Rocchetto, Simone Severini, and Leonard Wossnig. Quantum machine learning: a classical perspective. Proceedings of the Royal Society A, 474(2209):20170551, 2018. arXiv: https://arxiv.org/abs/1707.08561. doi:https://doi.org/10.1098/rspa.2017.0551.</p> </li> <li> <p>Ewin Tang. A quantum-inspired classical algorithm for recommendation systems. In Proceedings of the 51st ACM Symposium on the Theory of Computing (STOC), 217\u2013228. 2019. arXiv: https://arxiv.org/abs/1807.04271. doi:10.1145/3313276.3316310.</p> </li> <li> <p>Maria Schuld and Nathan Killoran. Is quantum advantage the right goal for quantum machine learning? PRX Quantum, 3(3):030101, 2022. arXiv: https://arxiv.org/abs/2203.01340. URL: https://link.aps.org/doi/10.1103/PRXQuantum.3.030101, doi:10.1103/PRXQuantum.3.030101.</p> </li> </ol>"},{"location":"areas-of-application/machine-learning-with-classical-data/quantum-machine-learning-via-energy-based-models/","title":"Quantum machine learning via energy-based models","text":""},{"location":"areas-of-application/machine-learning-with-classical-data/quantum-machine-learning-via-energy-based-models/#overview","title":"Overview","text":"<p>An important class of models in machine learning are energy-based models, which are heavily inspired by statistical mechanics. The goal of energy-based models is to train a physical model (i.e., tune the interaction strengths between a set of particles) such that the model closely matches the training set when the model is in thermal equilibrium (made more precise below). Energy-based models are an example of generative models since, once they are trained, they can then be used to form new examples that are similar to the training set by sampling from the model's thermal distribution.</p><p>Due to their deep connection to physics, energy-based models are prime candidates for various forms of quantization. However, one challenge faced by quantum approaches is that the statistical mechanical nature of the learning problem also often lends itself to efficient, approximate classical methods. As a result, the best quantum algorithms may also be heuristic in nature, which prevents an end-to-end complexity analysis. While energy-based models are less widely used than deep neural networks today, they were an important conceptual development in machine learning [1] and continue to foster interest due to their sound theoretical basis, and their connection to statistical mechanics.</p><p>There are a number of proposals for generalizing energy-based models to quantum machine learning. The starting point is a graph where the vertices are divided into visible \\(\\{v\\}\\) and hidden \\(\\{h\\}\\) nodes. When each node is assigned a value in some discrete or continuous set, this constitutes a \"configuration\" \\((h,v)\\) of the model. A training set \\(\\mathcal{D}\\) is provided as input, containing a list of configurations of the visible vertices. The hidden nodes are not part of the training set, but including them is essential for the model to be able to capture latent variables in the data.</p><p>A graphical model is then built on the vertices\u2014each vertex is a physical system (such as a spin-\\(1/2\\) particle) and edges between vertices represent physical interactions. The model is described by an energy functional \\(H(h,v)\\), which assigns an energy value to each possible configuration \\((h,v)\\) of the vertices. For example, in Boltzmann machines (BMs), the vertices are assigned binary variables, and the interactions are Ising interactions. The model can be used to generate samples (e.g., via Markov chain Monte Carlo methods) from the thermal distribution (also known as the Boltzmann distribution or the Gibbs distribution) at unit temperature, that is, the distribution where each configuration \\((h,v)\\) is sampled with probability proportional to \\(e^{-H(h,v)}\\). In unsupervised learning tasks, provided a set of training samples of configurations of the visible units \\(v\\), the goal is to tune the interaction weights of the model such that the model's thermal distribution best matches the distribution that generated the training set.</p><p>Quantum algorithms can potentially be helpful for training classical graphical models. One can also generalize the model itself by allowing the physical systems on each vertex to be quantum, and interactions between systems to be noncommuting.</p>"},{"location":"areas-of-application/machine-learning-with-classical-data/quantum-machine-learning-via-energy-based-models/#actual-end-to-end-problems-solved","title":"Actual end-to-end problem(s) solved","text":""},{"location":"areas-of-application/machine-learning-with-classical-data/quantum-machine-learning-via-energy-based-models/#classical-graphical-models","title":"Classical graphical models.","text":"<p>Let \\(G = (V,E)\\) denote a graph with vertices \\(V\\) and edges \\(E\\). For classical models, each vertex \\(j\\) is assigned a binary variable \\(z_j = \\pm 1\\). The variables are split into visible and hidden nodes, \\(z \\in \\{v\\} \\cup \\{h\\}\\). For classical BMs, the energy functional is often taken to be quadratic<sup>1</sup> with weights \\(\\{b_i,w_{ij}\\}\\): </p>\\[\\begin{equation} \\label{eq:EBM_energy} H(z)= \\sum_{i\\in V} b_i z_i+\\sum_{(i,j)\\in E}w_{ij} z_iz_j. \\end{equation}\\]<p>Note that interactions can occur between any pair of nodes (hidden or visible). In the special case of a restricted Boltzmann machine (RBM), each edge must pair up a hidden node with a visible node (i.e., the graph is bipartite), which can cause simplifications to certain training approaches.</p><p>The thermal distribution corresponding to the energy functional (at unit temperature) associates each configuration \\(v\\) of visible nodes with a probability \\(p(v)\\) such that </p>\\[\\begin{equation} p(v) = \\sum_h p(h,v), \\qquad p(h,v) = \\frac{e^{-H(h,v)}}{Z}, \\qquad Z = \\sum_{h,v} e^{-H(h,v)} \\end{equation}\\]<p>where \\(Z\\), the partition function, is the normalization to ensure probabilities sum to 1. Even though hidden nodes are integrated out in the calculation of \\(p(v)\\), they impact the distribution of \\(p(v)\\) through their interactions with the visible nodes.</p><p>Given a training set \\(\\mathcal{D} = \\{v_1,v_2,\\ldots,v_{\\lvert \\mathcal{D} \\rvert}\\}\\) of sample configurations of the visible nodes, the goal of the training phase is to modify the weights \\(\\theta \\in \\{b_i\\} \\cup \\{w_{ij}\\}\\) such that samples from the thermal distribution of the model most closely match the training samples. Ideally, this is done by finding the set of weights that maximizes the likelihood of observing the samples, i.e. \\(\\prod_{v\\in \\mathcal{D}} p(v)\\), or, equivalently, minimizing the (normalized) log-likelihood loss function, defined as </p>\\[\\begin{equation} L(b,w)=-\\frac{1}{\\lvert \\mathcal{D} \\rvert }\\sum_{v\\in\\mathcal{D}} \\log(p(v)) \\,. \\end{equation}\\]<p>The loss function can be minimized using some variant of gradient descent, which requires the evaluation of the derivatives \\(\\partial_{\\theta}L\\) for \\(\\theta \\in \\{b_i\\} \\cup \\{w_{ij}\\}\\). For the energy functional above, these derivatives can be readily calculated from ensemble averages (see, e.g., [2]). For example, </p>\\[\\begin{equation} \\label{eq:EBM_gradient} \\frac{\\partial L}{\\partial w_{ij}} = \\langle z_iz_j \\rangle_{v \\in \\mathcal{D}} - \\langle z_iz_j \\rangle \\end{equation}\\]<p>where \\(\\langle \\cdot \\rangle\\) denotes an average over samples from the thermal distribution \\(p(h,v)\\), while \\(\\langle \\cdot \\rangle_{v \\in \\mathcal{D}}\\) denotes an average where \\(v\\) is drawn at random from the training set \\(\\mathcal{D}\\), and \\(h\\) is sampled from the thermal distribution conditioned on that choice of \\(v\\). Without any further restrictions, the gradients will typically be difficult to evaluate, or estimate accurately. An exact computation requires computing a sum over the exponential number of configurations of the vertices.</p><p>In some cases, good estimates of the gradients can be obtained by repeatedly drawing samples from the thermal distribution and computing averages. Samples can be generated with Markov chain Monte Carlo (MCMC) methods such as Metropolis sampling or simulated annealing; however, the time required to sample from a distribution close to the thermal distribution depends on the mixing time of the Markov chain, which is generally unknown and can also be exponential in the graph size. Additionally, many samples need to be generated to produce a robust average, with precision \\(\\epsilon\\) requiring \\(\\mathcal{O}\\left( 1/\\epsilon^2 \\right)\\) samples. Approximate classical methods, such as contrastive divergence [3], avoid this issue by initializing the Markov chain at one of the training samples and deliberately taking a small number of steps\u2014this does not exactly correspond to optimizing the log-likelihood but in some cases has empirical success [4]. Once the model has been trained, new samples can also be generated via the same MCMC methods. The end-to-end tasks are (i) training the model, and then, (ii) generating samples from the trained model to accomplish some larger machine learning goal.</p>"},{"location":"areas-of-application/machine-learning-with-classical-data/quantum-machine-learning-via-energy-based-models/#quantum-graphical-models","title":"Quantum graphical models.","text":"<p>A separate end-to-end problem is found by generalizing the model itself to be quantum. For example, one can start with a classical BM and promote the binary variables to qubits. The energy functional is promoted to a quantum Hamiltonian and augmented with a transverse field, which does not commute with the Ising interactions. The result is a quantum Boltzmann machine (QBM), described by a transverse-field Ising (TFI) Hamiltonian [5]: </p>\\[\\begin{equation} \\label{eq:QBM_energy} H_{\\rm QBM}= -\\sum_{i\\in V}(\\kappa_i X_i +b_i Z_i) -\\sum_{(i,j)\\in E} w_{ij} Z_i Z_j, \\end{equation}\\]<p>where \\(X_i\\) and \\(Z_i\\) are the Pauli-\\(X\\) and Pauli-\\(Z\\) operators on qubit \\(i\\), and \\(b_i, \\kappa_i, w_{ij}\\) are real variational parameters of the model. The ground or Gibbs state of \\(H_{\\rm QBM}\\) can be prepared in a variety of ways, including: the adiabatic algorithm, Hamiltonian simulation, Gibbs sampling or as a variational quantum algorithm. These states can be measured (in the \\(Z\\) basis or in the \\(X\\) basis), yielding samples of the variables \\(v,h\\) drawn from different distributions than the thermal distribution for the classical BM. As in the classical case, the training phase for a QBM consists of varying the weights via gradient descent to maximize a likelihood function. However, the noncommutativity of the Hamiltonian leads to complications: the gradients of the loss function are no longer directly given by sample expectation values, although workarounds have been proposed [5, 6, 7, 8, 9]. The end-to-end problem is to train these models and generate samples.</p>"},{"location":"areas-of-application/machine-learning-with-classical-data/quantum-machine-learning-via-energy-based-models/#dominant-resource-costcomplexity","title":"Dominant resource cost/complexity","text":""},{"location":"areas-of-application/machine-learning-with-classical-data/quantum-machine-learning-via-energy-based-models/#complexity-of-classical-graphical-models","title":"Complexity of classical graphical models.","text":"<p>Recall that for classical BMs, one wishes to produce samples from the thermal distribution corresponding to the energy functional in Eq. \\(\\eqref{eq:EBM_energy}\\), i.e. Gibbs sampling (of diagonal Hamiltonians), either to assist in training the model or, if it has already been trained, to make inferences or generate new data. Specifically, given \\(H(h,v)\\), one wishes to draw samples of \\((h,v)\\) with probability proportional to \\(e^{-H(h,v)}\\), either with \\(v\\) free or with \\(v\\) fixed (sometimes referred to as \"clamped\") to a particular value from the training set \\(\\mathcal{D}\\). Classically, one approach is simulated annealing or other MCMC algorithms. Quantumly, one can take one of several analogous approaches, including \"quantum simulated annealing\" [10] and quantum annealing, discussed as follows.</p><p>For quantum simulated annealing, one prepares the coherent Gibbs state \\(\\sum_{v,h} \\sqrt{p(h,v)}\\ket{v,h}\\), and a quadratic speedup is obtained over classical simulated annealing. The method is to construct a Hamiltonian whose ground state is the coherent Gibbs state at temperature \\(T\\) (for which probabilities are proportional to \\(e^{-H(h,v)/T}\\), and follow an adiabatic path from \\(T=\\infty\\) to \\(T=1\\). Following the path is accomplished by repeatedly performing quantum phase estimation (QPE) to project onto the ground state of the Hamiltonian at a given temperature. As is typical for the adiabatic algorithm, the cost of this procedure is dominated by the inverse of the spectral gap\u2014this is the precision required for QPE to succeed. Specifically, for a graphical model with \\(|V|\\) vertices, the runtime will be \\(\\mathrm{poly}(|V|)/\\Delta\\), where \\(\\Delta\\) is the minimum spectral gap. Importantly, \\(\\Delta\\) can be related to the maximum mixing time \\(t_{\\rm mix}\\) of the simulated annealing Markov chain, as \\(1/\\Delta = \\mathcal{O}\\left( \\sqrt{t_{\\rm mix}} \\right)\\), which leads to the quadratic speedup, although it is possible that \\(\\Delta\\) is exponentially small in \\(|V|\\).</p><p>An alternative method for preparing (and sampling from) the coherent Gibbs state was proposed in [2]. There, one begins in an easy-to-prepare coherent mean-field state approximating the coherent Gibbs state. Then, one performs rejection sampling with amplitude amplification to gain a quadratic speedup over the analogous classical method. Additionally, it was proposed to use amplitude estimation to gain a quadratic improvement in the number of samples needed to achieve precision \\(\\epsilon\\), from \\(\\mathcal{O}\\left( 1/\\epsilon^2 \\right)\\) to \\(\\mathcal{O}\\left( 1/\\epsilon \\right)\\), mirroring later analyses that work for general Monte Carlo methods [11]. If these \\(\\mathcal{O}\\left( 1/\\epsilon \\right)\\) quantum samples are each for the same training sample \\(v \\in \\mathcal{D}\\), this is straightforward; however, if the samples are drawn randomly from \\(v \\in \\mathcal{D}\\), achieving the quadratic speedup from amplitude estimation requires accessing the data in \\(\\mathcal{D}\\) coherently and quickly. Such data access is provided by the quantum random access memory (QRAM) primitive, for which the circuit depth can be logarithmic in the size of the training data, at the expense of a number of ancilla qubits (and total gates) that is linear in the size of the training data.</p><p>For quantum annealing, the idea is to add a uniform transverse field, as in the QBM of Eq. \\(\\eqref{eq:QBM_energy}\\) with \\(\\kappa_i=\\kappa_j\\) for all \\(i,j\\). The transverse field is initially strong, and slowly turned off. This is similar to the adiabatic algorithm, but differs in that it is specifically carried out at finite ambient temperature. Thus, the system-bath interaction of the device naturally drives the state to the Gibbs state, which coincides with the classical thermal distribution once the transverse field is turned off. This is a heuristic method; it is efficient but there are few success guarantees. The hope is that the inclusion of an initial transverse field induces nonclassical fluctuations that help the system avoid becoming trapped in local minima as the transverse field is turned off.</p><p>Overall, computing the gradient of the loss function with respect to one parameter, up to precision \\(\\epsilon\\), will require complexity \\(\\mathcal{O}\\left( S/\\epsilon \\right)\\), where \\(S\\) is the complexity of sampling from the Gibbs state. The above assumes log-depth QRAM to be able to estimate the \\(\\langle z_i z_j \\rangle_{v \\in \\mathcal{D}}\\) term of Eq. \\(\\eqref{eq:EBM_gradient}\\). The complexity of \\(S\\) will be \\(\\mathrm{poly}(|V|)\\sqrt{t_{\\rm mix}}\\) if a quantum simulated annealing approach is used, or some hard-to-analyze quantity if the quantum annealing approach is used. If the number of training samples is small, one can also sequentially compute the sum over \\(v \\in \\mathcal{D}\\) and avoid the assumption of log-depth QRAM, leading to complexity \\(\\mathcal{O}\\left( S\\lvert \\mathcal{D} \\rvert/\\epsilon' \\right)\\) (where \\(\\epsilon' \\geq \\epsilon\\) may be order-1). This must be carried out for all \\(|E|+|V|\\) weights in the model, although these could be simultaneously estimated to precision \\(\\epsilon\\) at cost \\(\\tilde{\\mathcal{O}}(\\sqrt{|E|+|V|}/\\epsilon)\\) samples, using methods from [12], which leverage the quantum gradient estimation primitive. It is not clear what value of \\(\\epsilon\\) is required in practice. Reference [2] takes \\(\\epsilon \\sim 1/\\sqrt{\\lvert \\mathcal{D} \\rvert}\\), to match the natural uncertainty coming from a finite number of training samples. In this case, the overall complexity is dominated by </p>\\[\\begin{equation} \\widetilde{\\mathcal{O}}\\left( S \\cdot \\sqrt{|V|+|E|} \\cdot \\sqrt{|\\mathcal{D}|} \\right) \\end{equation}\\]<p>assuming log-depth QRAM, and </p>\\[\\begin{equation} \\widetilde{\\mathcal{O}}\\left( S \\cdot \\sqrt{|V|+|E|} \\cdot |\\mathcal{D}| \\right) \\end{equation}\\]<p>without log-depth QRAM (the precision for each training sample can be taken \\(\\epsilon' = \\mathcal{O}\\left( 1 \\right)\\)).</p>"},{"location":"areas-of-application/machine-learning-with-classical-data/quantum-machine-learning-via-energy-based-models/#complexity-of-quantum-graphical-models","title":"Complexity of quantum graphical models.","text":"<p>For QBMs, the dominant cost is producing samples from the quantum Gibbs state of Eq. \\(\\eqref{eq:QBM_energy}\\), i.e. the state \\(\\rho \\propto e^{-H_{\\rm QBM}}\\), which can be accomplished through methods for Gibbs sampling. Rigorous methods for Gibbs sampling may scale exponentially in the size of the graph, without further assumptions. Such scaling would likely not be tolerable in practice. However, Monte Carlo\u2013style methods for Gibbs sampling, which follow a similar approach as MCMC, but in an inherently quantum way, may be more effective in this case. These could have \\(\\mathrm{poly}(|V|)\\) scaling for some parameter settings, but must also have exponential scaling in the worst case, as sampling low-energy Ising-model configurations is known to be NP-hard.</p><p>One can also heuristically apply quantum annealing, beginning from a large transverse field and reducing its strength slowly to some final nonzero value. However, some hardware platforms may only admit global control over the transverse field, preventing one from tuning the transverse field strengths \\(\\kappa_i\\) individually. In any of these approaches, it is difficult to make any rigorous statements about the Gibbs sampling complexity.</p>"},{"location":"areas-of-application/machine-learning-with-classical-data/quantum-machine-learning-via-energy-based-models/#existing-error-corrected-resource-estimates","title":"Existing error corrected resource estimates","text":"<p>There are no error-corrected estimates for annealing. However, [13, 14] discuss in detail how to embed the fully connected architecture of a RBM into the 2D lattice architecture available on planar quantum annealers.</p><p>Reference [14] reports an embedding ratio scaling which is roughly quadratic\u2014that is, a graphical model with \\(|V|\\) vertices requires \\(\\mathcal{O}\\left( |V|^2 \\right)\\) qubits to accommodate the architectural limitations of the device. A proper fault-tolerant resource estimation has not been performed for the fault-tolerant algorithm of [2].</p>"},{"location":"areas-of-application/machine-learning-with-classical-data/quantum-machine-learning-via-energy-based-models/#caveats","title":"Caveats","text":"<p>There are two main caveats to quantum approaches to training classical models, which apply to both the annealing and to the fault-tolerant setting. (i) Classical heuristic algorithms, such as greedy methods or contrastive divergence, often perform well in practice and are the method of choice for existing classical analyses. These methods are also often highly parallelizable. If the quantum algorithm offers a speedup over a slower, exact classical method, this may not be relevant if the faster approximate classical methods are already sufficient. (ii) The situations where one might hope for the heuristic quantum annealing approach to perform better might not be relevant problems, for instance in highly regular lattice based problems.</p><p>A caveat of the QBM is that the gradients of the loss function are not exactly related to sample averages, and imperfect workarounds, such as those proposed in [5], must be pursued. Like many other situations in machine learning, the resulting end-to-end solution is heuristic and evidence of its efficacy requires empirical demonstration.</p>"},{"location":"areas-of-application/machine-learning-with-classical-data/quantum-machine-learning-via-energy-based-models/#comparable-classical-complexity-and-challenging-instance-sizes","title":"Comparable classical complexity and challenging instance sizes","text":"<p>For classical models, an exact computation of the gradients would scale exponentially in the size of the graph, as \\(\\mathcal{O}\\left( |\\mathcal{D}|2^{|V|} \\right)\\) for the gradient of a single parameter. Approximate methods based on simulated annealing or other MCMC methods would scale as \\(\\mathcal{O}\\left( S_c/\\epsilon^2 \\right)\\), where \\(S_c\\) is the classical sample time, scaling as \\(S_c = \\mathrm{poly}(|V|)t_{\\rm mix}\\). On the other hand, these methods can also be implemented heuristically at reduced cost (e.g., contrastive divergence, where one does not wait for the chain to mix), and they can also be implemented on parallel architectures. For instance, in [15], an architecture was proposed to train deep BMs efficiently. Experiments demonstrated that heuristic training methods could be carried out for graphs of size 1 million in 100 seconds on field-programmable gate arrays available in 2010. Much larger sizes would be accessible to a scaled-up version of the same architecture on modern hardware. It is unlikely that any exact method, quantum or classical, could match this efficiency.</p><p>For the quantum models, the classical complexity of sampling from the Gibbs state of the model would be exponential in the graph size \\(|V|\\). Thus, training these models would likely not be pursued classically.</p>"},{"location":"areas-of-application/machine-learning-with-classical-data/quantum-machine-learning-via-energy-based-models/#speedup","title":"Speedup","text":"<p>For the classical models, the speedup can be quadratic in most of the parameters: producing a sample can in some cases be sped up quadratically, and the number of samples required to achieve a certain precision also enjoys a quadratic speedup (e.g., \\(t_{\\rm mix}\\) to \\(\\sqrt{t_{\\rm mix}}\\) and \\(\\mathcal{O}\\left( 1/\\epsilon^2 \\right)\\) to \\(\\mathcal{O}\\left( 1/\\epsilon \\right)\\)). The methods that give these provable quadratic speedups are based on primitives such as amplitude amplification, where superquadratic speedups are not possible without exploiting additional structure. Larger superpolynomial speedups are only possible under optimistic assumptions about the success of heuristic quantum annealing approaches at producing samples faster than classical approaches.</p><p>For the quantum models, the speedup is technically exponential, assuming that for the models considered, quantum algorithms for Gibbs sampling scale efficiently while approximate classical methods (e.g., tensor networks) scale exponentially. Nevertheless, it has yet to be demonstrated that there are specific tasks where these models are superior to classical machine learning models that can be trained and operated more efficiently classically.</p>"},{"location":"areas-of-application/machine-learning-with-classical-data/quantum-machine-learning-via-energy-based-models/#outlook","title":"Outlook","text":"<p>While energy-based models are naturally in a form that can readily be extended to the quantum domain, there still lacks decisive evidence of quantum advantage for a specific end-to-end classical machine learning problem. There remains some uncertainty on the outlook of these approaches due to the centrality of heuristic quantum approaches. One may hold out hope that these heuristics could outperform classical heuristics in some specific settings, but the success of classical heuristics and effectiveness of approximate classical approaches presents a formidable barrier to achieving any quantum advantage in this area.</p>"},{"location":"areas-of-application/machine-learning-with-classical-data/quantum-machine-learning-via-energy-based-models/#further-reading","title":"Further reading","text":"<p>We refer the reader to [4] for more information on quantum approaches to energy-based models.</p>"},{"location":"areas-of-application/machine-learning-with-classical-data/quantum-machine-learning-via-energy-based-models/#bibliography","title":"Bibliography","text":"<ol> <li> <p>Ruslan Salakhutdinov and Hugo Larochelle. Efficient learning of deep boltzmann machines. In Proceedings of the 13th International Conference on Artificial Intelligence and Statistics (AISTATS), 693\u2013700. JMLR Workshop and Conference Proceedings, 2010. URL: https://proceedings.mlr.press/v9/salakhutdinov10a.html.</p> </li> <li> <p>Nathan Wiebe, Ashish Kapoor, and Krysta M. Svore. Quantum deep learning. Quantum Information and Computation, 16(7\u20138):541\u2013587, 5 2016. arXiv: https://arxiv.org/abs/1412.3489. doi:10.26421/QIC16.7-8-1.</p> </li> <li> <p>Geoffrey E Hinton. Training products of experts by minimizing contrastive divergence. Neural Computation, 14(8):1771\u20131800, 2002. doi:10.1162/089976602760128018.</p> </li> <li> <p>Maria Schuld and Francesco Petruccione. Machine learning with quantum computers. Springer, 2021. doi:10.1007/978-3-030-83098-4.</p> </li> <li> <p>Mohammad H. Amin, Evgeny Andriyash, Jason Rolfe, Bohdan Kulchytskyy, and Roger Melko. Quantum boltzmann machine. Physical Review X, 8(2):021050, 2018. arXiv: https://arxiv.org/abs/1601.02036. doi:10.1103/PhysRevX.8.021050.</p> </li> <li> <p>M\u00e1ria Kieferov\u00e1 and Nathan Wiebe. Tomography and generative training with quantum boltzmann machines. Physical Review A, 96(6):062327, 2017. arXiv: https://arxiv.org/abs/1612.05204. doi:10.1103/PhysRevA.96.062327.</p> </li> <li> <p>Nathan Wiebe and Leonard Wossnig. Generative training of quantum boltzmann machines with hidden units. arXiv: https://arxiv.org/abs/1905.09902, 2019.</p> </li> <li> <p>Eric R Anschuetz and Yudong Cao. Realizing quantum boltzmann machines through eigenstate thermalization. arXiv: https://arxiv.org/abs/1903.01359, 2019.</p> </li> <li> <p>Christa Zoufal, Aur\u00e9lien Lucchi, and Stefan Woerner. Variational quantum boltzmann machines. Quantum Machine Intelligence, 3(1):7, 2021. arXiv: https://arxiv.org/abs/2006.06004. URL: https://doi.org/10.1007/s42484-020-00033-7, doi:10.1007/s42484-020-00033-7.</p> </li> <li> <p>Rolando Somma, Sergio Boixo, and Howard Barnum. Quantum simulated annealing. arXiv: https://arxiv.org/abs/0712.1008, 2007.</p> </li> <li> <p>Ashley Montanaro. Quantum speedup of monte carlo methods. Proceedings of the Royal Society A, 2015. arXiv: https://arxiv.org/abs/1504.06987. doi:10.1098/rspa.2015.0301.</p> </li> <li> <p>William J. Huggins, Kianna Wan, Jarrod McClean, Thomas E. O'Brien, Nathan Wiebe, and Ryan Babbush. Nearly optimal quantum algorithm for estimating multiple expectation values. Physical Review Letters, 129:240501, 12 2022. arXiv: https://arxiv.org/abs/2111.09283. URL: https://link.aps.org/doi/10.1103/PhysRevLett.129.240501, doi:10.1103/PhysRevLett.129.240501.</p> </li> <li> <p>Steven H Adachi and Maxwell P Henderson. Application of quantum annealing to training of deep neural networks. arXiv: https://arxiv.org/abs/1510.06356, 2015.</p> </li> <li> <p>Marcello Benedetti, John Realpe-G\u00f3mez, Rupak Biswas, and Alejandro Perdomo-Ortiz. Quantum-assisted learning of hardware-embedded probabilistic graphical models. Physical Review X, 7(4):041052, 2017. arXiv: https://arxiv.org/abs/1609.02542. doi:10.1103/PhysRevX.7.041052.</p> </li> <li> <p>Sang Kyun Kim, Peter Leonard McMahon, and Kunle Olukotun. A large-scale architecture for restricted boltzmann machines. In 18th IEEE Annual International Symposium on Field-Programmable Custom Computing Machines, volume, 201\u2013208. 2010. doi:10.1109/FCCM.2010.38.</p> </li> <li> <p>David Sherrington and Scott Kirkpatrick. Solvable model of a spin-glass. Physical Review Letters, 35(26):1792, 1975. doi:10.1103/PhysRevLett.35.1792.</p> </li> </ol> <ol> <li> <p>This quadratic energy functional is related to the Sherrington\u2013Kirkpatrick (SK) model [16] with an external field, which is a model for spin glasses in the statistical mechanics literature. For the SK model, the couplings \\(w_{ij}\\) are chosen randomly for each pair of nodes, and it is typically computationally hard to find configurations with optimal energy (see the section on beyond quadratic speedups in combinatorial optimization for some additional information).\u00a0\u21a9</p> </li> </ol>"},{"location":"areas-of-application/machine-learning-with-classical-data/quantum-machine-learning-via-quantum-linear-algebra/","title":"Quantum machine learning via quantum linear algebra","text":""},{"location":"areas-of-application/machine-learning-with-classical-data/quantum-machine-learning-via-quantum-linear-algebra/#overview","title":"Overview","text":"<p>Linear algebra in high dimensional spaces with tensor product structure is the workhorse of quantum computation as well as of much of machine learning (ML). It is therefore unsurprising that efforts have been made to find quantum algorithms for various learning tasks, including but not restricted to: cluster-finding [1], principal component analysis [2], least-squares fitting [3, 4], recommendation systems [5], binary classification [6], and Gaussian process regression [7]. One of the main computational bottlenecks in all of these tasks is the manipulation of large matrices. Significant speedup for this class of problems has been argued for via quantum linear algebra, as exemplified by the quantum linear system solver (QLSS). The main question marks for viability are: (i) can quantum linear algebra be fully dequantized [8] for ML tasks, (ii) can the classical training data be loaded efficiently into a quantum random access memory (QRAM), and (iii) do the quantum ML algorithms that avoid the above mentioned pitfalls address relevant machine learning problems? Our current understanding suggests that significant quantum advantage would require an exceptional confluence of (i)-(iii) that has not yet been found in the specific applications analyzed to date, though modest speedups are plausible.</p>"},{"location":"areas-of-application/machine-learning-with-classical-data/quantum-machine-learning-via-quantum-linear-algebra/#ml-applications","title":"ML applications","text":"<p>The structure of this section differs from other sections in this survey, due to the one-off nature of many of the quantum machine learning proposals and the fact that they are often heuristic. Rather than cover every proposal, we explore three specific applications. Each example explains which end-to-end problem is being solved and roughly how the proposed quantum algorithm solves that problem, arriving at its dominant complexity. In each case, the quantum algorithm assumes access to fast coherent data access (log-depth QRAM) and leverages quantum primitives for solving linear systems (and linear algebra more generally). Under certain conditions, these primitives can be exponentially faster than classical methods that manipulate all the entries of vectors in the exponentially large vector space. However, for these examples, it is crucial to carefully define the end-to-end problem, as exponential advantages can be lost at the readout step, where the answer to a machine learning question must be retrieved from the quantum state encoding the solution to the linear algebra problem. In the three examples below, this is accomplished with some form of amplitude or overlap estimation.</p><p>Furthermore, we note that, even if these quantum algorithms are exponentially faster than classical algorithms that manipulate the full state vector, in some cases this speedup has been \"dequantized\" via algorithms that merely sample from the entries of the vector. Specifically, for some end-to-end problems, there exist classical \"quantum-inspired\" algorithms [8, 9, 10] that solve the problem in time only polynomially slower than the quantum algorithm. The assumption that the quantum algorithm has fast QRAM access to the classical data is analogous to the assumption that the classical algorithm has fast sample-and-query (SQ) access to the data. We do not cover these techniques in detail, but we note that most of the machine learning tasks based on linear algebra for which quantum algorithms have been proposed have also been dequantized in some capacity [9]. However, in some cases it remains possible that there could be an exponential quantum advantage if the quantum algorithm is able to exploit additional structure in the matrices involved, such as sparsity, that the classical algorithm is not. The three examples below roughly illustrate the spectrum of possibilities: some tasks are fully dequantized, whereas others, to the best of our current knowledge, could still support exponential advantages if certain conditions are met.</p>"},{"location":"areas-of-application/machine-learning-with-classical-data/quantum-machine-learning-via-quantum-linear-algebra/#example-1-gaussian-process-regression","title":"Example 1: Gaussian process regression","text":""},{"location":"areas-of-application/machine-learning-with-classical-data/quantum-machine-learning-via-quantum-linear-algebra/#actual-end-to-end-problem","title":"Actual end-to-end problem:","text":"<p>Gaussian process regression (GPR) is a nonparametric, Bayesian method for regression. GPR is closely related to kernel methods [11], as well as to other regression models, including linear regression [12]. Our presentation of the problem follows that of [12, Chapter 2] and [13]. Given training data \\(\\{x_j,y_j\\}_{j=1}^M\\), with inputs \\(x_j \\in \\mathbb{R}^N\\) and noisy outputs \\(y_j\\in\\mathbb{R}\\), the goal is to model the underlying function \\(f(x)\\) generating the output \\(y\\) </p>\\[\\begin{equation} y=f(x)+\\epsilon_{\\rm noise}, \\end{equation}\\]<p>where \\(\\epsilon_{\\rm noise}\\) is drawn from i.i.d. Gaussian noise with variance \\(\\sigma^2\\). Modeling \\(f(x)\\) as a Gaussian process means that for inputs \\(\\{x_j\\}_{j=1}^M\\), the outputs \\(\\{f(x_j)\\}_{j=1}^M\\) are treated as random variables with a joint multivariate Gaussian distribution, in such a way that any subset of these values are jointly normally distributed in a manner consistent with the global distribution. While this multivariate Gaussian distribution governing \\(\\{f(x_j)\\}_{j=1}^M\\) will generally be correlated for different \\(j\\), the additional additive error \\(\\epsilon_{\\rm noise}\\) on our observations \\(y_j\\) is independent from the choice of \\(f(x_j)\\) and uncorrelated from point to point. The Gaussian process is specified by the distribution \\(\\mathcal{N}\\left( m, K \\right)\\) where \\(m\\) is the length-\\(M\\) vector obtained by evaluating a \"mean function\\\" \\(m(x)\\) at the points \\(\\{x_j\\}_{j=1}^M\\), and \\(K\\) is an \\(M \\times M\\) covariance kernel matrix obtained by evaluating a covariance kernel function \\(k(x,x')\\) at \\(x,x' \\in \\{x_j\\}_{j=1}^M\\). The functional form of the mean and covariance kernel are specified by the user and determine the properties of the Gaussian process, such as its smoothness.<sup>1</sup> These functions typically contain a small number of hyperparameters which can be optimized using the training data. A commonly used covariance kernel function is the squared exponential covariance function \\(k(x,x') = \\exp{\\left(-\\frac{1}{2\\ell^2} (x-x')^2\\right)}\\) where \\(\\ell\\) is a hyperparameter controlling the length scale of the Gaussian process.</p><p>Given choices for \\(m(x)\\) and \\(k(x,x')\\) and the observed data \\(\\{x_j,y_j\\}_{j=1}^M\\), our task is to predict the value \\(f(x_*)\\) of a new test point \\(x_*\\). Because the Gaussian process assumes that all \\(M+1\\) values \\(\\{f(x_1),\\ldots,f(x_M), f(x_*)\\}\\) have a jointly Gaussian distribution, it is possible to condition upon the observed data to obtain the distribution for \\(f(x_*)\\) which is \\(p(f_* | x_*, \\{x_j,y_j\\}) \\sim \\mathcal{N}\\left(\\bar{f}_* , \\mathbb{V}[f_*] \\right)\\). Our goal is to compute \\(\\bar{f}_*\\), the mean (linear predictor) of the distribution for \\(f(x_*)\\), as well as the variance \\(\\mathbb{V}[f_*]\\), which gives uncertainty on the prediction. Computing the underlying multivariate Gaussian distribution can be bypassed by exploiting the closure of Gaussians under linear operations, in particular, conditioning. This re-expresses the problem as linear algebra with the kernel matrix. Assuming the common choice of \\(m(x) =0\\), and defining the length-\\(M\\) vector \\(k_* \\in \\mathbb{R}^M\\) to have its \\(j\\)th entry given by \\(k(x_*, x_j)\\), we obtain </p>\\[\\begin{align} \\bar{f}_* &amp; = k_*^\\intercal [K + \\sigma^2 I]^{-1} y \\\\ \\mathbb{V}[f_*] &amp; = k(x_*, x_*) - k_*^\\intercal [K + \\sigma^2 I]^{-1} k_* \\end{align}\\]<p>which characterize the prediction for the test point. The advantages of GPR are a small number of hyperparameters, model interpretability, and that it naturally returns uncertainty estimates for the predictions. Its main disadvantage is the computational cost.</p>"},{"location":"areas-of-application/machine-learning-with-classical-data/quantum-machine-learning-via-quantum-linear-algebra/#dominant-resource-cost","title":"Dominant resource cost:","text":"<p>In classical implementations, the cost is dominated by performing the inversion \\([K+ \\sigma^2 I]^{-1}\\), typically via a Cholesky decomposition, resulting in a complexity of \\(\\mathcal{O}\\left( M^3 \\right)\\) (see [12, Chapter 8] and [14] for approximations used to reduce the classical cost). In [7], a quantum algorithm was proposed that leverages the quantum linear system solver (QLSS) to perform this inversion more efficiently. The quantum computer uses the classical data to infer the linear predictor and variance for a test point \\(x_*\\), and this process must be repeated for the computation of each new test point output. We analyze the complexity of computing \\(\\bar{f}_*\\), with a simple extension for \\(\\mathbb{V}[f_*]\\). Given classically observed/precomputed values of \\(y\\) and \\(k_*\\), the quantum algorithm uses state preparation from classical data (based on QRAM) to prepare quantum states representing \\(\\frac{1}{\\nrm{y}} \\ket{y}\\) and \\(\\frac{1}{\\nrm{k_*}} \\ket{k_*}\\),<sup>2</sup> each with a gate depth of \\(\\mathcal{O}\\left( \\log(M) \\right)\\) (though using \\(\\mathcal{O}\\left( M \\right)\\) gates overall). The algorithm also uses a block-encoding of classical data (also using QRAM) for \\(A:=[K + \\sigma^2 I]\\), with a normalization factor of \\(\\alpha = \\nrm{K + \\sigma^2 I}_F\\) (Frobenius norm).<sup>3</sup> The state-of-the-art QLSS has complexity \\(\\mathcal{O}\\left( \\frac{\\alpha \\kappa}{\\nrm{A}} \\log(1/\\epsilon) \\right)\\) calls to an \\(\\alpha\\)-normalized block-encoding of matrix \\(A\\) with condition number \\(\\kappa\\). In this case, the minimum singular value of \\(A\\) is at least \\(\\sigma^2\\), so \\(\\kappa/\\nrm{A}\\leq \\sigma^{-2}\\). The QLSS produces the normalized state \\(\\ket{A^{-1}y}\\), and a similar approach yields an estimate for the norm \\(\\lVert A^{-1}y \\rVert\\) to relative error \\(\\epsilon\\) at cost \\(\\widetilde{\\mathcal{O}}\\left( \\alpha \\kappa/\\nrm{A}\\epsilon \\right)\\). Given unitary circuits performing these tasks, we can estimate the quantity \\(\\bar{f}_* = \\braket{k_*}{A^{-1}y} \\cdot \\nrm{k^*}\\nrm{A^{-1}y}\\) to precision \\(\\epsilon\\) using overlap estimation with gate depth upper bounded by </p>\\[\\begin{equation} \\widetilde{\\mathcal{O}}\\left( \\log(M) \\cdot \\nrm{K+\\sigma^2 I}_F \\sigma^{-2} \\cdot \\frac{\\nrm{k_*} \\left\\lVert[K + \\sigma^2 I]^{-1}y\\right\\rVert }{\\epsilon} \\right)\\,, \\end{equation}\\]<p>where the three factors come from QRAM, QLSS, and overlap estimation, respectively. Using QRAM as described above would use \\(\\mathcal{O}\\left( M^2 \\right)\\) ancilla qubits. Note that classical \"quantum-inspired\" methods for solving linear systems, based on sample-and-query (SQ) access, also have \\(\\mathrm{poly}(\\nrm{A}_F,\\kappa,\\epsilon^{-1},\\log(M))\\) complexity [9, 15, 10], and thus the quantum algorithm as stated above offers at most a polynomial speedup in the case of dense matrices.</p><p>On the other hand, [7] considers the case where the vectors and kernels are sparse<sup>4</sup> and uses this to reduce the cost of the quantum algorithm and of QRAM. In this case, using block-encodings of sparse matrices, the factor \\(\\nrm{A}_F\\) in the complexity expression is replaced by a factor \\(s \\nrm{A}_{\\max}\\), where \\(s\\) is the sparsity of the matrix \\(A\\) and \\(\\nrm{A}_{\\max}\\) is the maximum magnitude of any entry of \\(A\\)\u2014log-depth QRAM with \\(\\Omega(M)\\) ancilla qubits would still be necessary to implement the sparse-access oracle to the \\(sM\\) arbitrary nonzero entries of \\(A\\) in depth \\(\\mathcal{O}\\left( \\log(M) \\right)\\). The upshot is that in the sparse case, because the algorithm assumes the kernel is not low rank, this algorithm is not dequantized by SQ access [16] and may still offer an exponential speedup over quantum-inspired methods. However, we note that the assumption of sparsity in \\([K + \\sigma^2 I]\\) may also enable the use of more efficient classical algorithms for computing the inverse (see QLSS). Moreover, we must include the classical precomputation of evaluating the entries of this matrix. A related, and similarly efficient, quantum algorithm is proposed in [13] for optimizing the hyperparameters of the GP kernel by maximizing the marginal likelihood of the observed data given the model.</p>"},{"location":"areas-of-application/machine-learning-with-classical-data/quantum-machine-learning-via-quantum-linear-algebra/#example-2-support-vector-machines","title":"Example 2: Support vector machines","text":""},{"location":"areas-of-application/machine-learning-with-classical-data/quantum-machine-learning-via-quantum-linear-algebra/#actual-end-to-end-problem_1","title":"Actual end-to-end problem:","text":"<p>The task for the support vector machine (SVM) is to classify an \\(N\\)-dimensional vector \\(x_*\\) into one of two classes (\\(y_* = \\pm 1\\)), given \\(M\\) labeled data points of the form \\(\\{(x_j,y_j): x_j\\in \\mathbb{R}^N, y_j=\\pm 1\\}_{j=1,...,M}\\) used for training. The training phase solves a continuous optimization problem to find a maximum-margin hyperplane, described by normal vector \\(w \\in \\mathbb{R}^M\\) and offset \\(b \\in \\mathbb{R}\\), which separates the training data. That is, data points with \\(y_j=1\\) lie on one side of the plane, and data points with \\(y_j=-1\\) lie on the other side. Once trained, the classification of \\(x_*\\) is inferred via the formula </p>\\[\\begin{equation} \\label{eq:SVM_classify} y_*={\\rm sign}\\left(b+\\langle w, x_*\\rangle\\right)\\,. \\end{equation}\\]<p>In the \"hard-margin\" version of the problem where all training points must be classified correctly (assuming it is possible to do so, i.e. the data is linearly separable), the solution \\((w,b)\\) is given by </p>\\[\\begin{equation} \\label{eq:SVM_hardmargin} \\argmin_{(w,b)} \\; \\nrm{w}^2, \\qquad \\text{subject to:} \\qquad y_j \\cdot (\\langle w,x_j \\rangle + b) \\geq 1 \\qquad \\forall j \\end{equation}\\]<p>where \\(\\nrm{\\cdot}\\) denotes the standard Euclidean vector norm.</p><p>In the \"soft-margin\" version of the problem, the hyperplane need not correctly classify all training points. The relation \\(y_j \\cdot (\\langle w, x_j\\rangle+b) \\geq 1\\) is relaxed to \\(y_j \\cdot (\\langle w, x_j \\rangle +b) \\geq 1-\\xi_j\\), with \\(\\xi_j \\geq 0\\). Now, \\((w,b)\\) are determined by </p>\\[\\begin{equation} \\label{eq:SVM_softmargin} \\argmin_{(w,b, \\xi)} \\; \\nrm{w}^2 + \\gamma \\nrm{\\xi}_1, \\qquad \\text{subject to:} \\qquad y_j \\cdot (\\langle w,x_j \\rangle + b) \\geq 1-\\xi_j \\qquad \\forall j\\,, \\end{equation}\\]<p>where \\(\\nrm{\\cdot}_1\\) denotes the vector 1-norm, and \\(\\gamma\\) is a user-specified parameter related to how much to penalize points that lie within the margin. Both Eqs. \\(\\eqref{eq:SVM_hardmargin}\\) and \\(\\eqref{eq:SVM_softmargin}\\) are convex programs, in particular, quadratic programs, which can also be rewritten as second-order cone programs [17]. Another feature of these formulations is that the solution vectors \\(w\\) and \\(\\xi\\) are usually sparse; the \\(j\\)th entry is only nonzero for values of \\(j\\) where \\(x_j\\) lies on or within the margin near the hyperplane\u2014these \\(x_j\\) are called the \"support vectors.\"</p><p>In [18], a \"least-squares\" version of the SVM problem was proposed, which has no inequality constraints:<sup>5</sup> </p>\\[\\begin{equation} \\label{eq:SVM_LS} \\argmin_{(w,b,\\xi)} \\; \\nrm{w}^2 + \\frac{\\gamma}{M} \\nrm{\\xi}^2, \\qquad \\text{subject to:} \\qquad y_j \\cdot (\\langle w,x_j \\rangle + b) = 1-\\xi_j \\qquad \\forall j\\,. \\end{equation}\\]<p>This is an equality-constrained least-squares problem, which is simpler than a quadratic program and can be solved using Lagrange multipliers and inverting a linear system. Specifically, one introduces vector \\(\\beta \\in \\mathbb{R}^M\\) and solves the \\((M+1) \\times (M+1)\\) linear system \\(Au = v\\), where </p>\\[\\begin{equation} A=\\begin{pmatrix} 0 &amp; \\mathbf{1}^\\intercal/\\sqrt{M} \\\\ \\mathbf{1}/\\sqrt{M} &amp; K/M + \\gamma^{-1}I \\end{pmatrix}, \\qquad u = \\begin{pmatrix} b \\\\ \\beta \\end{pmatrix}, \\qquad v =\\frac{1}{\\sqrt{M}}\\begin{pmatrix} 0 \\\\ y \\end{pmatrix} \\end{equation}\\]<p>with \\(K\\) the kernel matrix for which \\(K_{ij} = \\langle x_i, x_j \\rangle\\), \\(\\mathbf{1}\\) the all-ones vector, and \\(I\\) the identity matrix. The vector \\(w\\) is inferred from \\(\\beta\\) via the formula \\(w = \\sum_j \\beta_j x_j/\\sqrt{M}\\).</p><p>However, unlike the first two formulations, the least-squares formulation does not generally have sparse solution vectors \\((w,b)\\) (see [19]). Additionally, its solution can be qualitatively different, due to the fact that correctly classified data points can lead to negative \\(\\xi_j\\) that apply penalties to the objective function through the appearance of \\(\\nrm{\\xi}^2\\).</p>"},{"location":"areas-of-application/machine-learning-with-classical-data/quantum-machine-learning-via-quantum-linear-algebra/#dominant-resource-cost_1","title":"Dominant resource cost:","text":"<p>The hard-margin and soft-margin formulations of SVM are quadratic programs, which can be mapped to second-order cone programs and solved with quantum interior point methods (QIPMs). This solution was proposed in [17], and, assuming access to log-depth QRAM it can find \\(\\epsilon\\)-accurate estimates for the solution \\((w,b)\\) in time scaling as \\(\\widetilde{\\mathcal{O}}\\left( M^{0.5}(M+N)\\kappa_{\\rm IPM}\\zeta\\log(1/\\epsilon)/\\xi' \\right)\\), where \\(\\kappa_{\\rm IPM}\\), \\(\\zeta\\), and \\(\\xi'\\) are instance-specific parameters related to the QIPM. This compares to \\(\\mathcal{O}\\left( M^{0.5}(M+N)^{3}\\log(1/\\epsilon) \\right)\\) for naively implemented classical interior point methods. In [17], numerical simulations on random SVM instances were performed to compute these instance-specific parameters, and the results were consistent with a small polynomial speedup. However, the resource estimate of [20] for a related problem suggests a practical advantage may be difficult to realize with this approach.</p><p>The least-squares formulation can be solved directly with the quantum linear system solver (QLSS), as pursued in [6]. This can be compared to classically solving the linear system via Gaussian elimination, with cost \\(\\mathcal{O}\\left( M^3 \\right)\\). The QLSS requires the ability to prepare the state \\(\\ket{v}\\), which can be accomplished in \\(\\mathcal{O}\\left( \\log(M) \\right)\\) depth through methods for preparation of states from classical data, although requiring \\(\\mathcal{O}\\left( M \\right)\\) total gates and ancilla qubits. One also needs a block-encoding of the matrix \\(A\\). One method is through block-encodings from classical data, which requires classical precomputation of the \\(\\mathcal{O}\\left( M^2 \\right)\\) entries of \\(K\\) (incurring classical cost \\(\\mathcal{O}\\left( M^2N \\right)\\)) and producing a block-encoding with normalization factor \\(\\alpha = \\nrm{A}_F\\) (Frobenius norm). Henceforth we assume that \\(\\nrm{x_j} \\leq 1\\) for all \\(j\\), which can always be achieved by scaling down the training data (inducing a scaling up of \\(w\\) and \\(\\sqrt{\\gamma}\\) by an equal factor). This implies \\(\\nrm{K/M}_F \\leq 1\\) and hence \\(\\nrm{A}_F \\leq \\sqrt{2}+1+\\sqrt{M}\\gamma^{-1}\\). A better block-encoding can be obtained by block-encoding \\(K/M\\) via the method for Gram matrices<sup>6</sup> and \\(\\gamma^{-1}I\\) via the trivial method, and then combining these with the rest of \\(A\\) via linear combination of block-encodings. This avoids the need to classically calculate the inner products \\(\\langle x_i, x_j \\rangle\\), and has a better normalization \\(\\alpha \\leq \\sqrt{2} + 1+\\gamma^{-1}\\).</p><p>Given these constructions, the QLSS outputs the state \\(\\ket{u} = (b\\ket{0} + \\sum_{j=1}^M \\beta_j \\ket{j})/\\sqrt{b^2+\\nrm{\\beta}^2}\\); the cost is \\(\\smash{\\widetilde{\\mathcal{O}}\\left( \\alpha \\kappa_A/ \\nrm{A} \\right)}\\), where \\(\\kappa_A\\) is the condition number of \\(A\\). We may assert that \\(\\nrm{A} \\geq 1\\). This follows by noting that the lower right block of \\(A\\) is positive semidefinite, and that 1 is an eigenvalue of \\(A\\) when the lower-right block is set to zero. The condition number should be upper bounded by an \\(M\\)-independent function of \\(\\gamma\\) due to the appearance of the regularizing \\(\\gamma^{-1}I\\).</p><p>Reading out all \\(M+1\\) entries of \\(\\ket{u}\\) via tomography would multiply the cost by \\(\\Omega(M)\\). However, in [6], it was observed that to classify a test point \\(x_*\\) via Eq. \\(\\eqref{eq:SVM_classify}\\), one can use overlap estimation rather than classically learning the solution vector. In our notation and normalization, this can be carried out as follows. Let \\(\\ket{x_j}:=\\sum_{i=1}^M x_{ji} \\ket{i}/\\nrm{x_j}\\), with \\(x_{ji}\\) denoting the \\(i\\)th entry of the vector \\(x_j\\). Starting with \\(\\ket{u}\\), we prepare \\(\\ket{x_j}\\) into an ancilla register, using methods for controlled state preparation from classical data, forming </p>\\[\\begin{equation} \\ket{\\tilde{u}} = \\frac{b\\ket{0}\\ket{0} + \\sum_{j=1}^M \\beta_j \\ket{j}\\left(\\nrm{x_j}\\ket{x_j} + \\sqrt{1-\\nrm{x_j}^2}\\ket{M+1}\\right)}{\\sqrt{b^2+\\nrm{\\beta}^2}}\\,. \\end{equation}\\]<p>One also creates a reference state \\(\\ket{\\tilde{x}_*}\\) encoding \\(x_*\\), defined as </p>\\[\\begin{equation} \\ket{\\tilde{x}_*} = \\frac{1}{\\sqrt{2}}\\ket{0}\\ket{0} + \\frac{1}{\\sqrt{2M}}\\sum_{j=1}^M \\ket{j}\\left(\\nrm{x_*}\\ket{x_*} + \\sqrt{1-\\nrm{x_*}^2 }\\ket{M+2}\\right)\\,. \\end{equation}\\]<p>The right-hand side of Eq. \\(\\eqref{eq:SVM_classify}\\) is then given by \\(\\sqrt{2}\\sqrt{b^2+\\nrm{\\beta}^2}\\braket{\\tilde{u}}{\\tilde{x}_*}\\). Thus, the overlap \\(\\braket{\\tilde{u}}{\\tilde{x}_*}\\) must be estimated to precision \\(\\epsilon = 1/\\sqrt{2(b^2+\\nrm{\\beta}^2)}\\) in order to distinguish \\(\\pm 1\\) and classify \\(x_*\\). Additionally, the norm \\(\\nrm{u} = \\sqrt{b^2 + \\nrm{\\beta}^2}\\) must be calculated; this can separately be done to relative error \\(\\epsilon'\\) at cost \\(\\widetilde{\\mathcal{O}}\\left( \\alpha \\kappa_A/\\epsilon' \\right)\\) (see QLSS). We may also note that as \\(u = A^{-1}v\\) and \\(\\nrm{v}=1\\), we have \\(\\nrm{u} \\leq \\kappa_A/\\nrm{A}\\). Thus, the overall circuit depth required to classify \\(x_*\\) is </p>\\[\\begin{equation} \\widetilde{\\mathcal{O}}\\left( \\frac{\\alpha \\kappa_A^2}{ \\nrm{A}^2} \\right) \\,. \\end{equation}\\]<p>There is no explicit \\(\\mathrm{poly}(N,M)\\) dependence. However, for certain data sets and parameter choices, such dependence could be hidden in \\(\\kappa_A\\) or \\(\\alpha\\), making an apples-to-apples comparison with Gaussian elimination less clear.</p><p>Furthermore, this task has been dequantized under the assumption of SQ access [21, 9, 10]. In time scaling as \\(\\mathrm{poly}(\\nrm{A}_F, \\epsilon^{-1}, \\log(NM))\\), one can classically sample from the solution vector \\(\\ket{u}\\) to error \\(\\epsilon\\), and furthermore, given sample access, one can estimate inner products \\(\\braket{\\tilde{u}}{\\tilde{v}}\\) in time \\(\\mathcal{O}\\left( 1/\\epsilon^2 \\right)\\) [22]. However, the cost can be reduced through a trick that is analogous to how the quantum algorithm can block-encode the \\(\\gamma^{-1}I\\) part of \\(A\\) separately to avoid the dependence on a large \\(\\nrm{A}_F\\). In particular, [9, Corollary 6.18] gives a classical complexity that would be polynomially related to the quantum complexity above under appropriate matching of parameters, but the power of this polynomial speedup could still be significant. In any case, such a speedup crucially requires log-depth QRAM access to the training data, which requires total gate complexity \\(\\Omega(NM)\\) and \\(\\mathcal{O}\\left( NM \\right)\\) ancilla qubits.</p>"},{"location":"areas-of-application/machine-learning-with-classical-data/quantum-machine-learning-via-quantum-linear-algebra/#example-3-supervised-cluster-assignment","title":"Example 3: Supervised cluster assignment","text":""},{"location":"areas-of-application/machine-learning-with-classical-data/quantum-machine-learning-via-quantum-linear-algebra/#actual-end-to-end-problem_2","title":"Actual end-to-end problem:","text":"<p>Suppose we are given access to a vector \\(x\\in\\mathbb{C}^N\\) and a set of \\(M\\) samples \\(\\{y_j\\in \\mathbb{C}^N\\}_{j=1,\\ldots,M}\\). We want to estimate the distance between \\(x\\) and the centroid of the set \\(\\{y_j\\}\\) to judge whether \\(x\\) was drawn from the same set as \\(\\{ y_j\\}\\). If we have multiple sets \\(\\{y_j\\}\\), we can infer that \\(x\\) belongs to the one for which the distance is shortest; as a result, this is also called the \"nearest-centroid problem.\" Specifically, the computational task is to estimate \\(\\lVert x-\\frac{1}{M}Y \\mathbf{1} \\rVert\\) to additive constant error \\(\\epsilon\\) with probability \\(1-\\delta\\), where \\(Y\\in \\mathbb{C}^{N\\times M}\\) is the matrix whose columns are \\(y_j\\), and \\(\\mathbf{1}\\) is the vector of \\(M\\) ones\u2014the vector \\(Y\\mathbf{1}/M\\) is the centroid of the set.</p>"},{"location":"areas-of-application/machine-learning-with-classical-data/quantum-machine-learning-via-quantum-linear-algebra/#dominant-resource-cost_2","title":"Dominant resource cost:","text":"<p>Naively computing the centroid incurs classical cost \\(\\mathcal{O}\\left( NM \\right)\\). In [1], a quantum solution to this problem was proposed. Let \\(\\bar{x}=x/\\lVert x\\rVert\\) and let \\(\\bar{Y}\\) be normalized so that all columns have unit norm. Define \\(N \\times (M+1)\\) matrix \\(R\\) and length-\\((M+1)\\) vector \\(w\\) as follows: </p>\\[\\begin{align} R=\\begin{pmatrix}\\bar{x} &amp; \\bar{Y}/\\sqrt{M}\\end{pmatrix}, \\qquad w = \\begin{pmatrix} \\lVert x \\rVert \\\\ -1_Y/\\sqrt{M}\\end{pmatrix}\\,, \\end{align}\\]<p>where \\(1_Y\\) is the length-\\(M\\) vector containing the norms of the columns of \\(Y\\), defined such that \\(\\bar{Y}1_Y=Y\\mathbf{1}\\). Then, \\(Rw=x-\\frac{1}{M} Y\\mathbf{1}\\). Using methods for block-encoding and state preparation from classical data, one constructs \\(\\mathcal{O}\\left( \\log(NM) \\right)\\)-depth circuits that block-encode \\(R\\) (with normalization factor \\(\\nrm{R}_F = 2\\)) and prepare the state \\(\\ket{w}\\). If we apply the block-encoding of \\(R\\) to \\(\\ket{w}\\) and measure the block-encoding ancillas, the probability that we obtain \\(\\ket{0}\\) is precisely \\((\\nrm{Rw}/2\\nrm{w})^2\\). Thus, using amplitude estimation, one learns \\(\\nrm{Rw}\\) to precision \\(\\epsilon\\) with probability at least \\(1-\\delta\\) at cost \\(\\mathcal{O}\\left( \\nrm{w}\\log(1-\\delta)/\\epsilon \\right)\\) calls to the log-depth block-encoding and state preparation routines.</p><p>The advantage over naive classical methods essentially boils down to the assumption of efficient classical data loading for a specific data set. Subsequently, this quantum algorithm was dequantized, and it was understood that a similar feat is possible classically in the SQ access model [8]. Specifically, the classical algorithm runs in time \\(\\widetilde{\\mathcal{O}}\\left( \\nrm{w}^2\\log(1-\\delta)/\\epsilon^2 \\right)\\), reducing the exponential speedup to merely quadratic.</p>"},{"location":"areas-of-application/machine-learning-with-classical-data/quantum-machine-learning-via-quantum-linear-algebra/#caveats","title":"Caveats","text":"<p>The overwhelming caveat in these and other proposals is access to the classical data in quantum superposition. These quantum machine learning algorithms assume that we can load a vector of \\(N\\) entries or a matrix of \\(N^2\\) entries in \\(\\mathrm{polylog}(N)\\) time. While efficient quantum data structures, i.e. QRAM, have been proposed for this task, they introduce a number of caveats. In order to coherently load \\(N\\) pieces of data in \\(\\log(N)\\) time, QRAM uses a number of ancilla qubits, arranged in a tree structure. To load data of size \\(N\\), the QRAM data structure requires \\(\\mathcal{O}\\left( N \\right)\\) qubits, which is exponentially larger than the \\(\\mathcal{O}\\left( \\log(N) \\right)\\) data qubits used in the algorithms above. This spatial complexity does not yet include the overheads of quantum error correction and fault-tolerant computation, in particular the large spatial resources required to distill magic states in parallel. As such, we do not yet know if it is possible to build a QRAM that can load the data sufficiently quickly, while maintaining moderate spatial resources.</p><p>In addition, achieving speedups by efficiently representing the data as a quantum state may suggest that methods based on tensor networks could achieve similar performance, in some settings. Taking this line of reasoning to the extreme, a number of efficient classical algorithms have been developed by \"dequantizing\\\" the quantum algorithms. That is, by assuming an analogous access model (the SQ access model) to the training data, as well as some assumptions on sparsity and/or rank of the inputs, there exist approximate classical sampling algorithms with polynomial overhead as compared to the quantum algorithms [8, 22]. This means that any apparent exponential speedup must be an artifact of the data loading/data access assumptions.</p><p>A further caveat is inherited from the QLSS subroutine, which is that the complexity is large when the matrices involved are ill conditioned. This caveat is somewhat mitigated in the Gaussian process regression and support vector machine examples above, where the matrix to be inverted is regularized by adding the identity matrix.</p>"},{"location":"areas-of-application/machine-learning-with-classical-data/quantum-machine-learning-via-quantum-linear-algebra/#end-to-end-resource-analysis","title":"End-to-end resource analysis","text":"<p>To the best of our knowledge, full end-to-end resource estimation has not been performed for any specific quantum machine learning tasks.</p>"},{"location":"areas-of-application/machine-learning-with-classical-data/quantum-machine-learning-via-quantum-linear-algebra/#outlook","title":"Outlook","text":"<p>Much of the promise of quantum speedup for classical machine learning based on linear algebra hinges on the extent to which quantum algorithms can be dequantized. At present, the results of [8] seem to prohibit an exponential speedup for many of the problems proposed, but there is still the possibility of a large polynomial speedup. The most recent asymptotic scaling analysis [16] for dequantization methods still allows for a power \\(4\\) speedup in the Frobenius norm of the \"data matrix\" and a power 9 speedup in the polynomial approximation degree (see [23] for more details). However, the classical algorithms are steadily improving, and their scaling might be further reduced.</p><p>It is also worth noting that the classical probabilistic algorithms based on the SQ access model are not currently used in practice. This could be due to a number of reasons, including the poor polynomial scaling, the fact that the access model might not be well suited to many practical scenarios, or simply because the method is new and has not been tested in practice (see [24, 25] for some work in this direction).</p><p>On the other hand, some machine learning tasks based on quantum linear algebra are not known to be dequantized, such as Gaussian process regression under the assumption that the kernel matrix is sparse. In particular, avoiding dequantization and achieving an exponential quantum speedup appears to require that the matrices involved are simultaneously sparse, well conditioned, and have a large Frobenius norm. In this situation, quantum algorithm can leverage block-encodings for which the normalization factor is equal to the sparsity, rather than general block-encodings of classical data for which the normalization factor is the Frobenius norm. Quantum-inspired classical algorithms based on SQ access will still scale polynomially with the Frobenius norm, although other classical algorithms may be able to exploit the sparsity more directly. Perhaps unsurprisingly, the prototypical matrices that satisfy these criteria are sparse unitary matrices (such as those naturally implemented by a local quantum gate). For unitary matrices, the condition number is 1, and the Frobenius norm is equal to the square root of the Hilbert space dimension\u2014exponentially large in the system size. A central question is whether situations like this occur in interesting end-to-end machine learning problems. Even if they do, an exponential speedup is not guaranteed. An additional hurdle arises in the quantum readout step, which incurs a cost scaling as the inverse in the precision target. To avoid exponential overhead, the end-to-end problem must not require exponentially small precision.</p>"},{"location":"areas-of-application/machine-learning-with-classical-data/quantum-machine-learning-via-quantum-linear-algebra/#further-reading","title":"Further reading","text":"<p>For further reading, we recommend the following review articles and references therein: Machine learning with quantum computers [26], Quantum machine learning [27].</p>"},{"location":"areas-of-application/machine-learning-with-classical-data/quantum-machine-learning-via-quantum-linear-algebra/#bibliography","title":"Bibliography","text":"<ol> <li> <p>Seth Lloyd, Masoud Mohseni, and Patrick Rebentrost. Quantum algorithms for supervised and unsupervised machine learning. arXiv: https://arxiv.org/abs/1307.0411, 2013.</p> </li> <li> <p>Seth Lloyd, Masoud Mohseni, and Patrick Rebentrost. Quantum principal component analysis. Nature Physics, 10:631\u2013633, 2014. arXiv: https://arxiv.org/abs/1307.0401. doi:10.1038/nphys3029.</p> </li> <li> <p>Maria Schuld, Ilya Sinayskiy, and Francesco Petruccione. Prediction by linear regression on a quantum computer. Physical Review A, 94(2):022342, 2016. arXiv: https://arxiv.org/abs/1601.07823. doi:10.1103/PhysRevA.94.022342.</p> </li> <li> <p>Iordanis Kerenidis and Anupam Prakash. Quantum gradient descent for linear systems and least squares. Physical Review A, 101(2):022316, 2020. arXiv: https://arxiv.org/abs/1704.04992. doi:10.1103/PhysRevA.101.022316.</p> </li> <li> <p>Iordanis Kerenidis and Anupam Prakash. Quantum recommendation systems. In Proceedings of the 8th Innovations in Theoretical Computer Science Conference (ITCS), 49:1\u201349:21. 2017. arXiv: https://arxiv.org/abs/1603.08675. doi:10.4230/LIPIcs.ITCS.2017.49.</p> </li> <li> <p>Patrick Rebentrost, Masoud Mohseni, and Seth Lloyd. Quantum support vector machine for big data classification. Physical Review Letters, 113(13):130503, 2014. arXiv: https://arxiv.org/abs/1307.0471. doi:10.1103/PhysRevLett.113.130503.</p> </li> <li> <p>Zhikuan Zhao, Jack K. Fitzsimons, and Joseph F. Fitzsimons. Quantum-assisted gaussian process regression. Physical Review A, 99(5):052331, 2019. arXiv: https://arxiv.org/abs/1512.03929. doi:10.1103/PhysRevA.99.052331.</p> </li> <li> <p>Ewin Tang. Quantum principal component analysis only achieves an exponential speedup because of its state preparation assumptions. Physical Review Letters, 127(6):060503, 2021. arXiv: https://arxiv.org/abs/1811.00414. doi:10.1103/PhysRevLett.127.060503.</p> </li> <li> <p>Nai-Hui Chia, Andr\u00e1s Gily\u00e9n, Tongyang Li, Han-Hsuan Lin, Ewin Tang, and Chunhao Wang. Sampling-based sublinear low-rank matrix arithmetic framework for dequantizing quantum machine learning. In Proceedings of the 52nd ACM Symposium on the Theory of Computing (STOC), 387\u2013400. 2020. arXiv: https://arxiv.org/abs/1910.06151. doi:10.1145/3357713.3384314.</p> </li> <li> <p>Changpeng Shao and Ashley Montanaro. Faster quantum-inspired algorithms for solving linear systems. ACM Transactions on Quantum Computing, 2022. arXiv: https://arxiv.org/abs/2103.10309. doi:10.1145/3520141.</p> </li> <li> <p>Motonobu Kanagawa, Philipp Hennig, Dino Sejdinovic, and Bharath K Sriperumbudur. Gaussian processes and kernel methods: a review on connections and equivalences. arXiv: https://arxiv.org/abs/1807.02582, 2018.</p> </li> <li> <p>Carl Edward Rasmussen and Christopher K. I. Williams. Gaussian Processes for Machine Learning. The MIT Press, 11 2005. ISBN 9780262256834. URL: https://doi.org/10.7551/mitpress/3206.001.0001, doi:10.7551/mitpress/3206.001.0001.</p> </li> <li> <p>Zhikuan Zhao, Jack K. Fitzsimons, Michael A. Osborne, Stephen J. Roberts, and Joseph F. Fitzsimons. Quantum algorithms for training gaussian processes. Physical Review A, 100:012304, 7 2019. arXiv: https://arxiv.org/abs/1803.10520. URL: https://link.aps.org/doi/10.1103/PhysRevA.100.012304, doi:10.1103/PhysRevA.100.012304.</p> </li> <li> <p>Haitao Liu, Yew-Soon Ong, Xiaobo Shen, and Jianfei Cai. When gaussian process meets big data: a review of scalable gps. IEEE Transactions on Neural Networks and Learning Systems, 31(11):4405\u20134423, 2020. arXiv: https://arxiv.org/abs/1807.01065. doi:https://doi.org/10.1109/TNNLS.2019.2957109.</p> </li> <li> <p>Andr\u00e1s Gily\u00e9n, Zhao Song, and Ewin Tang. An improved quantum-inspired algorithm for linear regression. Quantum, 6:754, 2022. arXiv: https://arxiv.org/abs/2009.07268. doi:10.22331/q-2022-06-30-754.</p> </li> <li> <p>Nai-Hui Chia, Andr\u00e1s Pal Gily\u00e9n, Tongyang Li, Han-Hsuan Lin, Ewin Tang, and Chunhao Wang. Sampling-based sublinear low-rank matrix arithmetic framework for dequantizing quantum machine learning. Journal of the ACM, 69(5):1\u201372, 2022. Earlier version in STOC'20, arXiv: https://arxiv.org/abs/1910.06151. doi:10.1145/3549524.</p> </li> <li> <p>Iordanis Kerenidis, Anupam Prakash, and D\u00e1niel Szil\u00e1gyi. Quantum algorithms for second-order cone programming and support vector machines. Quantum, 5:427, 2021. arXiv: https://arxiv.org/abs/1908.06720. doi:10.22331/q-2021-04-08-427.</p> </li> <li> <p>J. A. K. Suykens and J. Vandewalle. Least squares support vector machine classifiers. Neural Processing Letters, 9(3):293\u2013300, 1999. URL: https://doi.org/10.1023/A:1018628609742, doi:10.1023/A:1018628609742.</p> </li> <li> <p>J.A.K. Suykens, J. De Brabanter, L. Lukas, and J. Vandewalle. Weighted least squares support vector machines: robustness and sparse approximation. Neurocomputing, 48(1):85\u2013105, 2002. URL: https://www.sciencedirect.com/science/article/pii/S0925231201006440, doi:https://doi.org/10.1016/S0925-2312(01)00644-0.</p> </li> <li> <p>Alexander M Dalzell, B David Clader, Grant Salton, Mario Berta, Cedric Yen-Yu Lin, David A Bader, Nikitas Stamatopoulos, Martin J A Schuetz, Fernando G S L Brand\u00e3o, Helmut G Katzgraber, and others. End-to-end resource analysis for quantum interior point methods and portfolio optimization. PRX Quantum, pages to appear, 2023. arXiv: https://arxiv.org/abs/2211.12489.</p> </li> <li> <p>Chen Ding, Tian-Yi Bao, and He-Liang Huang. Quantum-inspired support vector machine. IEEE Transactions on Neural Networks and Learning Systems, 33(12):7210\u20137222, 2022. arXiv: https://arxiv.org/abs/1906.08902. doi:10.1109/TNNLS.2021.3084467.</p> </li> <li> <p>Ewin Tang. A quantum-inspired classical algorithm for recommendation systems. In Proceedings of the 51st ACM Symposium on the Theory of Computing (STOC), 217\u2013228. 2019. arXiv: https://arxiv.org/abs/1807.04271. doi:10.1145/3313276.3316310.</p> </li> <li> <p>Ainesh Bakshi and Ewin Tang. An improved classical singular value transformation for quantum machine learning. arXiv: https://arxiv.org/abs/2303.01492, 2023.</p> </li> <li> <p>Juan Miguel Arrazola, Alain Delgado, Bhaskar Roy Bardhan, and Seth Lloyd. Quantum-inspired algorithms in practice. Quantum, 4:307, 2020. arXiv: https://arxiv.org/abs/1905.10415. doi:10.22331/q-2020-08-13-307.</p> </li> <li> <p>Nadiia Chepurko, Kenneth Clarkson, Lior Horesh, Honghao Lin, and David Woodruff. Quantum-inspired algorithms from randomized numerical linear algebra. In Kamalika Chaudhuri, Stefanie Jegelka, Le Song, Csaba Szepesvari, Gang Niu, and Sivan Sabato, editors, Proceedings of the 39th International Conference on Machine Learning (ICML), volume 162 of Proceedings of Machine Learning Research, 3879\u20133900. PMLR, 7 2022. arXiv: https://arxiv.org/abs/2011.04125. URL: https://proceedings.mlr.press/v162/chepurko22a.html.</p> </li> <li> <p>Maria Schuld and Francesco Petruccione. Machine learning with quantum computers. Springer, 2021. doi:10.1007/978-3-030-83098-4.</p> </li> <li> <p>Jacob Biamonte, Peter Wittek, Nicola Pancotti, Patrick Rebentrost, Nathan Wiebe, and Seth Lloyd. Quantum machine learning. Nature, 549:195\u2013202, 2017. arXiv: https://arxiv.org/abs/1611.09347. doi:10.1038/nature23474.</p> </li> <li> <p>Meng-Han Chen, Chao-Hua Yu, Jian-Liang Gao, Kai Yu, Song Lin, Gong-De Guo, and Jing Li. Quantum algorithm for gaussian process regression. Physical Review A, 106:012406, 7 2022. arXiv: https://arxiv.org/abs/2106.06701. URL: https://link.aps.org/doi/10.1103/PhysRevA.106.012406, doi:10.1103/PhysRevA.106.012406.</p> </li> <li> <p>Andr\u00e1s Gily\u00e9n, Yuan Su, Guang Hao Low, and Nathan Wiebe. Quantum singular value transformation and beyond: exponential improvements for quantum matrix arithmetics. In Proceedings of the 51st ACM Symposium on the Theory of Computing (STOC), 193\u2013204. 2019. arXiv: https://arxiv.org/abs/1806.01838. doi:10.1145/3313276.3316366.</p> </li> </ol> <ol> <li> <p>This can be visualized by sampling a function from the distribution, which means sampling a value of \\(f(x_j)\\) from the distribution for each \\(x_j\\), and plotting the values of \\(f(x_j)\\) as a curve.\u00a0\u21a9</p> </li> <li> <p>For any vector \\(v\\), the notation \\(\\ket{v}\\) denotes the normalized quantum state whose amplitudes in the computational basis are proportional to the entries of \\(v\\).\u00a0\u21a9</p> </li> <li> <p>It may be more efficient to load in the \\(\\{x_j\\}\\) values and then coherently evaluate the kernel entries using quantum arithmetic. Some ideas in this direction are explored in [28]. One might also consider block-encoding \\(K\\) and \\(\\sigma^2 I\\) separately and combining them with linear combination of unitaries.\u00a0\u21a9</p> </li> <li> <p>For the squared exponential covariance function mentioned above, the kernel matrix will not be sparse, but [7] notes several applications of GPR where sparsity is well justified.\u00a0\u21a9</p> </li> <li> <p>Our definition of the least-squares SVM is equivalent to the normal presentation found in [18, 6]; however, we choose slightly different conventions for normalization of certain parameters, such as \\(\\gamma\\), with respect to \\(M\\). The goal of our choices is to make the final complexity expression free of any explicit \\(M\\) dependence.\u00a0\u21a9</p> </li> <li> <p>We sketch a possible instantiation of this method here. Define \\(\\ket{x_i} = \\nrm{x_i}^{-1} \\sum_{k=1}^M x_{ik}\\ket{k}\\) where \\(x_{ik}\\) is the \\(k\\)th entry of \\(x_i\\). Suppose \\(M=2^m\\) is a power of 2. Following the setup in block-encodings and [29, Lemma 47], we must define sets of \\(M\\) orthonormal states \\(\\{\\ket{\\psi_i}\\}\\) and \\(\\{\\ket{\\phi_j}\\}\\). We choose \\(\\ket{\\psi_i} = (\\nrm{x_i}\\ket{x_i} + \\sqrt{1-\\nrm{x_i}^2}\\ket{M+1})(H^{\\otimes m} \\ket{i})\\ket{0^m}\\), where \\(H\\) denotes the Hadamard transform. We choose \\(\\ket{\\phi_j} = (\\nrm{x_j}\\ket{x_j} + \\sqrt{1-\\nrm{x_j}^2}\\ket{M+2})\\ket{0^m}(H^{\\otimes m}\\ket{j})\\). These states can be prepared in \\(\\mathcal{O}\\left( \\log(M) \\right)\\) depth using \\(\\mathcal{O}\\left( M \\right)\\) total gates and ancilla qubits with methods for controlled state preparation from classical data. It can be verified that these sets are orthonormal, and that \\(\\braket{\\psi_i}{\\phi_j} = \\langle x_i, x_j \\rangle/M\\). Hence, the Gram matrix construction yields a block-encoding of \\(K/M\\) with normalization factor 1.\u00a0\u21a9</p> </li> </ol>"},{"location":"areas-of-application/machine-learning-with-classical-data/quantum-neural-networks-and-quantum-kernel-methods/","title":"Quantum neural networks and quantum kernel methods","text":""},{"location":"areas-of-application/machine-learning-with-classical-data/quantum-neural-networks-and-quantum-kernel-methods/#overview","title":"Overview","text":"<p>In this article we discuss two collections of proposals to use a quantum computer as a machine learning model, often known as quantum neural networks and quantum kernel methods. Many early ideas were motivated by the constraints of near-term, \"NISQ\\\" [1] devices. Despite this, not all subsequent proposals are necessarily implementable on NISQ devices. Moreover, the proposals need not be restricted to running on NISQ devices, but could also be run on devices with explicit quantum error correction. For simplicity, we present concrete examples based on supervised machine learning tasks. However, outside of these examples we keep our discussion more general, and note that the techniques are also applicable to other settings, such as unsupervised learning.</p><p>Given access to some data, our goal is to obtain a function or distribution that emulates certain properties of the data, which we will call a model. This is obtained by first defining a model family or hypothesis set, and using a learning algorithm to select a model from this set. For example, in supervised learning, we have data \\(x_i \\in X\\) that have respective labels \\(y_i \\in Y\\). The goal is then to find a model function \\(h: X \\rightarrow Y\\) which correctly labels previously unseen data with high probability. Note that we have left the exact descriptions of the sets \\(X\\) and \\(Y\\) ambiguous. They could, for instance, correspond to sets of numbers or vectors. More generally, this description encompasses the possibility of operating on quantum data such that each \\(x_i\\) corresponds to a quantum state.</p><p>Quantum neural networks and quantum kernel methods use a quantum computer to assist in constructing the model, in place of a classical model such as a neural network. Specifically, here the model will be constructed by preparing some quantum state(s) encoding the data, and measuring some observable(s) to obtain model predictions. We first elaborate on both quantum neural networks, and quantum kernel methods.</p>"},{"location":"areas-of-application/machine-learning-with-classical-data/quantum-neural-networks-and-quantum-kernel-methods/#quantum-neural-networks","title":"Quantum neural networks","text":"<p>Actual end-to-end problem(s) solved. Given data \\(x\\), we consider a model constructed from a parameterized quantum circuit: </p>\\[\\begin{equation} \\label{eq:qnn} h_{\\boldsymbol{\\theta}}(x) = \\operatorname{Tr}\\left[ \\rho(x, \\boldsymbol{\\theta} ) O\\right]\\,, \\end{equation}\\]<p>where \\(\\rho(x, \\boldsymbol{\\theta} )\\) is a quantum state that encodes both the data \\(x\\) as well as a set of adjustable parameters \\(\\boldsymbol{\\theta}\\), and \\(O\\) is some chosen measurement observable. For instance, if \\(x\\) corresponds to a classical vector, \\(\\rho(x, \\boldsymbol{\\theta} )\\) could correspond to initializing in the \\(\\ketbra{0}{0}\\) state and applying some data-encoding gates \\(U(x)\\) followed by parameterized gates \\(V(\\boldsymbol{\\theta})\\). Alternatively, the data itself could be a quantum state, and a more general operation in the form of a parameterized channel \\(\\mathcal{V}(\\boldsymbol{\\theta})\\) could be applied. The model is optimized via a learning algorithm which aims to find the optimal parameters \\(\\boldsymbol{\\theta}^*\\) by minimizing a loss function, which assesses the quality of the model. For instance, in supervised learning, given some labelled training data set \\(T=\\{(x_i, y_i)\\}\\), a suitable choice of loss should compare how close each \\(h_{\\boldsymbol{\\theta}}(x_i)\\) is to the true label \\(y_i\\) for all data in \\(T\\). The quality of the model can then be assessed on a set of previously unseen data outside of \\(T\\).</p><p>We remark that this setting has substantial overlap with the setting of variational quantum algorithms (VQAs)\u2014indeed, quantum neural networks can be thought of as a VQA that incorporates data\u2014thus the same challenges and considerations that apply to VQAs also apply here. There will additionally also be extra considerations due to the role of the data.</p><p>Dominant resource cost/complexity. The encoding of data \\(x\\) and parameters \\(\\boldsymbol{\\theta}\\) in Eq. \\(\\eqref{eq:qnn}\\) should be sufficiently expressive that it (1) leads to good performance on data and (2) is (at minimum) not efficiently simulable classically, if one is to seek quantum advantage. These criteria can be used to derive lower bounds on the circuit depth, in some settings.</p><p>The learning algorithm to find optimal parameters is usually performed by classical heuristics, such as gradient descent, and can have significant time overhead, requiring evaluation of Eq. \\(\\eqref{eq:qnn}\\) at many parameter values (see variational quantum algorithms for more details).</p><p>The size of the training dataset required can also have direct implications for runtime, with a larger amount of training data typically taking a longer time to process. Reference [2] proves that good generalization can be achieved with the size of the training data \\(|T|\\) growing in tandem with the number of adjustable parameters \\(M\\). Specifically, it is shown that the deviation between training error (performance on training data set) and test error (performance on previously unseen data) with high probability scales as \\(\\mathcal{O}\\left( \\sqrt{M\\log(M) / |T|} \\right)\\). Thus, only a mild amount of data is required for good generalization. We stress that this alone does not say anything about the ability for quantum neural networks to obtain low training error.</p><p>Scope for advantage. Quantum neural networks could achieve advantage in a number of ways, including improved runtime, or needing less training data. In supervised learning settings, generalization performance is a separate consideration, and an additional domain for possible quantum advantage. Machine learning with quantum neural networks has yielded some promising performance empirically and encouraging theoretical guarantees exist for certain stages of the full pipeline in restricted settings [3, 4, 2, 5, 6]. Nevertheless, there are currently no practical use cases with full end-to-end performance guarantees.</p>"},{"location":"areas-of-application/machine-learning-with-classical-data/quantum-neural-networks-and-quantum-kernel-methods/#quantum-kernel-methods","title":"Quantum kernel methods","text":"<p>Actual end-to-end problem(s) solved. Quantum kernel methods are a generalization of classical kernel methods, of which support vector machines are a prominent example. Given a dataset \\(T=\\{x_i\\}\\subset X\\) the model can be written </p>\\[\\begin{align} \\label{eq:kernel} h_{\\boldsymbol{\\alpha}}(x) = \\sum_{i:\\, x_i \\in T} \\alpha_i \\kappa(x,x_i)\\,, \\end{align}\\]<p>where \\(\\boldsymbol{\\alpha}=(\\alpha_1, \\alpha_2, ...)\\) is a vector of parameters to be optimized, and \\(\\kappa(x,x'): X \\times X \\rightarrow \\mathbb{R}\\) is a measure of similarity known as the kernel function. This model has several theoretical motivations:</p><ul> <li>If the matrix with entries \\(K_{ij}=\\kappa(x_i,x_j)\\) is symmetric positive semi-definite for any \\(\\{x_1,...,x_m\\}\\subseteq X\\), \\(\\kappa(x_i,x_j)\\) can be interpreted as an inner product of feature vectors \\(\\phi(x_i), \\phi(x_j)\\) which embed the data \\(x_i\\) and \\(x_j\\) in a (potentially high dimensional) Hilbert space. Due to the so-called kernel trick, linear statistical methods can be used to learn a linear function in this high dimensional space, only using the information of the inner products \\(\\kappa(x_i,x_j)\\) and never having to explicitly evaluate \\(\\phi(x_i)\\) and \\(\\phi(x_j)\\).</li> <li>Concretely, the Representer Theorem [7] states that the optimal model over the dataset \\(T\\) can be expressed as a linear combination of kernel values evaluated over \\(T\\)\u2014that is, the optimal model exactly takes the form in Eq. \\(\\eqref{eq:kernel}\\).</li> <li>Further, if the loss function is convex, then the dual optimization program to find the optimal parameters \\(\\boldsymbol{\\alpha}^*\\) is also convex [8].</li> </ul><p>A key question that remains is then how to choose a kernel function. Quantum kernel methods embed data in quantum states, and thus evaluate \\(\\kappa(x_i,x_j)\\) on a quantum computer. Similar to quantum neural networks or any other quantum model, the quantum kernel should be hard to simulate classically. As an example, we present two common choices of quantum kernel.</p><ul> <li>The fidelity quantum kernel  \\[\\begin{equation} \\label{eq:fidelity-kernel} \\kappa_F(x,x') = \\operatorname{Tr}[\\rho(x)\\rho(x')]\\,, \\end{equation}\\] <p>which can be evaluated either with a SWAP test or, given classical data with unitary embeddings, it can be evaluated with the overlap circuit \\(|\\bra{0}U(x')^{\\dag}U(x)\\ket{0}|^2\\). - The fidelity kernel can run into issues for high dimensional systems, as the inner product in Eq. \\(\\eqref{eq:fidelity-kernel}\\) can be very small for \\(x\\neq x'\\). This motivated the proposal of a family of projected quantum kernels [9], of which one example is the Gaussian projected quantum kernel </p> \\[\\begin{equation} \\kappa_P(x,x') =\\exp \\left(-\\gamma \\sum_{k=1}^n\\left\\|\\rho_k(x)-\\rho_k\\left(x'\\right)\\right\\|_2^2\\right) \\end{equation}\\] <p>where \\(\\rho_k(x)\\) is the reduced state of the \\(n\\)-qubit state \\(\\rho(x)\\) on qubit \\(k\\), and \\(\\gamma\\) is a hyperparameter.</p> </li> </ul><p>Dominant resource cost/complexity. During the optimization of the dual program to find the optimal parameters \\(\\boldsymbol{\\alpha}^*\\), \\(\\mathcal{O}\\left( |T|^2 \\right)\\) expectation values corresponding to the kernel values in Eq. \\(\\eqref{eq:kernel}\\) need to be accurately evaluated, as well as when computing \\(h_{\\boldsymbol{\\alpha}^*}(x)\\) for a new data point \\(x\\) with the optimized model. This can lead to a significant overhead in applications with large datasets. Alternatively, the primal optimization problem has reduced complexity in the data set size, but greatly exacerbated dependence on the error [10]. The gate complexity is wholly dependent on the choice of data encoding leading to the kernel function. As the kernel function should be classically non-simulable, this gives intuition that there should be some minimum requirements in terms of gate complexity. However, in the absence of standardized techniques for data encoding it is hard to make more precise statements.</p><p>Scope for advantage. In Ref. [11] the authors demonstrate that using a particular constructed dataset and data embedding, concrete quantum advantage can be obtained for a constructed machine learning problem based on the discrete logarithm problem. The original work was based on the fidelity kernel, but a similar advantage can also be more simply obtained for the projected quantum kernel [9]. This can also be adapted beyond kernel methods to the reinforcement learning setting [12]. Whilst great strides have been made in understanding the complexity of quantum kernel methods [13, 9], at present there do not yet exist examples of end-to-end theoretical guarantees of advantage for more physically relevant classical data.</p>"},{"location":"areas-of-application/machine-learning-with-classical-data/quantum-neural-networks-and-quantum-kernel-methods/#caveats","title":"Caveats","text":"<p>One consideration we have not discussed so far is how to encode classical data into a quantum circuit, which is a significant aspect of constructing the quantum model. There are many possibilities, such as amplitude encoding or encoding data into rotation angles of single-qubit rotations (e.g., see [14, 15, 16, 17]). While certain strategies are popular, in general it is unclear what is the best choice for a given problem at hand, and thus selecting the data-encoding strategy can itself be a heuristic process. The same question extends to the choice of quantum neural network or quantum kernel. While certain choices may perform well in specific problem instances, there is at present a lack of strong evidence why such approaches may be advantageous over their classical counterparts in general.</p><p>While optimization of parameterized quantum circuits is predominantly a concern for quantum neural networks, the search for good quantum kernels has also motivated proposals of trainable kernels [16, 18, 19] where a parameterized quantum circuit is used to construct the quantum kernel (note, this is distinct from the \"classical\" optimization of \\(\\boldsymbol{\\alpha}\\) in Eq. \\(\\eqref{eq:kernel}\\)). In the case that the parameter optimization process is performed using heuristics, it is subject to the same challenges and considerations that arise with VQAs (see variational quantum algorithms for more details).</p><p>Finite statistics is an important consideration for both settings. Where there is optimization of parameterized quantum circuits, one must take care to avoid the barren plateau phenomenon [20, 21, 22, 23, 24] (again see variational quantum algorithms for more details). Analogous effects can also occur in the kernel setting [25], which can arise even purely due to the data-encoding circuit [9, 26].</p>"},{"location":"areas-of-application/machine-learning-with-classical-data/quantum-neural-networks-and-quantum-kernel-methods/#outlook","title":"Outlook","text":"<p>The use of classical machine learning models is often highly heuristic, and guided by empirical evidence or physical intuition. Despite this, they have found remarkable success in solving many computational problems. The quantum techniques outlined in this section also broadly follow this approach (though theoretical progress has also been substantial in certain areas), and there is no a priori reason why they cannot also be useful. Nevertheless, it is challenging to make concrete predictions for quantum advantage, particularly on classical data. This is exacerbated by our limited analytic understanding of end-to-end applications, even in the fully classical setting. Indeed, it may ultimately be challenging to have the same complete end-to-end theoretical analysis that other quantum algorithms enjoy, aside for a few select examples [27]. Within the realm of quantum data, there appears to be ripe potential for concrete provable advantage [28, 29, 30], however this is beyond the scope of this article.</p>"},{"location":"areas-of-application/machine-learning-with-classical-data/quantum-neural-networks-and-quantum-kernel-methods/#further-reading","title":"Further reading","text":"<p>Refs. [8, 16] provide pedagogical expositions of quantum kernel methods, Refs. [31, 32] are comprehensive reviews of quantum neural networks, and Ref. [33] is a review of quantum machine learning models at large, including an exposition of machine learning with quantum data.</p>"},{"location":"areas-of-application/machine-learning-with-classical-data/quantum-neural-networks-and-quantum-kernel-methods/#bibliography","title":"Bibliography","text":"<ol> <li> <p>John Preskill. Quantum computing in the nisq era and beyond. Quantum, 2:79, 2018. arXiv: https://arxiv.org/abs/1801.00862. doi:10.22331/q-2018-08-06-79.</p> </li> <li> <p>Matthias C Caro, Hsin-Yuan Huang, Marco Cerezo, Kunal Sharma, Andrew Sornborger, Lukasz Cincio, and Patrick J Coles. Generalization in quantum machine learning from few training data. Nature Communications, 13(1):4919, 2022. arXiv: https://arxiv.org/abs/2111.05292. URL: https://www.nature.com/articles/s41467-022-32550-3, doi:https://doi.org/10.1038/s41467-022-32550-3.</p> </li> <li> <p>Louis Schatzki, Martin Larocca, Frederic Sauvage, and Marco Cerezo. Theoretical guarantees for permutation-equivariant quantum neural networks. arXiv: https://arxiv.org/abs/2210.09974, 2022.</p> </li> <li> <p>Matthias C Caro, Elies Gil-Fuster, Johannes Jakob Meyer, Jens Eisert, and Ryan Sweke. Encoding-dependent generalization bounds for parametrized quantum circuits. Quantum, 5:582, 2021. arXiv: https://arxiv.org/abs/2106.03880. doi:https://doi.org/10.22331/q-2021-11-17-582.</p> </li> <li> <p>Junyu Liu, Khadijeh Najafi, Kunal Sharma, Francesco Tacchino, Liang Jiang, and Antonio Mezzacapo. Analytic theory for the dynamics of wide quantum neural networks. Physical Review Letters, 130:150601, 4 2023. arXiv: https://arxiv.org/abs/2203.16711. URL: https://link.aps.org/doi/10.1103/PhysRevLett.130.150601, doi:10.1103/PhysRevLett.130.150601.</p> </li> <li> <p>Xuchen You, Shouvanik Chakrabarti, Boyang Chen, and Xiaodi Wu. Analyzing convergence in quantum neural networks: deviations from neural tangent kernels. arXiv: https://arxiv.org/abs/2303.14844, 2023. URL: https://arxiv.org/abs/2303.14844.</p> </li> <li> <p>Bernhard Sch\u00f6lkopf, Ralf Herbrich, and Alex J. Smola. A generalized representer theorem. In Proceedings of the 14th Conference On Learning Theory (COLT), 416\u2013426. Springer Berlin Heidelberg, 2001. doi:https://doi.org/10.1007/3-540-44581-1\\_27.</p> </li> <li> <p>Maria Schuld. Supervised quantum machine learning models are kernel methods. arXiv: https://arxiv.org/abs/2101.11020, 2021.</p> </li> <li> <p>Hsin-Yuan Huang, Michael Broughton, Masoud Mohseni, Ryan Babbush, Sergio Boixo, Hartmut Neven, and Jarrod R McClean. Power of data in quantum machine learning. Nature Communications, 12(1):2631, 2021. arXiv: https://arxiv.org/abs/2011.01938. doi:https://doi.org/10.1038/s41467-021-22539-9.</p> </li> <li> <p>Gian Gentinetta, Arne Thomsen, David Sutter, and Stefan Woerner. The complexity of quantum support vector machines. arXiv: https://arxiv.org/abs/2203.00031, 2022.</p> </li> <li> <p>Yunchao Liu, Srinivasan Arunachalam, and Kristan Temme. A rigorous and robust quantum speed-up in supervised machine learning. Nature Physics, 17(9):1013\u20131017, 2021. arXiv: https://arxiv.org/abs/2010.02174. URL: https://www.nature.com/articles/s41567-021-01287-z, doi:https://doi.org/10.1038/s41567-021-01287-z.</p> </li> <li> <p>Sofiene Jerbi, Casper Gyurik, Simon Marshall, Hans Briegel, and Vedran Dunjko. Parametrized quantum policies for reinforcement learning. In Advances in Neural Information Processing Systems 34 (NIPS), 28362\u201328375. 2021. arXiv: https://arxiv.org/abs/2103.05577. URL: https://proceedings.neurips.cc/paper/2021/hash/eec96a7f788e88184c0e713456026f3f-Abstract.html.</p> </li> <li> <p>Leonardo Banchi, Jason Pereira, and Stefano Pirandola. Generalization in quantum machine learning: a quantum information standpoint. PRX Quantum, 2:040321, 11 2021. arXiv: https://arxiv.org/abs/2102.08991. URL: https://link.aps.org/doi/10.1103/PRXQuantum.2.040321, doi:10.1103/PRXQuantum.2.040321.</p> </li> <li> <p>Seth Lloyd, Maria Schuld, Aroosa Ijaz, Josh Izaac, and Nathan Killoran. Quantum embeddings for machine learning. arXiv: https://arxiv.org/abs/2001.03622, 2020. URL: https://arxiv.org/abs/2001.03622.</p> </li> <li> <p>Vojt\u011bch Havl\u00ed\u010dek, Antonio D C\u00f3rcoles, Kristan Temme, Aram W Harrow, Abhinav Kandala, Jerry M Chow, and Jay M Gambetta. Supervised learning with quantum-enhanced feature spaces. Nature, 567(7747):209\u2013212, 2019. arXiv: https://arxiv.org/abs/1804.11326. URL: https://www.nature.com/articles/s41586-019-0980-2, doi:10.1038/s41586-019-0980-2.</p> </li> <li> <p>Thomas Hubregtsen, David Wierichs, Elies Gil-Fuster, Peter-Jan H. S. Derks, Paul K. Faehrmann, and Johannes Jakob Meyer. Training quantum embedding kernels on near-term quantum computers. Physical Review A, 106:042431, 10 2022. arXiv: https://arxiv.org/abs/2105.02276. URL: https://link.aps.org/doi/10.1103/PhysRevA.106.042431, doi:10.1103/PhysRevA.106.042431.</p> </li> <li> <p>Ryan LaRose and Brian Coyle. Robust data encodings for quantum classifiers. Physical Review A, 102:032420, 9 2020. arXiv: https://arxiv.org/abs/2003.01695. URL: https://link.aps.org/doi/10.1103/PhysRevA.102.032420, doi:10.1103/PhysRevA.102.032420.</p> </li> <li> <p>Gian Gentinetta, David Sutter, Christa Zoufal, Bryce Fuller, and Stefan Woerner. Quantum kernel alignment with stochastic gradient descent. arXiv: https://arxiv.org/abs/2304.09899, 2023.</p> </li> <li> <p>Jennifer R Glick, Tanvi P Gujarati, Antonio D Corcoles, Youngseok Kim, Abhinav Kandala, Jay M Gambetta, and Kristan Temme. Covariant quantum kernels for data with group structure. arXiv: https://arxiv.org/abs/2105.03406, 2021.</p> </li> <li> <p>Jarrod R McClean, Sergio Boixo, Vadim N Smelyanskiy, Ryan Babbush, and Hartmut Neven. Barren plateaus in quantum neural network training landscapes. Nature Communications, 9(1):1\u20136, 2018. arXiv: https://arxiv.org/abs/1803.11173. URL: https://www.nature.com/articles/s41467-018-07090-4, doi:10.1038/s41467-018-07090-4.</p> </li> <li> <p>M. Cerezo, Akira Sone, Tyler Volkoff, Lukasz Cincio, and Patrick J Coles. Cost function dependent barren plateaus in shallow parametrized quantum circuits. Nature Communications, 12(1):1\u201312, 2021. arXiv: https://arxiv.org/abs/2001.00550. URL: https://www.nature.com/articles/s41467-021-21728-w, doi:10.1038/s41467-021-21728-w.</p> </li> <li> <p>Zo\u00eb Holmes, Kunal Sharma, M. Cerezo, and Patrick J Coles. Connecting ansatz expressibility to gradient magnitudes and barren plateaus. PRX Quantum, 3:010313, 1 2022. arXiv: https://arxiv.org/abs/2101.02138. URL: https://link.aps.org/doi/10.1103/PRXQuantum.3.010313, doi:10.1103/PRXQuantum.3.010313.</p> </li> <li> <p>Carlos Ortiz Marrero, M\u00e1ria Kieferov\u00e1, and Nathan Wiebe. Entanglement-induced barren plateaus. PRX Quantum, 2(4):040316, 2021. arXiv: https://arxiv.org/abs/2010.15968. URL: https://journals.aps.org/prxquantum/abstract/10.1103/PRXQuantum.2.040316, doi:10.1103/PRXQuantum.2.040316.</p> </li> <li> <p>Kunal Sharma, M. Cerezo, Lukasz Cincio, and Patrick J Coles. Trainability of dissipative perceptron-based quantum neural networks. Physical Review Letters, 128(18):180505, 2022. arXiv: https://arxiv.org/abs/2005.12458. doi:10.1103/PhysRevLett.128.180505.</p> </li> <li> <p>Jonas K\u00fcbler, Simon Buchholz, and Bernhard Sch\u00f6lkopf. The inductive bias of quantum kernels. In Advances in Neural Information Processing Systems 34 (NIPS), 12661\u201312673. 2021. arXiv: https://arxiv.org/abs/2106.03747. URL: https://proceedings.neurips.cc/paper/2021/hash/69adc1e107f7f7d035d7baf04342e1ca-Abstract.html.</p> </li> <li> <p>Supanut Thanasilp, Samson Wang, Marco Cerezo, and Zo\u00eb Holmes. Exponential concentration and untrainability in quantum kernel methods. arXiv: https://arxiv.org/abs/2208.11060, 2022. URL: https://arxiv.org/abs/2208.11060.</p> </li> <li> <p>Maria Schuld and Nathan Killoran. Is quantum advantage the right goal for quantum machine learning? PRX Quantum, 3(3):030101, 2022. arXiv: https://arxiv.org/abs/2203.01340. URL: https://link.aps.org/doi/10.1103/PRXQuantum.3.030101, doi:10.1103/PRXQuantum.3.030101.</p> </li> <li> <p>Hsin-Yuan Huang, Michael Broughton, Jordan Cotler, Sitan Chen, Jerry Li, Masoud Mohseni, Hartmut Neven, Ryan Babbush, Richard Kueng, John Preskill, and others. Quantum advantage in learning from experiments. Science, 376(6598):1182\u20131186, 2022. arXiv: https://arxiv.org/abs/2112.00778. doi:DOI: 10.1126/science.abn7293.</p> </li> <li> <p>Sitan Chen, Jordan Cotler, Hsin-Yuan Huang, and Jerry Li. Exponential separations between learning with and without quantum memory. In Proceedings of the 62nd IEEE Symposium on Foundations of Computer Science (FOCS), 574\u2013585. IEEE, 2022. arXiv: https://arxiv.org/abs/2111.05881. doi:10.1109/FOCS52979.2021.00063.</p> </li> <li> <p>Matthias C. Caro, Hsin-Yuan Huang, Nicholas Ezzell, Joe Gibbs, Andrew T. Sornborger, Lukasz Cincio, Patrick J. Coles, and Zo\u00eb Holmes. Out-of-distribution generalization for learning quantum dynamics. Nature Communications, 14(1):3751, 2023. arXiv: https://arxiv.org/abs/2204.10268. URL: https://doi.org/10.1038/s41467-023-39381-w, doi:10.1038/s41467-023-39381-w.</p> </li> <li> <p>Marcello Benedetti, Erika Lloyd, Stefan Sack, and Mattia Fiorentini. Parameterized quantum circuits as machine learning models. Quantum Science and Technology, 4(4):043001, 2019. arXiv: https://arxiv.org/abs/1906.07682. URL: https://iopscience.iop.org/article/10.1088/2058-9565/ab4eb5, doi:10.1088/2058-9565/ab4eb5.</p> </li> <li> <p>M. Cerezo, Andrew Arrasmith, Ryan Babbush, Simon C Benjamin, Suguru Endo, Keisuke Fujii, Jarrod R McClean, Kosuke Mitarai, Xiao Yuan, Lukasz Cincio, and Patrick J. Coles. Variational quantum algorithms. Nature Reviews Physics, pages 625\u2013644, 2021. arXiv: https://arxiv.org/abs/2012.09265. doi:10.1038/s42254-021-00348-9.</p> </li> <li> <p>M Cerezo, Guillaume Verdon, Hsin-Yuan Huang, Lukasz Cincio, and Patrick J Coles. Challenges and opportunities in quantum machine learning. Nature Computational Science, 2(9):567\u2013576, 2022. arXiv: https://arxiv.org/abs/2303.09491. doi:https://doi.org/10.1038/s43588-022-00311-3.</p> </li> </ol>"},{"location":"areas-of-application/machine-learning-with-classical-data/tensor-pca/","title":"Tensor PCA","text":""},{"location":"areas-of-application/machine-learning-with-classical-data/tensor-pca/#overview","title":"Overview","text":"<p>Inference problems play an important role in machine learning. One of the most widespread methods is principal component analysis (PCA), a technique that extracts the most significant information from a stream of potentially noisy data. In the special case where the data is generated from a rank-\\(1\\) vector plus Gaussian noise\u2014the spiked matrix model\u2014it is known that there is a phase transition in the signal-to-noise ratio in the large sparse vector limit [1]. Above the transition point, the principal component can be recovered efficiently, while below the transition point, the principal component cannot be recovered at all. In the tensor extension of the problem, there are two transitions. One information theoretical, below which the principal component cannot be recovered, and another computational, below which the principal component can be recovered, but only inefficiently, and above which it can be recovered efficiently. Thus, the tensor PCA problem offers a much richer mathematical setting, which has connections to optimization and spin glass theory; however, it is yet unclear if the tensor PCA framework has natural practical applications. A quantum algorithm [2] for tensor PCA was proposed which has provable runtime guarantees for the spiked tensor model; it offers a potentially quartic speedup over its classical counterpart and also efficiently recovers the signal from the noise at a smaller signal-to-noise ratio than other classical methods.</p>"},{"location":"areas-of-application/machine-learning-with-classical-data/tensor-pca/#actual-end-to-end-problems-solved","title":"Actual end-to-end problem(s) solved","text":"<p>Consider the spiked tensor problem. Let \\(v\\in \\mathbb{R}^N\\) (or \\(\\in \\mathbb{C}^N\\))<sup>1</sup> be an unknown signal vector, and let \\(p \\in \\mathbb{N}\\) be a positive integer. Construct the tensor </p>\\[\\begin{equation} T= \\lambda v^{\\otimes p} + V, \\end{equation}\\]<p>where \\(V\\) is a random tensor in \\(\\mathbb{R}^{p^N}\\) (or \\(\\mathbb{C}^{p^N}\\)), with each entry drawn from a normal distribution with mean zero and variance \\(1\\). The vector \\(v\\) is assumed to have norm \\(\\sum_j v_j^* v_j=\\sqrt{N}\\), and can be identified with a quantum state. The quantity \\(\\lambda\\) is the signal-to-noise ratio.</p><p>The main question we are interested in is for what values of \\(\\lambda\\) can we detect or reconstruct \\(v\\) from (full) access to \\(T\\), and how efficiently can this be done? In [3], it was shown that the maximum likelihood solution \\(w^{\\rm ML}\\) to the objective function </p>\\[\\begin{equation} w^{\\rm ML} = \\argmax_{w\\in \\mathbb{C}^n} \\langle T, w^{\\otimes p}\\rangle\\,, \\end{equation}\\]<p>will have high correlation with \\(v\\) as long as \\(\\lambda\\gg N^{(1-p)/2}\\), where \\(\\langle \\cdot, \\cdot \\rangle\\) denotes the standard dot product after writing the \\(N^p\\) entries of the tensor as a vector. However, the best known efficient classical algorithm [4] requires \\(\\lambda\\gg N^{-p/4}\\) to recover an approximation of \\(v\\). Using the spectral method, i.e., mapping the tensor \\(T\\) to a \\(N^{p/2} \\times N^{p/2}\\) matrix and extracting the maximal eigenvalue, recovery can be done in time complexity \\(\\mathcal{O}\\left( N^p \\right)\\), ignoring logarithmic prefactors.</p><p>Hastings [2] proposes classical and quantum algorithms to solve the spiked tensor model by first mapping \\(T\\) to a bosonic quantum Hamiltonian with \\(N\\) modes, \\(n_{\\rm bos}\\) bosons, and \\(p\\)-body interactions, where \\(n_{\\rm{bos}}\\) is a tunable integer parameter satisfying \\(n_{\\rm bos} &gt; p/2\\) </p>\\[\\begin{equation} H_{\\rm PCA}(T) = \\frac{1}{2}\\left(\\sum_{\\mu_1,...,\\mu_p =1}^{N} T_{\\mu_1,...,\\mu_p} \\left(\\prod_{i=1}^{p/2}a^\\dag_{\\mu_i}\\right)\\left(\\prod_{j=1+p/2}^{p}a_{\\mu_j}\\right)+ \\mathrm{h.c.}\\right)\\label{eq:hamPCA}. \\end{equation}\\]<p>The operators \\(a_\\mu\\) and \\(a^\\dag_\\mu\\) are annihilation and creation operators of a boson in mode \\(\\mu\\), and we restrict to the sector for which \\(\\sum_\\mu a^\\dag_\\mu a_\\mu = n_{\\rm bos}\\).</p><p>Hastings shows that the vector \\(v\\) can be efficiently recovered from a vector in the large energy subspace of \\(H_{\\rm PCA}(T)\\) when the largest eigenvalue of \\(H_{\\rm PCA}(T)\\) is at least a constant factor larger than \\(E_{\\max}\\), where \\(E_{\\max}\\) corresponds to the case where there is no signal. It is shown that, roughly, </p>\\[\\begin{align} E_{\\max} &amp;\\sim&amp; n_{\\rm bos}^{p/4+1/2}N^{p/4}\\\\ E_0 &amp;\\approx&amp; \\lambda (p/2)!\\left(\\begin{matrix}n_{\\rm bos}\\\\ p/2\\end{matrix} \\right) N^{p/2} \\approx \\lambda n_{\\rm bos}^{p/2}N^{p/2}, \\end{align}\\]<p>where \\(E_0\\) is the maximum eigenvalue of \\(H_{\\rm PCA}(T)\\). Thus, if \\(\\lambda \\gg N^{-p/4}\\), there will be a gap between \\(E_0\\) and \\(E_{\\max}\\), and this gap grows as \\(n_{\\rm bos}\\) increases. Compared to other approaches, this method allows for constant-factor improvements on the value of \\(\\lambda\\) above which recovery is possible. For a fixed value of \\(p\\), independent of \\(N\\), the new bounds constitute an improvement, when \\(n_{\\rm bos}\\gg p/2\\).</p><p>Hastings considers the case where \\(p\\) is constant and \\(N\\) grows, and assumes that \\(n_{\\rm bos} = \\mathcal{O}\\left( N^\\theta \\right)\\) for some \\(p\\)-dependent constant \\(\\theta &gt; 0\\) chosen sufficiently small. In fact, ultimately, it is determined that in the recovery regime \\(\\lambda \\gg N^{-p/4}\\), the parameter \\(n_{\\rm bos}\\) need only scale as \\(\\mathrm{polylog}(N)\\). In any case, terms in the complexity \\(\\mathcal{O}\\left( N^p \\right)\\) are dominated by terms \\(\\mathcal{O}\\left( N^{n_{\\rm bos}} \\right)\\).</p>"},{"location":"areas-of-application/machine-learning-with-classical-data/tensor-pca/#dominant-resource-costcomplexity","title":"Dominant resource cost/complexity","text":"<p>Hastings shows that the dominant eigenvector can be classically extracted in \\(\\widetilde{\\mathcal{O}}\\left( N^{n_{\\rm bos}} \\right)\\) time via the power method, where the tilde indicates that we ignore polylogarithmic factors.</p><p>He proposes three quantum algorithms for the same problem. The first runs phase estimation on a random state. Since the random state will have overlap \\(\\Omega(N^{-n_{\\rm bos}})\\) with the high energy subspace, the expected runtime is \\(\\mathcal{O}\\left( N^{n_{\\rm bos}} \\right)\\). The second algorithm proposes to further use amplitude amplification, reducing the runtime to \\(\\mathcal{O}\\left( N^{n_{\\rm bos}/2} \\right)\\). The third algorithm further improves the runtime by choosing a specific initial high energy state, and showing that the overlap with the state scales as \\(\\Omega(N^{-n_{\\rm bos}/2})\\), which combined with amplitude amplification, leads to a \\(\\mathcal{O}\\left( N^{n_{\\rm bos}/4} \\right)\\) runtime. As discussed above, the estimates assume that factors of \\(\\mathcal{O}\\left( N^p \\right)\\) can be ignored, since they are negligible with respect to the query complexity of \\(N^{\\mathcal{O}\\left( n_{\\rm bos} \\right)}\\).</p><p>This constitutes a quartic speedup over the classical spectral algorithm acting on \\(H_{\\rm PCA}\\) for the same choice of \\(n_{\\rm bos}\\) that is also presented in [2]. Since the ansatz state is a product state, it can be prepared efficiently.</p><p>Hastings further argues that the Hamiltonian simulation in the phase estimation subroutine can be done within the sparse access model. In the second-quantized Hamiltonian (Eq. \\(\\eqref{eq:hamPCA}\\)) the occupancy of each mode is limited by \\(n_{\\rm bos}\\), defining a cutoff for each register. We need \\(N \\log(n_{\\rm bos})\\) qubits, leading to a sparse Hamiltonian, since \\(n_{\\rm bos}^N\\gg N^{n_{\\rm bos}}/n_{\\rm bos}!\\) for \\(N\\gg n_{\\rm bos}\\). The tensor \\(T\\) only has dimension \\(N^p\\ll N^{n_{\\rm bos}}\\). Thus we can use sparse Hamiltonian simulation or a sparse block-encoding to perform quantum phase estimation.</p>"},{"location":"areas-of-application/machine-learning-with-classical-data/tensor-pca/#caveats","title":"Caveats","text":"<p>The spiked tensor model does not immediately appear to be related to any practical problems. Additionally, efficient recovery requires that the signal-to-noise ratio be rather high, which may not occur in real-world settings (and when it does, it is not clear that formulating the problem as a tensor PCA problem will be the most efficient path forward).</p>"},{"location":"areas-of-application/machine-learning-with-classical-data/tensor-pca/#comparable-classical-complexity-and-challenging-instance-sizes","title":"Comparable classical complexity and challenging instance sizes","text":"<p>The algorithms proposed in [2] improve on other spectral methods for the spiked tensor model, whenever \\(n_{\\rm bos}&gt;p/2\\) for sufficiently large \\(p\\). The threshold for which the new algorithms beat the older ones decreases as \\(n_{\\rm bos}\\) increases, although the complexity of the algorithm increases with \\(n_{\\rm bos}\\).</p>"},{"location":"areas-of-application/machine-learning-with-classical-data/tensor-pca/#speedup","title":"Speedup","text":"<p>The quartic speedup over the classical power method is achieved by combining a quadratic speedup from amplitude amplification with a quadratic speedup related to choosing a clever initial state for phase estimation. As discussed above, there is no readout issue, as the vector \\(v\\) can be efficiently recovered from the single particle density matrix obtained from the eigenvector of \\(H_{\\rm PCA}(T)\\). The quantum algorithm has \\(\\mathcal{O}\\left( N\\log(n_{\\rm bos}) \\right)\\) space complexity, which is an exponential improvement over the classical spectral algorithm presented in [2] for the same problem.</p>"},{"location":"areas-of-application/machine-learning-with-classical-data/tensor-pca/#outlook","title":"Outlook","text":"<p>The quartic speedup is very compelling. At present, it is not known whether there exist other large-scale inference problems with characteristics similarly leading to a speedup.</p>"},{"location":"areas-of-application/machine-learning-with-classical-data/tensor-pca/#bibliography","title":"Bibliography","text":"<ol> <li> <p>DC Hoyle and M Rattray. Pca learning for sparse high-dimensional data. Europhysics Letters, 62(1):117, 2003. doi:10.1209/epl/i2003-00370-1.</p> </li> <li> <p>Matthew B Hastings. Classical and quantum algorithms for tensor principal component analysis. Quantum, 4:237, 2020. arXiv: https://arxiv.org/abs/1907.12724. doi:10.22331/q-2020-02-27-237.</p> </li> <li> <p>Emile Richard and Andrea Montanari. A statistical model for tensor pca. In Advances in Neural Information Processing Systems 27 (NIPS). 2014. arXiv: https://arxiv.org/abs/1411.1076. URL: https://proceedings.neurips.cc/paper/2014/hash/b5488aeff42889188d03c9895255cecc-Abstract.html.</p> </li> <li> <p>Alexander S Wein, Ahmed El Alaoui, and Cristopher Moore. The kikuchi hierarchy and tensor pca. In Proceedings of the 60th IEEE Symposium on Foundations of Computer Science (FOCS), 1446\u20131468. IEEE, 2019. arXiv: https://arxiv.org/abs/1904.03858. doi:10.1109/FOCS.2019.000-2.</p> </li> </ol> <ol> <li> <p>Reference [2] provides reductions between real and complex cases.\u00a0\u21a9</p> </li> </ol>"},{"location":"areas-of-application/machine-learning-with-classical-data/topological-data-analysis/","title":"Topological data analysis","text":""},{"location":"areas-of-application/machine-learning-with-classical-data/topological-data-analysis/#overview","title":"Overview","text":"<p>In topological data analysis, we aim to compute the dominant topological features (connected components, and \\(k\\)-dimensional holes) of data points sampled from an underlying topological manifold (given a length scale at which to view the data) or of a graph. These features may be of independent interest (e.g., the number of connected components in the matter distribution in the universe) or can be used as generic features to compare datasets. Quantum algorithms for this problem leverage the ability of a register of qubits to efficiently store a state representing the system. This leads to quantum algorithms that are more efficient than known classical algorithms, in some regimes.</p>"},{"location":"areas-of-application/machine-learning-with-classical-data/topological-data-analysis/#actual-end-to-end-problems-solved","title":"Actual end-to-end problem(s) solved","text":"<p>We compute to accuracy \\(\\epsilon\\) the Betti numbers \\(\\beta_k^i\\) (the number of \\(k\\)-dimensional holes at a given length scale \\(i\\)) or the persistent Betti numbers \\(\\beta_k^{i,j}\\) (the number of \\(k\\)-dimensional holes that survive from scale \\(i\\) to scale \\(j\\)) of a simplicial complex built from datapoints sampled from an underlying manifold. The simplicial complex is a higher dimensional generalization of a graph, constructed by connecting datapoints within a given length scale of each other. A simplicial complex constructed in this way is known as a clique complex or a Vietoris-Rips complex.</p><p>The persistent Betti number \\(\\beta_k^{i,j}\\) is the quantity of primary interest for point cloud data, as it is unclear a priori what the 'true' length scale of the manifold is, and noise present in the data may lead to a large number of short-lived holes. The longest-lived features are considered to be the dominant topological features. The births and deaths of features are typically plotted on a \"persistence diagram.\" Different datasets can be compared by using stable distance measures between their diagrams, or vectorising the diagrams and using kernel methods or neural networks. For graphs, the length scale is not required, and so \\(\\beta_k^i\\) can be of interest. For statements common to both \\(\\beta_k^{i,j}\\) and \\(\\beta_k^i\\), we will use the notation \\(\\beta_k^*\\). Practical applications typically consider low values of \\(k\\), motivated both by computational cost, and interpretability.</p>"},{"location":"areas-of-application/machine-learning-with-classical-data/topological-data-analysis/#dominant-resource-costcomplexity","title":"Dominant resource cost/complexity","text":"<p>The quantum algorithms [1, 2, 3, 4, 5] for computing \\(\\beta_k^*\\) actually return these quantities normalized by the number of \\(k\\)-simplices present in the complex at the given length scale, \\(|S_k^i|\\). For a complex with \\(N\\) datapoints, we can either use \\(N\\) qubits to store the simplicial complex, or \\(\\mathcal{O}\\left( k\\log(N) \\right)\\) when \\(k \\ll N\\). Quantum algorithms have two subroutines:</p><ol> <li>Finding \\(k\\)-simplices present in the complex at the given length scale (using either classical rejection sampling or Grover's algorithm), which in the best case scales as \\(\\sqrt{\\binom{N}{k+1}/|S_k^i|}\\).</li> <li>Projecting onto the eigenspace of an operator that encodes the topology (using either quantum phase estimation or quantum singular value transformation). This introduces a dependence on the gap(s) \\(\\Lambda\\) of the operator(s) used to encode the topology.</li> </ol><p>The most efficient approaches use amplitude estimation to compute \\(\\sqrt{\\beta_k^*/|S_k^i|}\\) to additive error \\(\\delta\\) with complexity \\(\\mathcal{O}\\left( \\delta^{-1} \\right)\\). The most expensive subroutines within the quantum algorithms are the membership oracles that determine if a given simplex is present in the complex, the cost of which we denote by \\(m_k\\). The overall cost of the most efficient known approaches to compute \\(\\beta_k^*\\) to constant additive error \\(\\Delta\\) is approximately </p>\\[\\begin{equation} \\frac{m_k \\sqrt{\\beta_k^*}}{\\Delta} \\left( \\sqrt{\\binom{N}{k+1}} + \\frac{\\sqrt{|S_k^i|} \\mathrm{poly}(N,k)}{\\Lambda} \\right) . \\end{equation}\\]<p>The quantum algorithm must be repeated at all pairs of length scales to compute the persistence diagram.</p>"},{"location":"areas-of-application/machine-learning-with-classical-data/topological-data-analysis/#existing-error-corrected-resource-estimates","title":"Existing error corrected resource estimates","text":"<p>In [4] the gate depth (and non-Clifford gate depth) of all subroutines (including explicit implementations of the membership oracles) was established for computing \\(\\beta_k^{i,j}\\) and \\(\\beta_k^i\\). However that reference did not consider a final compilation to \\(T\\)/Toffoli gates for concrete problems of interest.</p><p>In [5] the Toffoli complexity of estimating \\(\\beta_k^i\\) was determined. The Toffoli complexity for estimating \\(\\beta_k^i\\) to relative error (rather than constant error), for a family of graphs with large \\(\\beta_k^i\\), was determined for \\(k=4,8,16,32\\) and \\(N \\leq 10^4\\). The resulting Toffoli counts ranged from \\(10^8\\) (\\(N=100, k=4\\)) to \\(10^{17}\\) (\\(N=10^4, k=32\\)), using \\(N\\) logical qubits.</p>"},{"location":"areas-of-application/machine-learning-with-classical-data/topological-data-analysis/#caveats","title":"Caveats","text":"<p>Quantum algorithms are unable to achieve exponential speedups for estimating \\(\\beta_k^*\\) to constant additive error. This is because they must efficiently find simplices in the complex (thus \\(|S_k^i|\\) must be large), but they return \\(\\beta_k^*/|S_k^i|\\), which means the error must be rescaled by \\(|S_k^i|\\) to achieve constant error. More rigorously, [6] showed that determining if the Betti number of a (clique-dense) clique complex is nonzero is QMA\\(_1\\)-hard. Thus, quantum algorithms should not be expected to provide exponential speedups for (persistent) Betti number estimation. In [7] it was shown that estimating normalized quasi-Betti numbers (which accounts for miscounting low-lying but nonzero singular values) of general cohomology groups is DQC1-hard<sup>1</sup>. The hardness of estimating normalized (persistent) Betti numbers of a clique complex, subject to a gap assumption of \\(\\Lambda = \\Omega(1/\\mathrm{poly}(N))\\)\u2014which is the problem solved by existing quantum algorithms\u2014has not been established (see [7, Sec. 1.1]).</p><p>Quantum algorithms also depend on the eigenvalue gap(s) \\(\\Lambda\\) of the operator(s) that encode the topology. The scaling of these gaps has not been studied for typical applications.</p><p>Finally, typical applications consider dimension \\(k \\leq 3\\). It is unclear whether this is because larger values of \\(k\\) are uninteresting, or because they are too expensive to compute classically.</p>"},{"location":"areas-of-application/machine-learning-with-classical-data/topological-data-analysis/#comparable-classical-complexity-and-challenging-instance-sizes","title":"Comparable classical complexity and challenging instance sizes","text":"<p>While classical algorithms are technically efficient for constant dimension \\(k\\), they are limited in practice. For a number of benchmark calculations on systems with up to \\(\\mathcal{O}\\left( 10^9 \\right)\\) simplices we refer to [8].</p><p>The 'textbook' classical algorithm for \\(\\beta_k^*\\) scales as \\(\\mathcal{O}\\left( |S_{k+1}^j|^\\omega \\right)\\) where \\(\\omega \\approx 2.4\\) is the cost of matrix multiplication [9]. In practice the cost is considered closer to \\(\\mathcal{O}\\left( |S_{k+1}^j| \\right)\\) due to sparsity in the complex [9] (well studied classical heuristics that sparsify the complex can also be used to achieve this scaling [10]). The textbook algorithm only needs to be run once to compute the persistence diagram.</p><p>Classical algorithms based on the power method [11] scale approximately as </p>\\[\\begin{equation} \\widetilde{\\mathcal{O}}\\left( \\frac{|S_k^i| (k^2 \\beta_k^i + k (\\beta_k^i)^2)}{\\Lambda} \\log\\left(\\frac{1}{\\Delta}\\right) \\right) \\end{equation}\\]<p>to compute \\(\\beta_k^i\\) to additive error \\(\\Delta\\). This is only quadratically worse than the quantum algorithm for \\(|S_k^i| = \\mathcal{O}\\left( \\binom{N}{k+1} \\right)\\). The power method has recently been extended to compute persistent Betti numbers, with a similar complexity [4]. The power method is more efficient than the rigorous textbook classical algorithm described above, but it must be repeated for each pair of length scales to compute the persistence diagram, which is a disadvantage in practice.</p><p>Recently, randomized classical algorithms have been proposed for estimating \\(\\beta_k^i/|S_k^i|\\) to additive error [5, 12]. The algorithm of [12] runs in polynomial time for clique complexes for constant gap \\(\\Lambda\\) and error \\(\\Delta = 1/\\mathrm{poly}(N)\\) (or \\(\\Delta\\) constant and \\(\\Lambda = \\mathcal{O}\\left( 1/\\log(N) \\right)\\)).</p>"},{"location":"areas-of-application/machine-learning-with-classical-data/topological-data-analysis/#speedup","title":"Speedup","text":"<p>For the task of computing \\(\\beta_k^{i,j}\\) to constant additive error, quantum algorithms can achieve an almost quintic speedup over the rigorous scaling of the textbook classical algorithm for large \\(k\\) (subject to the dependence of the gap parameters on \\(N\\)). For a dimension sufficiently low to be studied classically, \\(k=3\\), the speedup would be approximately cubic, subject to the gap dependence. However, when compared against the aforementioned observed scaling of the textbook classical algorithm of \\(\\mathcal{O}\\left( |S_{k+1}^j| \\right)\\) (or against classical heuristics that achieve this scaling) the quantum speedup is reduced to (sub)-quadratic for all \\(k\\), even before considering the gap dependence. Moreover, the quantum algorithm has large constant factor overheads from the precision \\(\\Delta\\) and the number of repetitions to compute the persistence diagram.</p><p>A more apples-to-apples comparison between the quantum algorithm and the power method shows that the quantum algorithm is only quadratically better than rigorous classical algorithms [11, 4].</p><p>For the task of computing \\(\\beta_k^i\\) to relative error, graphs have been found for which the quantum algorithm provides superpolynomial [5] or quartic [5, 13] speedups over both the power method and the heuristic/observed scaling of the textbook approach. As noted above, this task can also be addressed with recent randomized classical algorithms [5, 12]. The algorithm of [12] runs in polynomial time for clique complexes with constant gap \\(\\Lambda\\) and error \\(\\Delta = 1/\\mathrm{poly}(N)\\) (or \\(\\Delta\\) constant and \\(\\Lambda = \\mathcal{O}\\left( (1/\\log(N) \\right)\\)). These are more restrictive conditions than quantum algorithms (which can simultaneously have both \\(\\Lambda, \\Delta = \\mathcal{O}\\left( 1/\\mathrm{poly}(N) \\right)\\)).</p>"},{"location":"areas-of-application/machine-learning-with-classical-data/topological-data-analysis/#nisq-implementations","title":"NISQ implementations","text":"<p>In [14] a NISQ-friendly compilation of the quantum algorithm described above was proposed, trading deep quantum circuits for many repetitions of shallower circuits, which comes at the cost of worsening the asymptotic scaling of the algorithm (see the table in [4] for a quantitative comparison). A proof-of-principle experiment was performed [14]. In [7] it was shown that the TDA problem can be mapped to a fermionic Hamiltonian, and it was proposed to use the variational quantum eigensolver to find the ground states of this Hamiltonian (the degeneracy of which gives \\(\\beta_k^i\\)). It is unclear what ansatz circuits one should use to make this approach advantageous compared to classical algorithms, as naive (e.g., random) trial states would have exponentially small overlap with the target states.</p>"},{"location":"areas-of-application/machine-learning-with-classical-data/topological-data-analysis/#outlook","title":"Outlook","text":"<p>Given the large overheads induced by error correction, it seems unlikely that the quantum algorithms for computing (persistent) Betti numbers to constant additive error will achieve practical advantage for current calculations of interest. This is because the quantum speedup over classical approaches is only quadratic for this task, and classical algorithms are efficient for the \\(k \\leq 3\\) regime typically considered.</p><p>If more datasets can be identified where the high-dimensional (persistent) Betti numbers are large and practically interesting to compute to relative error, then quantum algorithms may be of practical relevance. We refer to [15] for a recent survey of applications of TDA.</p>"},{"location":"areas-of-application/machine-learning-with-classical-data/topological-data-analysis/#bibliography","title":"Bibliography","text":"<ol> <li> <p>Seth Lloyd, Silvano Garnerone, and Paolo Zanardi. Quantum algorithms for topological and geometric analysis of data. Nature Communications, 7(1):1\u20137, 2016. arXiv: https://arxiv.org/abs/1408.3106. doi:https://doi.org/10.1038/ncomms10138.</p> </li> <li> <p>Sam Gunn and Niels Kornerup. Review of a quantum algorithm for betti numbers. arXiv: https://arxiv.org/abs/1906.07673, 2019.</p> </li> <li> <p>Ryu Hayakawa. Quantum algorithm for persistent betti numbers and topological data analysis. Quantum, 6:873, 12 2022. arXiv: https://arxiv.org/abs/2111.00433. URL: https://doi.org/10.22331/q-2022-12-07-873, doi:10.22331/q-2022-12-07-873.</p> </li> <li> <p>Sam McArdle, Andr\u00e1s Gily\u00e9n, and Mario Berta. A streamlined quantum algorithm for topological data analysis with exponentially fewer qubits. arXiv: https://arxiv.org/abs/2209.12887, 2022.</p> </li> <li> <p>Dominic W Berry, Yuan Su, Casper Gyurik, Robbie King, Joao Basso, Alexander Del Toro Barba, Abhishek Rajput, Nathan Wiebe, Vedran Dunjko, and Ryan Babbush. Quantifying quantum advantage in topological data analysis. arXiv: https://arxiv.org/abs/2209.13581, 2022.</p> </li> <li> <p>Marcos Crichigno and Tamara Kohler. Clique homology is qma1-hard. arXiv: https://arxiv.org/abs/2209.11793, 2022.</p> </li> <li> <p>Chris Cade and P Marcos Crichigno. Complexity of supersymmetric systems and the cohomology problem. arXiv: https://arxiv.org/abs/2107.00011, 2021.</p> </li> <li> <p>Nina Otter, Mason A Porter, Ulrike Tillmann, Peter Grindrod, and Heather A Harrington. A roadmap for the computation of persistent homology. EPJ Data Science, 6:1\u201338, 2017. arXiv: https://arxiv.org/abs/1506.08903. doi:10.1140/epjds/s13688-017-0109-5.</p> </li> <li> <p>Nikola Milosavljevi\u0107, Dmitriy Morozov, and Primoz Skraba. Zigzag persistent homology in matrix multiplication time. In Proceedings of the 27th Annual Symposium on Computational geometry, 216\u2013225. 2011. doi:https://doi.org/10.1145/1998196.1998229.</p> </li> <li> <p>Konstantin Mischaikow and Vidit Nanda. Morse theory for filtrations and efficient computation of persistent homology. Discrete &amp; Computational Geometry, 50(2):330\u2013353, 2013. doi:https://doi.org/10.1007/s00454-013-9529-6.</p> </li> <li> <p>Joel Friedman. Computing betti numbers via combinatorial laplacians. Algorithmica, 21(4):331\u2013346, 1998. doi:https://doi.org/10.1007/PL00009218.</p> </li> <li> <p>Simon Apers, Sayantan Sen, and D\u00e1niel Szab\u00f3. A (simple) classical algorithm for estimating betti numbers. arXiv: https://arxiv.org/abs/2211.09618, 2022.</p> </li> <li> <p>Alexander Schmidhuber and Seth Lloyd. Complexity-theoretic limitations on quantum algorithms for topological data analysis. arXiv: https://arxiv.org/abs/2209.14286, 2022.</p> </li> <li> <p>Ismail Yunus Akhalwaya, Shashanka Ubaru, Kenneth L Clarkson, Mark S Squillante, Vishnu Jejjala, Yang-Hui He, Kugendran Naidoo, Vasileios Kalantzis, and Lior Horesh. Exponential advantage on noisy quantum computers. arXiv: https://arxiv.org/abs/2209.09371, 2022.</p> </li> <li> <p>Felix Hensel, Michael Moor, and Bastian Rieck. A survey of topological machine learning methods. Frontiers in Artificial Intelligence, 4:681108, 2021. doi:10.3389/frai.2021.681108.</p> </li> <li> <p>E. Knill and R. Laflamme. Power of one bit of quantum information. Physical Review Letters, 81:5672\u20135675, 12 1998. arXiv: https://arxiv.org/abs/quant-ph/9802037. URL: https://link.aps.org/doi/10.1103/PhysRevLett.81.5672, doi:10.1103/PhysRevLett.81.5672.</p> </li> </ol> <ol> <li> <p>DQC1 is a complexity class that is physically motivated by the \"one clean qubit model\\\" [16]. This model has a single pure state qubit which can be initialized, manipulated and measured freely, as well as \\(N-1\\) maximally mixed qubits.\u00a0\u21a9</p> </li> </ol>"},{"location":"areas-of-application/nuclear-and-particle-physics/introduction/","title":"Nuclear and particle physics","text":"<p>Simulating nuclear and particle physics appears an inherently quantum problem. There have been proposals to use quantum computers to accelerate simulations of quantum field theories, nuclear structure, neutrino physics, and quantum gravity [1]. In this section, we will focus on the simulation of quantum field theories and nuclear structure, as these have received the most attention in the literature to date and are the closest to having end-to-end fault-tolerant resource estimates available. The building blocks of quantum algorithms for data analysis in high energy physics [2] can be found in the sections on variational quantum algorithms and machine learning. For existing reviews of quantum computing for nuclear and particle physics, we direct the reader to [3, 4, 1, 5].</p>"},{"location":"areas-of-application/nuclear-and-particle-physics/introduction/#bibliography","title":"Bibliography","text":"<ol> <li> <p>Christian W. Bauer, Zohreh Davoudi, A. Baha Balantekin, Tanmoy Bhattacharya, Marcela Carena, Wibe A. de Jong, Patrick Draper, Aida El-Khadra, Nate Gemelke, Masanori Hanada, Dmitri Kharzeev, Henry Lamm, Ying-Ying Li, Junyu Liu, Mikhail Lukin, Yannick Meurice, Christopher Monroe, Benjamin Nachman, Guido Pagano, John Preskill, Enrico Rinaldi, Alessandro Roggero, David I. Santiago, Martin J. Savage, Irfan Siddiqi, George Siopsis, David Van Zanten, Nathan Wiebe, Yukari Yamauchi, K\u00fcbra Yeter-Aydeniz, and Silvia Zorzetti. Quantum simulation for high-energy physics. PRX Quantum, 4:027001, 5 2023. arXiv: https://arxiv.org/abs/2204.03381. URL: https://link.aps.org/doi/10.1103/PRXQuantum.4.027001, doi:10.1103/PRXQuantum.4.027001.</p> </li> <li> <p>Andrea Delgado, Kathleen E Hamilton, Jean-Roch Vlimant, Duarte Magano, Yasser Omar, Pedrame Bargassa, Anthony Francis, Alessio Gianelle, Lorenzo Sestini, Donatella Lucchesi, and others. Quantum computing for data analysis in high-energy physics. arXiv: https://arxiv.org/abs/2203.08805, 2022.</p> </li> <li> <p>John Preskill. Simulating quantum field theory with a quantum computer. arXiv: https://arxiv.org/abs/1811.10085, 2019. doi:10.22323/1.334.0024.</p> </li> <li> <p>Mari Carmen Ba\u00f1uls, Rainer Blatt, Jacopo Catani, Alessio Celi, Juan Ignacio Cirac, Marcello Dalmonte, Leonardo Fallani, Karl Jansen, Maciej Lewenstein, Simone Montangero, Christine A. Muschik, Benni Reznik, Enrique Rico, Luca Tagliacozzo, Karel Van Acoleyen, Frank Verstraete, Uwe-Jens Wiese, Matthew Wingate, Jakub Zakrzewski, and Peter Zoller. Simulating lattice gauge theories within quantum technologies. The European Physical Journal D, 74(8):165, 8 2020. arXiv: https://arxiv.org/abs/1911.00003. URL: https://doi.org/10.1140/epjd/e2020-100571-8, doi:10.1140/epjd/e2020-100571-8.</p> </li> <li> <p>Lena Funcke, Tobias Hartung, Karl Jansen, and Stefan K\u00fchn. Review on quantum computing for lattice field theory. In Proceedings of the 39th International Symposium on Lattice Field Theory, volume 430, 228. 2023. arXiv: https://arxiv.org/abs/2302.00467. doi:10.22323/1.430.0228.</p> </li> </ol>"},{"location":"areas-of-application/nuclear-and-particle-physics/nuclear-structure-problem/","title":"Nuclear structure problem","text":""},{"location":"areas-of-application/nuclear-and-particle-physics/nuclear-structure-problem/#overview","title":"Overview","text":"<p>The structure of nuclei can be approximately described using the shell model (see [1] for an overview), a phenomenological model with parameters fitted to experimental observations. However, high accuracy descriptions of nuclear structure, exotic nuclei, accurate scattering cross sections, or non-equilibrium phenomena require a first-principles treatment. Describing the properties of nuclei from first principles (e.g., lattice quantum chromodynamics simulations) is beyond the reach of analytic and current computational capabilities for all but the simplest nuclei [2]. Nevertheless, we can integrate out the short-range physics to obtain effective field theories (EFTs) that describe the interactions of nucleons. The prototypical example is chiral effective field theory, which describes the interactions of nucleons and virtual pions. The parameters of the EFT can be inferred from experiments (in the future it may also be possible to determine the parameters directly from lattice QCD calculations), resulting in a many-body Hamiltonian that describes the formation and potential decay of nuclei.</p>"},{"location":"areas-of-application/nuclear-and-particle-physics/nuclear-structure-problem/#actual-end-to-end-problems-solved","title":"Actual end-to-end problem(s) solved","text":"<p>The EFT provides a many-body Hamiltonian describing how nucleons interact. Classical techniques to find the eigenstates and eigenenergies of this Hamiltonian include coordinate-space methods (e.g., quantum Monte Carlo methods) as well as projecting onto a basis set and using techniques such as perturbation theory or coupled cluster [3]. In this sense, the problem is similar to the electronic structure problem in quantum chemistry. A common problem is to prepare the ground state of a collection of nucleons, in order to compute nuclear binding energies and determine if a given nucleus is stable (for example, determining the long lifetime of \\(^{14}\\)C [4, 5]). Simulations can also be used to calculate scattering cross sections, which are used to analyze experiments on nucleus-neutrino scattering [6], beta decay, and nuclear reactions. Reactions such as nuclear fission and nuclear fusion can also be studied using explicitly time-dependent approaches [7], although these have higher computational costs than static calculations. Simulating both fusion and fission reactions has a number of use cases, such as an improved understanding of nuclear astrophysics, where reactions commonly occur at energies too high or too low to be replicated in experiments [8].</p>"},{"location":"areas-of-application/nuclear-and-particle-physics/nuclear-structure-problem/#dominant-resource-costcomplexity","title":"Dominant resource cost/complexity","text":"<p>The quantum computing approaches to date have ported much of the machinery from quantum algorithms for the electronic structure problem [9]. The nuclear structure problem can be tackled by projecting the Hamiltonian onto a single-particle basis (often harmonic oscillator eigenstates) [3]. In second quantization, a qubit is required for each single-particle basis function included. The EFT can be expanded to higher orders in the coupling parameter; it is typical to retain at least 3-nucleon couplings caused by the pion, and higher-order terms could also be included. Including the 3-nucleon coupling results in a Hamiltonian with \\(\\mathcal{O}\\left( N^6 \\right)\\) terms, which can be contrasted with the \\(\\mathcal{O}\\left( N^4 \\right)\\) scaling of the electronic structure Hamiltonian. As such, algorithms that scale with the number of terms (e.g., product formulae) may have a higher cost for nuclear structure calculations than electronic structure problems of a similar size. Nevertheless, an exact comparison depends on a number of other factors (dependent upon the algorithm used), such as the commutativity of the Hamiltonian terms, structure of the coefficients, and the energy scales in the problem.</p><p>Quantum algorithms that prepare energy eigenstates scale either as \\(1/\\gamma\\) (where \\(\\gamma\\) is the overlap of the initial state with the desired eigenstate) [10], or with the minimum gap size along an adiabatic path (see adiabatic state preparation) [11]. If we are only interested in measuring the energy of the state, this can be obtained using the quantum phase estimation algorithm, which also projects the system into the corresponding energy eigenstate. The cost of this approach scales as \\(\\mathcal{O}\\left( 1/\\gamma^2 \\right)\\). Once the desired state has been prepared, observables can be measured to precision \\(\\epsilon\\) with complexity \\(\\mathcal{O}\\left( 1/\\epsilon^2 \\right)\\) (direct sampling) or \\(\\mathcal{O}\\left( 1/\\epsilon \\right)\\) (amplitude estimation).</p><p>The above algorithms for preparing states (and related algorithms for performing time evolution in dynamics simulations) require access to the Hamiltonian, which introduces a dependence on the norm of the Hamiltonian or the number of terms (or both). These costs have not yet been elucidated for nuclear structure calculations.</p>"},{"location":"areas-of-application/nuclear-and-particle-physics/nuclear-structure-problem/#existing-error-corrected-resource-estimates","title":"Existing error corrected resource estimates","text":"<p>We are not aware of any error corrected resource estimates for problems in nuclear physics. For an initial investigation into the cost of nucleus-neutrino scattering, see [6].</p>"},{"location":"areas-of-application/nuclear-and-particle-physics/nuclear-structure-problem/#caveats","title":"Caveats","text":"<p>For quantum algorithms to be efficient, we must be able to prepare an initial state that has only polynomially vanishing overlap with the desired state. This is the same problem that afflicts quantum algorithms for the electronic structure problem. For simulations of nuclear dynamics, it may be necessary to work with a basis set that is sufficiently flexible to account for the varying positions of the nuclei.</p><p>The parameter values of the EFT are obtained from fits to experimental data, and so may introduce systematic inaccuracies into the nuclear structure calculation.</p>"},{"location":"areas-of-application/nuclear-and-particle-physics/nuclear-structure-problem/#comparable-classical-complexity-and-challenging-instance-sizes","title":"Comparable classical complexity and challenging instance sizes","text":"<p>Classical approaches use similar techniques to those developed for the electronic structure problem, such as perturbation theory, Monte Carlo methods, or coupled cluster. Refs. [5, 3] provide an excellent overview of state-of-the-art approaches. Classical methods can provide excellent agreement with experiments for the binding energies of small nuclei with 20-50 nucleons [3]. As a further example, recent high-accuracy simulations of the \\(^{100}\\)Sn nucleus have enabled improved agreement between theory and experiment for observed \\(\\beta\\)-decay rates [12]. Time-dependent simulations of dynamics or non-equilibrium phenomena are more challenging and are an active area of research [7, 8].</p>"},{"location":"areas-of-application/nuclear-and-particle-physics/nuclear-structure-problem/#speedup","title":"Speedup","text":"<p>The majority of classical approaches for the nuclear structure problem scale polynomially with system size, but introduce controllable errors due to the use of approximations (e.g., truncating the expansion in coupled cluster methods) [3]. For quantum computers to achieve exponential speedups, we require the identification of systems where (1) Classical methods must exponentially increase their resources to obtain accurate results and (2) It is efficient to prepare an initial state for the quantum calculation that only has polynomially decaying overlap with the desired state. There have recently been initial investigations into whether these requirements coexist in chemical systems [13]. We are not aware of similar work in nuclear physics.</p>"},{"location":"areas-of-application/nuclear-and-particle-physics/nuclear-structure-problem/#nisq-implementation","title":"NISQ implementation","text":"<p>Almost all of the work to date on applying quantum computing to the nuclear structure problem has focused on variational algorithms, such as [14, 15, 16]. There is currently no evidence that near-term quantum devices will be able to implement sufficiently deep circuits to achieve advantage over their classical counterparts with these methods.</p>"},{"location":"areas-of-application/nuclear-and-particle-physics/nuclear-structure-problem/#outlook","title":"Outlook","text":"<p>Further research is required to determine the fault-tolerant resources for solving nuclear structure problems on quantum computers. While the problem is inherently similar to the electronic structure problem in quantum chemistry, it is necessary to adapt known algorithms to the nuclear setting, and to understand and optimize their scaling for classically challenging problems. The simulation of nuclear reaction dynamics appears a particularly interesting target, which has not yet received a thorough reformulation suitable for quantum simulation.</p>"},{"location":"areas-of-application/nuclear-and-particle-physics/nuclear-structure-problem/#bibliography","title":"Bibliography","text":"<ol> <li> <p>David J. Dean. Beyond the nuclear shell model. Physics Today, 60(11):48\u201353, 2007. URL: https://doi.org/10.1063/1.2812123, arXiv:https://doi.org/10.1063/1.2812123, doi:10.1063/1.2812123.</p> </li> <li> <p>Christian W. Bauer, Zohreh Davoudi, A. Baha Balantekin, Tanmoy Bhattacharya, Marcela Carena, Wibe A. de Jong, Patrick Draper, Aida El-Khadra, Nate Gemelke, Masanori Hanada, Dmitri Kharzeev, Henry Lamm, Ying-Ying Li, Junyu Liu, Mikhail Lukin, Yannick Meurice, Christopher Monroe, Benjamin Nachman, Guido Pagano, John Preskill, Enrico Rinaldi, Alessandro Roggero, David I. Santiago, Martin J. Savage, Irfan Siddiqi, George Siopsis, David Van Zanten, Nathan Wiebe, Yukari Yamauchi, K\u00fcbra Yeter-Aydeniz, and Silvia Zorzetti. Quantum simulation for high-energy physics. PRX Quantum, 4:027001, 5 2023. arXiv: https://arxiv.org/abs/2204.03381. URL: https://link.aps.org/doi/10.1103/PRXQuantum.4.027001, doi:10.1103/PRXQuantum.4.027001.</p> </li> <li> <p>Heiko Hergert. A guided tour of ab initio nuclear many-body theory. Frontiers in Physics, 2020. arXiv: https://arxiv.org/abs/2008.05061. URL: https://www.frontiersin.org/articles/10.3389/fphy.2020.00379, doi:10.3389/fphy.2020.00379.</p> </li> <li> <p>P. Maris, J. P. Vary, P. Navr\u00e1til, W. E. Ormand, H. Nam, and D. J. Dean. Origin of the anomalous long lifetime of \\(^14\\mathrm C\\). Physical Review Letters, 106:202502, 5 2011. arXiv: https://arxiv.org/abs/1101.5124. URL: https://link.aps.org/doi/10.1103/PhysRevLett.106.202502, doi:10.1103/PhysRevLett.106.202502.</p> </li> <li> <p>G Hagen, T Papenbrock, M Hjorth-Jensen, and D J Dean. Coupled-cluster computations of atomic nuclei. Reports on Progress in Physics, 77(9):096302, 9 2014. arXiv: https://arxiv.org/abs/1312.7872. URL: https://dx.doi.org/10.1088/0034-4885/77/9/096302, doi:10.1088/0034-4885/77/9/096302.</p> </li> <li> <p>Alessandro Roggero, Andy C. Y. Li, Joseph Carlson, Rajan Gupta, and Gabriel N. Perdue. Quantum computing for neutrino-nucleus scattering. Physical Review D, 101:074038, 4 2020. arXiv: https://arxiv.org/abs/1911.06368. URL: https://link.aps.org/doi/10.1103/PhysRevD.101.074038, doi:10.1103/PhysRevD.101.074038.</p> </li> <li> <p>Michael Bender, R\u00e9mi Bernard, George Bertsch, Satoshi Chiba, Jacek Dobaczewski, No\u00ebl Dubray, Samuel A Giuliani, Kouichi Hagino, Denis Lacroix, Zhipan Li, Piotr Magierski, Joachim Maruhn, Witold Nazarewicz, Junchen Pei, Sophie P\u00e9ru, Nathalie Pillet, J\u00f8rgen Randrup, David Regnier, Paul-Gerhard Reinhard, Luis M Robledo, Wouter Ryssens, Jhilam Sadhukhan, Guillaume Scamps, Nicolas Schunck, C\u00e9dric Simenel, Janusz Skalski, Ionel Stetcu, Paul Stevenson, Sait Umar, Marc Verriere, Dario Vretenar, Micha\u0142 Warda, and Sven \u00c5berg. Future of nuclear fission theory. Journal of Physics G: Nuclear and Particle Physics, 47(11):113002, 10 2020. arXiv: https://arxiv.org/abs/2005.10216. URL: https://dx.doi.org/10.1088/1361-6471/abab4f, doi:10.1088/1361-6471/abab4f.</p> </li> <li> <p>Petr Navr\u00e1til and Sofia Quaglioni. Ab initio nuclear reaction theory with applications to astrophysics. In Handbook of Nuclear Physics, pages 1\u201346. Springer, 2022. doi:10.1007/978-981-15-8818-1\\_7-1.</p> </li> <li> <p>Paul D Stevenson. Comments on quantum computing in nuclear physics. International Journal of Unconventional Computing, 2023. URL: https://openresearch.surrey.ac.uk/esploro/outputs/other/Comments-on-Quantum-Computing-in-Nuclear/99641066502346.</p> </li> <li> <p>Lin Lin and Yu Tong. Near-optimal ground state preparation. Quantum, 4:372, 2020. arXiv: https://arxiv.org/abs/2002.12508. doi:10.22331/q-2020-12-14-372.</p> </li> <li> <p>Kianna Wan and Isaac Kim. Fast digital methods for adiabatic state preparation. arXiv: https://arxiv.org/abs/2004.04164, 2020.</p> </li> <li> <p>P. Gysbers, G. Hagen, J. D. Holt, G. R. Jansen, T. D. Morris, P. Navr\u00e1til, T. Papenbrock, S. Quaglioni, A. Schwenk, S. R. Stroberg, and K. A. Wendt. Discrepancy between experimental and theoretical \u03b2-decay rates resolved from first principles. Nature Physics, 15(5):428\u2013431, 5 2019. arXiv: https://arxiv.org/abs/1903.00047. URL: https://doi.org/10.1038/s41567-019-0450-7, doi:10.1038/s41567-019-0450-7.</p> </li> <li> <p>Seunghoon Lee, Joonho Lee, Huanchen Zhai, Yu Tong, Alexander M. Dalzell, Ashutosh Kumar, Phillip Helms, Johnnie Gray, Zhi-Hao Cui, Wenyuan Liu, Michael Kastoryano, Ryan Babbush, John Preskill, David R. Reichman, Earl T. Campbell, Edward F. Valeev, Lin Lin, and Garnet Kin-Lic Chan. Evaluating the evidence for exponential quantum advantage in ground-state quantum chemistry. Nature Communications, 14(1):1952, 2023. arXiv: https://arxiv.org/abs/2208.02199. URL: https://doi.org/10.1038/s41467-023-37587-6, doi:10.1038/s41467-023-37587-6.</p> </li> <li> <p>E. F. Dumitrescu, A. J. McCaskey, G. Hagen, G. R. Jansen, T. D. Morris, T. Papenbrock, R. C. Pooser, D. J. Dean, and P. Lougovski. Cloud quantum computing of an atomic nucleus. Physical Review Letters, 120:210501, 5 2018. arXiv: https://arxiv.org/abs/1801.03897. URL: https://link.aps.org/doi/10.1103/PhysRevLett.120.210501, doi:10.1103/PhysRevLett.120.210501.</p> </li> <li> <p>Hsuan-Hao Lu, Natalie Klco, Joseph M. Lukens, Titus D. Morris, Aaina Bansal, Andreas Ekstr\u00f6m, Gaute Hagen, Thomas Papenbrock, Andrew M. Weiner, Martin J. Savage, and Pavel Lougovski. Simulations of subatomic many-body physics on a quantum frequency processor. Physical Review A, 100:012320, 7 2019. arXiv: https://arxiv.org/abs/1810.03959. URL: https://link.aps.org/doi/10.1103/PhysRevA.100.012320, doi:10.1103/PhysRevA.100.012320.</p> </li> <li> <p>I. Stetcu, A. Baroni, and J. Carlson. Variational approaches to constructing the many-body nuclear ground state for quantum computing. Physical Review C, 105:064308, 6 2022. arXiv: https://arxiv.org/abs/2110.06098. URL: https://link.aps.org/doi/10.1103/PhysRevC.105.064308, doi:10.1103/PhysRevC.105.064308.</p> </li> </ol>"},{"location":"areas-of-application/nuclear-and-particle-physics/quantum-field-theories/","title":"Quantum field theories","text":""},{"location":"areas-of-application/nuclear-and-particle-physics/quantum-field-theories/#overview","title":"Overview","text":"<p>We seek the static and dynamic properties of quantum field theories, specifically gauge field theories and scalar field theories. Gauge field theories describe the interactions between matter and/or gauge degrees of freedom, and can be classified by their symmetry groups, such as U\\((1)\\) (describing quantum electrodynamics), SU\\((2)\\) (the weak interaction), and SU\\((3)\\) (quantum chromodynamics). Scalar field theories describe interactions between scalar fields, such as the Higgs field or \\(\\phi^4\\) theory.</p><p>Interacting quantum field theories are typically not analytically solvable, and techniques such as perturbation theory are only accurate in some parameter regimes. For example, low energies of quantum chromodynamics (QCD), which is the regime of quark confinement and hadron formation, cannot be treated perturbatively. As such, complex scattering processes at particle accelerators are currently treated with a combination of first-principles calculations and approximate phenomenological methods.</p><p>To tackle quantum field theories numerically from first principles, lattice field theory is employed. However, lattice field theory is computationally expensive on classical devices (either due to the size of the Hilbert space in Hamiltonian formulations, or due to the sign-problem present in Lagrangian formulations tackled via Monte Carlo methods). As such, there have been a number of proposals to use quantum computers for calculating the static and dynamic properties of lattice field theories. For further background see [1, 2, 3] and references therein.</p>"},{"location":"areas-of-application/nuclear-and-particle-physics/quantum-field-theories/#actual-end-to-end-problems-solved","title":"Actual end-to-end problem(s) solved","text":"<p>We focus on the case of lattice gauge field theories in the Hamiltonian formulation, which explicitly separates temporal and spatial degrees of freedom [4]. We discretize \\(d\\)-dimensional space using an \\(L^d\\) lattice (noncubic lattices can also be used). Matter degrees of freedom (e.g. fermions, quarks) are placed on the vertices of the lattice. Gauge degrees of freedom (e.g. the value of the electromagnetic field) are placed on the links between lattice sites. Dynamical simulations proceed by initializing the system in a desired state [5], performing time evolution under the Hamiltonian, and measuring relevant observables. Static simulations aim to prepare a state of interest, such as the ground state of a collection of quarks representing a composite hadron, the binding energy of which can then be measured.</p><p>The measured observable values may be incorporated as part of a larger computation; for example, accurate scattering matrix elements may be used in a phenomenological model of complex scattering processes studied at particle accelerators [6].</p>"},{"location":"areas-of-application/nuclear-and-particle-physics/quantum-field-theories/#dominant-resource-costcomplexity","title":"Dominant resource cost/complexity","text":"<p>We will focus predominantly on the simulation of dynamics, as the majority of studies to date have considered this application. We have \\(N=L^d\\) lattice sites. In the standard formulation, we allocate one qubit per fermion (or antifermion) type per lattice site. Each gauge degree of freedom (one in U\\((1)\\), three in SU\\((2)\\), eight in SU\\((3)\\)) requires its own register associated with each edge between lattice sites. The values of the gauge degrees of freedom are encoded in binary, up to a maximum cutoff value \\(\\Lambda\\), so the corresponding register requires \\(\\log(\\Lambda)\\) qubits. It was shown in [7] that for time evolution performed with fixed lattice spacing, the cutoff can be set as \\(\\Lambda = \\Lambda_0 + \\widetilde{\\mathcal{O}}\\left( T \\mathrm{polylog}(N/\\epsilon) \\right)\\), where \\(\\Lambda_0\\) is the maximum initial value of the gauge fields, \\(T\\) is the time evolution duration, and \\(\\epsilon\\) is the resulting error in the final state. Hence, the overall number of qubits required to store the state of the system scales as </p>\\[\\begin{equation} \\mathcal{O}\\left( L^d \\log\\left( \\Lambda_0 + T \\mathrm{polylog}\\left(\\frac{L^d}{\\epsilon} \\right) \\right) \\right). \\end{equation}\\]<p>Algorithms for implementing time evolution under lattice gauge field theory Hamiltonians are presented in [7, 8, 9, 10]. It is necessary to maintain gauge-invariance during the simulation, which can be achieved either by the choice of formulation, or by actively protecting symmetries. As an example of the former option, one can calculate the desired Hamiltonian matrix elements on the fly using Clebsch\u2013Gordon coefficients [11], but this is expensive in terms of elementary quantum operations [9]. The algorithm of [9] yielded an asymptotic complexity of approximately </p>\\[\\begin{equation} \\label{Eq:LGTscaling} \\widetilde{\\mathcal{O}}\\left( \\frac{(T L^3)^{3/2} \\Lambda}{\\epsilon^{1/2}} \\right) \\end{equation}\\]<p>for performing time evolution for time \\(T\\) to accuracy \\(\\epsilon\\).</p>"},{"location":"areas-of-application/nuclear-and-particle-physics/quantum-field-theories/#existing-error-corrected-resource-estimates","title":"Existing error corrected resource estimates","text":"<p>The number of T gates required to simulate instances of the lattice Schwinger model (U\\((1)\\) lattice gauge field theory in \\(d=1\\) with both matter and gauge degrees of freedom) was studied in [8]. That work considered the resources required to perform Trotterized time evolution and estimate the electron-positron pair density. The most complex simulations analyzed (64 lattice sites, cutoff of \\(\\Lambda=8\\)) required \\(5 \\times 10^{13}\\) \\(T\\) gates per shot, and \\(333\\) logical qubits. Such a circuit would need to be repeated \\(\\mathcal{O}\\left( 1/\\epsilon^2 \\right)\\) times to estimate the pair density to accuracy \\(\\epsilon\\). Note that a simulation of the 64-site lattice Schwinger model with \\(\\Lambda=8\\) is well within the range of classical simulations [12, 13].</p><p>Ref. [9] performed similar resource estimates for the simulation of dynamical quantities in U\\((1)\\), SU\\((2)\\), and SU\\((3)\\) lattice gauge field theory for \\(d=3\\). We present a selection of the resource estimates in Table 1. There are large logarithmic and constant factors hidden by the big-\\(\\mathcal{O}\\left( \\cdot \\right)\\) scaling in Eq. \\(\\eqref{Eq:LGTscaling}\\); for simulating heavy ion collisions, the asymptotic expression yields estimates of \\(10^{15.5}\\) gates, considerably smaller than the SU\\((3)\\) estimate in Table 1. The large constant factors present in these resource estimates stem from the use of quantum arithmetic (for example, constituting 99.998% of the gate count in the hadronic tensor calculation [9]), which is particularly prevalent in the SU\\((2)\\) and SU\\((3)\\) simulations. Nevertheless, any implementation scaling as \\(\\Omega(TL^3 \\Lambda)\\) already pays a factor of \\(10^{10}\\) for \\(T=L=\\Lambda=100\\), highlighting the potentially large resource counts of simulating quantum field theories. In addition, these resource estimates only consider the cost of time evolution, not the additional overheads of initial state preparation and observable estimation.</p> <p></p> Simulation Parameters QFT #Logical qubits #\\(T\\) gates Computing transport coefficients (relevant to the study of quark-gluon plasmas) \\(\\begin{gathered}L=10, T=1\\\\ \\Lambda=10, \\epsilon=10^{-8}\\end{gathered}\\) \\(\\begin{gathered}\\mathrm{U}(1)\\\\\\mathrm{SU}(3)\\end{gathered}\\) \\(\\begin{gathered}10^4\\\\10^5\\end{gathered}\\) \\(\\begin{gathered}10^{17}\\\\10^{49}\\end{gathered}\\) Simulation of heavy ion collisions \\(\\begin{gathered}L=100, T=10\\\\ \\Lambda=10, \\epsilon=10^{-8}\\end{gathered}\\) \\(\\begin{gathered}\\mathrm{U}(1)\\\\ \\mathrm{SU}(3)\\end{gathered}\\) \\(\\begin{gathered}10^7\\\\ 10^{8}\\end{gathered}\\) \\(\\begin{gathered}10^{23}\\\\ 10^{55}\\end{gathered}\\) Computing hadronic tensor of the proton \\(\\begin{gathered}L=20, T=8000\\\\ \\Lambda=10, \\epsilon=10^{-8} \\end{gathered}\\) \\(\\mathrm{SU}(3)\\) \\(10^6\\) \\(10^{56}\\) <p>Table 1: Resource estimates from [9] for simulation of a range of problems. The estimates consider time evolution for time \\(T\\) of an \\(L \\times L \\times L\\) lattice, using a cutoff of \\(\\Lambda\\) for the gauge fields. The precision in the evolution is bounded by \\(\\epsilon\\). </p>"},{"location":"areas-of-application/nuclear-and-particle-physics/quantum-field-theories/#caveats","title":"Caveats","text":"<p>Discretization of the continuous field theory to the lattice setting introduces a number of nuances that are also present in classical approaches, but must be considered afresh in quantum calculations. As discussed in [14], discretization of the fermion field breaks the Lorentz invariance of the fermion kinetic term, which introduces unphysical additional flavors of fermions (known as the fermion doubling problem). This issue can be mitigated in several established ways, each with their own merits and drawbacks for quantum simulation. It is also necessary to carefully track other errors resulting from discretization and ensure that these vanish when scaling and extrapolating to the continuum limit [15].</p><p>As noted in [2, Sec. 6b] and [16], there are a number of possible bases that can be used for the gauge degrees of freedom, and it is currently unclear which choice is optimal for quantum simulation.</p>"},{"location":"areas-of-application/nuclear-and-particle-physics/quantum-field-theories/#comparable-classical-complexity-and-challenging-instance-sizes","title":"Comparable classical complexity and challenging instance sizes","text":"<p>The end-to-end scattering processes typically considered at particle accelerators are too complex to be solved from first principles and are tackled using a range of approximate techniques [6]. These calculations often include parameters obtained from first-principles lattice gauge theory calculations on simpler systems, and they typically proceed through a Lagrangian formulation, rather than a Hamiltonian formulation. This leads to Monte Carlo sampling of a path integral in Euclidean spacetime, the application of which to dynamical problems or static problems with high fermion density is limited by the fermionic sign problem. For example, it is challenging to compute parton distribution functions with classical methods [2]. Nevertheless, classical approaches have been very effective for static problems with lower fermion density; for a review of current state-of-the-art calculations and limitations see [17] and its companion whitepapers referenced therein.</p><p>Recent work has investigated the Hamiltonian formulation of lattice gauge theories (LGTs) using tensor network methods; see, for example, [12] (\\(d=2, L=16\\), U\\((1)\\) LGT with gauge field cutoff \\(\\Lambda=1\\)) and [13] (\\(d=3, L=8\\), U\\((1)\\) LGT with gauge field cutoff \\(\\Lambda=1\\)). Like quantum simulations, tensor network approaches are sign-problem free and so may be of interest in regimes out of reach of conventional Monte Carlo\u2013based approaches.</p>"},{"location":"areas-of-application/nuclear-and-particle-physics/quantum-field-theories/#speedup","title":"Speedup","text":"<p>For simulations with a sign problem, classical Monte Carlo methods are exponentially costly in system size. In addition, it was observed that the bond dimensions required for tensor network approaches increase rapidly with system size [13], suggesting the potential for exponential quantum speedups for dynamical problems. This suggestion is reinforced by the BQP-completeness of the simulation of certain field theoretic processes [18]. Nevertheless, the constant factors for quantum simulations of LGTs are currently high, and we require the ability to efficiently prepare initial states of interest.</p>"},{"location":"areas-of-application/nuclear-and-particle-physics/quantum-field-theories/#nisq-implementation","title":"NISQ implementation","text":"<p>There has been significant research on implementing simplified models of LGTs using analog quantum simulators such as cold atoms or trapped ions; see for example [19, 2] and references therein. There have also been works applying variational algorithms to LGTs, such as [20, 21, 22].</p>"},{"location":"areas-of-application/nuclear-and-particle-physics/quantum-field-theories/#outlook","title":"Outlook","text":"<p>Investigations into how quantum computers can be used to complement classical methods for simulating lattice field theories are still in their initial stages. While quantum computers can, in principle, efficiently simulate the complex scattering experiments performed in particle accelerators, the resources required to do so would be astronomical using currently known techniques. Future work must determine the best targets for quantum simulations, and work to reduce asymptotic scaling factors and constant prefactors. In particular, the qubit encoding (currently scaling as \\(\\mathcal{O}\\left( L^d \\right)\\) qubits for a lattice in \\(d\\) spatial dimensions with each dimension having \\(L\\) sites) means that a large number of logical qubits will likely be required for calculations of interest where, as illustrated by examples above, we may consider \\(L = 10\\)\u2013\\(100\\) to challenge classical approaches.</p>"},{"location":"areas-of-application/nuclear-and-particle-physics/quantum-field-theories/#bibliography","title":"Bibliography","text":"<ol> <li> <p>John Preskill. Simulating quantum field theory with a quantum computer. arXiv: https://arxiv.org/abs/1811.10085, 2019. doi:10.22323/1.334.0024.</p> </li> <li> <p>Christian W. Bauer, Zohreh Davoudi, A. Baha Balantekin, Tanmoy Bhattacharya, Marcela Carena, Wibe A. de Jong, Patrick Draper, Aida El-Khadra, Nate Gemelke, Masanori Hanada, Dmitri Kharzeev, Henry Lamm, Ying-Ying Li, Junyu Liu, Mikhail Lukin, Yannick Meurice, Christopher Monroe, Benjamin Nachman, Guido Pagano, John Preskill, Enrico Rinaldi, Alessandro Roggero, David I. Santiago, Martin J. Savage, Irfan Siddiqi, George Siopsis, David Van Zanten, Nathan Wiebe, Yukari Yamauchi, K\u00fcbra Yeter-Aydeniz, and Silvia Zorzetti. Quantum simulation for high-energy physics. PRX Quantum, 4:027001, 5 2023. arXiv: https://arxiv.org/abs/2204.03381. URL: https://link.aps.org/doi/10.1103/PRXQuantum.4.027001, doi:10.1103/PRXQuantum.4.027001.</p> </li> <li> <p>Yannick Meurice, Ryo Sakai, and Judah Unmuth-Yockey. Tensor lattice field theory for renormalization and quantum computing. Reviews of Modern Physics, 94:025005, 5 2022. arXiv: https://arxiv.org/abs/2010.06539. URL: https://link.aps.org/doi/10.1103/RevModPhys.94.025005, doi:10.1103/RevModPhys.94.025005.</p> </li> <li> <p>John B. Kogut. An introduction to lattice gauge theory and spin systems. Reviews of Modern Physics, 51:659\u2013713, 10 1979. URL: https://link.aps.org/doi/10.1103/RevModPhys.51.659, doi:10.1103/RevModPhys.51.659.</p> </li> <li> <p>Mohsen Bagherimehrab, Yuval R. Sanders, Dominic W. Berry, Gavin K. Brennen, and Barry C. Sanders. Nearly optimal quantum algorithm for generating the ground state of a free quantum field theory. PRX Quantum, 3:020364, 6 2022. arXiv: https://arxiv.org/abs/2110.05708. URL: https://link.aps.org/doi/10.1103/PRXQuantum.3.020364, doi:10.1103/PRXQuantum.3.020364.</p> </li> <li> <p>Thomas Gehrmann and Bogdan Malaescu. Precision qcd physics at the lhc. Annual Review of Nuclear and Particle Science, 72(1):233\u2013258, 2022. arXiv: https://arxiv.org/abs/2111.02319. URL: https://doi.org/10.1146/annurev-nucl-101920-014923, arXiv:https://doi.org/10.1146/annurev-nucl-101920-014923, doi:10.1146/annurev-nucl-101920-014923.</p> </li> <li> <p>Yu Tong, Victor V. Albert, Jarrod R. McClean, John Preskill, and Yuan Su. Provably accurate simulation of gauge theories and bosonic systems. Quantum, 6:816, 9 2022. arXiv: https://arxiv.org/abs/2110.06942. URL: https://doi.org/10.22331/q-2022-09-22-816, doi:10.22331/q-2022-09-22-816.</p> </li> <li> <p>Alexander F. Shaw, Pavel Lougovski, Jesse R. Stryker, and Nathan Wiebe. Quantum algorithms for simulating the lattice schwinger model. Quantum, 4:306, 8 2020. arXiv: https://arxiv.org/abs/2002.11146. URL: https://doi.org/10.22331/q-2020-08-10-306, doi:10.22331/q-2020-08-10-306.</p> </li> <li> <p>Angus Kan and Yunseong Nam. Lattice quantum chromodynamics and electrodynamics on a universal quantum computer. arXiv: https://arxiv.org/abs/2107.12769, 2021.</p> </li> <li> <p>Abhishek Rajput, Alessandro Roggero, and Nathan Wiebe. Hybridized methods for quantum simulation in the interaction picture. Quantum, 6:780, 2022. arXiv: https://arxiv.org/abs/2109.03308. doi:10.22331/q-2022-08-17-780.</p> </li> <li> <p>Tim Byrnes and Yoshihisa Yamamoto. Simulating lattice gauge theories on a quantum computer. Physical Review A, 73:022328, 2 2006. arXiv: https://arxiv.org/abs/quant-ph/0510027. URL: https://link.aps.org/doi/10.1103/PhysRevA.73.022328, doi:10.1103/PhysRevA.73.022328.</p> </li> <li> <p>Timo Felser, Pietro Silvi, Mario Collura, and Simone Montangero. Two-dimensional quantum-link lattice quantum electrodynamics at finite density. Physical Review X, 10:041040, 11 2020. arXiv: https://arxiv.org/abs/1911.09693. URL: https://link.aps.org/doi/10.1103/PhysRevX.10.041040, doi:10.1103/PhysRevX.10.041040.</p> </li> <li> <p>Giuseppe Magnifico, Timo Felser, Pietro Silvi, and Simone Montangero. Lattice quantum electrodynamics in (3+1)-dimensions at finite density with tensor networks. Nature Communications, 12(1):3600, 6 2021. arXiv: https://arxiv.org/abs/2011.10658. URL: https://doi.org/10.1038/s41467-021-23646-3, doi:10.1038/s41467-021-23646-3.</p> </li> <li> <p>Simon V. Mathis, Guglielmo Mazzola, and Ivano Tavernelli. Toward scalable simulations of lattice gauge theories on quantum computers. Physical Review D, 102:094501, 11 2020. arXiv: https://arxiv.org/abs/2005.10271. URL: https://link.aps.org/doi/10.1103/PhysRevD.102.094501, doi:10.1103/PhysRevD.102.094501.</p> </li> <li> <p>Stephen P. Jordan, Keith S. M. Lee, and John Preskill. Quantum algorithms for quantum field theories. Science, 336(6085):1130\u20131133, 2012. arXiv: https://arxiv.org/abs/1111.3633. URL: https://www.science.org/doi/abs/10.1126/science.1217069, arXiv:https://www.science.org/doi/pdf/10.1126/science.1217069, doi:10.1126/science.1217069.</p> </li> <li> <p>Anthony Ciavarella, Natalie Klco, and Martin J. Savage. Trailhead for quantum simulation of su(3) yang\u2013mills lattice gauge theory in the local multiplet basis. Physical Review D, 103:094501, 5 2021. arXiv: https://arxiv.org/abs/2101.10227. URL: https://link.aps.org/doi/10.1103/PhysRevD.103.094501, doi:10.1103/PhysRevD.103.094501.</p> </li> <li> <p>B\u00e1lint Jo\u00f3, Chulwoo Jung, Norman H. Christ, William Detmold, Robert G. Edwards, Martin Savage, and Phiala Shanahan. Status and future perspectives for lattice gauge theory calculations to the exascale and beyond. The European Physical Journal A, 55(11):199, 11 2019. arXiv: https://arxiv.org/abs/1904.09725. URL: https://doi.org/10.1140/epja/i2019-12919-7, doi:10.1140/epja/i2019-12919-7.</p> </li> <li> <p>Stephen P. Jordan, Hari Krovi, Keith S. M. Lee, and John Preskill. Bqp-completeness of scattering in scalar quantum field theory. Quantum, 2:44, 1 2018. arXiv: https://arxiv.org/abs/1703.00454. URL: https://doi.org/10.22331/q-2018-01-08-44, doi:10.22331/q-2018-01-08-44.</p> </li> <li> <p>I. M. Georgescu, S. Ashhab, and Franco Nori. Quantum simulation. Reviews of Modern Physics, 86(1):153\u2013185, 2014. arXiv: https://arxiv.org/abs/1308.6253. arXiv:1308.6253, doi:10.1103/RevModPhys.86.153.</p> </li> <li> <p>C. Kokail, C. Maier, R. van Bijnen, T. Brydges, M. K. Joshi, P. Jurcevic, C. A. Muschik, P. Silvi, R. Blatt, C. F. Roos, and P. Zoller. Self-verifying variational quantum simulation of lattice models. Nature, 569(7756):355\u2013360, 5 2019. arXiv: https://arxiv.org/abs/1810.03421. URL: https://doi.org/10.1038/s41586-019-1177-4, doi:10.1038/s41586-019-1177-4.</p> </li> <li> <p>Yasar Y. Atas, Jinglei Zhang, Randy Lewis, Amin Jahanpour, Jan F. Haase, and Christine A. Muschik. Su(2) hadrons on a quantum computer via a variational approach. Nature Communications, 12(1):6499, 11 2021. arXiv: https://arxiv.org/abs/2102.08920. URL: https://doi.org/10.1038/s41467-021-26825-4, doi:10.1038/s41467-021-26825-4.</p> </li> <li> <p>Junyu Liu, Zimu Li, Han Zheng, Xiao Yuan, and Jinzhao Sun. Towards a variational jordan\u2013lee\u2013preskill quantum algorithm. Machine Learning: Science and Technology, 3(4):045030, 12 2022. arXiv: https://arxiv.org/abs/2109.05547. doi:https://dx.doi.org/10.1088/2632-2153/aca06b.</p> </li> </ol>"},{"location":"areas-of-application/quantum-chemistry/electronic-structure-problem/","title":"Electronic structure problem","text":""},{"location":"areas-of-application/quantum-chemistry/electronic-structure-problem/#overview","title":"Overview","text":"<p>We seek the energy eigenstates (or thermal states) of the Hamiltonian used to describe the electrons in molecules or material systems. The electrons interact with each other, in addition to fields produced by the nuclei (which are typically assumed to be fixed in position, and classical) and any external applied fields.</p><p>In simulations of a finite sized system, there is not a clear distinction between a \"molecule\" and a \"material\"\u2014materials may be viewed as an extended molecule, typically with a repeating underlying atomic structure. In materials we are additionally concerned with extrapolating finite size properties to the thermodynamic limit by repeating the simulation at a range of system sizes. This enables the measurement of thermodynamic properties, such as phase diagrams. For molecular systems, we are interested in measuring microscopic properties, such as excitation energies, reaction rates, dipole moments, or nuclear forces.</p><p>One may also consider time evolution under the electronic structure Hamiltonian; this is a less well-studied problem in both classical and quantum settings, likely due to the high costs of classical simulations. As such, we will predominantly focus on static properties, commenting on dynamics simulations where relevant.</p>"},{"location":"areas-of-application/quantum-chemistry/electronic-structure-problem/#actual-end-to-end-problems-solved","title":"Actual end-to-end problem(s) solved","text":"<p>The Hamiltonian of a system consisting of \\(K\\) nuclei and \\(\\eta\\) electrons interacting via the Coulomb interaction is (in atomic units) </p>\\[\\begin{align} H = -\\sum_{i=1}^\\eta \\frac{(\\nabla_{i})^2}{2} - \\sum_{I=1}^K \\frac{(\\nabla_{I})^2}{2M_I} - \\sum_{i,I}\\frac{Z_I}{|r_{i}-R_{I}|} +\\frac{1}{2}\\sum_{i\\neq j}\\frac{1}{|r_{i}-r_{j}|} + \\frac{1}{2}\\sum_{I\\neq J}\\frac{Z_IZ_J}{|R_{I}-R_{J}|} \\end{align}\\]<p>where \\(\\nabla\\) is the derivative operator, \\(r_{i}\\) gives the position of the \\(i\\)th electron, and \\(R_{I}\\) and \\(Z_I\\) give the position and charge of the \\(I\\)th nucleus. It is often appropriate to make the Born\u2013Oppenheimer approximation, fixing the positions of the nuclei, which are treated as classical particles. The resulting electronic Hamiltonian at a fixed nuclear configuration is given by </p>\\[\\begin{equation} \\label{Eq:BornOppElectronic} H(\\{R_{I}\\}) = -\\sum_i\\frac{(\\nabla_{i})^2}{2} - \\sum_{i,I}\\frac{Z_I}{|r_{i}-R_{I}|} + \\frac{1}{2}\\sum_{i\\neq j}\\frac{1}{|r_{i}-r_{j}|} + V(\\{R_{I}\\}) \\end{equation}\\]<p>where \\(V(\\{R_{I}\\})\\) is the constant offset from the nuclear repulsion energy. This Hamiltonian can be projected onto a basis set \\(\\{\\phi_i(r)\\}_{i=1}^N\\) of electron spin orbital functions or grid points, and solved for the electronic eigenstates \\(\\ket{E_i}\\) or thermal state \\(\\rho \\propto e^{-\\beta H}\\). We note that for many molecules, the ground state of the electronic structure Hamiltonian is a good approximation for the thermal state at room temperature. This can be contrasted with the vibrational structure of molecules, where excited states are also populated at room temperature. When simulating dynamics, it is necessary to use a basis set that is sufficiently flexible (or adaptive) to accurately describe the states at all times (for example, many chemical basis sets are highly optimized for ground state calculations and so are less suitable for dynamics calculations).</p><p>The electronic energy is the largest contribution to the energy of molecular/material systems in ambient conditions, and dictates the equilibrium structure and motion of the nuclei. As a result, the electronic energy eigenstates (or thermal states) often provide a good description of a wide range of system properties. Preparing the desired electronic state for a given nuclear configuration is typically the first step in learning properties of the system. We then measure the expectation values of observables with respect to these states. Properties of interest for molecular systems include:</p><ul> <li>Energy values, potentially across a range of nuclear configurations (for electronic excitation energies at a fixed nuclear geometry, determining molecular geometries by computing the electronic ground state energy at different geometries, and finding reaction pathways &amp; rates by computing energy differences between a sequence of geometries involved in a reaction).</li> <li>Determining transition probabilities between states (for reactions and optical properties).</li> <li>Differential changes in electronic energy in response to an applied field, for example, electronic or magnetic dipole moments, polarizability.</li> <li>Calculating forces on the nuclei, for use in molecular dynamics calculations (used in a range of applications, including protein folding and calculating drug molecule binding affinities).</li> </ul><p>Properties of interest for materials include:</p><ul> <li>Energy densities for given system parameters (to determine phase diagrams).</li> <li>Thermodynamic properties (magnetization, thermal/electrical conductivity, bulk modulus).</li> <li>Particle densities and correlation functions between positions.</li> </ul><p>In order to understand how these observables vary as the system parameters (i.e. nuclear positions, atomic doping, temperature, applied field etc.) are changed, the desired state may need to be prepared and measured a number of times.</p><p>In dynamics simulations, one may consider how the system evolves in response to a perturbation such as that induced by an ultrafast laser pulse [1, 2, 3], or in particle scattering interactions.</p>"},{"location":"areas-of-application/quantum-chemistry/electronic-structure-problem/#dominant-resource-costcomplexity","title":"Dominant resource cost/complexity","text":""},{"location":"areas-of-application/quantum-chemistry/electronic-structure-problem/#mapping-the-problem-to-qubits","title":"Mapping the problem to qubits:","text":"<p>We discretize the electron positions by projecting onto a basis of spin orbitals. The discretization error typically decays as \\(1/N\\) where \\(N\\) is the number of spin orbitals used [4, 5] and is limited by the resolution of singularities in the Coulomb interaction at charge coalescences. A variety of functional forms have been considered for the electron orbitals (see Table 1). The optimal choice will be system dependent and must consider:</p><ul> <li>The resolution of the orbital (improved by matching the character of local vs delocalized physics in the system to that of the orbital).</li> <li>The cost of computing the Hamiltonian, either in classical precomputation or (if required) coherently on a quantum device (see \"Accessing the Hamiltonian,\" below).</li> <li>The properties of the resulting Hamiltonian (number of terms, 1-norm, locality of terms, etc.) which determine the cost of accessing the Hamiltonian in algorithms.</li> </ul><p>We can represent electronic states on a quantum computer using either first or second quantized representations.</p><ul> <li>For \\(\\eta\\) electrons in \\(N\\) spin orbitals, first quantization uses \\(\\eta\\) registers, which each contain \\(\\log_2(N)\\) qubits; each register enumerates which orbital its corresponding electron is in, and the wavefunction must then be antisymmetrized to respect fermionic constraints [6]. The Hamiltonian of Eq. \\(\\eqref{Eq:BornOppElectronic}\\) in first quantization can be written as  \\[\\begin{equation} H = \\sum_\\alpha^\\eta \\sum_{i,j}^N h_{ij} \\ket{i}\\bra{j}_\\alpha + \\frac{1}{2} \\sum_{\\alpha \\neq \\beta}^\\eta \\sum_{i,j,k,l}^N h_{ijkl} \\ket{i}\\bra{l}_\\alpha \\otimes \\ket{j}\\bra{k}_\\beta \\end{equation}\\] <p>with one- and two-electron integrals </p> \\[\\begin{align} h_{ij} &amp; = \\int dr \\phi_i^*(r) \\left(-\\frac{(\\nabla)^2}{2} - \\sum_I \\frac{Z_I}{|r - R_I|} \\right) \\phi_j(r) \\\\   h_{ijkl} &amp; = \\int dr_1 dr_2 \\frac{\\phi_i^*(r_1) \\phi_j^*(r_2) \\phi_k(r_2) \\phi_l(r_1)}{|r_1 - r_2|}. \\end{align}\\] </li> <li>In second quantization, antisymmetry is stored in the operators, which obey fermionic anticommutation relations. The Hamiltonian of Eq. \\(\\eqref{Eq:BornOppElectronic}\\) in second quantization can be written as  \\[\\begin{equation} H = \\sum_{i,j}^N h_{ij} a_i^\\dag a_j + \\frac{1}{2} \\sum_{i,j,k,l}^N h_{ijkl} a_i^\\dag a_j^\\dag a_k a_l. \\end{equation}\\] <p>Under the commonly used Jordan\u2013Wigner mapping (other mappings have also been studied, see [7] for discussion) we require \\(N\\) qubits, where each qubit stores the occupancy of the corresponding spin orbital. These mappings induce a mapping of the Hamiltonian (and other observables) to qubit operators.</p> </li> </ul> <p></p> Representation Gaussians Plane waves Bloch/Wannier functions Grids First quantized [8] <sup>1</sup> [9, 10] Not yet studied [11, 12, 10] Second quantized [13] [14] [15, 16] [14, Appendix A] <p>Table 1: Representative references (chosen based on their discussion of their choice of representation) showing the use of different basis functions in quantum algorithms for the electronic structure problem. Note, this is not intended to be a complete list of all works that have used these basis sets. </p>"},{"location":"areas-of-application/quantum-chemistry/electronic-structure-problem/#accessing-the-hamiltonian","title":"Accessing the Hamiltonian:","text":"<p>Quantum algorithms for the electronic structure problem require access to the Hamiltonian. This is typically provided by block-encoding or Hamiltonian simulation. For some approaches, it may be necessary to compute Hamiltonian coefficients (molecular integrals) or matrix elements coherently [12, 8, 17, 18, 9, 10], or load them from a quantum memory [19, 20, 21]. As this access is often a dominant contribution to the cost of quantum algorithms, significant effort has been spent on methods of factorizing the electronic structure Hamiltonian to reduce the resources required for accessing it coherently [22, 19, 20, 21, 16]. Some data-loading routines provide the ability to trade gate count for additional ancilla qubits, leading to a larger logical qubit count than required to store the system wavefunction (see the section on loading classical data for additional details).</p>"},{"location":"areas-of-application/quantum-chemistry/electronic-structure-problem/#state-preparation","title":"State preparation:","text":"<p>Solving the electronic structure problem on a quantum computer reduces to the task of preparing a desired state, and measuring observables. The state to be prepared is typically an energy eigenstate, a thermal state, or a time evolved state.</p><ul> <li>Energy eigenstates: In the following discussion, we refer to the overlap \\(\\gamma = |\\braket{\\psi}{E_j}|\\) between a desired eigenstate \\(\\ket{E_j}\\) and a given initial state \\(\\ket{\\psi}\\), and the minimum gap \\(\\Delta\\) between the desired energy eigenvalue and other energy eigenvalues. Below, we list several methods for preparing energy eigenstates, or approximations to them.</li> <li>Approximate eigenstates: Approximate eigenstates obtained from a classical calculation can be prepared as quantum trial states using the methods of [23, 24], which scale as \\(\\mathcal{O}\\left( ND \\right)\\), where \\(D\\) is the number of Slater determinants in the trial state. These states can be used as input for the methods below.</li> <li>Eigenstate filtering: Methods such as those in [25, 26] filter out undesired eigenstates using spectral window functions applied via quantum singular value transformation (QSVT) to a block-encoding of the Hamiltonian. The complexity to prepare the ground state (to infidelity \\(\\epsilon\\), with failure probability less than \\(\\theta\\)) using this approach scales as \\(\\widetilde{\\mathcal{O}}\\left( \\frac{\\alpha}{\\gamma \\Delta} \\log(\\theta^{-1} \\epsilon^{-1}) \\right)\\) calls to an \\((\\alpha, m, 0)\\)-block-encoding of the Hamiltonian (where \\(\\alpha \\geq \\nrm{H}\\) is a normalization factor of the block-encoding). For comparison to related methods, we refer the reader to [27, 26].</li> <li>Adiabatic state preparation (ASP): ASP can be used to prepare a target eigenstate (typically the ground state) by evolving from the corresponding easy-to-prepare eigenstate of an initial Hamiltonian \\(H(0)\\) to the full electronic structure Hamiltonian \\(H(1)\\). Time evolution can be implemented using algorithms for Hamiltonian simulation. The total evolution time is typically chosen according to the heuristic \\(T \\gg \\max_{0 \\leq s \\leq 1} \\nrm{\\frac{dH}{ds}} / \\Delta(s)^2\\) where \\(s\\) describes the adiabatic path \\(H(s)\\) and \\(\\Delta(s)\\) is the spectral gap of \\(H(s)\\). It is difficult to analytically bound this complexity for molecular systems (see e.g., [28]) motivating numerical studies on small molecules [29, 30, 31, 32].</li> <li>Quantum phase estimation (QPE): The above techniques all provide methods of preparing approximate eigenstates, in some cases using promises on the gap \\(\\Delta\\), or by exploiting pre-existing knowledge of the energy eigenvalue. Given an approximate eigenstate, we can use QPE to project into the desired eigenstate and provide an estimate of the eigenenergy. QPE makes \\(\\mathcal{O}\\left( \\gamma^{-2} \\epsilon^{-1} \\right)\\) calls to a unitary \\(U\\) encoding the spectrum of the Hamiltonian, where \\(\\gamma = |\\braket{\\psi}{E_j}|\\) is the overlap between the state \\(\\ket{\\psi}\\) input to quantum phase estimation, and the desired energy eigenstate \\(\\ket{E_j}\\), and \\(\\epsilon\\) is the desired precision in the energy estimate. It is possible to improve the complexity to \\(\\mathcal{O}\\left( \\gamma^{-1} \\epsilon^{-1} \\right)\\) using amplitude amplification, or to \\(\\mathcal{O}\\left( \\gamma^{-2} \\Delta^{-1} + \\epsilon^{-1} \\right)\\) by exploiting knowledge of the gap \\(\\Delta\\) between the energy eigenstates to perform rejection sampling [6]. The unitary encoding the Hamiltonian is typically either \\(U \\approx e^{-iHt}\\) (the approximation error must be balanced against the error from QPE) implemented via Hamiltonian simulation, or a quantum walk operator \\(W\\) which acts like \\(e^{i\\arccos{H}}\\) and can be implemented via qubitization [33, 6] (note that if phase estimation is performed on a qubitization operator, the output state will have the form \\(\\frac{1}{\\sqrt{2}}(\\ket{E_j}\\ket{0} \\pm \\ket{\\phi_j 0^\\perp})\\), which reduces the success probability of obtaining the desired eigenstate by 50% [6]). The costs to implement \\(U\\) are inherited from the method used, based on the properties (commutativity, locality, number of terms, 1-norm, cost of coherently calculating coefficients) of the Hamiltonian in the chosen spin orbital basis.</li> <li>Thermal states: Several quantum algorithms have been proposed for preparing thermal states [34, 35, 36, 37]. The most efficient algorithms typically make repeated calls to a block-encoding of the Hamiltonian. The complexity of these methods for concrete electronic structure problems of interest has not yet been determined. Thermal states could also be used as an approximation to the ground state, by choosing the temperature to be sufficiently low compared to the gap between the ground and first excited state [37].</li> <li>Time evolved states: A time evolved state can be prepared using Hamiltonian simulation algorithms, up to an error \\(\\epsilon\\). While many proposed quantum algorithms for chemistry simulation have considered using Hamiltonian simulation as a subroutine in quantum phase estimation, these have typically considered the use of Gaussian basis functions, which are not sufficiently flexible to accurately describe the time dynamics of the electrons. Classical algorithms for this task typically consider grid- or plane wave\u2013based methods for dynamics simulations. Reference [38] compared the costs of Trotter-based methods [12] and prior work in the interaction picture [18, 9, 39] against classical mean-field methods, finding large polynomial speedups, even for this apples-to-oranges comparison.</li> </ul>"},{"location":"areas-of-application/quantum-chemistry/electronic-structure-problem/#measuring-observables","title":"Measuring observables:","text":"<p>In a fault-tolerant computation, it is preferable to measure observables through phase estimation-like approaches, rather than direct measurement averaging, as the former is asymptotically more efficient and can be made robust to logical errors through repetition and majority voting. Measurement schemes have been developed which achieve this using overlap estimation [40] (which can be viewed as a special case of amplitude estimation) or the approach of [41, 42] based on the quantum gradient estimation algorithm of [43]. Both approaches require access to a state preparation unitary \\(U_\\psi\\), and its inverse<sup>2</sup>. The algorithm based on overlap estimation can be formulated as performing amplitude estimation on \\(U_O\\), a unitary block-encoding of the observable \\(O\\) with subnormalization factor \\(\\alpha_O\\). The complexity to compute the expectation value to precision \\(\\epsilon\\) is \\(\\mathcal{O}\\left( \\alpha_O/\\epsilon \\right)\\) calls to \\(U_O\\) and \\(U_\\psi\\) (or the reflection \\(R_\\psi = I - 2 \\ket{\\psi}\\bra{\\psi}\\)) and their inverses. This approach has been considered in the context of measuring: correlation functions, density of states, and linear response properties (all in [44]), and energy gradients with respect to various parameters (which can be used to compute forces or dipole moments, and for which a range of estimation strategies are possible) [45, 46].</p><p>The gradient-based algorithm simultaneously computes the value of \\(M\\) (noncommuting) observables \\(O_j\\) by making \\(\\widetilde{\\mathcal{O}}\\left( M^{1/2}/\\epsilon \\right)\\) calls to \\(U_\\psi, U_\\psi^\\dag\\) (or \\(R_\\psi\\)) and either \\(\\widetilde{\\mathcal{O}}\\left( M^{3/2}/\\epsilon \\right)\\) calls to gates of the form \\(e^{i x O_j}\\) [41] or \\(\\widetilde{\\mathcal{O}}\\left( M/\\epsilon \\right)\\) calls to a block-encoding of the observables [42]. The algorithm also requires \\(\\mathcal{O}\\left( M \\log(1/\\epsilon) \\right)\\) additional qubits. This approach has been considered in the context of measuring nuclear forces [45], fermionic reduced density matrices [41] and dynamic correlation functions [41].</p>"},{"location":"areas-of-application/quantum-chemistry/electronic-structure-problem/#existing-error-corrected-resource-estimates","title":"Existing error corrected resource estimates","text":"<p>There are a large number of resource estimates for performing phase estimation to learn the ground state energies of molecular or material systems, which we list in Table 2 and Table 3. These resource estimates use compilation methods described in the fault-tolerant quantum computing section. We also note the existence of a software package that provides features for calculating the non-Clifford costs of quantum phase estimation for the electronic structure problem [47]. There are currently no results that provide resource estimates for solving a full end-to-end application (see caveats below).</p> <p></p> Molecule(s) References Number of Logical qubits Number of \\(T\\)/Toffoli gates FeMo-co(Nitrogen fixation) [28, 19, 20, 21, 48, 47] \\(2196\\)[21] \\(\\sim 193\\)[48] \\(3.2 \\times 10^{10}\\)[21]  \\(\\sim 5 \\times 10^{11}\\)\u00a0[48] Cytochrome P450(Biological drug metabolizing enzyme) [49] \\(1434\\) \\(7.8 \\times 10^{9}\\) Lithium-ionbattery molecules [50, 9] \\((10^4-10^5)\\) [50] (\\(2000 - 3000\\))\u00a0[9] \\((10^{12} - 10^{14})\\) [50] \u00a0 \\((10^{11} - 10^{12})\\)\u00a0[9] Chromium dimer [51] \\(\\sim 1300\\) \\(\\sim 10^{10}\\) Ruthenium catalyst(CO<sub>2</sub> fixation) [20] \\(\\sim 4000\\) \\(\\sim 3 \\times 10^{10}\\) Ibrutinib(drug molecule) [52] \\(2207\\) \\(1.1 \\times 10^{10}\\) <p>Table 2: Fault-tolerant resource estimates for quantum phase estimation applied to a range of molecular systems. The presented gate counts are for a single run of the phase estimation circuit. QPE must be run a number of times if the overlap is \\(\\leq 1\\), and to account for rounding errors in phase estimation [53]. The molecules presented can have different numbers of electrons, orbitals, and classical simulation complexities, and so the results may not be directly comparable, even within a single row of the table. </p> <p></p> Material(s) References Number of Logical qubits Number of \\(T\\)/Toffoli gates Homogeneous electron gas(Prototypical model) [54, 55, 56, 9] \\((1500-5000)\\)[9] \\(\\sim(100 - 1000)\\)\u00a0[54, 56] \\((10^9-10^{14})\\)[9]  \\(\\sim(10^8 - 10^{11})\\)\u00a0[54, 56] Lithium-ionbattery materials [57, 58, 16] (\\(2375 - 6652\\))[57]  \\(10^4\\) [58]   \\((10^5 - 10^6)\\)[16] (\\(5 \\times 10^{12} - 5 \\times 10^{14}\\)) [57]  \\(10^{15}\\)\u00a0[58] \\((10^{12} - 10^{14})\\)\u00a0[16] Condensed phase elementsLithium, Diamond, etc [54, 55] \\(128\\)\u00a0[55] \\((10^8 - 10^{11})\\)\u00a0[55] Transition metal catalystsNickel/Palladium Oxide [15] \\(10^4 - 10^5\\) \\(10^{10} - 10^{13}\\) <p>Table 3: Fault-tolerant resource estimates for quantum phase estimation applied to a range of material systems. The presented gate counts are for a single run of the phase estimation circuit. QPE must be run a number of times if the overlap is \\(\\leq 1\\), and to account for rounding errors in phase estimation [53]. The systems presented in a given row may be different chemical compounds, and/or can have different numbers of electrons, orbitals, and classical simulation complexities, and so the results may not be directly comparable. </p> <p>There have been comparatively few studies of the fault-tolerant resources required for the simulation of chemical dynamics. Recent work has computed the resources required to calculate the energy loss of charged particles moving through a medium (\"stopping power\\\"), as pertaining to nuclear fusion experiments [59]. End-to-end resource estimates were determined, including the costs of initial state preparation, measurement of observables, and repetitions across a range of parameters. The resource estimates for the end-to-end task ranged from \\(\\sim 2000\\) logical qubits and \\(\\mathcal{O}\\left( 10^{13} \\right)\\) Toffoli gates, to \\(\\sim 30000\\) logical qubits and \\(\\mathcal{O}\\left( 10^{17} \\right)\\) Toffoli gates.</p>"},{"location":"areas-of-application/quantum-chemistry/electronic-structure-problem/#caveats","title":"Caveats","text":"<p>Existing resource estimates typically consider only a single run of phase estimation and assume that we have access to the desired energy eigenstate. As outlined above, both phase estimation and eigenstate filtering scale as \\(\\Omega{\\gamma^{-1} \\Delta^{-1}}\\) when we have a lower bound on the gap. The \"orthogonality catastrophe\" suggests that the overlap of simple trial states with the desired eigenstate will decay exponentially as a function of system size. It is still an open question [23, 31] as to whether initial states with nonexponentially vanishing overlaps can be prepared for systems of interest. This issue may become more pressing for materials systems as we scale to the thermodynamic limit. In general, we know that the problem of finding the ground state of electronic structure Hamiltonians is QMA-hard [60], but it is not yet known if these complexity theoretic statements provide intuition for physically realistic Hamiltonians.</p><p>As noted above, to accurately resolve the system, a large basis set must be used (the discretization error decays as \\(1/N\\) where \\(N\\) is the number of spin orbitals considered). In practice, one typically repeats the calculation using increasingly accurate basis sets and then extrapolates to the continuum limit. Most quantum resource estimates to date have considered basis sets of the minimal allowable size (for exceptions, see [50, 9, 51, 56, 57, 58, 16, 59]), and so underestimate the resources required to achieve sufficiently accurate results to be informative.</p><p>The end-to-end applications typically solved in the electronic structure problem can require between tens (structure determination) and millions (molecular dynamics) of energy evaluations\u2014each with different Hamiltonian parameters that may require preparing a new state to be measured. For example, a recent analysis of quantum algorithms applied to pharmaceutical chemistry [61] highlighted that to calculate the binding affinity between a drug molecule and its target (free energy differences) requires sampling a range of thermodynamic configurations, resulting in millions to billions of single-point energy evaluations. This introduces a large overhead when preparing a different state for each configuration and measuring its energy [45], although alternative approaches may provide more favorable scaling [62].</p>"},{"location":"areas-of-application/quantum-chemistry/electronic-structure-problem/#comparable-classical-complexity-and-challenging-instance-sizes","title":"Comparable classical complexity and challenging instance sizes","text":"<p>The cost of exact diagonalization of the electronic structure Hamiltonian scales exponentially with the number of electrons and basis set size. As such, classical approaches to the electronic structure problem typically utilize a range of approximations that reduce their complexity to polynomial in an approximation parameter but introduce a (potentially uncontrolled) deviation from the exact ground state, leading to a bias in energy estimates and/or the expectation values of other observables. Approaches include: Hartree\u2013Fock, density functional theory, perturbation theory, configuration interaction methods, coupled cluster methods, quantum Monte Carlo techniques, and tensor network approaches. The cheapest approaches can be applied to thousands of orbitals, but can be qualitatively inaccurate for strongly correlated systems. The most expensive approaches are more effective for strongly correlated systems, but their higher computational cost limits their applicability to roughly 100 spin orbitals. For example, [49] found that a density matrix renormalization group (DMRG) calculation performed on an 86 spin orbital active space of the Cytochrome P450 enzyme molecule referenced in Table 2 required around 50 hours, using 32 threads, 48 GB of RAM, and 235 GB of disk memory. We also refer to [63] for a comparison of 20 first-principles many-body electronic structure methods applied to a test set of seven transition metal atoms and their ions and monoxides.</p><p>Due to their extended nature, material systems are most commonly targeted with density functional theory (DFT). DFT can be applied to systems with thousands of electrons and orbitals, but can lead to uncontrolled energy bias in strongly correlated systems. Quantum Monte Carlo and tensor network methods have been successfully applied to prototypical models of material systems, and are becoming increasingly practical for more realistic models. We refer to [64, 65, 66, 67] for cutting edge benchmarks of classical electronic structure methods on hydrogen chains and Hubbard models scaling to the thermodynamic limit, which act as simplified models for real materials.</p>"},{"location":"areas-of-application/quantum-chemistry/electronic-structure-problem/#speedup","title":"Speedup","text":"<p>It is nontrivial to determine the speedup of quantum algorithms for the electronic structure problem over their classical counterparts. If we consider the subtask of determining energy eigenstates, then for speedup greater than polynomial to be achieved, we require:</p><ul> <li>The ability to prepare a trial state with nonexponentially vanishing overlap with the ground state as the system size increases.</li> <li>Polynomially scaling classical algorithms having an exponential growth in their approximation parameter (e.g., bond dimension, number of excitations) as the system size increases.</li> </ul><p>Whether these two requirements can coexist in systems of interest is an active area of research [31]. Even if exponential speedups are not available, it may be the case that quantum algorithms provide polynomial speedups over exact classical algorithms\u2014and potentially over approximate classical algorithms.</p><p>From a complexity theoretic viewpoint, we know that simulating the dynamics of a quantum system is a BQP-complete problem [68]. Combined with the observed difficulty of classically simulating the time evolution of electronic structure Hamiltonians, this may be taken as evidence for the possibility of an exponential speedup when simulating dynamics. In [38] quantum algorithms for simulating the dynamics of electrons in a grid or plane-wave basis [12, 18, 9] were compared against classical methods for mean-field dynamics. Large polynomial speedups were observed, ranging from superquadratic to seventh power in the salient parameters, depending on the relation between \\(N\\) and \\(\\eta\\).</p>"},{"location":"areas-of-application/quantum-chemistry/electronic-structure-problem/#nisq-implementations","title":"NISQ implementations","text":"<p>Solving the electronic structure problem is one of the most widely studied and touted NISQ applications. The primary NISQ approach is the variational quantum eigensolver (VQE). There have been a number of experimental demonstrations on small molecules, e.g., Refs. [69, 70], as well as proposals to simulate material systems [71, 72]. Related methods, such as quantum computing assisted quantum Monte Carlo methods [73] have also been developed. Nevertheless, current device noise rates are too high to enable the running of circuits sufficiently deep that they can outperform classical electronic structure methods. There is currently no evidence that heuristic NISQ approaches will be able to scale to large system sizes and provide advantage over classical methods. There have also been proposals to simulate the electronic structure problem using analog quantum simulators [74], though to the best of our knowledge, these have not yet been experimentally demonstrated.</p>"},{"location":"areas-of-application/quantum-chemistry/electronic-structure-problem/#outlook","title":"Outlook","text":"<p>Solving the electronic structure problem has repeatedly been identified as one of the most promising applications for quantum computers. Nevertheless, the discussion above highlights a number of challenges for current quantum approaches to become practical. Most notably, after accounting for the approximations typically made (i.e. incorporating the cost of initial state preparation, using nonminimal basis sets, including repetitions for correctness checking and sampling a range of parameters), a large number of logical qubits and total \\(T\\)/Toffoli gates are required. A major difficulty is that, unlike problems such as factoring, the end-to-end electronic structure problem typically requires solving a large number of closely related problem instances.</p><p>Solving the electronic structure problem for materials is likely to be more difficult than for molecules for both classical and quantum algorithms. This is predominantly due to the larger system sizes considered. First quantized quantum algorithms may provide a promising approach to efficiently represent the large system sizes required, and their natural use of a plane wave basis is well suited to periodic material systems [9]. Nevertheless, additional developments are required to understand how to best apply these algorithms to real systems [58].</p>"},{"location":"areas-of-application/quantum-chemistry/electronic-structure-problem/#bibliography","title":"Bibliography","text":"<ol> <li> <p>Bern Kohler, Jeffrey L. Krause, Ferenc Raksi, Kent R. Wilson, Vladislav V. Yakovlev, Robert M. Whitnell, and YiJing Yan. Controlling the future of matter. Accounts of Chemical Research, 28(3):133\u2013140, 1995. URL: https://doi.org/10.1021/ar00051a006, arXiv:https://doi.org/10.1021/ar00051a006, doi:10.1021/ar00051a006.</p> </li> <li> <p>A. Assion, T. Baumert, M. Bergt, T. Brixner, B. Kiefer, V. Seyfried, M. Strehle, and G. Gerber. Control of chemical reactions by feedback-optimized phase-shaped femtosecond laser pulses. Science, 282(5390):919\u2013922, 1998. URL: https://www.science.org/doi/abs/10.1126/science.282.5390.919, arXiv:https://www.science.org/doi/pdf/10.1126/science.282.5390.919, doi:10.1126/science.282.5390.919.</p> </li> <li> <p>Ferenc Krausz and Misha Ivanov. Attosecond physics. Reviews of Modern Physics, 81:163\u2013234, 2 2009. URL: https://link.aps.org/doi/10.1103/RevModPhys.81.163, doi:10.1103/RevModPhys.81.163.</p> </li> <li> <p>Asger Halkier, Trygve Helgaker, Poul J\u00f8rgensen, Wim Klopper, Henrik Koch, Jeppe Olsen, and Angela K. Wilson. Basis-set convergence in correlated calculations on ne, n\\(\\_2\\), and h\\(\\_2\\)o. Chemical Physics Letters, 286(3):243\u2013252, 1998. URL: https://www.sciencedirect.com/science/article/pii/S0009261498001110, doi:https://doi.org/10.1016/S0009-2614(98)00111-0.</p> </li> <li> <p>James J. Shepherd, Andreas Gr\u00fcneis, George H. Booth, Georg Kresse, and Ali Alavi. Convergence of many-body wave-function expansions using a plane-wave basis: from homogeneous electron gas to solid state systems. Physical Review B, 86:035111, 7 2012. arXiv: https://arxiv.org/abs/1202.4990. URL: https://link.aps.org/doi/10.1103/PhysRevB.86.035111, doi:10.1103/PhysRevB.86.035111.</p> </li> <li> <p>Dominic W. Berry, M\u00e1ria Kieferov\u00e1, Artur Scherer, Yuval R. Sanders, Guang Hao Low, Nathan Wiebe, Craig Gidney, and Ryan Babbush. Improved techniques for preparing eigenstates of fermionic hamiltonians. npj Quantum Information, 4(1):22, 5 2018. arXiv: https://arxiv.org/abs/1711.10460. URL: https://doi.org/10.1038/s41534-018-0071-5, doi:10.1038/s41534-018-0071-5.</p> </li> <li> <p>Sam McArdle, Suguru Endo, Al\u00e1n Aspuru-Guzik, Simon C. Benjamin, and Xiao Yuan. Quantum computational chemistry. Reviews of Modern Physics, 92:015003, 3 2020. arXiv: https://arxiv.org/abs/1808.10402. URL: https://link.aps.org/doi/10.1103/RevModPhys.92.015003, doi:10.1103/RevModPhys.92.015003.</p> </li> <li> <p>Ryan Babbush, Dominic W Berry, Yuval R Sanders, Ian D Kivlichan, Artur Scherer, Annie Y Wei, Peter J Love, and Al\u00e1n Aspuru-Guzik. Exponentially more precise quantum simulation of fermions in the configuration interaction representation. Quantum Science and Technology, 3(1):015006, 2017. arXiv: https://arxiv.org/abs/1506.01029. doi:10.1088/2058-9565/aa9463.</p> </li> <li> <p>Yuan Su, Dominic W Berry, Nathan Wiebe, Nicholas Rubin, and Ryan Babbush. Fault-tolerant quantum simulations of chemistry in first quantization. PRX Quantum, 2(4):040332, 2021. arXiv: https://arxiv.org/abs/2105.12767. doi:10.1103/PRXQuantum.2.040332.</p> </li> <li> <p>Hans Hon Sang Chan, Richard Meister, Tyson Jones, David P. Tew, and Simon C. Benjamin. Grid-based methods for chemistry simulations on a quantum computer. Science Advances, 9(9):eabo7484, 2023. arXiv: https://arxiv.org/abs/2202.05864. URL: https://www.science.org/doi/abs/10.1126/sciadv.abo7484, arXiv:https://www.science.org/doi/pdf/10.1126/sciadv.abo7484, doi:10.1126/sciadv.abo7484.</p> </li> <li> <p>Ian D Kivlichan, Nathan Wiebe, Ryan Babbush, and Al\u00e1n Aspuru-Guzik. Bounding the costs of quantum simulation of many-body physics in real space. Journal of Physics A: Mathematical and Theoretical, 50(30):305301, 6 2017. arXiv: https://arxiv.org/abs/1608.05696. URL: https://dx.doi.org/10.1088/1751-8121/aa77b8, doi:10.1088/1751-8121/aa77b8.</p> </li> <li> <p>Ivan Kassal, Stephen P. Jordan, Peter J. Love, Masoud Mohseni, and Al\u00e1n Aspuru-Guzik. Polynomial-time quantum algorithm for the simulation of chemical dynamics. Proceedings of the National Academy of Sciences, 105(48):18681\u201318686, 2008. arXiv: https://arxiv.org/abs/0801.2986. URL: https://www.pnas.org/doi/abs/10.1073/pnas.0808245105, arXiv:https://www.pnas.org/doi/pdf/10.1073/pnas.0808245105, doi:10.1073/pnas.0808245105.</p> </li> <li> <p>James D. Whitfield, Jacob Biamonte, and Al\u00e1n Aspuru-Guzik. Simulation of electronic structure hamiltonians using quantum computers. Molecular Physics, 109(5):735\u2013750, 2011. arXiv: https://arxiv.org/abs/1001.3855. URL: https://doi.org/10.1080/00268976.2011.552441, arXiv:https://doi.org/10.1080/00268976.2011.552441, doi:10.1080/00268976.2011.552441.</p> </li> <li> <p>Ryan Babbush, Nathan Wiebe, Jarrod Mcclean, James Mcclain, Hartmut Neven, and Garnet Kin-Lic Chan. Low-depth quantum simulation of materials. Physical Review X, 8(1):11044, 2018. URL: https://doi.org/10.1103/PhysRevX.8.011044, doi:10.1103/PhysRevX.8.011044.</p> </li> <li> <p>Aleksei V. Ivanov, Christoph S\u00fcnderhauf, Nicole Holzmann, Tom Ellaby, Rachel N. Kerber, Glenn Jones, and Joan Camps. Quantum computation for periodic solids in second quantization. Physical Review Research, 5:013200, 3 2023. arXiv: https://arxiv.org/abs/2210.02403. URL: https://link.aps.org/doi/10.1103/PhysRevResearch.5.013200, doi:10.1103/PhysRevResearch.5.013200.</p> </li> <li> <p>Nicholas C Rubin, Dominic W Berry, Fionn D Malone, Alec F White, Tanuj Khattar, A Eugene DePrince III, Sabrina Sicolo, Michael K\u00fchn, Michael Kaicher, Joonho Lee, and others. Fault-tolerant quantum simulation of materials using bloch orbitals. arXiv: https://arxiv.org/abs/2302.05531, 2023.</p> </li> <li> <p>Ryan Babbush, Dominic W Berry, Ian D Kivlichan, Annie Y Wei, Peter J Love, and Al\u00e1n Aspuru-Guzik. Exponentially more precise quantum simulation of fermions in second quantization. New Journal of Physics, 18(3):033032, 3 2016. arXiv: https://arxiv.org/abs/1506.01020. URL: https://dx.doi.org/10.1088/1367-2630/18/3/033032, doi:10.1088/1367-2630/18/3/033032.</p> </li> <li> <p>Ryan Babbush, Dominic W. Berry, Jarrod R. McClean, and Hartmut Neven. Quantum simulation of chemistry with sublinear scaling in basis size. npj Quantum Information, 5(1):92, 11 2019. arXiv: https://arxiv.org/abs/1807.09802. URL: https://doi.org/10.1038/s41534-019-0199-y, doi:10.1038/s41534-019-0199-y.</p> </li> <li> <p>Dominic W. Berry, Craig Gidney, Mario Motta, Jarrod R. McClean, and Ryan Babbush. Qubitization of arbitrary basis quantum chemistry leveraging sparsity and low rank factorization. Quantum, 3:208, 12 2019. arXiv: https://arxiv.org/abs/1902.02134. URL: https://doi.org/10.22331/q-2019-12-02-208, doi:10.22331/q-2019-12-02-208.</p> </li> <li> <p>Vera von Burg, Guang Hao Low, Thomas H\u00e4ner, Damian S. Steiger, Markus Reiher, Martin Roetteler, and Matthias Troyer. Quantum computing enhanced computational catalysis. Physical Review Research, 3(3):033055, 2021. arXiv: https://arxiv.org/abs/2007.14460. doi:10.1103/PhysRevResearch.3.033055.</p> </li> <li> <p>Joonho Lee, Dominic W Berry, Craig Gidney, William J Huggins, Jarrod R McClean, Nathan Wiebe, and Ryan Babbush. Even more efficient quantum computations of chemistry through tensor hypercontraction. PRX Quantum, 2(3):030305, 2021. arXiv: https://arxiv.org/abs/2011.03494. doi:10.1103/PRXQuantum.2.030305.</p> </li> <li> <p>Mario Motta, Erika Ye, Jarrod R McClean, Zhendong Li, Austin J Minnich, Ryan Babbush, and Garnet Kin Chan. Low rank representations for quantum simulation of electronic structure. npj Quantum Information, 7(1):1\u20137, 2021. arXiv: https://arxiv.org/abs/1808.02625. URL: https://www.nature.com/articles/s41534-021-00416-z, doi:https://doi.org/10.1038/s41534-021-00416-z.</p> </li> <li> <p>Norm M. Tubman, Carlos Mejuto-Zaera, Jeffrey M. Epstein, Diptarka Hait, Daniel S. Levine, William Huggins, Zhang Jiang, Jarrod R. McClean, Ryan Babbush, Martin Head-Gordon, and K. Birgitta Whaley. Postponing the orthogonality catastrophe: efficient state preparation for electronic structure simulations on quantum devices. arXiv: https://arxiv.org/abs/1809.05523, 2018.</p> </li> <li> <p>Kenji Sugisaki, Shigeaki Nakazawa, Kazuo Toyota, Kazunobu Sato, Daisuke Shiomi, and Takeji Takui. Quantum chemistry on quantum computers: a method for preparation of multiconfigurational wave functions on quantum computers without performing post-hartree\u2013fock calculations. ACS Central Science, 5(1):167\u2013175, 2019. URL: https://doi.org/10.1021/acscentsci.8b00788, arXiv:https://doi.org/10.1021/acscentsci.8b00788, doi:10.1021/acscentsci.8b00788.</p> </li> <li> <p>Lin Lin and Yu Tong. Optimal polynomial based quantum eigenstate filtering with application to solving quantum linear systems. Quantum, 4:361, 2020. arXiv: https://arxiv.org/abs/1910.14596. doi:10.22331/q-2020-11-11-361.</p> </li> <li> <p>Lin Lin and Yu Tong. Near-optimal ground state preparation. Quantum, 4:372, 2020. arXiv: https://arxiv.org/abs/2002.12508. doi:10.22331/q-2020-12-14-372.</p> </li> <li> <p>Yimin Ge, Jordi Tura, and J. Ignacio Cirac. Faster ground state preparation and high-precision ground energy estimation with fewer qubits. Journal of Mathematical Physics, 60(2):022202, 2019. arXiv: https://arxiv.org/abs/1712.03193. doi:10.1063/1.5027484.</p> </li> <li> <p>Markus Reiher, Nathan Wiebe, Krysta M. Svore, Dave Wecker, and Matthias Troyer. Elucidating reaction mechanisms on quantum computers. Proceedings of the National Academy of Sciences, 114(29):7555\u20137560, 2017. arXiv: https://arxiv.org/abs/1605.03590. URL: https://www.pnas.org/doi/abs/10.1073/pnas.1619152114, arXiv:https://www.pnas.org/doi/pdf/10.1073/pnas.1619152114, doi:10.1073/pnas.1619152114.</p> </li> <li> <p>Libor Veis and Ji\u0159\u00ed Pittner. Adiabatic state preparation study of methylene. The Journal of Chemical Physics, 140(21):214111, 2014. arXiv: https://arxiv.org/abs/1401.3186.pdf. URL: https://doi.org/10.1063/1.4880755, arXiv:https://doi.org/10.1063/1.4880755, doi:10.1063/1.4880755.</p> </li> <li> <p>Vladimir Kremenetski, Carlos Mejuto-Zaera, Stephen J. Cotton, and Norm M. Tubman. Simulation of adiabatic quantum computing for molecular ground states. The Journal of Chemical Physics, 155(23):234106, 2021. arXiv: https://arxiv.org/abs/2103.12059. URL: https://doi.org/10.1063/5.0060124, arXiv:https://doi.org/10.1063/5.0060124, doi:10.1063/5.0060124.</p> </li> <li> <p>Seunghoon Lee, Joonho Lee, Huanchen Zhai, Yu Tong, Alexander M. Dalzell, Ashutosh Kumar, Phillip Helms, Johnnie Gray, Zhi-Hao Cui, Wenyuan Liu, Michael Kastoryano, Ryan Babbush, John Preskill, David R. Reichman, Earl T. Campbell, Edward F. Valeev, Lin Lin, and Garnet Kin-Lic Chan. Evaluating the evidence for exponential quantum advantage in ground-state quantum chemistry. Nature Communications, 14(1):1952, 2023. arXiv: https://arxiv.org/abs/2208.02199. URL: https://doi.org/10.1038/s41467-023-37587-6, doi:10.1038/s41467-023-37587-6.</p> </li> <li> <p>Kenji Sugisaki, Kazuo Toyota, Kazunobu Sato, Daisuke Shiomi, and Takeji Takui. Adiabatic state preparation of correlated wave functions with nonlinear scheduling functions and broken-symmetry wave functions. Communications Chemistry, 5(1):84, 7 2022. URL: https://doi.org/10.1038/s42004-022-00701-8, doi:10.1038/s42004-022-00701-8.</p> </li> <li> <p>David Poulin, Alexei Kitaev, Damian S. Steiger, Matthew B. Hastings, and Matthias Troyer. Quantum algorithm for spectral measurement with a lower gate count. Physical Review Letters, 121:010501, 7 2018. arXiv: https://arxiv.org/abs/1711.11025. URL: https://link.aps.org/doi/10.1103/PhysRevLett.121.010501, doi:10.1103/PhysRevLett.121.010501.</p> </li> <li> <p>David Poulin and Pawel Wocjan. Sampling from the thermal quantum gibbs state and evaluating partition functions with a quantum computer. Physical Review Letters, 103(22):220502, 2009. arXiv: https://arxiv.org/abs/0905.2199. doi:10.1103/PhysRevLett.103.220502.</p> </li> <li> <p>Anirban Narayan Chowdhury and Rolando D. Somma. Quantum algorithms for gibbs sampling and hitting-time estimation. Quantum Information and Computation, 17(1&amp;2):41\u201364, 2017. arXiv: https://arxiv.org/abs/1603.02940. doi:10.26421/QIC17.1-2.</p> </li> <li> <p>K. Temme, T. J. Osborne, K. G. Vollbrecht, D. Poulin, and F. Verstraete. Quantum metropolis sampling. Nature, 471(7336):87\u201390, 3 2011. arXiv: https://arxiv.org/abs/0911.3635. doi:10.1038/nature09770.</p> </li> <li> <p>Chi-Fang Chen, Michael J. Kastoryano, Fernando G. S. L. Brand\u00e3o, and Andr\u00e1s Gily\u00e9n. Quantum thermal state preparation. arXiv: https://arxiv.org/abs/2303.18224, 2023.</p> </li> <li> <p>Ryan Babbush, William J. Huggins, Dominic W. Berry, Shu Fay Ung, Andrew Zhao, David R. Reichman, Hartmut Neven, Andrew D. Baczewski, and Joonho Lee. Quantum simulation of exact electron dynamics can be more efficient than classical mean-field methods. Nature Communications, 14(1):4058, 7 2023. URL: https://doi.org/10.1038/s41467-023-39024-0, doi:10.1038/s41467-023-39024-0.</p> </li> <li> <p>Guang Hao Low and Nathan Wiebe. Hamiltonian simulation in the interaction picture. arXiv: https://arxiv.org/abs/1805.00675, 2018.</p> </li> <li> <p>Emanuel Knill, Gerardo Ortiz, and Rolando D. Somma. Optimal quantum measurements of expectation values of observables. Physical Review A, 75:012328, 1 2007. arXiv: https://arxiv.org/abs/quant-ph/0607019. URL: https://link.aps.org/doi/10.1103/PhysRevA.75.012328, doi:10.1103/PhysRevA.75.012328.</p> </li> <li> <p>William J. Huggins, Kianna Wan, Jarrod McClean, Thomas E. O'Brien, Nathan Wiebe, and Ryan Babbush. Nearly optimal quantum algorithm for estimating multiple expectation values. Physical Review Letters, 129:240501, 12 2022. arXiv: https://arxiv.org/abs/2111.09283. URL: https://link.aps.org/doi/10.1103/PhysRevLett.129.240501, doi:10.1103/PhysRevLett.129.240501.</p> </li> <li> <p>Joran van Apeldoorn, Arjan Cornelissen, Andr\u00e1s Gily\u00e9n, and Giacomo Nannicini. Quantum tomography using state-preparation unitaries. In Proceedings of the 34th ACM-SIAM Symposium on Discrete Algorithms (SODA), 1265\u20131318. 2023. arXiv: https://arxiv.org/abs/2207.08800. doi:10.1137/1.9781611977554.ch47.</p> </li> <li> <p>Andr\u00e1s Gily\u00e9n, Srinivasan Arunachalam, and Nathan Wiebe. Optimizing quantum optimization algorithms via faster quantum gradient computation. In Proceedings of the 30th ACM-SIAM Symposium on Discrete Algorithms (SODA), 1425\u20131444. 2019. arXiv: https://arxiv.org/abs/1711.00465. doi:10.1137/1.9781611975482.87.</p> </li> <li> <p>Patrick Rall. Quantum algorithms for estimating physical quantities using block encodings. Physical Review A, 102:022408, 8 2020. arXiv: https://arxiv.org/abs/2004.06832. URL: https://link.aps.org/doi/10.1103/PhysRevA.102.022408, doi:10.1103/PhysRevA.102.022408.</p> </li> <li> <p>Thomas E. O'Brien, Michael Streif, Nicholas C. Rubin, Raffaele Santagati, Yuan Su, William J. Huggins, Joshua J. Goings, Nikolaj Moll, Elica Kyoseva, Matthias Degroote, Christofer S. Tautermann, Joonho Lee, Dominic W. Berry, Nathan Wiebe, and Ryan Babbush. Efficient quantum computation of molecular forces and other energy gradients. Physical Review Research, 4:043210, 12 2022. arXiv: https://arxiv.org/abs/2111.12437. URL: https://link.aps.org/doi/10.1103/PhysRevResearch.4.043210, doi:10.1103/PhysRevResearch.4.043210.</p> </li> <li> <p>Mark Steudtner, Sam Morley-Short, William Pol, Sukin Sim, Cristian L Cortes, Matthias Loipersberger, Robert M Parrish, Matthias Degroote, Nikolaj Moll, Raffaele Santagati, and others. Fault-tolerant quantum computation of molecular observables. arXiv: https://arxiv.org/abs/2303.14118, 2023.</p> </li> <li> <p>Pablo A. M. Casares, Roberto Campos, and M. A. Martin-Delgado. Tfermion: a non-clifford gate cost assessment library of quantum phase estimation algorithms for quantum chemistry. Quantum, 6:768, 7 2022. arXiv: https://arxiv.org/abs/2110.05899. URL: https://doi.org/10.22331/q-2022-07-20-768, doi:10.22331/q-2022-07-20-768.</p> </li> <li> <p>Kianna Wan, Mario Berta, and Earl T. Campbell. Randomized quantum algorithm for statistical phase estimation. Physical Review Letters, 129:030503, 7 2022. arXiv: https://arxiv.org/abs/2110.12071. URL: https://link.aps.org/doi/10.1103/PhysRevLett.129.030503, doi:10.1103/PhysRevLett.129.030503.</p> </li> <li> <p>Joshua J Goings, Alec White, Joonho Lee, Christofer S Tautermann, Matthias Degroote, Craig Gidney, Toru Shiozaki, Ryan Babbush, and Nicholas C Rubin. Reliably assessing the electronic structure of cytochrome p450 on today's classical computers and tomorrow's quantum computers. Proceedings of the National Academy of Sciences, 119(38):e2203533119, 2022. arXiv: https://arxiv.org/abs/2202.01244. doi:10.1073/pnas.2203533119.</p> </li> <li> <p>Isaac H. Kim, Ye-Hua Liu, Sam Pallister, William Pol, Sam Roberts, and Eunseok Lee. Fault-tolerant resource estimate for quantum chemical simulations: case study on li-ion battery electrolyte molecules. Physical Review Research, 4:023019, 4 2022. arXiv: https://arxiv.org/abs/2104.10653. URL: https://link.aps.org/doi/10.1103/PhysRevResearch.4.023019, doi:10.1103/PhysRevResearch.4.023019.</p> </li> <li> <p>Vincent E Elfving, Benno W Broer, Mark Webber, Jacob Gavartin, Mathew D Halls, K Patrick Lorton, and A Bochevarov. How will quantum computers provide an industrially relevant computational advantage in quantum chemistry? arXiv: https://arxiv.org/abs/2009.12472, 2020.</p> </li> <li> <p>Nick S. Blunt, Joan Camps, Ophelia Crawford, R\u00f3bert Izs\u00e1k, Sebastian Leontica, Arjun Mirani, Alexandra E. Moylett, Sam A. Scivier, Christoph S\u00fcnderhauf, Patrick Schopf, Jacob M. Taylor, and Nicole Holzmann. Perspective on the current state-of-the-art of quantum computing for drug discovery applications. Journal of Chemical Theory and Computation, 18(12):7001\u20137023, 2022. arXiv: https://arxiv.org/abs/2206.00551. doi:10.1021/acs.jctc.2c00574.</p> </li> <li> <p>Michael A. Nielsen and Isaac L. Chuang. Quantum computation and quantum information. Cambridge University Press, 2000. doi:10.1017/CBO9780511976667.</p> </li> <li> <p>Ryan Babbush, Craig Gidney, Dominic W. Berry, Nathan Wiebe, Jarrod McClean, Alexandru Paler, Austin Fowler, and Hartmut Neven. Encoding electronic spectra in quantum circuits with linear t complexity. Physical Review X, 8(4):041015, 2018. arXiv: https://arxiv.org/abs/1805.03662. doi:10.1103/PhysRevX.8.041015.</p> </li> <li> <p>Ian D. Kivlichan, Craig Gidney, Dominic W. Berry, Nathan Wiebe, Jarrod McClean, Wei Sun, Zhang Jiang, Nicholas Rubin, Austin Fowler, Al\u00e1n Aspuru-Guzik, Hartmut Neven, and Ryan Babbush. Improved fault-tolerant quantum simulation of condensed-phase correlated electrons via trotterization. Quantum, 4:296, 7 2020. arXiv: https://arxiv.org/abs/1902.10673. URL: https://doi.org/10.22331/q-2020-07-16-296, doi:10.22331/q-2020-07-16-296.</p> </li> <li> <p>Sam McArdle, Earl Campbell, and Yuan Su. Exploiting fermion number in factorized decompositions of the electronic structure hamiltonian. Physical Review A, 105:012403, 1 2022. arXiv: https://arxiv.org/abs/2107.07238. URL: https://link.aps.org/doi/10.1103/PhysRevA.105.012403, doi:10.1103/PhysRevA.105.012403.</p> </li> <li> <p>Alain Delgado, Pablo A. M. Casares, Roberto dos Reis, Modjtaba Shokrian Zini, Roberto Campos, Norge Cruz-Hern\u00e1ndez, Arne-Christian Voigt, Angus Lowe, Soran Jahangiri, M. A. Martin-Delgado, Jonathan E. Mueller, and Juan Miguel Arrazola. Simulating key properties of lithium-ion batteries with a fault-tolerant quantum computer. Physical Review A, 106:032428, 9 2022. arXiv: https://arxiv.org/abs/2204.11890. URL: https://link.aps.org/doi/10.1103/PhysRevA.106.032428, doi:10.1103/PhysRevA.106.032428.</p> </li> <li> <p>Modjtaba Shokrian Zini, Alain Delgado, Roberto dos Reis, Pablo Antonio Moreno Casares, Jonathan E. Mueller, Arne-Christian Voigt, and Juan Miguel Arrazola. Quantum simulation of battery materials using ionic pseudopotentials. Quantum, 7:1049, 7 2023. arXiv: https://arxiv.org/abs/2302.07981. URL: https://doi.org/10.22331/q-2023-07-10-1049, doi:10.22331/q-2023-07-10-1049.</p> </li> <li> <p>Nicholas C Rubin, Dominic W Berry, Alina Kononov, Fionn D Malone, Tanuj Khattar, Alec White, Joonho Lee, Hartmut Neven, Ryan Babbush, and Andrew D Baczewski. Quantum computation of stopping power for inertial fusion target design. arXiv: https://arxiv.org/abs/2308.12352, 2023.</p> </li> <li> <p>James Daniel Whitfield, Peter John Love, and Alan Aspuru-Guzik. Computational complexity in electronic structure. Phys. Chem. Chem. Phys., 15:397\u2013411, 2013. arXiv: https://arxiv.org/abs/1208.3334. URL: http://dx.doi.org/10.1039/C2CP42695A, doi:10.1039/C2CP42695A.</p> </li> <li> <p>Raffaele Santagati, Alan Aspuru-Guzik, Ryan Babbush, Matthias Degroote, Leticia Gonzalez, Elica Kyoseva, Nikolaj Moll, Markus Oppel, Robert M Parrish, Nicholas C Rubin, and others. Drug design on quantum computers. arXiv: https://arxiv.org/abs/2301.04114, 2023.</p> </li> <li> <p>Sophia Simon, Raffaele Santagati, Matthias Degroote, Nikolaj Moll, Michael Streif, and Nathan Wiebe. Improved precision scaling for simulating coupled quantum-classical dynamics. arXiv: https://arxiv.org/abs/2307.13033, 2023.</p> </li> <li> <p>Kiel T. Williams, Yuan Yao, Jia Li, Li Chen, Hao Shi, Mario Motta, Chunyao Niu, Ushnish Ray, Sheng Guo, Robert J. Anderson, Junhao Li, Lan Nguyen Tran, Chia-Nan Yeh, Bastien Mussard, Sandeep Sharma, Fabien Bruneval, Mark van Schilfgaarde, George H. Booth, Garnet Kin-Lic Chan, Shiwei Zhang, Emanuel Gull, Dominika Zgid, Andrew Millis, Cyrus J. Umrigar, and Lucas K. Wagner. Direct comparison of many-body methods for realistic electronic hamiltonians. Physical Review X, 10:011041, 2 2020. arXiv: https://arxiv.org/abs/1910.00045. URL: https://link.aps.org/doi/10.1103/PhysRevX.10.011041, doi:10.1103/PhysRevX.10.011041.</p> </li> <li> <p>J. P. F. LeBlanc, Andrey E. Antipov, Federico Becca, Ireneusz W. Bulik, Garnet Kin-Lic Chan, Chia-Min Chung, Youjin Deng, Michel Ferrero, Thomas M. Henderson, Carlos A. Jim\u00e9nez-Hoyos, E. Kozik, Xuan-Wen Liu, Andrew J. Millis, N. V. Prokof'ev, Mingpu Qin, Gustavo E. Scuseria, Hao Shi, B. V. Svistunov, Luca F. Tocchio, I. S. Tupitsyn, Steven R. White, Shiwei Zhang, Bo-Xiao Zheng, Zhenyue Zhu, and Emanuel Gull. Solutions of the two-dimensional hubbard model: benchmarks and results from a wide range of numerical algorithms. Physical Review X, 5:041041, 12 2015. arXiv: https://arxiv.org/abs/1505.02290. URL: https://link.aps.org/doi/10.1103/PhysRevX.5.041041, doi:10.1103/PhysRevX.5.041041.</p> </li> <li> <p>Mario Motta, David M. Ceperley, Garnet Kin-Lic Chan, John A. Gomez, Emanuel Gull, Sheng Guo, Carlos A. Jim\u00e9nez-Hoyos, Tran Nguyen Lan, Jia Li, Fengjie Ma, Andrew J. Millis, Nikolay V. Prokof'ev, Ushnish Ray, Gustavo E. Scuseria, Sandro Sorella, Edwin M. Stoudenmire, Qiming Sun, Igor S. Tupitsyn, Steven R. White, Dominika Zgid, and Shiwei Zhang. Towards the solution of the many-electron problem in real materials: equation of state of the hydrogen chain with state-of-the-art many-body methods. Physical Review X, 7:031059, 9 2017. arXiv: https://arxiv.org/abs/1705.01608. URL: https://link.aps.org/doi/10.1103/PhysRevX.7.031059, doi:10.1103/PhysRevX.7.031059.</p> </li> <li> <p>Mario Motta, Claudio Genovese, Fengjie Ma, Zhi-Hao Cui, Randy Sawaya, Garnet Kin-Lic Chan, Natalia Chepiga, Phillip Helms, Carlos Jim\u00e9nez-Hoyos, Andrew J. Millis, Ushnish Ray, Enrico Ronca, Hao Shi, Sandro Sorella, Edwin M. Stoudenmire, Steven R. White, and Shiwei Zhang. Ground-state properties of the hydrogen chain: dimerization, insulator-to-metal transition, and magnetic phases. Physical Review X, 10:031058, 9 2020. arXiv: https://arxiv.org/abs/1911.01618. URL: https://link.aps.org/doi/10.1103/PhysRevX.10.031058, doi:10.1103/PhysRevX.10.031058.</p> </li> <li> <p>Thomas Sch\u00e4fer, Nils Wentzell, Fedor \u0160imkovic, Yuan-Yao He, Cornelia Hille, Marcel Klett, Christian J. Eckhardt, Behnam Arzhang, Viktor Harkov, Fran \u00e7 \u00e7ois-Marie Le R\u00e9gent, Alfred Kirsch, Yan Wang, Aaram J. Kim, Evgeny Kozik, Evgeny A. Stepanov, Anna Kauch, Sabine Andergassen, Philipp Hansmann, Daniel Rohe, Yuri M. Vilk, James P. F. LeBlanc, Shiwei Zhang, A.-M. S. Tremblay, Michel Ferrero, Olivier Parcollet, and Antoine Georges. Tracking the footprints of spin fluctuations: a multimethod, multimessenger study of the two-dimensional hubbard model. Physical Review X, 11:011058, 3 2021. arXiv: https://arxiv.org/abs/2006.10769. URL: https://link.aps.org/doi/10.1103/PhysRevX.11.011058, doi:10.1103/PhysRevX.11.011058.</p> </li> <li> <p>Seth Lloyd. Universal quantum simulators. Science, 273(5278):1073\u20131078, 1996. doi:10.1126/science.273.5278.1073.</p> </li> <li> <p>Abhinav Kandala, Antonio Mezzacapo, Kristan Temme, Maika Takita, Markus Brink, Jerry M. Chow, and Jay M. Gambetta. Hardware-efficient variational quantum eigensolver for small molecules and quantum magnets. Nature, 549(7671):242\u2013246, 9 2017. arXiv: https://arxiv.org/abs/1704.05018. URL: https://doi.org/10.1038/nature23879, doi:10.1038/nature23879.</p> </li> <li> <p>Google AI Quantum, Frank Arute, Kunal Arya, Ryan Babbush, Dave Bacon, Joseph C. Bardin, Rami Barends, Sergio Boixo, Michael Broughton, Bob B. Buckley, David A. Buell, Brian Burkett, Nicholas Bushnell, Yu Chen, Zijun Chen, Benjamin Chiaro, Roberto Collins, William Courtney, Sean Demura, Andrew Dunsworth, Edward Farhi, Austin Fowler, Brooks Foxen, Craig Gidney, Marissa Giustina, Rob Graff, Steve Habegger, Matthew P. Harrigan, Alan Ho, Sabrina Hong, Trent Huang, William J. Huggins, Lev Ioffe, Sergei V. Isakov, Evan Jeffrey, Zhang Jiang, Cody Jones, Dvir Kafri, Kostyantyn Kechedzhi, Julian Kelly, Seon Kim, Paul V. Klimov, Alexander Korotkov, Fedor Kostritsa, David Landhuis, Pavel Laptev, Mike Lindmark, Erik Lucero, Orion Martin, John M. Martinis, Jarrod R. McClean, Matt McEwen, Anthony Megrant, Xiao Mi, Masoud Mohseni, Wojciech Mruczkiewicz, Josh Mutus, Ofer Naaman, Matthew Neeley, Charles Neill, Hartmut Neven, Murphy Yuezhen Niu, Thomas E. O'Brien, Eric Ostby, Andre Petukhov, Harald Putterman, Chris Quintana, Pedram Roushan, Nicholas C. Rubin, Daniel Sank, Kevin J. Satzinger, Vadim Smelyanskiy, Doug Strain, Kevin J. Sung, Marco Szalay, Tyler Y. Takeshita, Amit Vainsencher, Theodore White, Nathan Wiebe, Z. Jamie Yao, Ping Yeh, and Adam Zalcman. Hartree\u2013fock on a superconducting qubit quantum computer. Science, 369(6507):1084\u20131089, 2020. arXiv: https://arxiv.org/abs/2004.04174. URL: https://www.science.org/doi/abs/10.1126/science.abb9811, arXiv:https://www.science.org/doi/pdf/10.1126/science.abb9811, doi:10.1126/science.abb9811.</p> </li> <li> <p>Nobuyuki Yoshioka, Takeshi Sato, Yuya O. Nakagawa, Yu-ya Ohnishi, and Wataru Mizukami. Variational quantum simulation for periodic materials. Physical Review Research, 4:013052, 1 2022. arXiv: https://arxiv.org/abs/2008.09492. URL: https://link.aps.org/doi/10.1103/PhysRevResearch.4.013052, doi:10.1103/PhysRevResearch.4.013052.</p> </li> <li> <p>David Zsolt Manrique, Irfan T Khan, Kentaro Yamamoto, Vijja Wichitwechkarn, and David Munoz Ramo. Momentum-space unitary coupled cluster and translational quantum subspace expansion for periodic systems on quantum computers. arXiv: https://arxiv.org/abs/2008.08694, 2020.</p> </li> <li> <p>William J. Huggins, Bryan A. O'Gorman, Nicholas C. Rubin, David R. Reichman, Ryan Babbush, and Joonho Lee. Unbiasing fermionic quantum monte carlo with a quantum computer. Nature, 603(7901):416\u2013420, 3 2022. arXiv: https://arxiv.org/abs/2106.16235. URL: https://doi.org/10.1038/s41586-021-04351-z, doi:10.1038/s41586-021-04351-z.</p> </li> <li> <p>Javier Arg\u00fcello-Luengo, Alejandro Gonz\u00e1lez-Tudela, Tao Shi, Peter Zoller, and J. Ignacio Cirac. Analogue quantum chemistry simulation. Nature, 574(7777):215\u2013218, 10 2019. arXiv: https://arxiv.org/abs/1807.09228. URL: https://doi.org/10.1038/s41586-019-1614-4, doi:10.1038/s41586-019-1614-4.</p> </li> </ol> <ol> <li> <p>This reference is not technically a first quantized representation, as antisymmetry is stored in the operators rather than the wavefunction, but it stores states in an analogously compressed way to first quantized representations.\u00a0\u21a9</p> </li> <li> <p>Note that it can be substantially cheaper to directly execute the reflection \\(R_\\psi = I - 2 \\ket{\\psi}\\bra{\\psi}\\) used in both methods, rather than through the use of \\(U_\\psi\\), as the complexity of \\(R_\\psi\\) does not depend on the overlap \\(\\gamma\\) that appears in state preparation\u2014see [26] for additional discussion.\u00a0\u21a9</p> </li> </ol>"},{"location":"areas-of-application/quantum-chemistry/introduction/","title":"Quantum chemistry","text":"<p>Computational chemistry seeks to use the rules of quantum mechanics to predict the physical properties and behavior of atoms, molecules, and materials. Despite the apparent exponential cost of exact classical methods for this task, scientists have made incredible progress over the last century via increasingly sophisticated approximate methods. As a result, computational chemistry is now a core part of the analyses of chemistry experiments, the pharmaceutical drug discovery pipeline, and the optimization of materials for catalysts and batteries. Two of the most widely performed calculations are the computation of the electronic structure and the vibrational structure of chemical systems. Given the inherently quantum mechanical nature of these problems, it follows that a number of quantum algorithms have been proposed for computational chemistry [1]. In this section, we focus on the electronic structure problem for molecules and materials, as well as the vibrational structure problem. For further reviews of quantum computing for chemistry, we refer readers to [2, 3, 4, 5].</p>"},{"location":"areas-of-application/quantum-chemistry/introduction/#bibliography","title":"Bibliography","text":"<ol> <li> <p>Al\u00e1n Aspuru-Guzik, Anthony D Dutoi, Peter J Love, and Martin Head-Gordon. Simulated quantum computation of molecular energies. Science, 309(5741):1704\u20131707, 2005. arXiv: https://arxiv.org/abs/0604193. doi:10.1126/science.1113479.</p> </li> <li> <p>Sam McArdle, Suguru Endo, Al\u00e1n Aspuru-Guzik, Simon C. Benjamin, and Xiao Yuan. Quantum computational chemistry. Reviews of Modern Physics, 92:015003, 3 2020. arXiv: https://arxiv.org/abs/1808.10402. URL: https://link.aps.org/doi/10.1103/RevModPhys.92.015003, doi:10.1103/RevModPhys.92.015003.</p> </li> <li> <p>Yudong Cao, Jonathan Romero, Jonathan P. Olson, Matthias Degroote, Peter D. Johnson, M\u00e1ria Kieferov\u00e1, Ian D. Kivlichan, Tim Menke, Borja Peropadre, Nicolas P. D. Sawaya, Sukin Sim, Libor Veis, and Al\u00e1n Aspuru-Guzik. Quantum chemistry in the age of quantum computing. Chemical Reviews, 2019. arXiv: https://arxiv.org/abs/1812.09976. arXiv:1812.09976, doi:10.1021/acs.chemrev.8b00803.</p> </li> <li> <p>Bela Bauer, Sergey Bravyi, Mario Motta, and Garnet Kin-Lic Chan. Quantum algorithms for quantum chemistry and quantum materials science. Chemical Reviews, 120(22):12685\u201312717, 2020. arXiv: https://arxiv.org/abs/2001.03685. doi:10.1021/acs.chemrev.9b00829.</p> </li> <li> <p>Mario Motta and Julia E. Rice. Emerging quantum computing algorithms for quantum chemistry. WIREs Molecular Computational Science, 12(3):e1580, 2022. arXiv: https://arxiv.org/abs/2109.02873. URL: https://wires.onlinelibrary.wiley.com/doi/abs/10.1002/wcms.1580, arXiv:https://wires.onlinelibrary.wiley.com/doi/pdf/10.1002/wcms.1580, doi:https://doi.org/10.1002/wcms.1580.</p> </li> </ol>"},{"location":"areas-of-application/quantum-chemistry/vibrational-structure-problem/","title":"Vibrational structure problem","text":""},{"location":"areas-of-application/quantum-chemistry/vibrational-structure-problem/#overview","title":"Overview","text":"<p>We seek the energy eigenstates (or thermal states) of the Hamiltonian that describes the vibrations of the nuclei in a molecule around their equilibrium positions. This Hamiltonian contains the kinetic energy of the nuclei and the effective potential that they move on, which is determined by the electronic potential energy surface (i.e. the electronic energy expressed as a function of the nuclear coordinates).</p>"},{"location":"areas-of-application/quantum-chemistry/vibrational-structure-problem/#actual-end-to-end-problems-solved","title":"Actual end-to-end problem(s) solved","text":"<p>Solving the Schrodinger equation while treating electrons and nuclei on an equal footing has prohibitively high computational cost for all but the smallest systems. For systems where it is valid to separate the electronic and nuclear motions (the Born\u2013Oppenheimer approximation), we can imagine the nuclei moving on the electronic potential energy surface (PES). For molecules composed of light atoms (where relativistic effects can be neglected) the vibrations of the nuclei around their equilibrium positions provide a first-order correction to the electronic energies, and influence photo-emission/absorption properties. For a system with \\(G\\) classical nuclei at equilibrium positions \\(\\{R_I\\}\\) the vibrational Hamiltonian can be written as </p>\\[\\begin{equation} H = - \\sum_I \\frac{\\nabla_I^2}{2 M_I} + V_e(\\{ R_I \\}) \\end{equation}\\]<p>where \\(V_e(\\{ R_I \\})\\) denotes the nuclear potential determined by the electronic potential energy surface, obtained by first solving the electronic structure problem for a range of nuclear positions. The vibrational structure problem can be made classically tractable by modelling \\(V_e\\) as a harmonic potential, which reduces the problem to solving a number of coupled quantum harmonic oscillators. In order to accurately describe nonrigid molecules or highly excited vibrational states, additional anharmonic terms are required in the potential. These can be obtained by expanding the potential \\(V_e\\) to degree \\(d\\). Obtaining accurate solutions of this Hamiltonian is prohibitively costly for many systems of interest. We seek to prepare eigenstates (or thermal states) of this anharmonic vibrational Hamiltonian, and then measure the expectation values of observables with respect to these states. Properties of interest include:</p><ul> <li>The vibrational energy at the minimum of the PES, which provides a first-order correction to the electronic energies (for calculating excitation energies, determining stable molecular structures, or finding reaction pathways and rates).</li> <li>Determining transition probabilities between states, and transition dipole moments (for calculating infrared/Raman spectra between vibrational levels of the same electronic state, or vibronic spectra between vibrational levels of different electronic states).</li> </ul><p>Thermal states are often of greater interest in the vibrational case than in the electronic case: the differences between vibrational energy levels are smaller than the differences between electronic energy levels, and as a result, excited vibrational states are populated even at room temperature. This can be contrasted with the electronic structure problem, where the larger electronic energy gaps of many molecules mean that ground states are typically of primary interest at room temperature.</p>"},{"location":"areas-of-application/quantum-chemistry/vibrational-structure-problem/#dominant-resource-costcomplexity","title":"Dominant resource cost/complexity","text":"<p>A molecule with \\(G\\) atoms has \\(M= 3G - 6\\) (\\(M=3G-5\\) for linear molecules) vibrational modes. Each vibrational mode is treated as distinguishable and is considered to be in one of \\(N\\) vibrational energy levels of the harmonic oscillator Hamiltonian (one can also work in different basis sets). We thus require \\(M\\log(N)\\) qubits to represent the problem, where the energy level of each vibrational mode is encoded in binary (or an equivalent representation, such as the Gray code [1]).</p><p>Preparing the desired eigenstate or thermal state can be achieved using the methods introduced for the electronic structure problem, although the costs of most of these methods have not yet been determined for the vibrational problem. For example, energy eigenstates can be prepared using quantum phase estimation (QPE), given a state with sufficient overlap with the target state. Methods for preparing eigenstates depend polynomially on either the overlap between an initial state and the desired eigenstate (e.g. QPE or quantum singular-value transformation (QSVT)-based eigenstate filtering [2]), or on the minimum energy gap along an adiabatic path from the initial to desired state (e.g., [3]). The complexities of subroutines to prepare eigenstates and extract observables are determined by the following observations:</p><ol> <li>All methods scale as \\(\\Omega(1/\\epsilon)\\) to measure the desired observable to an error of \\(\\pm \\epsilon\\). For the energy, we typically seek \\(\\epsilon \\sim (1 - 10)\\) cm\\(^{-1}\\) \\(\\approx (4.56 \\times 10^{-6}) - (4.56 \\times 10^{-5})~\\mathrm{Hartree}\\) (due to the close historical ties with spectroscopy, in vibrational chemistry it is common to see energies expressed as wavenumbers. Interconversion can be performed using the Planck relation). For comparison, the largest matrix elements in the vibrational Hamiltonian (the harmonic couplings) are typically on the order of 1000 cm\\(^{-1}\\), and there are \\(\\mathcal{O}\\left( M \\right)\\) such terms [4]. As such, the ratio \\(\\nrm{H}_1 / \\epsilon\\) that features multiplicatively in the complexity of quantum phase estimation (at least, variants based on qubitization) can be on the order of \\(10^4\\) (or larger) for modest system sizes with \\(M \\approx 100\\).</li> <li>To date, only product-formula-based methods have been considered for providing coherent access to the vibrational Hamiltonian. These methods scale with the number of Pauli terms in the Hamiltonian, which grows as \\(\\mathcal{O}\\left( M^d N^{2d} \\right)\\) for a degree \\(d\\) of anharmonic terms considered in the Hamiltonian (often at least 4th order).</li> </ol>"},{"location":"areas-of-application/quantum-chemistry/vibrational-structure-problem/#existing-error-corrected-resource-estimates","title":"Existing error corrected resource estimates","text":"<p>To date, there have been no error corrected resource estimates for the vibrational structure problem. In terms of initial steps in this direction, [1] considered the resources required to map vibrational operators to qubit operators, while [4] compared the number of terms (and their magnitudes) in vibrational Hamiltonians to those in electronic structure Hamiltonians.</p>"},{"location":"areas-of-application/quantum-chemistry/vibrational-structure-problem/#caveats","title":"Caveats","text":"<p>Both classical and quantum algorithms for the vibrational structure problem require the availability of a high-accuracy electronic PES, from classical calculations. For a grid-based interpolation of the multidimensional PES with \\(h\\) points per dimension, we require \\(\\mathcal{O}\\left( h^M \\right)\\) PES evaluations. Nevertheless, a number of interpolation techniques and adaptive methods have been developed to obtain high-accuracy PESs, at lower costs. Moreover, a number of molecules with classically challenging vibrational spectra have been identified with classically easy electronic structures [4].</p><p>There has been less work on the number of vibrational basis states required to achieve a given accuracy than in the electronic case. While rigorous results exist for more simple bosonic Hamiltonians [5], the truncation level \\(N\\) has not yet been established for anharmonic potentials.</p><p>When calculating overlaps between the vibrational states belonging to different electronic energy levels (vibronic transitions), the Hamiltonians are expressed in different coordinates, and so one must either transform the state or the Hamiltonian using the Duschinsky transformation (see, e.g., [6, 7] for a discussion of this issue).</p>"},{"location":"areas-of-application/quantum-chemistry/vibrational-structure-problem/#comparable-classical-complexity-and-challenging-instance-sizes","title":"Comparable classical complexity and challenging instance sizes","text":"<p>A hierarchy of classical methods has been developed for the vibrational structure problem, which trade increased accuracy for increased cost. Vibrational states with a multireference nature (which are required to describe vibrational resonances that arise due to near-degeneracies between different vibrational eigenstates, resulting from anharmonicities in the PES) require more accurate (and thus costly) methods. Moreover, nonrigid molecules require a higher degree approximation of the PES, leading to an increased cost for classical methods (and potentially increasing the complexity of the resulting eigenstates). For such challenging systems, accurate classical results have been obtained for molecules with \\(G=20\\)\u2013\\(30\\) atoms [8, 9, 10, 11].</p>"},{"location":"areas-of-application/quantum-chemistry/vibrational-structure-problem/#speedup","title":"Speedup","text":"<p>In order to achieve superpolynomial speedup over classical methods for preparing a given eigenstate we require:</p><ul> <li>Polynomially scaling classical methods to grow their approximation parameter exponentially as the system size increases.</li> <li>The ability to prepare an initial state with nonexponentially vanishing overlap with the desired state, in polynomial time.</li> </ul><p>There exist spectroscopy calculations in which the initial state is easy to prepare for both quantum and classical computers, but certain excited states may be difficult to prepare, due to their small overlap with this initial state. However, in such calculations this can be exploited as a feature, rather than a bug. For example in [12] it was proposed to use quantum phase estimation to project from the initial state into other eigenstates with probability given by the squared overlap between the states. This corresponds to the transition probability measured in the desired spectrum. We note that whereas a single (exponentially costly) classical diagonalization of the vibrational Hamiltonian would provide complete access to the entire vibrational absorption/emission spectrum, a large number of repetitions of the quantum algorithm would be required to reconstruct the spectrum. Even if quantum algorithms do not provide an exponential speedup, they may still provide polynomial speedups over exact (and approximate) classical methods.</p>"},{"location":"areas-of-application/quantum-chemistry/vibrational-structure-problem/#nisq-implementations","title":"NISQ implementations","text":"<p>There have been proposals to apply variational algorithms to solve the vibrational structure problem [7, 13, 1, 4], but it seems unlikely that sufficiently deep circuits can be implemented to surpass classical methods. There have also been a number of analog quantum simulations that map the vibrational structure problem onto bosonic modes such as photons [14, 6, 15]. Nevertheless, it appears challenging to scale these simulations to sufficiently large system sizes, due to the decoherence present in the simulation platforms.</p>"},{"location":"areas-of-application/quantum-chemistry/vibrational-structure-problem/#outlook","title":"Outlook","text":"<p>Further work is required to identify target systems that are challenging to simulate classically, but that may be amenable to quantum algorithms. In addition, existing quantum algorithms need to be further optimized for the accuracy required in vibrational structure problems and the form of the vibrational Hamiltonian. This will enable resource estimates for end-to-end applications, such as estimating vibrational spectra.</p>"},{"location":"areas-of-application/quantum-chemistry/vibrational-structure-problem/#bibliography","title":"Bibliography","text":"<ol> <li> <p>Nicolas PD Sawaya, Tim Menke, Thi Ha Kyaw, Sonika Johri, Al\u00e1n Aspuru-Guzik, and Gian Giacomo Guerreschi. Resource-efficient digital quantum simulation of d-level systems for photonic, vibrational, and spin-s hamiltonians. npj Quantum Information, 6(1):1\u201313, 2020. arXiv: https://arxiv.org/abs/1909.12847. doi:https://doi.org/10.1038/s41534-020-0278-0.</p> </li> <li> <p>Lin Lin and Yu Tong. Near-optimal ground state preparation. Quantum, 4:372, 2020. arXiv: https://arxiv.org/abs/2002.12508. doi:10.22331/q-2020-12-14-372.</p> </li> <li> <p>Kianna Wan and Isaac Kim. Fast digital methods for adiabatic state preparation. arXiv: https://arxiv.org/abs/2004.04164, 2020.</p> </li> <li> <p>Nicolas P. D. Sawaya, Francesco Paesani, and Daniel P. Tabor. Near- and long-term quantum algorithmic approaches for vibrational spectroscopy. Physical Review A, 104:062419, 12 2021. arXiv: https://arxiv.org/abs/2009.05066. URL: https://link.aps.org/doi/10.1103/PhysRevA.104.062419, doi:10.1103/PhysRevA.104.062419.</p> </li> <li> <p>Yu Tong, Victor V. Albert, Jarrod R. McClean, John Preskill, and Yuan Su. Provably accurate simulation of gauge theories and bosonic systems. Quantum, 6:816, 9 2022. arXiv: https://arxiv.org/abs/2110.06942. URL: https://doi.org/10.22331/q-2022-09-22-816, doi:10.22331/q-2022-09-22-816.</p> </li> <li> <p>Joonsuk Huh, Gian Giacomo Guerreschi, Borja Peropadre, Jarrod R. McClean, and Al\u00e1n Aspuru-Guzik. Boson sampling for molecular vibronic spectra. Nature Photonics, 9(9):615\u2013620, 9 2015. arXiv: https://arxiv.org/abs/1412.8427. doi:10.1038/nphoton.2015.153.</p> </li> <li> <p>Sam McArdle, Alexander Mayorov, Xiao Shan, Simon Benjamin, and Xiao Yuan. Digital quantum simulation of molecular vibrations. Chemical Science, 10:5725\u20135735, 2019. arXiv: https://arxiv.org/abs/1811.04069. URL: http://dx.doi.org/10.1039/C9SC01313J, doi:10.1039/C9SC01313J.</p> </li> <li> <p>Tucker Carrington Jr. Perspective: computing (ro-) vibrational spectra of molecules with more than four atoms. The Journal of Chemical Physics, 146(12):120902, 2017. doi:https://doi.org/10.1063/1.4979117.</p> </li> <li> <p>Alberto Baiardi, Christopher J Stein, Vincenzo Barone, and Markus Reiher. Vibrational density matrix renormalization group. Journal of Chemical Theory and Computation, 13(8):3764\u20133777, 2017. arXiv: https://arxiv.org/abs/1703.09313. doi:10.1021/acs.jctc.7b00329.</p> </li> <li> <p>Phillip S Thomas, Tucker Carrington Jr, Jay Agarwal, and Henry F Schaefer III. Using an iterative eigensolver and intertwined rank reduction to compute vibrational spectra of molecules with more than a dozen atoms: uracil and naphthalene. The Journal of Chemical Physics, 149(6):064108, 2018. doi:https://doi.org/10.1063/1.5039147.</p> </li> <li> <p>Vincenzo Barone, Silvia Alessandrini, Malgorzata Biczysko, James R. Cheeseman, David C. Clary, Anne B. McCoy, Ryan J. DiRisio, Frank Neese, Mattia Melosso, and Cristina Puzzarini. Computational molecular spectroscopy. Nature Reviews Methods Primers, 1(1):38, 5 2021. URL: https://doi.org/10.1038/s43586-021-00034-1, doi:10.1038/s43586-021-00034-1.</p> </li> <li> <p>Nicolas P. D. Sawaya and Joonsuk Huh. Quantum algorithm for calculating molecular vibronic spectra. The Journal of Physical Chemistry Letters, 10(13):3586\u20133591, 2019. arXiv: https://arxiv.org/abs/1812.10495. URL: https://doi.org/10.1021/acs.jpclett.9b01117, arXiv:https://doi.org/10.1021/acs.jpclett.9b01117, doi:10.1021/acs.jpclett.9b01117.</p> </li> <li> <p>Pauline J. Ollitrault, Alberto Baiardi, Markus Reiher, and Ivano Tavernelli. Hardware efficient quantum algorithms for vibrational structure calculations. Chemical Science, 11:6842\u20136855, 2020. arXiv: https://arxiv.org/abs/2003.12578. URL: http://dx.doi.org/10.1039/D0SC01908A, doi:10.1039/D0SC01908A.</p> </li> <li> <p>Chris Sparrow, Enrique Mart\u00edn-L\u00f3pez, Nicola Maraviglia, Alex Neville, Christopher Harrold, Jacques Carolan, Yogesh N. Joglekar, Toshikazu Hashimoto, Nobuyuki Matsuda, Jeremy L. O'Brien, David P. Tew, and Anthony Laing. Simulating the vibrational quantum dynamics of molecules using photonics. Nature, 557(7707):660\u2013667, 5 2018. URL: https://doi.org/10.1038/s41586-018-0152-9, doi:10.1038/s41586-018-0152-9.</p> </li> <li> <p>Christopher S. Wang, Jacob C. Curtis, Brian J. Lester, Yaxing Zhang, Yvonne Y. Gao, Jessica Freeze, Victor S. Batista, Patrick H. Vaccaro, Isaac L. Chuang, Luigi Frunzio, Liang Jiang, S. M. Girvin, and Robert J. Schoelkopf. Efficient multiphoton sampling of molecular vibronic spectra on a superconducting bosonic processor. Physical Review X, 10:021060, 6 2020. arXiv: https://arxiv.org/abs/1908.03598. URL: https://link.aps.org/doi/10.1103/PhysRevX.10.021060, doi:10.1103/PhysRevX.10.021060.</p> </li> </ol>"},{"location":"fault-tolerant-quantum-computation/basics-of-fault-tolerance/","title":"Basics of fault tolerance","text":""},{"location":"fault-tolerant-quantum-computation/basics-of-fault-tolerance/#rough-overview-in-words","title":"Rough overview (in words)","text":"<p>The error rates of all known realizations of physical qubits and basic operations are too high to enable implementation of the majority of quantum algorithms considered in this survey. Even if the probability \\(p\\) for each basic operation to malfunction was minute, we would nevertheless expect an error to occur in any quantum circuit comprising more than \\(\\mathcal{O}\\left( 1/p \\right)\\) operations. One may optimistically assume that in the foreseeable future \\(p= 10^{-6}\\) might be achieved by certain quantum architectures, such as trapped ions [1, 2]. This, in turn, limits the size of any quantum circuit that one may hope to reliably execute to roughly one million basic operations. Such a bound places a severe restriction on the algorithms that could be run and is orders of magnitude smaller than the resources needed to implement the quantum algorithms described in the other parts of this survey.</p><p>The theory of quantum fault tolerance [3] and quantum error correction [4, 5, 6] provides a collection of techniques to deal with imperfect operations and unavoidable noise afflicting the physical hardware, at the expense of moderately increased resource overheads. In the basic model for fault tolerance one assumes that each elementary component of a quantum circuit (including the identity gate) may fail with some small but nonzero probability, independently of the other components, and classical information processing is noiseless. For concreteness and simplicity, one may choose to model any noisy component as an ideal component followed by (or, in the case of measurements, preceded by) some Pauli channel acting on the same subset of qubits. Let \\(\\mathcal C\\) be a quantum circuit (possibly with classical input and output) describing a desired quantum algorithm. Since each component of \\(\\mathcal C\\) may fail, one should not implement \\(\\mathcal C\\) directly; rather, one needs to implement a different quantum circuit \\(\\mathcal F(\\mathcal C)\\), which is fault-tolerant (FT) version of \\(\\mathcal C\\). This, in turn, can be achieved by replacing each qubit in \\(\\mathcal C\\) with a logical qubit encoded in some quantum error-correcting (QEC) code and each elementary component of \\(\\mathcal C\\) with a corresponding FT gadget; see Fig. 1. The desired quantum computation will then be realized on the logical level of \\(\\mathcal F(\\mathcal C)\\) without leaving the protective encoding guaranteed by the QEC code.</p><p> <p>Figure 1(a): A quantum circuit \\(\\mathcal C\\) consists of state preparation, unitary gates, and measurements.</p> </p> <p> </p> <p>1(b): An FT realization of \\(\\mathcal C\\) is a quantum circuit \\(\\mathcal F(\\mathcal C)\\) obtained by replacing each qubit in \\(\\mathcal C\\) with a logical qubit encoded in some QEC code and using appropriate FT gadgets interspersed with QEC gadgets in place of each basic component of \\(\\mathcal C\\). Note that some gadgets may require considerable resources (not shown in the picture); see logical gates and QEC gadgets with the surface code for more details.    </p> <p>To realize universal FT quantum computation, it suffices to have state preparation gadgets (for at least one type of state), measurement gadgets (for at least one type of measurement), gate gadgets (for a universal set of gates) and QEC gadgets. One requires that all these gadgets satisfy certain FT conditions; see, for instance, [7, 8]. Although the asymptotic scaling of resource overheads associated with FT gadgets is manageable (for instance, polylogarithmic in the inverse of the target logical error rate), the constant prefactors tend to be large, resulting in the qubit and time overheads that currently constitute one of the main bottlenecks to practical FT quantum computation. We will discuss this point in more detail for the implementation of logical gates and QEC gadgets with the planar architecture based on the surface code [9, 10].</p>"},{"location":"fault-tolerant-quantum-computation/basics-of-fault-tolerance/#rough-overview-in-math","title":"Rough overview (in math)","text":"<p>Designing FT gadgets is a challenging task for several reasons. First, FT gadgets are usually developed and optimized for a specific QEC code. Second, even though they comprise imperfect basic components, they are required to work reliably as long as a number of malfunctioning components is limited. Third, FT gadgets may spread errors, however they must not do so in an uncontrollable way.</p><p>Given a set of FT gadgets, one can reliably perform an arbitrarily long quantum computation as long as the physical error rate of each basic component is below some constant value, often referred to as the FT threshold. This result is established by the celebrated threshold theorem [11, 12, 13, 7]. To be more precise, consider the basic model for FT. The threshold theorem asserts that there exists a constant \\(p_\\text{FT}&gt;0\\), such that for any \\(\\epsilon&gt;0\\) and any quantum circuit \\(\\mathcal C\\) there exists a quantum circuit \\(\\widetilde{\\mathcal C}\\) that produces an output with statistical distance at most \\(\\epsilon\\) from the output of \\(\\mathcal C\\), provided the physical error rate \\(p\\) is below \\(p_\\text{FT}\\). Moreover, \\(\\widetilde{\\mathcal C}\\) uses a number of qubits and timesteps that are at most \\(\\mathrm{polylog}(|\\mathcal C|/\\epsilon)\\) times bigger than the number of qubits and timesteps in \\(\\mathcal C\\), where \\(|\\mathcal C|\\) denotes the number of basic components in \\(\\mathcal C\\).</p><p>The basic idea behind the proof of the threshold theorem proceeds as follows. Consider a quantum circuit \\(\\mathcal F(\\mathcal C)\\), which is an FT implementation of \\(\\mathcal C\\). Assuming the basic model for fault tolerance described above, for sufficiently small physical error rate \\(p\\), the logical error rate for \\(\\mathcal F(\\mathcal C)\\) should be smaller than \\(p\\), since \\(\\mathcal F(\\mathcal C)\\) is an FT implementation of \\(\\mathcal C\\). One can then consider a quantum circuit \\(\\mathcal F\\circ \\mathcal F(\\mathcal C)\\), which is an FT implementation of \\(\\mathcal F(\\mathcal C)\\), reducing the logical error rate even further. By repeating this process, one eventually obtains a quantum circuit \\(\\widetilde{\\mathcal C} = \\mathcal F\\circ\\ldots \\circ \\mathcal F(\\mathcal C)\\) with the logical error rate below \\(\\epsilon\\). The resulting FT protocol is based on concatenated QEC codes.</p><p>One may improve the scaling of the resource overheads from the threshold theorem with concatenated QEC codes. In particular, in the asymptotic limit of large quantum circuits, the ratio of qubits in \\(\\mathcal C\\) and \\(\\widetilde{\\mathcal C}\\) can be a constant [14]. In this construction, the FT protocol requires a family of QEC codes that satisfies certain properties, including the desired scaling of code parameters, computationally efficient decoding algorithms and constant-weight parity checks. Such a family of QEC codes was first provided in [15].</p>"},{"location":"fault-tolerant-quantum-computation/basics-of-fault-tolerance/#dominant-resource-cost-gatesqubits","title":"Dominant resource cost (gates/qubits)","text":"<p>At the heart of FT quantum computation, there is usually some QEC code. Since the choice of a QEC code affects the resource overheads, we would like to choose one for which the encoding rate (defined as the ratio \\(k/n\\), where \\(k\\) and \\(n\\) are the number of logical and physical qubits, respectively) as well as the relative code distance (defined as the ratio \\(d/n\\), where \\(d\\) is the minimum weight of any nontrivial logical operator) are as high as possible. Although for concatenated QEC codes (that feature in the threshold theorem), both \\(k/n\\) and \\(d/n\\) go to zero as \\(n\\) goes to infinity, we know that there exist QEC codes with good parameters, i.e, for which \\(k/n\\) and \\(d/n\\) are asymptotically constant [16]. Moreover, recent groundbreaking results [17, 18, 19, 20] provided constructions of QEC codes that not only have good parameters but also constant-weight parity checks (thus their name\u2014quantum low-density parity check codes). The latter property is particularly important from the perspective of fault tolerance. However, experimental realization of these constructions (in contrast to the surface code) seems extremely challenging, at least within the realm of solid-state qubits constrained by geometric locality of their physical entangling gates.</p><p>Another aspect of FT quantum computation that affects the resource overheads are the FT gadgets that are being used. One of the easiest ways to implement FT gadgets for gates is via transversal gates. By definition, transversal gates are implemented via a tensor product of single-qubit unitaries (or, more generally, via a depth-one quantum circuit) and therefore do not spread errors in an uncontrollable way. Unfortunately, transversal gates are limited by the Eastin\u2013Knill theorem [21, 22, 23, 24], which rules out the existence of a (finite-dimensional) QEC code with a universal set of transversal logical gates. One strategy to circumvent this limitation is to prepare certain magic states and use them to realize FT gates [25]; see the section on implementing logical gates for more details and a discussion of other strategies.</p><p>To realize FT gadgets for state preparation, QEC, and measurement, one typically chooses among three standard FT schemes: Shor's [3], Steane's [26], or Knill's [27]. Roughly speaking, Shor's scheme uses simple states (verified cat states) of the ancilla qubits at the expense of implementing many gates on the data qubits, whereas Steane's and Knill's schemes trade highly complex states of the ancilla qubits (logical states encoded in the underlying QEC code) for minimizing the number of gates on the data qubits. To determine the best choice, one needs to consider the underlying QEC code (e.g., Steane's scheme is applicable only to CSS codes [16, 5]) and the quantum hardware restrictions (e.g., lack of extra ancilla qubits). For an illuminating and detailed discussion of FT schemes, see, e.g., [8]. We remark that for QEC codes with additional structure, such as quantum low-density parity check codes, one may pursue different approaches toward FT quantum computation; see the section on QEC with the surface code.</p>"},{"location":"fault-tolerant-quantum-computation/basics-of-fault-tolerance/#caveats","title":"Caveats","text":"<p>Rigorous proofs provide lower bounds on the FT threshold \\(p_\\text{FT}\\). For instance, for an FT scheme based on the \\(7\\)-qubit code, one finds \\(p_\\text{FT} &gt; 2.73\\times 10^{-5}\\) [7]. For an FT scheme by Knill [27] that relies on complex ancilla preparation techniques, one finds \\(p_\\text{FT} &gt; 1.04\\times 10^{-3}\\) [28]. However, these values can differ by orders of magnitude from the values estimated in numerical simulations. For instance, the FT scheme by Knill is estimated to have an FT threshold \\(p_\\text{FT}\\) as high as \\(5\\times 10^{-2}\\), constituting one of the highest known FT thresholds. We remark that these values depend sensitively on the details of the FT schemes and the assumptions about noise. In particular, to obtain the aforementioned values we assume the ability to implement gates between any qubits. On the other hand, if we arrange qubits on some geometric lattice and restrict gates to be local, then FT thresholds still exist, however their values are significantly reduced.</p><p>One can expand the threshold theorem in many ways. Even using the basic model for fault tolerance, one may choose the failure probabilities for each elementary component of a quantum circuit differently, e.g., the failure probability of a measurement to be ten times higher than that of a gate. One can consider more general noise (which includes systematic errors, such as overrotations) arising due to a weak interaction between the system and a non-Markovian environment [7, 29]. In general, although experimental realizations of quantum computation may not satisfy exactly the assumptions of the threshold theorem, we expect the main conclusions to hold as long as the assumptions are not violated too much.</p><p>To simplify the analysis of FT schemes, we often assume unlimited classical computational power that one needs to, e.g., process the error syndrome and infer an appropriate recovery operator in a QEC gadget; a number of such decoding algorithms have been developed for QEC with the surface code. It is important not to abuse this assumption by, for instance, solving the initial problem with an inefficient classical algorithm. At some point, however, one needs to take into account the finite speed of classical information processing. If the classical unit that processes the error syndrome is unable to keep pace with the rate at which this syndrome is being produced, then the error syndrome will start to accumulate and one will suffer from the so-called backlog problem [30]. Subsequently, the speed of quantum computing will be exponentially reduced and the computational advantage of quantum computing will be annulled. This issue will be especially prominent for polynomial speedup quantum algorithms.</p>"},{"location":"fault-tolerant-quantum-computation/basics-of-fault-tolerance/#further-reading","title":"Further reading","text":"<ul> <li>An accessible introduction to quantum error correction and the theory of fault tolerance can be found in [31].</li> <li>A detailed introduction to quantum error correction and fault-tolerant quantum computation can be found in [8].</li> <li>A fairly recent perspective on roads towards fault-tolerant universal quantum computation can be found in [32].</li> <li>The error correction zoo provides a useful compilation of error correcting codes.</li> </ul>"},{"location":"fault-tolerant-quantum-computation/basics-of-fault-tolerance/#bibliography","title":"Bibliography","text":"<ol> <li> <p>A. Bermudez, X. Xu, R. Nigmatullin, J. O'Gorman, V. Negnevitsky, P. Schindler, T. Monz, U. G. Poschinger, C. Hempel, J. Home, F. Schmidt-Kaler, M. Biercuk, R. Blatt, S. Benjamin, and M. M\u00fcller. Assessing the progress of trapped-ion processors towards fault-tolerant quantum computation. Physical Review X, 7(4):041061, 12 2017. arXiv: https://arxiv.org/abs/1705.02771. doi:10.1103/physrevx.7.041061.</p> </li> <li> <p>Colin D. Bruzewicz, John Chiaverini, Robert McConnell, and Jeremy M. Sage. Trapped-ion quantum computing: progress and challenges. Applied Physics Reviews, 6(2):021314, 6 2019. arXiv: https://arxiv.org/abs/1904.04178. doi:10.1063/1.5088164.</p> </li> <li> <p>Peter W. Shor. Fault-tolerant quantum computation. In Proceedings of the 37th IEEE Symposium on Foundations of Computer Science (FOCS), 56\u201365. IEEE Comput. Soc. Press, 1996. arXiv: https://arxiv.org/abs/quant-ph/9605011. doi:10.1109/SFCS.1996.548464.</p> </li> <li> <p>Peter W. Shor. Scheme for reducing decoherence in quantum computer memory. Physical Review A, 52:R2493\u2013R2496, 1995. doi:10.1103/PhysRevA.52.R2493.</p> </li> <li> <p>A. M. Steane. Error correcting codes in quantum theory. Physical Review Letters, 77:793\u2013797, 1996. doi:10.1103/PhysRevLett.77.793.</p> </li> <li> <p>Daniel Gottesman. Class of quantum error-correcting codes saturating the quantum hamming bound. Physical Review A, 54(3):1862\u20131868, 1996. arXiv: https://arxiv.org/abs/quant-ph/9604038. doi:10.1103/PhysRevA.54.1862.</p> </li> <li> <p>Panos Aliferis, Daniel Gottesman, and John Preskill. Quantum accuracy threshold for concatenated distance-3 codes. Quantum Information and Computation, 6(2):97\u2013165, 2006. arXiv: https://arxiv.org/abs/quant-ph/0504218. doi:10.26421/QIC6.2-1.</p> </li> <li> <p>Daniel Gottesman. An introduction to quantum error correction and fault-tolerant quantum computation. In Proceedings of Symposia in Applied Mathematics, volume 68, 13\u201358. 2010. arXiv: https://arxiv.org/abs/0904.2557.</p> </li> <li> <p>A. Yu. Kitaev. Fault-tolerant quantum computation by anyons. Annals of Physics, 303(1):2\u201330, 2003. arXiv: https://arxiv.org/abs/quant-ph/9707021. doi:10.1016/S0003-4916(02)00018-0.</p> </li> <li> <p>Eric Dennis, Alexei Kitaev, Andrew Landahl, and John Preskill. Topological quantum memory. Journal of Mathematical Physics, 43(9):4452\u20134505, 2002. arXiv: https://arxiv.org/abs/quant-ph/0110143. doi:10.1063/1.1499754.</p> </li> <li> <p>Dorit Aharonov and Michael Ben-Or. Fault-tolerant quantum computation with constant error rate. SIAM Journal on Computing, 38(4):1207\u20131282, 7 2008. Earlier version in STOC'97, arXiv: https://arxiv.org/abs/quant-ph/9906129. URL: https://doi.org/10.1137/S0097539799359385, doi:10.1137/S0097539799359385.</p> </li> <li> <p>A Yu Kitaev. Quantum computations: algorithms and error correction. Russian Mathematical Surveys, 52(6):1191, 1997. doi:10.1070/RM1997v052n06ABEH002155.</p> </li> <li> <p>Emanuel Knill, Raymond Laflamme, and Wojciech H Zurek. Resilient quantum computation: error models and thresholds. Proceedings of the Royal Society A, 454(1969):365\u2013384, 1998. arXiv: https://arxiv.org/abs/quant-ph/9702058. doi:10.1098/rspa.1998.0166.</p> </li> <li> <p>Daniel Gottesman. Fault-tolerant quantum computation with constant overhead. Quantum Information and Computation, 14(15\u201316):1338\u20131372, 2014. arXiv: https://arxiv.org/abs/1310.2984. doi:10.26421/QIC14.15-16-5.</p> </li> <li> <p>Omar Fawzi, Antoine Grospellier, and Anthony Leverrier. Constant overhead quantum fault-tolerance with quantum expander codes. In Proceedings of the 59th IEEE Symposium on Foundations of Computer Science (FOCS). 2018. arXiv: https://arxiv.org/abs/1808.03821. doi:10.1109/focs.2018.00076.</p> </li> <li> <p>A. R. Calderbank and Peter W. Shor. Good quantum error-correcting codes exist. Physical Review A, 54(2):1098\u20131105, 1996. arXiv: https://arxiv.org/abs/quant-ph/9512032. doi:10.1103/physreva.54.1098.</p> </li> <li> <p>Nikolas P. Breuckmann and Jens N. Eberhardt. Balanced product quantum codes. IEEE Transactions on Information Theory, 67(10):6653\u20136674, 2021. arXiv: https://arxiv.org/abs/2012.09271. doi:10.1109/tit.2021.3097347.</p> </li> <li> <p>Pavel Panteleev and Gleb Kalachev. Asymptotically good quantum and locally testable classical ldpc codes. In Proceedings of the 54th ACM Symposium on the Theory of Computing (STOC), 375\u2013388. 2022. arXiv: https://arxiv.org/abs/2111.03654. doi:10.1145/3519935.3520017.</p> </li> <li> <p>Irit Dinur, Shai Evra, Ron Livne, Alexander Lubotzky, and Shahar Mozes. Locally testable codes with constant rate, distance, and locality. In Proceedings of the 54th ACM Symposium on the Theory of Computing (STOC), 357\u2013374. 2022. arXiv: https://arxiv.org/abs/2111.04808. doi:10.1145/3519935.3520024.</p> </li> <li> <p>Anthony Leverrier and Gilles Z\u00e9mor. Quantum tanner codes. In Proceedings of the 63rd IEEE Symposium on Foundations of Computer Science (FOCS), 872\u2013883. IEEE, 2022. arXiv: https://arxiv.org/abs/2202.13641. doi:10.1109/FOCS54457.2022.00117.</p> </li> <li> <p>Bryan Eastin and Emanuel Knill. Restrictions on transversal encoded quantum gate sets. Physical Review Letters, 102(11):110502, 2009. arXiv: https://arxiv.org/abs/0811.4262. doi:10.1103/physrevlett.102.110502.</p> </li> <li> <p>Bei Zeng, Andrew Cross, and Isaac L. Chuang. Transversality versus universality for additive quantum codes. IEEE Transactions on Information Theory, 57(9):6272\u20136284, 2011. arXiv: https://arxiv.org/abs/0706.1382. doi:10.1109/tit.2011.2161917.</p> </li> <li> <p>Tomas Jochym-O'Connor, Aleksander Kubica, and Theodore J. Yoder. Disjointness of stabilizer codes and limitations on fault-tolerant logical gates. Physical Review X, 8(2):021047, 2018. arXiv: https://arxiv.org/abs/1710.07256. doi:10.1103/physrevx.8.021047.</p> </li> <li> <p>Aleksander Kubica and Rafa\u0142 Demkowicz-Dobrza\u0144ski. Using quantum metrological bounds in quantum error correction: a simple proof of the approximate eastin\u2013knill theorem. Physical Review Letters, 126(15):150503, 2021. arXiv: https://arxiv.org/abs/2004.11893. doi:10.1103/physrevlett.126.150503.</p> </li> <li> <p>Sergey Bravyi and Alexei Kitaev. Universal quantum computation with ideal clifford gates and noisy ancillas. Physical Review A, 71(2):022316, 2005. arXiv: https://arxiv.org/abs/quant-ph/0403025. doi:10.1103/physreva.71.022316.</p> </li> <li> <p>A. M. Steane. Active stabilization, quantum computation, and quantum state synthesis. Physical Review Letters, 78(11):2252\u20132255, 1997. arXiv: https://arxiv.org/abs/quant-ph/9611027. doi:10.1103/physrevlett.78.2252.</p> </li> <li> <p>E. Knill. Quantum computing with realistically noisy devices. Nature, 434(7029):39\u201344, 2005. arXiv: https://arxiv.org/abs/quant-ph/0410199. doi:10.1038/nature03350.</p> </li> <li> <p>Panos Aliferis, Daniel Gottesman, and John Preskill. Accuracy threshold for postselected quantum computation. Quantum Information and Computation, 8(3&amp;4):181\u2013244, 2008. arXiv: https://arxiv.org/abs/quant-ph/0703264. doi:10.26421/QIC8.3-4-1.</p> </li> <li> <p>Barbara M. Terhal and Guido Burkard. Fault-tolerant quantum computation for local non-markovian noise. Physical Review A, 71(1):012336, 2005. arXiv: https://arxiv.org/abs/quant-ph/0402104. doi:10.1103/physreva.71.012336.</p> </li> <li> <p>Barbara M. Terhal. Quantum error correction for quantum memories. Reviews of Modern Physics, 87(2):307\u2013346, 2015. arXiv: https://arxiv.org/abs/1302.3428. doi:10.1103/revmodphys.87.307.</p> </li> <li> <p>Robert Raussendorf. Key ideas in quantum error correction. Philosophical Transactions of the Royal Society A, 370(1975):4541\u20134565, 2012. doi:10.1098/rsta.2011.0494.</p> </li> <li> <p>Earl T. Campbell, Barbara M. Terhal, and Christophe Vuillot. Roads towards fault-tolerant universal quantum computation. Nature, 549(7671):172\u2013179, 2017. arXiv: https://arxiv.org/abs/1612.07330. doi:10.1038/nature23460.</p> </li> </ol>"},{"location":"fault-tolerant-quantum-computation/introduction/","title":"Fault-tolerant quantum computation","text":"<p>Throughout this survey, we predominantly restrict our attention to the circuit model of quantum computation. Within this paradigm, any quantum algorithm can be expressed as a sequence of basic operations, such as product state preparation, unitary single- and two-qubit gates, and single-qubit Pauli measurements. In order to accurately determine complete end-to-end resource estimates for quantum algorithms it is essential to understand the costs of: (i) decomposing quantum algorithms into basic operations and (ii) realizing these basic operations reliably with the physical hardware. In other parts of this survey we assume noiseless logical qubits and operations (unless otherwise noted) and focus on item (i). In this section, we take into account that physical qubits and operations are noisy and discuss item (ii). We first review the fundamental ideas behind the theory of fault tolerance. We then illustrate them with concrete realizations in the paradigm of the surface code and lattice surgery.</p>"},{"location":"fault-tolerant-quantum-computation/logical-gates-with-the-surface-code/","title":"Logical gates with the surface code","text":""},{"location":"fault-tolerant-quantum-computation/logical-gates-with-the-surface-code/#rough-overview-in-words","title":"Rough overview (in words)","text":"<p>The ability to implement an arbitrary unitary operation, either exactly or approximately, is a prerequisite for performing quantum computation. It can be achieved with unitary gates that form a universal gate set [1, 2]. A commonly considered gate set contains two Clifford gates, the Hadamard gate \\(H\\) and the controlled-\\(X\\) gate \\(CX\\) (also known as the controlled NOT gate), and one non-Clifford gate, the \\(T = Z^{1/4}\\) gate. One can consider other non-Clifford gates, such as the Toffoli gate \\(CCX\\). Note that non-Clifford gates are essential for quantum computation, as any quantum circuit comprising only Clifford gates, state preparation, and measurement in the computational basis can be simulated in polynomial time on a probabilistic classical computer [3, 4].</p><p>Since we are interested in fault-tolerant quantum computation, we would like to implement a universal set of logical gates \\(\\overline H\\), \\(\\overline{CX}\\), and \\(\\overline T\\) on information encoded in some QEC code, such as the surface code. We can implement these gates with a planar layout of qubits and nearest-neighbor entangling gates. To be more precise, we consider a simple architecture [5] that comprises \\(N\\) surface code patches, each encoding a logical qubit into the surface code with code distance \\(d\\), and the routing space in between; see Fig. 1(a). In such an architecture, the total number of data and ancilla qubits is \\(\\mathcal O(N d^2)\\).</p> <p> </p> <p>Figure 1(a): A planar layout of qubits comprises surface code patches (shaded), each using the layout depicted in Quantum error correction with the surface code Fig. 1(a) and encoding a logical qubit, and the routing space in between.</p> <p></p> <p>Figure 1(b): Logical Pauli measurement \\(\\overline{M_{XX}}\\) is implemented by preparing the routing space qubits (turquoise dots) in the state \\(\\ket 0\\) and repeatedly measuring parity checks (lightly shaded) in the routing space spanning between the two surface code patches. Other logical Pauli measurements, e.g., \\(\\overline{M_{ZZ}}\\) and \\(\\overline{M_{YZ}}\\), require connecting different boundaries of the two patches. </p>"},{"location":"fault-tolerant-quantum-computation/logical-gates-with-the-surface-code/#rough-overview-in-math","title":"Rough overview (in math)","text":"<p>The logical \\(\\overline H\\) does not pose any challenges. From a practical standpoint, it is transversal, since it can be realized by applying the Hadamard gate \\(H\\) to every data qubit in the surface code patch, followed by swapping of the roles of Pauli \\(Z\\)- and \\(X\\)-type parity checks in the subsequent QEC rounds. As such, the logical \\(\\overline H\\) takes constant time and the surface code patch is effectively rotated (which may alter how subsequent operations are implemented).</p><p>The logical \\(\\overline{CX}\\) is more challenging than the logical \\(\\overline H\\), since it is impossible to implement it transversally with the planar layout of qubits and nearest-neighbor entangling gates shown in Fig. 1(a). Instead, one can use the following quantum circuit, where the first qubit (top wire) is the control and the third qubit (bottom wire) is the target of the logical \\(\\overline{CX}\\) gate                         It is straightforward to fault-tolerantly realize preparation of the logical state \\(\\ket{\\overline{+}}\\), logical Pauli measurement \\(\\overline{M_Z}\\), and logical Pauli operators \\(\\overline{Z}\\) and \\(\\overline{X}\\). In addition, the required logical Pauli measurements \\(\\overline{M_{ZZ}}\\) and \\(\\overline{M_{XX}}\\) can be implemented fault-tolerantly via \"lattice surgery\" techniques [5]; see Fig. 1(b) for an illustration of how to realize \\(\\overline{M_{XX}}\\). Unlike the logical \\(\\overline H\\), logical Pauli measurements \\(\\overline{M_{ZZ}}\\) and \\(\\overline{M_{XX}}\\) and, subsequently, the logical \\(\\overline{CX}\\) cannot be realized in constant time; rather, due to the need to account for measurement errors, they typically incur time overhead of \\(\\mathcal{O}\\left( d \\right)\\).</p><p>The logical \\(\\overline T\\) can be implemented using gate teleportation [6] via the following quantum circuit     <p>Figure 2</p>                      where the logical resource state \\(\\ket{\\overline{T}} = \\left(\\ket{\\overline{0}} + e^{i\\pi/4}\\ket{\\overline{1}}\\right)/\\sqrt{2}\\), the logical gate \\(\\overline{S} = \\overline{Z}^{\\,1/2}\\), and the first qubit (top wire) is the control and the second qubit (bottom wire) is the target of the logical \\(\\overline{CX}\\) gate. Even though the logical \\(\\overline{S}\\) is a Clifford gate, its fault-tolerant implementation with the surface code may not be effortless [7] (unless one uses nonlocal entangling gates [8, 9]) Moreover, the need to apply the logical \\(\\overline{S}\\) conditioned on the measurement outcome of \\(\\overline{M_Z}\\) may slow down quantum computation. For that reason, it may be beneficial to use the following quantum circuit from [10, Fig. 17(b)]     <p>Figure 3</p>                     which is an alternative to the one in Fig. 2 that uses one additional logical qubit but requires only logical Pauli corrections, rather than logical Clifford corrections. In either case, given the logical resource state \\(\\ket{\\overline T}\\), the logical \\(\\overline T\\) typically incurs time overhead of \\(\\mathcal{O}\\left( d \\right)\\). We conclude that implementing the logical \\(\\overline T\\) reduces to the problem of preparing the logical state \\(\\ket{\\overline{T}}\\), which, in turn, can be realized via state distillation [11, 12]; see [13] for a brief overview of state distillation.</p>"},{"location":"fault-tolerant-quantum-computation/logical-gates-with-the-surface-code/#dominant-resource-cost-gatesqubits","title":"Dominant resource cost (gates/qubits)","text":"<p>State distillation provides a fault-tolerant method to prepare high-fidelity logical resource states, such as the logical state \\(\\ket{\\overline T}\\). The basic idea is to convert some number of noisy resource states into fewer but, crucially, less noisy resource states. Importantly, this task can be accomplished with quantum circuits comprising only Clifford gates (together with state preparation and measurement in the computational basis) and postselection. Typically, state distillation circuits are based on some QEC code, e.g., the 15-qubit Reed\u2013Muller code.</p><p>State distillation is often described as a resource-intensive method that contributes the most to the resource overhead of fault-tolerant quantum computation with the surface code [14] and, for that reason, many efforts have been devoted to finding possible alternatives [15, 16, 17, 18, 13]. However, recent results indicate that state distillation may not be as costly as one may think [10, 19], especially when one optimizes it for specific quantum hardware and noise that exhibits some bias [20]. In the task of estimating the ground state energy density of the Fermi\u2013Hubbard model, state distillation of logical Toffoli resource states injected one at a time uses less than \\(10\\%\\) of the total resources and is never a bottleneck on runtime of the quantum algorithm [21].</p><p>Oftentimes, a quantum algorithm is expressed as a quantum circuit \\(\\mathcal C\\) comprising Clifford and \\(T\\) gates. Thus, by using the aforementioned logical gates \\(\\overline H\\), \\(\\overline{CX}\\), and \\(\\overline{T}\\), we can fault-tolerantly implement the logical quantum circuit \\(\\overline{\\mathcal C}\\) with the surface code of code distance \\(d\\) and a planar layout of qubits in Fig. 1(a). However, from the perspective of reducing the resource overheads, it may be beneficial to consider a quantum circuit \\(\\mathcal C'\\) equivalent to the circuit \\(\\mathcal C\\), which is obtained from \\(\\mathcal C\\) by commuting all Clifford gates to the end of \\(\\mathcal C\\) [10]. As a result, the circuit \\(\\mathcal C'\\) only comprises multiqubit Pauli \\(\\pi/8\\) rotations (which are a generalization of the \\(T\\) gate and can be realized via, e.g., quantum circuits analogous to the one in Fig. 3. Consequently, fault-tolerant implementation of the logical circuit \\(\\overline{\\mathcal{C}'}\\) incurs the qubit overhead of \\(\\mathcal{O}\\left( Nd^2 \\right)\\) and time overhead of \\(\\mathcal{O}\\left( Md \\right)\\), where \\(N\\) and \\(M\\) are the number of, respectively, qubits and \\(T\\) gates in \\(\\mathcal C\\). We remark that the time overhead can be reduced at the expense of increased qubit overhead\u2014first by distilling more resource states and being able to use them faster, then by implementing them in parallel [10].</p>"},{"location":"fault-tolerant-quantum-computation/logical-gates-with-the-surface-code/#caveats","title":"Caveats","text":"<p>Lattice surgery is not necessary to realize fault-tolerant quantum computation with a planar layout of qubits and nearest-neighbor gates. An alternative approach (which actually preceded the development of lattice surgery) relies on the surface code with defects and braiding [22, 23, 14, 7]. However, resource overhead estimates strongly suggest that this approach is not competitive with lattice surgery [24].</p><p>A simple architecture depicted in Fig. 1(a) can be improved in a couple ways to reduce the qubit overhead. First, it is possible to pack surface code patches more densely, resulting in more logical qubits for the given total number of qubits and target code distance [25, 10] Second, one can designate certain regions, commonly referred to as magic state factories, to solely produce resource states, such as the logical state \\(\\ket{\\overline T}\\), and optimize their design [26, 10, 19].</p><p>To simplify implementation of logical gates, one can consider other QEC codes, e.g., the three-dimensional color code [27, 28]. The gauge color code has redundant degrees of freedom, commonly referred to as gauge qubits. For different states of its gauge qubits, the gauge color code admits transversal implementation of different logical gates, which, combined, form a universal gate set (thus circumventing the Eastin\u2013Knill theorem [29, 30]). Importantly, changing the state of gauge qubits can be done fault-tolerantly in constant time. However, to realize this construction one needs, for instance, a three-dimensional layout of qubits with nearest-neighbor gates or a planar layout of qubits with a limited number of nonlocal gates, which are more challenging to engineer compared to the simple architecture in Fig. 1(a). To achieve code distance \\(d\\) with the gauge color code one incurs qubit overhead of \\(\\mathcal{O}\\left( d^3 \\right)\\) (compared to qubit overhead of \\(\\mathcal{O}\\left( d^2 \\right)\\) for the surface code), so, similarly to single-shot QEC described in Quantum error correction with the surface code, this approach trades time overhead for qubit overhead.</p>"},{"location":"fault-tolerant-quantum-computation/logical-gates-with-the-surface-code/#example-use-cases","title":"Example use cases","text":"<ul> <li>Lattice surgery techniques developed for the surface code can be straightforwardly adapted to, e.g., the color code [31] or the surface code with a twist [32], leading to fault-tolerant quantum computation with potentially reduced qubit overhead. In addition, lattice surgery techniques can also be used for the fault-tolerant transfer of encoded information between arbitrary topological quantum codes [33].</li> <li>Now, we are ready to present a rough, order-of-magnitude estimate of the resource overheads needed to realize fault-tolerant quantum computation in the architecture based on the surface code and lattice surgery. For concreteness, we consider the circuit noise of strength \\(p=0.001\\), where each basic operation, including state preparation, CNOT gate, and measurement, can fail with probability \\(p\\). Assume that we want to implement a quantum circuit \\(\\mathcal C\\) comprising \\(N=10^3\\) qubits and a certain number \\(M=10^{10}\\) of \\(T\\) gates. These resource counts are in the ballpark of estimates for various quantum algorithms in the application areas of quantum chemistry, hyperref[appl:CondensedMatter]condensed matter physics, and cryptanalysis. First, following the procedure from [10], we compile \\(\\mathcal C\\) into a new circuit \\(\\mathcal C'\\) of depth \\(M\\) that comprises \\(N\\) qubits and \\(M\\) multiqubit Pauli \\(\\pi/8\\)-rotations implemented one at a time. Since there are \\(NM\\) possible fault locations in the circuit \\(\\mathcal C'\\), the error rate for each qubit of \\(\\mathcal C'\\) should not exceed than  \\[\\begin{equation} \\epsilon \\approx 1/(N M). \\end{equation}\\] <p>Since each qubit of \\(\\mathcal C'\\) is realized as a logical qubit of the surface code with distance \\(d\\), then its logical error rate \\(p_\\text{fail}\\) can be approximated by </p> \\[\\begin{equation} p_\\text{fail} \\approx \\alpha (p/p_\\text{th})^{d/2}, \\end{equation}\\] <p>where we can crudely set \\(\\alpha = 0.05\\) and \\(p_\\text{th} = 0.01\\); see quantum error correction with the surface code for more details. Note that these values are empirical and depend heavily on the choice of the decoder; in our case\u2014the belief-matching algorithm [34]. Thus, in order for the logical error rate \\(p_\\text{fail}\\) to reach the target error rate \\(\\epsilon\\) we need the surface code distance at least </p> \\[\\begin{equation} d \\approx \\left\\lceil 2 \\log(\\alpha N M)/\\log(p_\\mathrm{th}/p) \\right\\rceil. \\end{equation}\\] <p>Assuming that half of all required qubits is devoted to realizing \\(N\\) surface code patches (each comprising \\(2d^2-1\\) data and ancilla qubits), with the other half used for resource state distillation and routing, we obtain that the fault-tolerant implementation of \\(\\mathcal C'\\) incurs qubit overhead of </p> \\[\\begin{equation} n_{\\mathcal C'} \\approx 4Nd^2 \\end{equation}\\] <p>and time overhead of </p> \\[\\begin{equation} t_{\\mathcal C'} \\approx Md\\tau, \\end{equation}\\] <p>where we crudely set \\(\\tau = 1\\ \\!\\mu s\\) to be the time needed to implement one syndrome measurement round with the superconducting circuits architecture. Finally, our order-of-magnitude resource estimate gives \\(2.3\\times 10^6\\) physical qubits and \\(67\\) hours of runtime. This general approach to resource estimation has been applied to a number of specific quantum algorithms in a variety of application areas; see, e.g., [35, 36, 37, 38, 39]. These references often go beyond a back-of-the-envelope calculation and provide a more meticulous analysis that accounts for exact qubit layouts and the physical footprint of resource state distillation factories. They also pursue optimizations to how the circuit is implemented (e.g. exploiting space-time tradeoffs) in light of these considerations.</p> </li> </ul>"},{"location":"fault-tolerant-quantum-computation/logical-gates-with-the-surface-code/#further-reading","title":"Further reading","text":"<ul> <li>An accessible overview of fault-tolerant quantum computation based on the surface code and lattice surgery can be found in [10].</li> <li>A convenient way to describe and optimize lattice surgery operations is via the ZX calculus, which is a diagrammatic language for quantum computing [40, 41].</li> <li>A direct comparison of the resource overhead associated with preparation of the logical resource state \\(\\ket{\\overline T}\\) using either state distillation or transversal gates (with the three-dimensional color code) can be found in [13].</li> <li>To read about a framework for estimating resources required to realize large-scale fault-tolerant quantum computation, see [38].</li> </ul>"},{"location":"fault-tolerant-quantum-computation/logical-gates-with-the-surface-code/#bibliography","title":"Bibliography","text":"<ol> <li> <p>A Yu Kitaev. Quantum computations: algorithms and error correction. Russian Mathematical Surveys, 52(6):1191, 1997. doi:10.1070/RM1997v052n06ABEH002155.</p> </li> <li> <p>Michael A. Nielsen and Isaac L. Chuang. Quantum computation and quantum information. Cambridge University Press, 2000. doi:10.1017/CBO9780511976667.</p> </li> <li> <p>Daniel Gottesman. The heisenberg representation of quantum computers. arXiv: https://arxiv.org/abs/quant-ph/9807006, 1998.</p> </li> <li> <p>Scott Aaronson and Daniel Gottesman. Improved simulation of stabilizer circuits. Physical Review A, 70:052328, 2004. arXiv: https://arxiv.org/abs/quant-ph/0406196. doi:10.1103/PhysRevA.70.052328.</p> </li> <li> <p>Dominic Horsman, Austin G Fowler, Simon Devitt, and Rodney Van Meter. Surface code quantum computing by lattice surgery. New Journal of Physics, 14(12):123011, 2012. arXiv: https://arxiv.org/abs/1111.4022. doi:10.1088/1367-2630/14/12/123011.</p> </li> <li> <p>Daniel Gottesman and Isaac L. Chuang. Demonstrating the viability of universal quantum computation using teleportation and single-qubit operations. Nature, 402(6760):390\u2013393, 1999. doi:10.1038/46503.</p> </li> <li> <p>Benjamin J. Brown, Katharina Laubscher, Markus S. Kesselring, and James R. Wootton. Poking holes and cutting corners to achieve clifford gates with the surface code. Physical Review X, 7:021029, 2017. arXiv: https://arxiv.org/abs/1609.04673. doi:10.1103/PhysRevX.7.021029.</p> </li> <li> <p>Aleksander Kubica, Beni Yoshida, and Fernando Pastawski. Unfolding the color code. New Journal of Physics, 17(8):083026, 2015. arXiv: https://arxiv.org/abs/1503.02065. doi:10.1088/1367-2630/17/8/083026.</p> </li> <li> <p>Jonathan E. Moussa. Transversal clifford gates on folded surface codes. Physical Review A, 94:042316, 2016. arXiv: https://arxiv.org/abs/1603.02286. doi:10.1103/PhysRevA.94.042316.</p> </li> <li> <p>Daniel Litinski. A game of surface codes: large-scale quantum computing with lattice surgery. Quantum, 3:128, 3 2019. arXiv: https://arxiv.org/abs/1808.02892. URL: https://doi.org/10.22331/q-2019-03-05-128, doi:10.22331/q-2019-03-05-128.</p> </li> <li> <p>E. Knill. Fault-tolerant postselected quantum computation: schemes. arXiv: https://arxiv.org/abs/quant-ph/0402171, 2004.</p> </li> <li> <p>Sergey Bravyi and Alexei Kitaev. Universal quantum computation with ideal clifford gates and noisy ancillas. Physical Review A, 71(2):022316, 2005. arXiv: https://arxiv.org/abs/quant-ph/0403025. doi:10.1103/physreva.71.022316.</p> </li> <li> <p>Michael E. Beverland, Aleksander Kubica, and Krysta M. Svore. Cost of universality: a comparative study of the overhead of state distillation and code switching with color codes. PRX Quantum, 2:020341, 2021. arXiv: https://arxiv.org/abs/2101.02211. doi:10.1103/PRXQuantum.2.020341.</p> </li> <li> <p>Austin G. Fowler, Matteo Mariantoni, John M. Martinis, and Andrew N. Cleland. Surface codes: towards practical large-scale quantum computation. Physical Review A, 86:032324, 9 2012. arXiv: https://arxiv.org/abs/1208.0928. URL: https://link.aps.org/doi/10.1103/PhysRevA.86.032324, doi:10.1103/PhysRevA.86.032324.</p> </li> <li> <p>Sergey Bravyi and Andrew Cross. Doubled color codes. arXiv: https://arxiv.org/abs/1509.03239, 2015.</p> </li> <li> <p>Tomas Jochym-O'Connor and Stephen D. Bartlett. Stacked codes: universal fault-tolerant quantum computation in a two-dimensional layout. Physical Review A, 93:022323, 2016. arXiv: https://arxiv.org/abs/1509.04255. doi:10.1103/PhysRevA.93.022323.</p> </li> <li> <p>H\u00e9ctor Bomb\u00edn. 2d quantum computation with 3d topological codes. arXiv: https://arxiv.org/abs/1810.09571, 2018.</p> </li> <li> <p>Christopher Chamberland and Andrew W. Cross. Fault-tolerant magic state preparation with flag qubits. Quantum, 3:143, 2019. arXiv: https://arxiv.org/abs/1811.00566. doi:10.22331/q-2019-05-20-143.</p> </li> <li> <p>Daniel Litinski. Magic state distillation: not as costly as you think. Quantum, 3:205, 12 2019. arXiv: https://arxiv.org/abs/1905.06903. URL: https://doi.org/10.22331/q-2019-12-02-205, doi:10.22331/q-2019-12-02-205.</p> </li> <li> <p>Daniel Litinski and Naomi Nickerson. Active volume: an architecture for efficient fault-tolerant quantum computers with limited non-local connections. arXiv: https://arxiv.org/abs/2211.15465, 2022.</p> </li> <li> <p>Christopher Chamberland, Kyungjoo Noh, Patricio Arrangoiz-Arriola, Earl T. Campbell, Connor T. Hann, Joseph Iverson, Harald Putterman, Thomas C. Bohdanowicz, Steven T. Flammia, Andrew Keller, Gil Refael, John Preskill, Liang Jiang, Amir H. Safavi-Naeini, Oskar Painter, and Fernando G.S.L. Brand\u00e3o. Building a fault-tolerant quantum computer using concatenated cat codes. PRX Quantum, 3:010329, 2022. arXiv: https://arxiv.org/abs/2012.04108. doi:10.1103/PRXQuantum.3.010329.</p> </li> <li> <p>Robert Raussendorf and Jim Harrington. Fault-tolerant quantum computation with high threshold in two dimensions. Physical Review Letters, 98:190504, 2007. arXiv: https://arxiv.org/abs/quant-ph/0610082. doi:10.1103/PhysRevLett.98.190504.</p> </li> <li> <p>R Raussendorf, J Harrington, and K Goyal. Topological fault-tolerance in cluster state quantum computation. New Journal of Physics, 9(6):199\u2013199, 2007. arXiv: https://arxiv.org/abs/quant-ph/0703143. doi:10.1088/1367-2630/9/6/199.</p> </li> <li> <p>Austin G. Fowler and Craig Gidney. Low overhead quantum computation using lattice surgery. arXiv: https://arxiv.org/abs/1808.06709, 2018.</p> </li> <li> <p>L. Lao, B. van Wee, I. Ashraf, J. van Someren, N. Khammassi, K. Bertels, and C. G. Almudever. Mapping of lattice surgery-based quantum circuits on surface code architectures. Quantum Science and Technology, 4(1):015005, 2018. arXiv: https://arxiv.org/abs/1805.11127. doi:10.1088/2058-9565/aadd1a.</p> </li> <li> <p>Joe O'Gorman and Earl T. Campbell. Quantum computation with realistic magic-state factories. Physical Review A, 95:032338, 2017. arXiv: https://arxiv.org/abs/1605.07197. doi:10.1103/PhysRevA.95.032338.</p> </li> <li> <p>H\u00e9ctor Bomb\u00edn. Gauge color codes: optimal transversal gates and gauge fixing in topological stabilizer codes. New Journal of Physics, 17(8):083002, 2015. arXiv: https://arxiv.org/abs/1311.0879. doi:10.1088/1367-2630/17/8/083002.</p> </li> <li> <p>Aleksander Kubica and Michael E. Beverland. Universal transversal gates with color codes: a simplified approach. Physical Review A, 91:032330, 2015. arXiv: https://arxiv.org/abs/1410.0069. doi:10.1103/PhysRevA.91.032330.</p> </li> <li> <p>Bryan Eastin and Emanuel Knill. Restrictions on transversal encoded quantum gate sets. Physical Review Letters, 102(11):110502, 2009. arXiv: https://arxiv.org/abs/0811.4262. doi:10.1103/physrevlett.102.110502.</p> </li> <li> <p>Bei Zeng, Andrew Cross, and Isaac L. Chuang. Transversality versus universality for additive quantum codes. IEEE Transactions on Information Theory, 57(9):6272\u20136284, 2011. arXiv: https://arxiv.org/abs/0706.1382. doi:10.1109/tit.2011.2161917.</p> </li> <li> <p>Andrew J. Landahl and Ciaran Ryan-Anderson. Quantum computing by color-code lattice surgery. arXiv: https://arxiv.org/abs/1407.5103, 2014.</p> </li> <li> <p>Theodore J. Yoder and Isaac H. Kim. The surface code with a twist. Quantum, 1:2, 2017. arXiv: https://arxiv.org/abs/1612.04795. doi:10.22331/q-2017-04-25-2.</p> </li> <li> <p>Hendrik Poulsen Nautrup, Nicolai Friis, and Hans J. Briegel. Fault-tolerant interface between quantum memories and quantum processors. Nature Communications, 2017. arXiv: https://arxiv.org/abs/1609.08062. doi:10.1038/s41467-017-01418-2.</p> </li> <li> <p>Oscar Higgott, Thomas C. Bohdanowicz, Aleksander Kubica, Steven T. Flammia, and Earl T. Campbell. Improved decoding of circuit noise and fragile boundaries of tailored surface codes. Physical Review X, 13:031007, 7 2023. arXiv: https://arxiv.org/abs/2203.04948. URL: https://link.aps.org/doi/10.1103/PhysRevX.13.031007, doi:10.1103/PhysRevX.13.031007.</p> </li> <li> <p>Joonho Lee, Dominic W Berry, Craig Gidney, William J Huggins, Jarrod R McClean, Nathan Wiebe, and Ryan Babbush. Even more efficient quantum computations of chemistry through tensor hypercontraction. PRX Quantum, 2(3):030305, 2021. arXiv: https://arxiv.org/abs/2011.03494. doi:10.1103/PRXQuantum.2.030305.</p> </li> <li> <p>Craig Gidney and Martin Eker\u00e5. How to factor 2048 bit rsa integers in 8 hours using 20 million noisy qubits. Quantum, 5:433, 4 2021. arXiv: https://arxiv.org/abs/1905.09749. URL: https://doi.org/10.22331/q-2021-04-15-433, doi:10.22331/q-2021-04-15-433.</p> </li> <li> <p>Ian D. Kivlichan, Craig Gidney, Dominic W. Berry, Nathan Wiebe, Jarrod McClean, Wei Sun, Zhang Jiang, Nicholas Rubin, Austin Fowler, Al\u00e1n Aspuru-Guzik, Hartmut Neven, and Ryan Babbush. Improved fault-tolerant quantum simulation of condensed-phase correlated electrons via trotterization. Quantum, 4:296, 7 2020. arXiv: https://arxiv.org/abs/1902.10673. URL: https://doi.org/10.22331/q-2020-07-16-296, doi:10.22331/q-2020-07-16-296.</p> </li> <li> <p>Michael E. Beverland, Prakash Murali, Matthias Troyer, Krysta M. Svore, Torsten Hoeffler, Vadym Kliuchnikov, Guang Hao Low, Mathias Soeken, Aarthi Sundaram, and Alexander Vaschillo. Assessing requirements to scale to practical quantum advantage. arXiv: https://arxiv.org/abs/2211.07629, 2022. URL: http://arxiv.org/abs/2211.07629.</p> </li> <li> <p>Yuval R. Sanders, Dominic W. Berry, Pedro C.S. Costa, Louis W. Tessler, Nathan Wiebe, Craig Gidney, Hartmut Neven, and Ryan Babbush. Compilation of fault-tolerant quantum heuristics for combinatorial optimization. PRX Quantum, 1(2):020312, 11 2020. arXiv: https://arxiv.org/abs/2007.07391. doi:10.1103/PRXQuantum.1.020312.</p> </li> <li> <p>Bob Coecke and Aleks Kissinger. Picturing Quantum Processes. Cambridge University Press, 2017. doi:10.1017/9781316219317.</p> </li> <li> <p>Niel de Beaudrap and Dominic Horsman. The zx calculus is a language for surface code lattice surgery. Quantum, 4:218, 2020. arXiv: https://arxiv.org/abs/1704.08670. doi:10.22331/q-2020-01-09-218.</p> </li> </ol>"},{"location":"fault-tolerant-quantum-computation/quantum-error-correction-with-the-surface-code/","title":"Quantum error correction with the surface code","text":""},{"location":"fault-tolerant-quantum-computation/quantum-error-correction-with-the-surface-code/#rough-overview-in-words","title":"Rough overview (in words)","text":"<p>To protect quantum information from detrimental effects of noise, we can encode it into a code space of some quantum error correcting (QEC) code [1, 2]. Oftentimes, we choose to work with stabilizer codes [3]. By definition, a code space of a stabilizer code is the simultaneous \\((+1)\\)-eigenspace of a set of commuting Pauli operators, commonly referred to as parity checks.</p><p>The surface code [4, 5, 6] is one of the most-studied stabilizer codes. It can be implemented with a planar layout of qubits and entangling gates only between neighboring qubits. For that reason, the surface code is particularly appealing for quantum hardware architectures with restricted qubit layout and connectivity, such as superconducting circuits [7, 8]. The most common realization of the surface code uses \\(n = L^2\\) data qubits to encode \\(k=1\\) logical qubit and has code distance \\(d=L\\), where \\(L\\) is the linear size of the \\(L\\times L\\) square lattice with open boundary conditions. Additionally, \\(n_A = L^2 -1\\) ancilla qubits are used to measure parity checks; see Figure 1(a).</p> <p> </p> <p>Figure 1(a): A planar layout of data and ancilla qubits (white and yellow dots, respectively) with entangling gates (green edges) only between neighboring qubits. This layout gives rise to the \\(L\\times L\\) square lattice with open boundary conditions, where \\(L=5\\) here.</p> <p></p> <p>Figure 1(b): The surface code can be realized by measuring Pauli \\(Z\\)- and \\(X\\)-type parity checks (light and dark faces, respectively). The error syndrome (red and blue stars) can be interpreted as the endpoints of string-like Pauli \\(X\\) and \\(Z\\) errors (red and blue dashed edges, respectively). </p> <p>In order to perform QEC, we have to be able to detect errors without revealing the encoded information. For stabilizer codes, we can achieve that by measuring their parity checks to obtain the error syndrome (which comprises the measurement outcomes returning \\(-1\\)). Then, the error syndrome is processed by specialized classical algorithms, also known as \"decoders,\" to find an appropriate recovery operator that attempts to remove errors afflicting the encoded information. For generic stabilizer codes, the problem of optimal decoding is computationally hard, even for simple noise models [9]. However, for QEC codes with some underlying structure, such as the surface code, there exist a variety of computationally efficient (albeit not optimal) decoding algorithms. In particular, the three most popular classes of decoders for the surface code are as follows.</p><ul> <li>Matching decoders, including the minimum-weight perfect matching algorithm [6] and its follow-up improvements, such as the belief-matching algorithm [10]. These decoders phrase the problem of surface code decoding as a graph-theoretic problem of perfect matching, which can be efficiently solved [11].</li> <li>Clustering decoders, such as the renormalization-group decoder [12, 13] and the union-find decoder [14]. These decoders primarily exploit the structure of the error syndrome in the surface code; see Fig. 1(b).</li> <li>Tensor-network decoders [15, 16, 17]. These decoders phrase the the problem of surface code decoding as a numerical problem of contracting tensor networks.</li> </ul><p>In order to assess the usefulness of decoders, one usually considers two criteria: runtime and performance. The first criterion, runtime, is defined as the time needed for the decoder to process the error syndrome. It is crucial that any practical decoder is able to operate at the rate compatible with the rate of parity check measurements; otherwise, the error syndrome will start to accumulate, leading to the backlog problem [18]. The second criterion, performance, is typically defined for a given noise model in terms of the logical error rate, i.e., the failure rate of the decoder to successfully undo the effects of noise on the encoded information. From the perspective of reducing runtime and improving performance, matching and clustering decoders stand out. Namely, they can achieve almost-linear runtime [19, 14], and their performance is close to optimal. To achieve optimal performance, one can use tensor-network decoders, however they are often not computationally efficient, with runtime that scales unfavorably.</p>"},{"location":"fault-tolerant-quantum-computation/quantum-error-correction-with-the-surface-code/#rough-overview-in-math","title":"Rough overview (in math)","text":"<p>In addition to being compatible with planar layouts of qubits and admitting computationally efficient decoders with good performance, the surface code also exhibits one of the highest QEC thresholds. Recall that a QEC threshold is specified for the following triple: a QEC code family of growing distance \\(d\\), a decoder and noise model. It is defined as the highest value \\(p_\\text{th}\\) such that for any error rate \\(p&lt; p_\\text{th}\\) the probability that the decoder fails to undo the effects of noise goes to zero as \\(d\\) goes to infinity. For example, the QEC threshold for the surface code, using minimum-weight perfect matching algorithm, with a circuit noise model based on depolarizing noise, is around \\(1\\%\\) [20, 10].</p><p>Typically, if the error rate \\(p\\) describing noise is sufficiently low and below the threshold \\(p_\\mathrm{th}\\), then the logical error rate \\(p_\\mathrm{fail}\\) scales as follows </p>\\[\\begin{equation} p_\\mathrm{fail} \\sim \\left(\\frac{p}{p_\\mathrm{th}}\\right)^{\\left\\lceil \\frac{d}{2}\\right\\rceil}. \\end{equation}\\]<p>This implies that in order to achieve the target error rate \\(\\epsilon\\), it suffices to implement the surface code with code distance \\(d = \\mathcal{O}\\left( \\log(1/\\epsilon) / \\log(p_\\text{th}/p) \\right)\\) using \\(n + n_A = \\mathcal{O}\\left( d^2 \\right) = \\mathcal{O}\\left( \\log^2(1/\\epsilon) / \\log^2(p_\\text{th}/p) \\right)\\) data and ancilla qubits. Subsequently, qubit overhead associated with QEC based on the surface code only scales polylogarithmically in the inverse target error rate \\(1/\\epsilon\\).</p>"},{"location":"fault-tolerant-quantum-computation/quantum-error-correction-with-the-surface-code/#dominant-resource-cost-gatesqubits","title":"Dominant resource cost (gates/qubits)","text":"<p>Performing reliable QEC in the presence of measurement errors becomes challenging since the error syndrome can be corrupted. A straightforward solution to the problem of unreliable error syndrome is to repeatedly measure the parity checks in order to gain enough confidence in their measurement outcomes [21, 6]. If this approach is applied to the surface code with code distance \\(d\\), then one needs to perform \\(\\mathcal{O}\\left( d \\right)\\) rounds of parity check measurements, incurring relatively large time overhead.</p><p>To reduce time overhead, one can pursue single-shot QEC [22], which does not require repeated measurement rounds. It is possible to realize single-shot QEC with the surface code [23, 24, 25], however, in addition to parity checks in Fig. 1(b), one would need to measure nonlocal high-weight parity checks, which is a serious limitation. A more streamlined approach is to consider a different realization of the surface code, the three-dimensional subsystem toric code [26, 27], which can be implemented with qubits arranged on the cubic lattice and local low-weight parity checks. Although this approach is natively defined in three spatial dimensions, it can be emulated with planar layouts of qubits and either a limited number of nonlocal gates or the ability to reshuffle qubits (which is available with, e.g., Rydberg atoms [28, 29]). In order to realize code distance \\(d\\) one incurs qubit overhead of \\(\\mathcal{O}\\left( d^3 \\right)\\) (compared to qubit overhead of \\(\\mathcal{O}\\left( d^2 \\right)\\) for the surface code). From that perspective, single-shot QEC with the subsystem toric code can be viewed as trading time overhead for qubit overhead.</p>"},{"location":"fault-tolerant-quantum-computation/quantum-error-correction-with-the-surface-code/#caveats","title":"Caveats","text":"<p>There have been efforts to improve surface code decoders by incorporating various machine learning methods, including neural networks [30, 31, 32] and reinforcement learning [33]. At the current stage, decoders solely based on machine learning methods seem to be of limited applicability, mostly due to high training costs and scalability issues. Nevertheless, these approaches are likely to be immensely beneficial for QEC in the settings where (possibly correlated) noise is unknown and may have to be learned first.</p><p>Typically, in QEC analysis one considers simple Pauli noise, such as depolarizing noise acting independently and identically on each qubit. If noise exhibits bias between the \\(X\\), \\(Y\\), and \\(Z\\) components of Pauli noise, then this structure can be exploited, leading to dramatically increased QEC thresholds, as exemplified by variants of the surface code [34, 35, 36]. Similarly, noise that is biased toward erasure errors can be beneficial from the perspective of QEC [37, 38, 39]. On the other hand, realistic noise may be coherent or correlated and thus not only difficult to correct, but also to numerically simulate. For instance, the logical error rates for coherent noise may be orders of magnitude higher than the estimates of the logical error rates for simple Pauli noise (assuming both types of noise have the same error rate) [40].</p><p>In addition to the three-dimensional subsystem toric code, one can also consider other higher-dimensional versions of the surface code. With these codes, roughly speaking, one improves the QEC capabilities at the expense of increased qubit overhead. Moreover, for the higher-dimensional surface code, it may suffice to use arguably the least complex decoders that are based on cellular automata (which, by definition, are parallelizable and only use local information about the error syndrome) [6, 41, 42, 43].</p>"},{"location":"fault-tolerant-quantum-computation/quantum-error-correction-with-the-surface-code/#example-use-cases","title":"Example use cases","text":"<ul> <li>Decoders for the surface code can be used for other QEC code families, such as the color code [44, 45, 46]. In fact, due to a close connection between the color codes and the surface codes [47, 48], any surface code decoder can be used as a subroutine in the restriction decoder for any color code (in two or more spatial dimensions) [49, 50].</li> </ul>"},{"location":"fault-tolerant-quantum-computation/quantum-error-correction-with-the-surface-code/#further-reading","title":"Further reading","text":"<ul> <li>The seminal paper by Dennis et al. [6] is a thorough introduction to QEC with the surface code.</li> <li>A recent perspective [51] on how to use matching decoders to decode stabilizer codes.</li> <li>Open-source software packages have been developed for implementing QEC with the surface code, such as Stim [52] and PyMatching [53].</li> </ul>"},{"location":"fault-tolerant-quantum-computation/quantum-error-correction-with-the-surface-code/#bibliography","title":"Bibliography","text":"<ol> <li> <p>Peter W. Shor. Scheme for reducing decoherence in quantum computer memory. Physical Review A, 52:R2493\u2013R2496, 1995. doi:10.1103/PhysRevA.52.R2493.</p> </li> <li> <p>A. M. Steane. Error correcting codes in quantum theory. Physical Review Letters, 77:793\u2013797, 1996. doi:10.1103/PhysRevLett.77.793.</p> </li> <li> <p>Daniel Gottesman. Class of quantum error-correcting codes saturating the quantum hamming bound. Physical Review A, 54(3):1862\u20131868, 1996. arXiv: https://arxiv.org/abs/quant-ph/9604038. doi:10.1103/PhysRevA.54.1862.</p> </li> <li> <p>A. Yu. Kitaev. Fault-tolerant quantum computation by anyons. Annals of Physics, 303(1):2\u201330, 2003. arXiv: https://arxiv.org/abs/quant-ph/9707021. doi:10.1016/S0003-4916(02)00018-0.</p> </li> <li> <p>S. B. Bravyi and A. Yu. Kitaev. Quantum codes on a lattice with boundary. arXiv: https://arxiv.org/abs/quant-ph/9811052, 1998.</p> </li> <li> <p>Eric Dennis, Alexei Kitaev, Andrew Landahl, and John Preskill. Topological quantum memory. Journal of Mathematical Physics, 43(9):4452\u20134505, 2002. arXiv: https://arxiv.org/abs/quant-ph/0110143. doi:10.1063/1.1499754.</p> </li> <li> <p>Michel H Devoret and Robert J Schoelkopf. Superconducting circuits for quantum information: an outlook. Science, 339:1169\u20131174, 2013. doi:10.1126/science.123193.</p> </li> <li> <p>Alexandre Blais, Arne L. Grimsmo, S. M. Girvin, and Andreas Wallraff. Circuit quantum electrodynamics. Reviews of Modern Physics, 93:025005, 2021. arXiv: https://arxiv.org/abs/2005.12667. URL: https://link.aps.org/doi/10.1103/RevModPhys.93.025005, doi:10.1103/RevModPhys.93.025005.</p> </li> <li> <p>Pavithran Iyer and David Poulin. Hardness of decoding quantum stabilizer codes. IEEE Transactions on Information Theory, 61(9):5209\u20135223, 2015. arXiv: https://arxiv.org/abs/1310.3235. doi:10.1109/TIT.2015.2422294.</p> </li> <li> <p>Oscar Higgott, Thomas C. Bohdanowicz, Aleksander Kubica, Steven T. Flammia, and Earl T. Campbell. Improved decoding of circuit noise and fragile boundaries of tailored surface codes. Physical Review X, 13:031007, 7 2023. arXiv: https://arxiv.org/abs/2203.04948. URL: https://link.aps.org/doi/10.1103/PhysRevX.13.031007, doi:10.1103/PhysRevX.13.031007.</p> </li> <li> <p>Jack Edmonds. Paths, trees, and flowers. Canadian Journal of Mathematics, 17:449\u2013467, 1965. doi:10.4153/CJM-1965-045-4.</p> </li> <li> <p>Guillaume Duclos-Cianci and David Poulin. Fast decoders for topological quantum codes. Physical Review Letters, 104:050504, 2010. arXiv: https://arxiv.org/abs/0911.0581. doi:10.1103/PhysRevLett.104.050504.</p> </li> <li> <p>Hussain Anwar, Benjamin J Brown, Earl T Campbell, and Dan E Browne. Fast decoders for qudit topological codes. New Journal of Physics, 16(6):063038, 2014. arXiv: https://arxiv.org/abs/1311.4895. doi:10.1088/1367-2630/16/6/063038.</p> </li> <li> <p>Nicolas Delfosse and Naomi H. Nickerson. Almost-linear time decoding algorithm for topological codes. Quantum, 5:595, 2021. arXiv: https://arxiv.org/abs/1709.06218. doi:10.22331/q-2021-12-02-595.</p> </li> <li> <p>Sergey Bravyi, Martin Suchara, and Alexander Vargo. Efficient algorithms for maximum likelihood decoding in the surface code. Physical Review A, 90:032326, 2014. arXiv: https://arxiv.org/abs/1405.4883. doi:10.1103/PhysRevA.90.032326.</p> </li> <li> <p>Andrew S. Darmawan and David Poulin. Tensor-network simulations of the surface code under realistic noise. Physical Review Letters, 119:040502, 2017. arXiv: https://arxiv.org/abs/1607.06460. doi:10.1103/PhysRevLett.119.040502.</p> </li> <li> <p>Christopher T. Chubb. General tensor network decoding of 2d pauli codes. arXiv: https://arxiv.org/abs/2101.04125, 2021.</p> </li> <li> <p>Barbara M. Terhal. Quantum error correction for quantum memories. Reviews of Modern Physics, 87(2):307\u2013346, 2015. arXiv: https://arxiv.org/abs/1302.3428. doi:10.1103/revmodphys.87.307.</p> </li> <li> <p>Oscar Higgott and Craig Gidney. Sparse blossom: correcting a million errors per core second with minimum-weight matching. arXiv: https://arxiv.org/abs/2303.15933, 2023.</p> </li> <li> <p>David S. Wang, Austin G. Fowler, and Lloyd C. L. Hollenberg. Surface code quantum computing with error rates over 1%. Physical Review A, 83:020302, 2011. doi:10.1103/PhysRevA.83.020302.</p> </li> <li> <p>Peter W. Shor. Fault-tolerant quantum computation. In Proceedings of the 37th IEEE Symposium on Foundations of Computer Science (FOCS), 56\u201365. IEEE Comput. Soc. Press, 1996. arXiv: https://arxiv.org/abs/quant-ph/9605011. doi:10.1109/SFCS.1996.548464.</p> </li> <li> <p>H\u00e9ctor Bomb\u00edn. Single-shot fault-tolerant quantum error correction. Physical Review X, 5(3):031043, 2015. arXiv: https://arxiv.org/abs/1404.5504. URL: https://doi.org/10.1103/physrevx.5.031043, doi:10.1103/physrevx.5.031043.</p> </li> <li> <p>Earl T. Campbell. A theory of single-shot error correction for adversarial noise. Quantum Science and Technology, 4(2):025006, 2019. arXiv: https://arxiv.org/abs/1805.09271. doi:10.1088/2058-9565/aafc8f.</p> </li> <li> <p>Alexei Ashikhmin, Ching Yi Lai, and Todd A. Brun. Quantum data-syndrome codes. IEEE Journal on Selected Areas in Communications, 38:449\u2013462, 2020. arXiv: https://arxiv.org/abs/1907.01393. doi:10.1109/JSAC.2020.2968997.</p> </li> <li> <p>Nicolas Delfosse, Ben W. Reichardt, and Krysta M. Svore. Beyond single-shot fault-tolerant quantum error correction. IEEE Transactions on Information Theory, 68(1):287\u2013301, 2022. arXiv: https://arxiv.org/abs/2002.05180. doi:10.1109/tit.2021.3120685.</p> </li> <li> <p>Aleksander Kubica and Michael Vasmer. Single-shot quantum error correction with the three-dimensional subsystem toric code. Nature Communications, 13(1):6272, 2022. arXiv: https://arxiv.org/abs/2106.02621. doi:10.1038/s41467-022-33923-4.</p> </li> <li> <p>Jacob C. Bridgeman, Aleksander Kubica, and Michael Vasmer. Lifting topological codes: three-dimensional subsystem codes from two-dimensional anyon models. arXiv: https://arxiv.org/abs/2305.06365, 2023.</p> </li> <li> <p>M. Saffman, T. G. Walker, and K. M\u00f8lmer. Quantum information with rydberg atoms. Reviews of Modern Physics, 82:2313\u20132363, 2010. arXiv: https://arxiv.org/abs/0909.4777. URL: https://link.aps.org/doi/10.1103/RevModPhys.82.2313, doi:10.1103/RevModPhys.82.2313.</p> </li> <li> <p>Antoine Browaeys and Thierry Lahaye. Many-body physics with individually controlled rydberg atoms. Nature Physics, 16:132\u2013142, 2020. arXiv: https://arxiv.org/abs/2002.07413. doi:10.1038/s41567-019-0733-z.</p> </li> <li> <p>Giacomo Torlai and Roger G. Melko. Neural decoder for topological codes. Physical Review Letters, 119:030501, 2017. arXiv: https://arxiv.org/abs/1610.04238. doi:10.1103/PhysRevLett.119.030501.</p> </li> <li> <p>Nishad Maskara, Aleksander Kubica, and Tomas Jochym-O'Connor. Advantages of versatile neural-network decoding for topological codes. Physical Review A, 99:052351, 2019. arXiv: https://arxiv.org/abs/1802.08680. doi:10.1103/PhysRevA.99.052351.</p> </li> <li> <p>Christopher Chamberland, Luis Goncalves, Prasahnt Sivarajah, Eric Peterson, and Sebastian Grimberg. Techniques for combining fast local decoders with global decoders under circuit-level noise. Quantum Science and Technology, 8(4):045011, 7 2023. arXiv: https://arxiv.org/abs/2208.01178. URL: https://dx.doi.org/10.1088/2058-9565/ace64d, doi:10.1088/2058-9565/ace64d.</p> </li> <li> <p>Ryan Sweke, Markus S Kesselring, Evert P L van Nieuwenburg, and Jens Eisert. Reinforcement learning decoders for fault-tolerant quantum computation. Machine Learning: Science and Technology, 2(2):025005, 2020. arXiv: https://arxiv.org/abs/1810.07207. doi:10.1088/2632-2153/abc609.</p> </li> <li> <p>David K. Tuckett, Stephen D. Bartlett, and Steven T. Flammia. Ultrahigh error threshold for surface codes with biased noise. Physical Review Letters, 120:050505, 2018. arXiv: https://arxiv.org/abs/1708.08474. doi:10.1103/PhysRevLett.120.050505.</p> </li> <li> <p>J. Pablo Bonilla Ataides, David K. Tuckett, Stephen D. Bartlett, Steven T. Flammia, and Benjamin J. Brown. The xzzx surface code. Nature Communications, 12:2172, 2021. arXiv: https://arxiv.org/abs/2009.07851. doi:10.1038/s41467-021-22274-1.</p> </li> <li> <p>Arpit Dua, Aleksander Kubica, Liang Jiang, Steven T. Flammia, and Michael J. Gullans. Clifford-deformed surface codes. arXiv: https://arxiv.org/abs/2201.07802, 2022.</p> </li> <li> <p>Thomas M. Stace, Sean D. Barrett, and Andrew C. Doherty. Thresholds for topological codes in the presence of loss. Physical Review Letters, 102:200501, 2009. arXiv: https://arxiv.org/abs/0904.3556. doi:10.1103/PhysRevLett.102.200501.</p> </li> <li> <p>Yue Wu, Shimon Kolkowitz, Shruti Puri, and Jeff D. Thompson. Erasure conversion for fault-tolerant quantum computing in alkaline earth rydberg atom arrays. Nature Communications, 13(1):4657, 2022. arXiv: https://arxiv.org/abs/2201.03540. doi:10.1038/s41467-022-32094-6.</p> </li> <li> <p>Aleksander Kubica, Arbel Haim, Yotam Vaknin, Fernando Brand\u00e3o, and Alex Retzker. Erasure qubits: overcoming the \\(t\\_1\\) limit in superconducting circuits. arXiv: https://arxiv.org/abs/2208.05461, 2022.</p> </li> <li> <p>Pavithran Iyer and David Poulin. A small quantum computer is needed to optimize fault-tolerant protocols. Quantum Science and Technology, 3(3):030504, 2018. arXiv: https://arxiv.org/abs/1711.04736. doi:10.1088/2058-9565/aab73c.</p> </li> <li> <p>Nikolas P. Breuckmann, Kasper Duivenvoorden, Dominik Michels, and Barbara M. Terhal. Local decoders for the 2d and 4d toric code. Quantum Information and Computation, 17(3&amp;4):0181, 2017. arXiv: https://arxiv.org/abs/1609.00510. doi:10.26421/QIC17.3-4-1.</p> </li> <li> <p>Aleksander Kubica and John Preskill. Cellular-automaton decoders with provable thresholds for topological codes. Physical Review Letters, 123:020501, 2019. arXiv: https://arxiv.org/abs/1809.10145. doi:10.1103/PhysRevLett.123.020501.</p> </li> <li> <p>Michael Vasmer, Dan E. Browne, and Aleksander Kubica. Cellular automaton decoders for topological quantum codes with noisy measurements and beyond. Scientific Reports, 11:2027, 2021. arXiv: https://arxiv.org/abs/2004.07247. doi:10.1038/s41598-021-81138-2.</p> </li> <li> <p>H. Bomb\u00edn and M. A. Martin-Delgado. Topological quantum distillation. Physical Review Letters, 97:180501, 2006. arXiv: https://arxiv.org/abs/quant-ph/0605138. doi:10.1103/PhysRevLett.97.180501.</p> </li> <li> <p>H\u00e9ctor Bomb\u00edn and M. Martin-Delgado. Exact topological quantum order in \\(d=3\\) and beyond: branyons and brane-net condensates. Physical Review B, 75:075103, 2007. arXiv: https://arxiv.org/abs/cond-mat/0607736. doi:10.1103/PhysRevB.75.075103.</p> </li> <li> <p>A. Kubica. The ABCs of the Color Code: A Study of Topological Quantum Codes as Toy Models for Fault-Tolerant Quantum Computation and Quantum Phases Of Matter. PhD thesis, Caltech, 2018. URL: http://dx.doi.org/10.7907/059V-MG69, doi:10.7907/059V-MG69.</p> </li> <li> <p>H\u00e9ctornd Guillaume Duclos-Cianci Bomb\u00edn and David Poulin. Universal topological phase of two-dimensional stabilizer codes. New Journal of Physics, 14(7):073048, 2012. arXiv: https://arxiv.org/abs/1103.4606. doi:10.1088/1367-2630/14/7/073048.</p> </li> <li> <p>Aleksander Kubica, Beni Yoshida, and Fernando Pastawski. Unfolding the color code. New Journal of Physics, 17(8):083026, 2015. arXiv: https://arxiv.org/abs/1503.02065. doi:10.1088/1367-2630/17/8/083026.</p> </li> <li> <p>Aleksander Kubica and Nicolas Delfosse. Efficient color code decoders in \\(d\\geq 2\\) dimensions from toric code decoders. Quantum, 7:929, 2023. arXiv: https://arxiv.org/abs/1905.07393. doi:10.22331/q-2023-02-21-929.</p> </li> <li> <p>Michael Vasmer and Aleksander Kubica. Morphing quantum codes. PRX Quantum, 3:030319, 2022. arXiv: https://arxiv.org/abs/2112.01446. doi:10.1103/PRXQuantum.3.030319.</p> </li> <li> <p>Benjamin J. Brown. Conservation laws and quantum error correction: towards a generalised matching decoder. IEEE BITS the Information Theory Magazine, ():1\u201312, 2023. arXiv: https://arxiv.org/abs/2207.06428. doi:10.1109/MBITS.2023.3246025.</p> </li> <li> <p>Craig Gidney. Stim: a fast stabilizer circuit simulator. Quantum, 5:497, 2021. arXiv: https://arxiv.org/abs/2103.02202. doi:10.22331/q-2021-07-06-497.</p> </li> <li> <p>Oscar Higgott. Pymatching: a python package for decoding quantum codes with minimum-weight perfect matching. ACM Transactions on Quantum Computing, 6 2022. arXiv: https://arxiv.org/abs/2105.13082. URL: https://doi.org/10.1145/3505637, doi:10.1145/3505637.</p> </li> </ol>"},{"location":"quantum-algorithmic-primitives/approximate-tensor-network-contraction/","title":"Approximate tensor network contraction","text":""},{"location":"quantum-algorithmic-primitives/approximate-tensor-network-contraction/#rough-overview-in-words","title":"Rough overview (in words)","text":"<p>Tensor network algorithms are a versatile tool that is playing an increasingly important role in problems both within and outside of physics and quantum computation [1], whenever the size of the underlying linear space is exponentially large in some appropriately defined dimension (i.e. tensor decomposition of the space). Their application to exponentially large linear systems is ultimately limited by the ability to contract (i.e., sum over repeated indices) large networks of tensors, in particular when the network forms a graph with many loops. Quantum approximate contraction of tensor networks [2] is a quantum algorithm for contracting arbitrary tensor networks up to a constant additive error. Estimating partition functions up to an additive error is a special case of the general problem, where all elements of the tensor network are positive.</p><p>This quantum approach to approximate tensor network contraction is of particular interest since many commercially relevant problems do not care about asymptotic speedups, but rather time-to-solution on smaller or medium problem sizes, and oftentimes approximate solutions found with heuristics are good enough. Tensor network (sometimes called quantum-inspired) algorithms for industrially relevant problems can be used heuristically, and the quantum approximate contraction backend might be used in cases where the classical algorithms do not provide sufficient accuracy, speed, or scale. Quantum-inspired classical algorithms based on tensor networks might allow for the identification of promising heuristic applications of quantum computing.</p><p>At this time, however, the only known problems where the quantum backend provides substantial speedup is for problems originating from quantum computing itself, such as quantum computational supremacy experiments based on random quantum circuits [3].</p>"},{"location":"quantum-algorithmic-primitives/approximate-tensor-network-contraction/#rough-overview-in-math","title":"Rough overview (in math)","text":"<p>We define a tensor network as an abstract object \\(T(G,M)\\) defined on a graph \\(G=(V,E)\\), where to each vertex \\(v\\in V\\) we associate a tensor \\(M^{(v)}\\) with one index for each adjacent edge. The tensor network \\(T(G,M)\\) is closed, in that all edges are contracted. This means that for any specific set of tensors \\(M\\) on \\(G\\), \\(T(G,M)\\) maps to a scalar. Given the graph \\(G\\), we define a contraction pathway corresponding to an ordering in which the vertices are merged together, one by one. The optimal contraction pathway is the ordering in which the maximum number of edges emanating from any vertex on the path is minimized. Classical exact contraction algorithms typically scale exponentially in the contraction width [4]; i.e. the total number of edges being cut along a specific contraction pathway. For generic, loopy networks, the contraction width is expected to be polynomially related to \\(|V|\\); thus, the exact contraction algorithm will quickly become intractable with growing \\(|V|\\). However, many approximate contraction methods exist [5, 6].</p><p>Given a contraction pathway, for any \\(\\epsilon &gt;0\\), there exists a quantum algorithm that runs in \\(\\mathcal{O}\\left( |V| \\epsilon^{-2} {\\rm poly}(q^d) \\right)\\) quantum time and outputs a complex number \\(r\\) such that [2]</p>\\[\\begin{equation} \\label{eqn:TNapprox} {\\rm Pr}\\left(|T(G,M)-r|\\geq \\epsilon \\Delta \\right) \\leq \\frac{1}{4}, \\end{equation}\\]<p>where \\(d\\) is the maximum degree of the graph and \\(q\\) is the dimension of the edge Hilbert space (or bond dimension). The parameter \\(\\Delta\\) is the sequential norm of the operations in the contraction path: \\(\\Delta = \\prod_{v\\in V} \\nrm{O_v}\\), where \\(O_v\\) are called swallowing operators (see Definitions 3.1 and 3.2 in [2]), which control the sequential contraction of the tensor network.</p><p>Intuitively, one can think of contracting the network one edge at a time along a connected pathway, such as a snake covering a 2D lattice. At each step of the way, the contracted vertices\u2014which form a potentially large tensor\u2014are encoded as a quantum state, and each new vertex is contracted by a local operator \\(O_v\\) (the process is called bubbling in [2]). The dimension of the \"state\" can increase or decrease with every operation. Each operator \\(O_v\\) in the contraction pathway is approximately mapped onto a unitary operator on the linear space (\\(q^d\\) dimensional) connecting vertex \\(v\\) in the network plus one ancilla qubit. The approximation comes from the Solovay\u2013Kitaev theorem. This way, the exact contraction of the tensor network is approximately mapped onto a quantum circuit of volume roughly equal to the graph \"volume.\" The output state of the quantum circuit encodes the result of the tensor network contraction into one of its amplitudes. In [2], they show how to estimate this amplitude using the Hadamard test, contributing the factor of \\(\\epsilon^{-2}\\) in the runtime. Alternatively, using the amplitude estimation subroutine, the \\(\\epsilon\\)-dependence could be reduced to \\(\\mathcal{O}\\left( \\epsilon^{-1} \\right)\\).</p><p>The algorithm can be thought of as the reverse process of mapping a quantum circuit to a tensor network.</p>"},{"location":"quantum-algorithmic-primitives/approximate-tensor-network-contraction/#dominant-resource-cost-gatesqubits","title":"Dominant resource cost (gates/qubits)","text":"<p>The dominant cost of the algorithm is on the one hand the \\({\\rm poly}(q^d)\\) scaling, which can be substantial for highly connected graphs. More importantly though, for problems of interest is the value of \\(\\Delta\\), which can grow exponentially with \\(|V|\\) and require extremely high precision \\(\\epsilon\\) to give a meaningful answer. In other words, \\(\\Delta\\) sets the scale of the approximation.</p><p>The complexity of the quantum algorithm depends sensitively on the structure of the graph \\(G(V,E)\\), on the tensors \\(\\{M_v\\}_{v\\in V}\\) and on the choice of the contraction pathway. A number of limiting cases are known [2]:</p><ul> <li>There are tensor networks for which it is NP-hard to obtain a classical additive approximation of the full contraction, suggesting the classical hardness of the problem.</li> <li>There exist families of tensor networks for which the additive approximation in Eq. \\(\\eqref{eqn:TNapprox}\\) is BQP-hard, suggesting that there exists a complexity separation between the classical and quantum problem.</li> <li>There are specific examples of tensor networks representing partition functions, for which the quantum approximation scale \\(\\Delta\\) is exponential in \\(|V|\\), but with a smaller exponent than the best known classical additive approximation scheme. There exist other examples where the converse is true [2].</li> </ul><p>Furthermore, approximate contraction of a tensor network representing a quantum partition function of a positive semidefinite Hamiltonian has been shown to be complete for the one clean qubit (DQC1) model of quantum computation [7], which suggests that approximate contraction is likely classically hard, at least for certain specific instances. Non-tensor-network classical algorithms for this problem have also been examined [8].</p>"},{"location":"quantum-algorithmic-primitives/approximate-tensor-network-contraction/#caveats","title":"Caveats","text":"<p>The main caveat at present is that we do not have a good understanding of the structure of the network that allows for significant speedup on a quantum computer, due in part to the appearance of the complicated parameter \\(\\Delta\\) in the complexity statement. It is possible that the only situations where this is possible is when the tensor network can be mapped directly to a quantum circuit, without significant overhead. For example, in [9], a specific kind of tensor network called DMERA was shown to admit an exponential quantum speedup for approximate contraction because it arises from a specific kind of quantum circuit. A more critical caveat is that we do not understand when classical contraction algorithms are inefficient in practice. Even quantum computational supremacy experiments [10], which were designed specifically to maximize the separation between quantum and classical simulation, allow for tractable tensor network simulations up to large system sizes (\\(\\sim 50\\)) and circuit depths (\\(\\sim 30\\)) [3], though these simulations become much more challenging if we allow for nonlocal gates.</p><p>Finally, it is likely difficult to make a proper comparison between classical approximate methods (for example the corner transfer matrix) and the above quantum approximation schemes, as the classical and quantum approximation errors have very different origins, and the quantum algorithm cannot be simulated at scale. The quantum algorithm might thus be regarded as a new heuristic to be be tested on a case to case basis once sufficiently powerful quantum hardware is available.</p>"},{"location":"quantum-algorithmic-primitives/approximate-tensor-network-contraction/#example-use-cases","title":"Example use cases","text":"<p>There is an obvious case where the quantum algorithm provides an advantage, and that is if you prepare a quantum circuit, and map it onto a tensor network. Less trivial examples involve estimating partition functions of classical statistical mechanics models\u2014although for this problem, good classical methods exist for the additive approximation [7]. Other applications involving large scale tensor network contractions, including: condensed matter physics and molecular simulations, inference problems [11] or differential equations simulation [12] might benefit from a quantum backend in some regimes, but a careful analysis has not yet been performed.</p>"},{"location":"quantum-algorithmic-primitives/approximate-tensor-network-contraction/#further-reading","title":"Further reading","text":"<ul> <li>Pedagogical introductions to tensor networks [1, 13].</li> <li>Quantum-inspired tensor network algorithms [14, 15, 16, 17].</li> <li>Complexity analysis of the quantum partition function problem [18].</li> </ul>"},{"location":"quantum-algorithmic-primitives/approximate-tensor-network-contraction/#bibliography","title":"Bibliography","text":"<ol> <li> <p>Jacob Biamonte and Ville Bergholm. Tensor networks in a nutshell. arXiv: https://arxiv.org/abs/1708.00006, 2017.</p> </li> <li> <p>Itai Arad and Zeph Landau. Quantum computation and the evaluation of tensor networks. SIAM Journal on Computing, 39(7):3089\u20133121, 2010. arXiv: https://arxiv.org/abs/0805.0040. doi:10.1137/080739379.</p> </li> <li> <p>Feng Pan and Pan Zhang. Simulating the sycamore quantum supremacy circuits. arXiv: https://arxiv.org/abs/2103.03074, 2021.</p> </li> <li> <p>Johnnie Gray and Stefanos Kourtis. Hyper-optimized tensor network contraction. Quantum, 5:410, 2021. arXiv: https://arxiv.org/abs/2002.01935. doi:10.22331/q-2021-03-15-410.</p> </li> <li> <p>Rom\u00e1n Or\u00fas and Guifr\u00e9 Vidal. Simulation of two-dimensional quantum systems on an infinite lattice revisited: corner transfer matrix for tensor contraction. Physical Review B, 80(9):094403, 2009. arXiv: https://arxiv.org/abs/0905.3225. doi:10.1103/PhysRevB.80.094403.</p> </li> <li> <p>Johnnie Gray and Garnet Kin-Lic Chan. Hyper-optimized compressed contraction of tensor networks with arbitrary geometry. arXiv: https://arxiv.org/abs/2206.07044, 2022.</p> </li> <li> <p>Anirban N Chowdhury, Rolando D Somma, and Yi\u011fit Suba\u015f\u0131. Computing partition functions in the one-clean-qubit model. Physical Review A, 103(3):032422, 2021. arXiv: https://arxiv.org/abs/1910.11842. doi:10.1103/PhysRevA.103.032422.</p> </li> <li> <p>Andrew Jackson, Theodoros Kapourniotis, and Animesh Datta. Partition-function estimation: quantum and quantum-inspired algorithms. Physical Review A, 107(1):012421, 2023. arXiv: https://arxiv.org/abs/2208.00930. doi:10.1103/PhysRevA.107.012421.</p> </li> <li> <p>Isaac H. Kim and Brian Swingle. Robust entanglement renormalization on a noisy quantum computer. arXiv: https://arxiv.org/abs/1711.07500, 2017.</p> </li> <li> <p>Frank Arute, Kunal Arya, Ryan Babbush, Dave Bacon, Joseph C Bardin, Rami Barends, Rupak Biswas, Sergio Boixo, Fernando GSL Brandao, David A Buell, and others. Quantum supremacy using a programmable superconducting processor. Nature, 574(7779):505\u2013510, 2019. doi:https://doi.org/10.1038/s41586-019-1666-5.</p> </li> <li> <p>Chunhua Deng, Fangxuan Sun, Xuehai Qian, Jun Lin, Zhongfeng Wang, and Bo Yuan. Tie: energy-efficient tensor train-based inference engine for deep neural network. In Proceedings of the 46th International Symposium on Computer Architecture (ISCA), 264\u2013278. 2019. doi:10.1145/3307650.3322258.</p> </li> <li> <p>Nikita Gourianov, Michael Lubasch, Sergey Dolgov, Quincy Y van den Berg, Hessam Babaee, Peyman Givi, Martin Kiffner, and Dieter Jaksch. A quantum-inspired approach to exploit turbulence structures. Nature Computational Science, 2(1):30\u201337, 2022. arXiv: https://arxiv.org/abs/2106.05782. doi:10.1038/s43588-021-00181-1.</p> </li> <li> <p>Rom\u00e1n Or\u00fas. Tensor networks for complex quantum systems. Nature Reviews Physics, 1(9):538\u2013550, 2019. arXiv: https://arxiv.org/abs/1812.04011. doi:10.1038/s42254-019-0086-7.</p> </li> <li> <p>Michael Kastoryano and Nicola Pancotti. A highly efficient tensor network algorithm for multi-asset fourier options pricing. arXiv: https://arxiv.org/abs/2203.02804, 2022.</p> </li> <li> <p>Raj Patel, Chia-Wei Hsing, Serkan Sahin, Saeed S Jahromi, Samuel Palmer, Shivam Sharma, Christophe Michel, Vincent Porte, Mustafa Abid, Stephane Aubert, and others. Quantum-inspired tensor neural networks for partial differential equations. arXiv: https://arxiv.org/abs/2208.02235, 2022.</p> </li> <li> <p>Timo Felser, Marco Trenti, Lorenzo Sestini, Alessio Gianelle, Davide Zuliani, Donatella Lucchesi, and Simone Montangero. Quantum-inspired machine learning on high-energy physics data. npj Quantum Information, 7(1):111, 2021. arXiv: https://arxiv.org/abs/2004.13747. doi:10.1038/s41534-021-00443-w.</p> </li> <li> <p>Soronzonbold Otgonbaatar and Dieter Kranzlm\u00fcller. Quantum-inspired tensor network for earth science. arXiv: https://arxiv.org/abs/2301.07528, 2023.</p> </li> <li> <p>Sergey Bravyi, Anirban Chowdhury, David Gosset, and Pawel Wocjan. On the complexity of quantum partition functions. arXiv: https://arxiv.org/abs/2110.15466, 2021.</p> </li> </ol>"},{"location":"quantum-algorithmic-primitives/gibbs-sampling/","title":"Gibbs sampling","text":""},{"location":"quantum-algorithmic-primitives/gibbs-sampling/#rough-overview-in-words","title":"Rough overview (in words)","text":"<p>Gibbs sampling is the task of preparing a quantum state in thermal equilibrium. This task is interesting in its own right as a means of testing the thermodynamic properties of quantum systems in a controlled way, but it is also a subroutine that is surprisingly useful within other quantum algorithms. Formally, given a Hamiltonian and a temperature, the task is to prepare the Gibbs state (also known as the thermal state) of that Hamiltonian at the associated temperature, or equivalently, to sample eigenstates of the Hamiltonian with probability proportional to their Boltzmann weights (motivating the name Gibbs sampling).</p><p>Physically, Gibbs sampling is routinely achieved in experiments via cooling as a manifestation of open-system thermodynamics, although theoretical understanding of such processes has been largely heuristic. Computationally, quantum Gibbs sampling is the quantum analogue of the same classical task in the computational basis, often achieved by Markov chain Monte Carlo (MCMC) methods. As a representative example, the Metropolis\u2013Hastings algorithm [1] uses rejection sampling to construct a Markov chain whose stationary state is the classical Gibbs distribution; the Gibbs distribution can be efficiently sampled if the Markov chain mixes rapidly. Nowadays, Monte Carlo methods have already surpassed their original intent (Ising model simulation) and found ubiquitous applications in optimization and machine learning due to their simplicity and robustness. It is natural to wonder if the same features will be present for quantum Gibbs sampling.</p><p>Surprisingly, quantum algorithms and theoretical understanding of Gibbs sampling are severely underdeveloped. The most direct quantum algorithms for Gibbs sampling suffer from an explicit cost exponential in the size of the system. Another approach is to quantize classical Monte Carlo algorithms [2], but this approach has faced serious technical challenges rooted in quantum mechanics: the energy-time uncertainty principle (for imposing the Boltzmann weights) and the no-cloning theorem (for \"rejecting\" a quantum state). Recently, a new wave [3, 4, 5, 6] of proposals revisits the issue from the angle of open-system thermodynamics and gives nature-inspired algorithms for Gibbs sampling. These more directly emulate the dynamical process of thermalization and have the potential to achieve better runtimes for specific systems where thermalization is expected to be fast.</p>"},{"location":"quantum-algorithmic-primitives/gibbs-sampling/#rough-overview-in-math","title":"Rough overview (in math)","text":"<p>Given a Hamiltonian \\(H = \\sum_i E_i\\ket{\\psi_i}\\bra{\\psi_i}\\) over \\(n\\) qubits, a desired inverse temperature \\(\\beta\\), and an error parameter \\(\\epsilon\\), the Gibbs sampling task is to prepare an \\(n\\)-qubit quantum state \\(\\rho\\) such that </p>\\[\\begin{align} \\nrm{ \\rho - \\sigma_{\\beta} }_{\\mathrm{tr}} \\le \\epsilon \\quad \\text{where}\\quad \\sigma_\\beta :=\\frac{ \\mathrm{e}^{-\\beta H }}{\\mathcal{Z}}\\propto \\sum_i \\mathrm{e}^{-\\beta E_i} \\ket{\\psi_i}\\bra{\\psi_i} \\quad \\text{and} \\quad \\mathcal{Z} := \\text{tr}[\\mathrm{e}^{-\\beta H }]. \\end{align}\\]<p>The above uses the convenient error metric given by the trace norm \\(\\lVert \\cdot \\rVert_{\\mathrm{tr}}\\), which controls the error for arbitrary bounded (possibly nonlocal) observables. In some applications, it could be sufficient to give a state \\(\\rho\\) that approximates all local observables up to high precision, even if the global distance between \\(\\rho\\) and \\(\\sigma_\\beta\\) is large. Note that \\(\\sigma_\\beta\\) corresponds to an ensemble of eigenstates of \\(H\\), where an eigenstate with energy \\(E_i\\) occurs with probability proportional to the Boltzmann weight \\(e^{-\\beta E_i}\\).</p><p>To solve this problem, the quantum algorithm requires access to \\(H\\), for example, through a block-encoding of \\(H\\). Block-encodings can often be efficiently constructed, for instance, when \\(H\\) is a sparse matrix or when \\(H\\) is given as a sum of \\(\\text{poly}(n)\\) local interaction terms. Henceforth, assume that \\(H\\) is offset such that it is guaranteed to be a nonnegative operator (no negative energies).</p><p>An early approach [7] for Gibbs sampling relied on quantum phase estimation (QPE) and amplitude amplification. In particular, one starts with a \\(2n\\)-qubit maximally entangled state (for which the reduced density matrix on the first \\(n\\) qubits is the maximally mixed state) and applies QPE to the first \\(n\\) qubits, reading an estimate of the energy into an ancilla register. Under the simplification that QPE has perfect resolution, one now has the state </p>\\[\\begin{equation} \\frac{1}{\\sqrt{2^n}} \\sum_{i} \\ket{\\psi_i} \\ket{\\phi_i} \\ket{E_i} \\end{equation}\\]<p>where \\(\\ket{\\psi_i}\\) is the \\(i\\)th eigenstate of \\(H\\), \\(E_i\\) is the associated energy, and the states \\(\\ket{\\phi_i}\\) form an arbitrary (unimportant) orthonormal basis. Next, one coherently rotates an ancilla qubit to put the correct Boltzmann weight into the amplitude: </p>\\[\\begin{equation} \\frac{1}{\\sqrt{2^{n}}}\\sum_{i} \\ket{\\psi_i} \\ket{\\phi_i} \\ket{E_i}\\left(e^{-\\beta E_i/2}\\ket{0} + \\sqrt{1-e^{-\\beta E_i}}\\ket{1}\\right)\\,. \\end{equation}\\]<p>Note that the probability of measuring the final qubit in \\(\\ket{0}\\) is precisely \\(\\mathcal{Z}/2^n\\). Rather than measure and postselect, one now performs amplitude amplification on the ancilla being \\(\\ket{0}\\) to produce </p>\\[\\begin{equation} \\frac{1}{\\sqrt{\\mathcal{Z}}} \\sum_i e^{-\\beta E_i/2}\\ket{\\psi_i}\\ket{\\phi_i}\\ket{E_i} \\end{equation}\\]<p>up to small error, which is a purification of the Gibbs state \\(\\sigma_\\beta = \\mathcal{Z}^{-1}\\sum_i e^{-\\beta E_i} \\ket{\\psi_i}\\bra{\\psi_i}\\). While QPE does not exactly produce the operation described above, a more complete analysis in [7, 8] shows the idea still works. This approach is akin to classical rejection sampling (see also [9]), where a state is chosen at random and accepted with probability \\(e^{-\\beta E_i}\\), such that repeating until acceptance yields a sample from the correct distribution. Due to amplitude amplification, the quantum algorithm enjoys a quadratic speedup.</p><p>More advanced methods that have exponentially better \\(\\epsilon\\) dependence have since been developed. Reference [10] used a linear combination of unitaries approach to perform the imaginary time evolution operator \\(e^{-\\beta H}\\), again followed by amplitude amplification. Technically, that work assumed access to an operator similar to \\(\\smash{\\sqrt{H}}\\), but this requirement was removed in Gibbs samplers appearing in [11, 12], which employ a method for implementing smooth Hamiltonian functions. Alternatively, one can use the quantum singular value transformation along with a polynomial approximation to the function \\(e^{-\\beta(1-x)/2}\\) on the interval \\(x \\in [-1,1]\\) [13, Section 5.3] and combine this with (fixed-point) amplitude amplification [14].</p><p>Another family of quantum algorithms is closer in spirit to classical Monte Carlo methods. They quantize the Metropolis\u2013Hastings algorithm (quantum Metropolis sampling [2]) or simulate the dynamics arising from a system-bath interaction [3, 4, 5, 6]. These algorithms make fundamental usage of quantum phase estimation for probing the energy, but most importantly (and most nontrivially), they construct a detailed-balance \"quantum Markov chain\" via either discretely or continuously \"rejecting\" the quantum state. Care must be taken to perform the rejection step coherently and to handle the fact that the energies cannot be learned to infinite precision. Abstractly, Monte Carlo\u2013style quantum algorithms emulate a discrete quantum channel (or a continuous Lindbladian) that converges to the Gibbs state after \\(\\ell\\) iterations </p>\\[\\begin{align} \\mathcal{N}[\\sigma_\\beta] \\approx \\sigma_\\beta\\quad \\text{and} \\quad \\nrm{ \\mathcal{N}^{\\ell}[\\rho_{0}] - \\sigma_{\\beta}}_{\\mathrm{tr}} \\le \\epsilon \\end{align}\\]<p>for some initial state \\(\\rho_0\\). Like the classical Metropolis\u2013Hastings algorithm, for some systems, the number of iterations \\(\\ell\\) for convergence can be exponentially large (or worse) in \\(n\\), while for other systems, the number of iterations needed can be much smaller. It is a generally difficult problem to determine \\(\\ell\\), but it is expected that the size of \\(\\ell\\) will be related to the natural thermalization rate of the system. Note that such a process can be further quantized to gain quadratic speedup [15, 6].</p>"},{"location":"quantum-algorithmic-primitives/gibbs-sampling/#dominant-resource-cost-gatesqubits","title":"Dominant resource cost (gates/qubits)","text":"<p>Assuming one has access to a block-encoding of the Hamiltonian \\(H\\), that is, a unitary whose upper left block is the operator \\(H/\\alpha\\), where \\(\\alpha\\) is a normalization constant at least as large as the spectral norm of \\(H\\), one can accomplish the Gibbs sampling task using [11, Lemma 44] (see also [12, Corollary 16]) </p>\\[\\begin{equation} \\label{eq:Gibbs_complexity} \\alpha\\beta \\sqrt{\\frac{2^n}{\\mathcal{Z}}} \\cdot \\text{poly}(\\log(1/\\epsilon), n) \\end{equation}\\]<p>calls to the block-encoding and a similar number of other gates. Note that since we have assumed \\(H\\) is non-negative, we have \\(\\mathcal{Z}\\leq 2^n\\). In the case that \\(H\\) is \\(d\\)-sparse, we can take \\(\\alpha = d\\). In the case one has access to \\(\\sqrt{H}\\), the \\(\\beta\\) dependence can be reduced from \\(\\beta\\) to \\(\\sqrt{\\beta}\\) [10]. This complexity statement might be regarded as a quadratic speedup compared to the classical method of rejection sampling, which requires \\(2^n/\\mathcal{Z}\\) samples on average; however, note that this classical method only directly applies to diagonal (classical) Hamiltonians \\(H\\). Otherwise, a classical approach may need to resort to exact diagonalization of \\(H\\), which has \\(\\mathcal{O}\\left( 2^n \\right)\\) space complexity and even worse time complexity.</p><p>Monte Carlo\u2013style quantum Gibbs sampling algorithms have complexity determined by </p>\\[\\begin{equation} \\label{eq:cost_mixing_iteration} (\\text{mixing time}) \\cdot (\\text{cost per iteration}). \\end{equation}\\]<p>The mixing time is expected to vary significantly for different systems of interest (based on classical Monte Carlo intuition), but for systems appearing in nature, one may be optimistic based on the observed fast thermalization of physical systems. The cost per iteration is dominated by the quantum phase estimation subroutine, which then scales with a certain energy resolution. An overall gate complexity can be roughly, e.g., \\(\\text{poly}(n, \\beta,1/\\epsilon)\\). However, as new algorithms are still being proposed, we do not give more concrete estimates of the complexity. Indeed, to put together an end-to-end resource estimate, one needs to design better algorithms to reduce the cost per iteration as well as to estimate the mixing time (e.g., by exact diagonalization of the map for small system sizes). Of course, if Gibbs sampling is employed as a heuristic (as in many classical applications of Monte Carlo methods), the cost will be empirical.</p>"},{"location":"quantum-algorithmic-primitives/gibbs-sampling/#caveats","title":"Caveats","text":"<p>On the one hand, the superpolynomial \\(\\mathcal{O}(\\sqrt{2^n})\\) complexity for Gibbs sampling that appears explicitly in Eq. \\(\\eqref{eq:Gibbs_complexity}\\) is necessary in general (for sufficiently large \\(\\beta\\) it allows one to solve NP-hard or even QMA-hard problems in the general case). On the other hand, most physical Hamiltonians (if they appear to thermalize in nature) should be simulable without exponential hidden prefactors. The Monte Carlo\u2013style approach to Gibbs sampling attempts to mimic nature more closely than the other algorithms with guaranteed complexities mentioned above; hence, it looks more promising for obtaining polynomial runtimes, but this must be verified through system-specific analysis or hardware demonstrations.</p><p>Finally, if the Hamiltonian comes from classical problems (such as solving semidefinite programs), loading the instance may have exponential cost (\\(\\mathrm{e}^{\\Omega(n)}\\)), which in the above presentation is hidden in the assumption of a block-encoding of classical data. Additionally, it is unclear whether systems arising from classical data, rather than underlying physical models, should be expected to \"thermalize\" quickly (i.e. whether Monte Carlo\u2013style algorithms converge in a small number of iterations).</p>"},{"location":"quantum-algorithmic-primitives/gibbs-sampling/#example-use-cases","title":"Example use cases","text":"<ul> <li>Multiplicative Weights Update (MWU) method and conic programming: Gibbs sampling is the main source of quantum speedup in the MWU method, which is used to solve semidefinite programs and other conic programs [16, 17, 11, 12, 18]. Existing analyses in this direction have employed Gibbs samplers with a guaranteed quadratic (but no larger) speedup, rather than the more heuristic and recent Monte Carlo\u2013style algorithms.</li> <li>Quantum chemistry: An important step of estimating the ground state energy of electronic structure Hamiltonians is generating an ansatz state that has a large overlap with the ground state. This might be done via Gibbs sampling at sufficiently low temperatures; the overlap with the ground state is \\(e^{-\\beta E_0}/\\mathcal{Z}\\).</li> <li>Condensed matter physics: Similar to quantum chemistry, Gibbs sampling provides a method for producing ansatz states for ground state energy calculation. Furthermore, condensed matter physicists are often interested in material properties at finite temperatures so that the Gibbs state can be equally interesting as the ground state itself.</li> <li>Computing partition functions: One of the early references to develop quantum Gibbs samplers [7] applied it to the problem of estimating the partition function \\(\\mathcal{Z}\\) up to small relative error. The partition function contains all the relevant thermodynamic information of the system.</li> </ul>"},{"location":"quantum-algorithmic-primitives/gibbs-sampling/#further-reading","title":"Further reading","text":"<p>Gibbs sampling has been studied in several specific cases. For example, [19] studied Gibbs sampling of local Hamiltonians in 1D. Moreover, [20] studied commuting spatially-local Hamiltonians and showed conditions under which they thermalize in polynomial time, suggesting efficient Gibbs sampling via Monte Carlo\u2013style methods. These conditions hold for any 1D system at any temperature, and in any higher spatial dimension above a certain threshold temperature.</p>"},{"location":"quantum-algorithmic-primitives/gibbs-sampling/#bibliography","title":"Bibliography","text":"<ol> <li> <p>W Keith Hastings. Monte carlo sampling methods using markov chains and their applications. Biometrika, 57:97\u2013109, 4 1970. doi:10.1093/biomet/57.1.97.</p> </li> <li> <p>K. Temme, T. J. Osborne, K. G. Vollbrecht, D. Poulin, and F. Verstraete. Quantum metropolis sampling. Nature, 471(7336):87\u201390, 3 2011. arXiv: https://arxiv.org/abs/0911.3635. doi:10.1038/nature09770.</p> </li> <li> <p>Chi-Fang Chen and Fernando G. S. L. Brand\u00e3o. Fast thermalization from the eigenstate thermalization hypothesis. arXiv: https://arxiv.org/abs/2112.07646, 2021.</p> </li> <li> <p>Oles Shtanko and Ramis Movassagh. Algorithms for gibbs state preparation on noiseless and noisy random quantum circuits. arXiv: https://arxiv.org/abs/2112.14688, 2021.</p> </li> <li> <p>Patrick Rall, Chunhao Wang, and Pawel Wocjan. Thermal state preparation via rounding promises. arXiv: https://arxiv.org/abs/2210.01670, 2022.</p> </li> <li> <p>Chi-Fang Chen, Michael J. Kastoryano, Fernando G. S. L. Brand\u00e3o, and Andr\u00e1s Gily\u00e9n. Quantum thermal state preparation. arXiv: https://arxiv.org/abs/2303.18224, 2023.</p> </li> <li> <p>David Poulin and Pawel Wocjan. Sampling from the thermal quantum gibbs state and evaluating partition functions with a quantum computer. Physical Review Letters, 103(22):220502, 2009. arXiv: https://arxiv.org/abs/0905.2199. doi:10.1103/PhysRevLett.103.220502.</p> </li> <li> <p>Chen-Fu Chiang and Pawel Wocjan. Quantum algorithm for preparing thermal gibbs states-detailed analysis. In Quantum Cryptography and Computing, volume 26, 138\u2013147. 2010. arXiv: https://arxiv.org/abs/1001.1130. doi:10.3233/978-1-60750-547-1-138.</p> </li> <li> <p>Maris Ozols, Martin Roetteler, and J\u00e9r\u00e9mie Roland. Quantum rejection sampling. ACM Trans. Comput. Theory, 8 2013. arXiv: https://arxiv.org/abs/1103.2774. URL: https://doi.org/10.1145/2493252.2493256, doi:10.1145/2493252.2493256.</p> </li> <li> <p>Anirban Narayan Chowdhury and Rolando D. Somma. Quantum algorithms for gibbs sampling and hitting-time estimation. Quantum Information and Computation, 17(1&amp;2):41\u201364, 2017. arXiv: https://arxiv.org/abs/1603.02940. doi:10.26421/QIC17.1-2.</p> </li> <li> <p>Joran van Apeldoorn, Andr\u00e1s Gily\u00e9n, Sander Gribling, and Ronald de Wolf. Quantum sdp-solvers: better upper and lower bounds. Quantum, 4:230, 2020. Earlier version in FOCS'17. arXiv: https://arxiv.org/abs/1705.01843. doi:10.22331/q-2020-02-14-230.</p> </li> <li> <p>Joran van Apeldoorn and Andr\u00e1s Gily\u00e9n. Improvements in quantum sdp-solving with applications. In Proceedings of the 46th International Colloquium on Automata, Languages, and Programming (ICALP), 99:1\u201399:15. 2019. arXiv: https://arxiv.org/abs/1804.05058. doi:10.4230/LIPIcs.ICALP.2019.99.</p> </li> <li> <p>Andr\u00e1s Gily\u00e9n, Yuan Su, Guang Hao Low, and Nathan Wiebe. Quantum singular value transformation and beyond: exponential improvements for quantum matrix arithmetics. In Proceedings of the 51st ACM Symposium on the Theory of Computing (STOC), 193\u2013204. 2019. arXiv: https://arxiv.org/abs/1806.01838. doi:10.1145/3313276.3316366.</p> </li> <li> <p>Theodore J. Yoder, Guang Hao Low, and Isaac L. Chuang. Fixed-point quantum search with an optimal number of queries. Physical Review Letters, 113(21):210501, 2014. arXiv: https://arxiv.org/abs/1409.3305. doi:10.1103/PhysRevLett.113.210501.</p> </li> <li> <p>Pawel Wocjan and Kristan Temme. Szegedy walk unitaries for quantum maps. Communications in Mathematical Physics, 2023. arXiv: https://arxiv.org/abs/2107.07365. URL: https://doi.org/10.1007/s00220-023-04797-4, doi:10.1007/s00220-023-04797-4.</p> </li> <li> <p>Fernando G. S. L. Brand\u00e3o and Krysta M. Svore. Quantum speed-ups for solving semidefinite programs. In Proceedings of the 58th IEEE Symposium on Foundations of Computer Science (FOCS), 415\u2013426. 2017. arXiv: https://arxiv.org/abs/1609.05537. URL: http://ieee-focs.org/FOCS-2017-Papers/3464a415.pdf, doi:10.1109/FOCS.2017.45.</p> </li> <li> <p>Fernando G. S. L. Brand\u00e3o, Amir Kalev, Tongyang Li, Cedric Yen-Yu Lin, Krysta M. Svore, and Xiaodi Wu. Quantum sdp solvers: large speed-ups, optimality, and applications to quantum learning. In Proceedings of the 46th International Colloquium on Automata, Languages, and Programming (ICALP), 27:1\u201327:14. 2019. arXiv: https://arxiv.org/abs/1710.02581. doi:10.4230/LIPIcs.ICALP.2019.27.</p> </li> <li> <p>Joran van Apeldoorn and Andr\u00e1s Gily\u00e9n. Quantum algorithms for zero-sum games. arXiv: https://arxiv.org/abs/1904.03180, 2019.</p> </li> <li> <p>Ersen Bilgin and Sergio Boixo. Preparing thermal states of quantum systems by dimension reduction. Physical Review Letters, 105:170405, 10 2010. arXiv: https://arxiv.org/abs/1008.4162. URL: https://link.aps.org/doi/10.1103/PhysRevLett.105.170405, doi:10.1103/PhysRevLett.105.170405.</p> </li> <li> <p>Michael J. Kastoryano and Fernando G. S. L. Brand\u00e3o. Quantum gibbs samplers: the commuting case. Communications in Mathematical Physics, 344(3):915\u2013957, 2016. arXiv: https://arxiv.org/abs/1409.3435. URL: https://doi.org/10.1007/s00220-016-2641-8, doi:10.1007/s00220-016-2641-8.</p> </li> </ol>"},{"location":"quantum-algorithmic-primitives/introduction/","title":"Quantum algorithmic primitives","text":"<p>To deliver an advantage over classical approaches, end-to-end quantum solutions must exploit known quantum phenomena capable of providing a quantum speedup. The disparate collection of known quantum applications is built from a common group of quantum algorithmic primitives, which are the source of quantum advantage. Algorithmic primitives are typically not suited for directly solving an end-to-end problem, due to their reliance on unspecified oracles or because their input and/or output does not exactly match that of the end-to-end problem (e.g., some primitives output a quantum state rather than classical data, and thus they have no direct classical analogue). Nevertheless, it can be very fruitful to think of algorithms as compositions of different algorithmic primitives, both for higher-level intuitive overview and for independently studying and optimizing the primitives themselves.</p><p>This part surveys a variety of quantum algorithmic primitives. For each, we sketch the basic idea of what they do and how they work, as well as discussing example use cases and important caveats. We generally assume that these primitives will need to be implemented in fault-tolerant fashion when they are used within an end-to-end solution for a given application, but we comment on NISQ implementations in passing.</p>"},{"location":"quantum-algorithmic-primitives/multiplicative-weights-update-method/","title":"Multiplicative weights update method","text":""},{"location":"quantum-algorithmic-primitives/multiplicative-weights-update-method/#rough-overview-in-words","title":"Rough overview (in words)","text":"<p>The multiplicative weights update (MWU) method is an algorithmic strategy, sometimes referred to as a \"meta-algorithm,\" with varying applications in classical and quantum algorithms. Reference [1] gives an overview of the MWU strategy. The introductory example problem where the MWU method is used is the problem of making predictions for a binary outcome given advice from a panel of \\(n\\) \"experts.\" The MWU approach assigns a weight to each of the \\(n\\) experts, and the weight is reduced by a multiplicative factor whenever the expert makes an incorrect prediction. The outcome of the process can be shown to give an approximately optimal strategy.</p><p>This general approach can be applied to convex programs including linear programs (LPs) and semidefinite programs (SDPs). The SDP version generalizes the MWU method to allow for matrix-valued weights and matrix-valued costs. These weight matrices are positive semidefinite operators with trace equal to one, i.e. density matrices. In fact, the states that arise in the SDP-solving algorithm are Gibbs states. Thus, they can be naturally represented as quantum states on a logarithmic number of qubits and generated through the process of Gibbs sampling. The existence of fast Gibbs samplers can lead to a quantum speedup in certain circumstances.</p>"},{"location":"quantum-algorithmic-primitives/multiplicative-weights-update-method/#rough-overview-in-math","title":"Rough overview (in math)","text":"<p>We present an example problem. Let \\(\\mathbf{1}\\) denote the all ones vector. Consider the following set of linear constraints on the vector \\(x = (x_1,\\ldots,x_n) \\in \\mathbb{R}^n\\) </p>\\[\\begin{align} \\langle a^{(j)},x \\rangle &amp; \\geq 0 \\qquad j = 1,\\ldots,m \\\\ \\langle \\mathbf{1},x \\rangle &amp; = 1 \\\\ x_i &amp; \\geq 0 \\qquad i=1,\\ldots,n \\end{align}\\]<p>for \\(m\\) fixed vectors \\(a^{(j)} \\in \\mathbb{R}^n\\) with entries in \\([-1,1]\\), for \\(j = 1, \\ldots, m\\), where \\(\\langle \\cdot,\\cdot \\rangle\\) denotes the standard dot product between vectors. Suppose we are given a value of \\(\\epsilon\\) and promised either that there is no choice of \\(x\\) that satisfies all the constraints or that there exists an \\(x^*\\) such that \\(\\langle a^{(j)}, x^* \\rangle \\geq \\epsilon\\) for all \\(j\\), with \\(\\langle \\mathbf{1}, x^*\\rangle=1\\) and \\(x^*_i \\geq 0\\) for all \\(i\\). We wish to determine which is the case and find a vector \\(x^*\\) in the second case. This is similar to the form of an LP and to the problem of solving for the optimal point of a zero-sum game [1, 2], and the MWU meta-algorithm can be straightforwardly applied to solve these problems.</p><p>A classical solution to this problem is given by the multiplicative weights method [1]. The algorithm iteratively updates the vector \\(x\\), with initialization \\(x = \\mathbf{1} / n\\). At each iteration, the algorithm finds a constraint \\(j\\) for which \\(\\langle a^{(j)}, x\\rangle &lt; 0\\) (or if no such \\(j\\) exists, it terminates and outputs \\(x\\)). Let \\(\\eta = \\mathcal{O}\\left( \\epsilon \\right)\\) be a fixed constant. Once \\(j\\) is found, the entries of the vector \\(x\\) are updated according to </p>\\[\\begin{equation} \\label{eq:MW_update_rule} x_i \\leftarrow \\frac{x_i e^{\\eta a_{ij}}}{\\sum_i x_i e^{\\eta a_{ij}}}\\, \\end{equation}\\]<p>where \\(a_{ij}\\) denotes entry \\(i\\) of vector \\(a^{(j)}\\), and the denominator works to enforce \\(\\langle \\mathbf{1}, x \\rangle = 1\\). By upweighting \\(x\\) in the direction of the violated constraint \\(a^{(j)}\\), this update rule brings the \\(x\\) closer to satisfying the constraint. The magic of the multiplicative weights method is that the promise problem described above can be solved after only \\(\\mathcal{O}\\left( \\log(n)/\\epsilon^2 \\right)\\) iterations [1]. By searching for a violated constraint using a Grover search, the runtime of each iteration can be sped up quantumly, giving rise to polynomial speedups for solving zero-sum games and LPs more generally [2].</p><p>The matrix MWU method generalizes the \\(n\\)-dimensional vector \\(x\\) to an \\(n \\times n\\) symmetric matrix \\(X\\). An example problem generalizing the above is </p>\\[\\begin{align} \\langle A^{(j)}, X \\rangle &amp; \\geq 0 \\qquad j = 1,\\ldots,m \\\\ \\langle \\mathbf{I}, X \\rangle &amp; = 1 \\\\ X &amp; \\succeq 0\\,, \\end{align}\\]<p>where \\(A^{(j)}\\) are fixed symmetric constraint matrices and the notation \\(\\langle U, V\\rangle := \\text{Tr}(UV)\\) generalizes the dot product from vectors to matrices. Here \\(\\mathbf{I}\\) denotes the identity matrix and \\(X \\succeq 0\\) denotes that \\(X\\) is positive semidefinite. The problem above is related to the general form of an SDP, and the matrix MWU approach can be applied to solve SDPs. Note that we recover the vector example if we specify that the matrices \\(A^{(j)}\\) and \\(X\\) are diagonal. The final two constraints indicate that \\(X\\) is a density matrix and is associated with a quantum state on \\(\\log_2(n)\\) qubits. When \\(X\\) is updated by a generalization of the rule in Eq. \\(\\eqref{eq:MW_update_rule}\\), then at every iteration of the MWU method, \\(X\\) will be a Gibbs state for a certain Hamiltonian that is a weighted sum of the symmetric constraint matrices \\(A^{(j)}\\). Thus, the quantum state \\(X\\) can be prepared on a quantum computer using algorithms for Gibbs sampling. Taking this approach, quantum algorithms can achieve guaranteed polynomial speedups for performing an iteration of the MWU method compared to classical approaches, and it is conceivable that larger speedups could be available if the associated quantum systems admit faster-than-worst-case Gibbs sampling.</p>"},{"location":"quantum-algorithmic-primitives/multiplicative-weights-update-method/#dominant-resource-cost-gatesqubits","title":"Dominant resource cost (gates/qubits)","text":"<p>The MWU method, both in the classical and quantum setting, consists of some number \\(T\\) of iterations, where each iteration updates a classical data structure. In typical applications \\(T = \\text{poly}(\\log(n)/\\epsilon)\\), where \\(n\\) is the problem size and \\(\\epsilon\\) is a precision parameter related to how close to optimal the solution has to be. This contrasts with other approaches to solving optimization problems, such as interior point methods, for which the number of iterations of can scale as \\(\\mathcal{O}\\left( \\text{poly}(n)\\log(1/\\epsilon) \\right)\\).</p><p>Each iteration typically takes \\(\\text{poly}(n,m,1/\\epsilon)\\) time and is carried out with subroutines that can often be sped up with quantum algorithms. These subroutines can include Grover search / amplitude amplification and, in the case of the matrix MWU method, Gibbs sampling, which end up dominating the quantum cost of the algorithm.</p><p>For example, in the setting of the matrix MWU method, the \\(n \\times n\\) Gibbs state \\(X\\) can be prepared as a \\(\\log_2(n)\\)-qubit state on a quantum computer with gate complexity roughly linear in the sparsity of the matrices \\(A^{(j)}\\), which is at worst \\(\\mathcal{O}\\left( n \\right)\\) (see, e.g., [3]), representing a speedup over manipulating all \\(\\mathcal{O}\\left( n^2 \\right)\\) entries of the matrix classically. There is also a possibility that for specific cases, the Gibbs sampling step for the \\(\\log_2(n)\\)-qubit system could be accomplished in \\(\\text{polylog}(n)\\) time if the system thermalizes rapidly, opening up the possibility that quantum algorithms based on the matrix MWU method could have faster runtime, perhaps as fast as \\(\\mathrm{poly}(\\log(n),1/\\epsilon)\\), representing an exponential speedup over their \\(\\mathrm{poly}(n,1/\\epsilon)\\)-time classical counterparts.</p>"},{"location":"quantum-algorithmic-primitives/multiplicative-weights-update-method/#caveats","title":"Caveats","text":"<p>One caveat is that the best outlook for quantum advantage occurs when the constraint matrices \\(A^{(j)}\\) that appear in applications are sparse matrices (and especially if they correspond to physical local Hamiltonians). However, this sparsity constraint may not be satisfied often in practice. There can in principle still be a speedup for dense matrices, but in this case, access to a large quantum random access memory might be required, which has its own caveats.</p><p>Another caveat to achieving a practically useful algorithm with either the classical or the quantum version of the MWU method is that the theoretical dependence of the runtime on the error parameter \\(\\epsilon\\) may lead to poor practical runtimes. The original quantum SDP solver based on MWU had \\(\\mathcal{O}\\left( \\epsilon^{-18} \\right)\\) dependence [4], and this was later improved to \\(\\mathcal{O}\\left( \\epsilon^{-5} \\right)\\) [5]. While this is technically \\(\\mathrm{poly}(1/\\epsilon)\\) scaling, the large power would likely lead the algorithm to be worse than alternatives, such as classical or quantum interior point methods which have \\(\\mathrm{polylog}(1/\\epsilon)\\) scaling, unless essentially-constant \\(\\epsilon\\) is tolerable. In the case of zero sum games, the quantum algorithm based on the MWU method has a slightly more tolerable \\(\\mathcal{O}\\left( \\epsilon^{-3} \\right)\\) dependence.</p>"},{"location":"quantum-algorithmic-primitives/multiplicative-weights-update-method/#example-use-cases","title":"Example use cases","text":"<ul> <li>The MWU method can be used to gain an asymptotic quantum speedup in solving zero-sum games, and relatedly, solving LPs [2]. This speedup is generated by Grover-like methods and does not require Gibbs sampling of quantum states. Many interesting optimization problems can be reduced to an LP.</li> <li>The MWU method can be used to gain an asymptotic speedup for solving SDPs in the regime where the precision parameter \\(\\epsilon\\) to which the program should be optimized is large. Many interesting optimization problems can be reduced to an SDP. One notable example is that approximate solutions to (discrete) binary optimization problems can be found by solving the (continuous) SDP relaxation of the problem and performing a rounding procedure on the solution (see, e.g., [6]).</li> </ul>"},{"location":"quantum-algorithmic-primitives/multiplicative-weights-update-method/#further-reading","title":"Further reading","text":"<ul> <li>See Arora, Hazan, Kale [1] for an overview of the MWU method from a classical perspective, including its matrix generalization.</li> <li>The quantum algorithm for SDP based on the MWU method was introduced by Brand\u00e3o and Svore [4]. This was improved in subsequent works [7, 3, 5]. The method was applied to the specific application of solving SDP relaxations of binary optimization problems in [6, 8], and to the specific application of computing optimal strategies of zero-sum games in [2].</li> </ul>"},{"location":"quantum-algorithmic-primitives/multiplicative-weights-update-method/#bibliography","title":"Bibliography","text":"<ol> <li> <p>Sanjeev Arora, Elad Hazan, and Satyen Kale. The multiplicative weights update method: a meta-algorithm and applications. Theory of Computing, 8(6):121\u2013164, 2012. doi:10.4086/toc.2012.v008a006.</p> </li> <li> <p>Joran van Apeldoorn and Andr\u00e1s Gily\u00e9n. Quantum algorithms for zero-sum games. arXiv: https://arxiv.org/abs/1904.03180, 2019.</p> </li> <li> <p>Joran van Apeldoorn, Andr\u00e1s Gily\u00e9n, Sander Gribling, and Ronald de Wolf. Quantum sdp-solvers: better upper and lower bounds. Quantum, 4:230, 2020. Earlier version in FOCS'17. arXiv: https://arxiv.org/abs/1705.01843. doi:10.22331/q-2020-02-14-230.</p> </li> <li> <p>Fernando G. S. L. Brand\u00e3o and Krysta M. Svore. Quantum speed-ups for solving semidefinite programs. In Proceedings of the 58th IEEE Symposium on Foundations of Computer Science (FOCS), 415\u2013426. 2017. arXiv: https://arxiv.org/abs/1609.05537. URL: http://ieee-focs.org/FOCS-2017-Papers/3464a415.pdf, doi:10.1109/FOCS.2017.45.</p> </li> <li> <p>Joran van Apeldoorn and Andr\u00e1s Gily\u00e9n. Improvements in quantum sdp-solving with applications. In Proceedings of the 46th International Colloquium on Automata, Languages, and Programming (ICALP), 99:1\u201399:15. 2019. arXiv: https://arxiv.org/abs/1804.05058. doi:10.4230/LIPIcs.ICALP.2019.99.</p> </li> <li> <p>Fernando G. S. L. Brand\u00e3o, Richard Kueng, and Daniel Stilck Fran\u00e7a. Faster quantum and classical sdp approximations for quadratic binary optimization. Quantum, 6:625, 1 2022. arXiv: https://arxiv.org/abs/1910.01155. URL: https://doi.org/10.22331/q-2022-01-20-625, doi:10.22331/q-2022-01-20-625.</p> </li> <li> <p>Fernando G. S. L. Brand\u00e3o, Amir Kalev, Tongyang Li, Cedric Yen-Yu Lin, Krysta M. Svore, and Xiaodi Wu. Quantum sdp solvers: large speed-ups, optimality, and applications to quantum learning. In Proceedings of the 46th International Colloquium on Automata, Languages, and Programming (ICALP), 27:1\u201327:14. 2019. arXiv: https://arxiv.org/abs/1710.02581. doi:10.4230/LIPIcs.ICALP.2019.27.</p> </li> <li> <p>Brandon Augustino, Giacomo Nannicini, Tam\u00e1s Terlaky, and Luis Zuluaga. Solving the semidefinite relaxation of qubos in matrix multiplication time, and faster with a quantum computer. arXiv: https://arxiv.org/abs/2301.04237, 2023.</p> </li> </ol>"},{"location":"quantum-algorithmic-primitives/quantum-adiabatic-algorithm/","title":"Quantum adiabatic algorithm","text":""},{"location":"quantum-algorithmic-primitives/quantum-adiabatic-algorithm/#rough-overview-in-words","title":"Rough overview (in words)","text":"<p>The quantum adiabatic algorithm (QAA) [1], sometimes referred to as adiabatic state preparation, is a continuous-time procedure for (approximately) preparing an eigenstate (typically the ground state) of a particular Hamiltonian of interest on a quantum device. The QAA also forms the basis for a model of quantum computation called adiabatic quantum computation which acts as an alternative to the standard quantum circuit model.</p><p>The main idea of the QAA is to begin in an eigenstate of a simpler Hamiltonian that is easy to prepare, and then slowly change the Hamiltonian to be equal to the more complex Hamiltonian of interest. The adiabatic theorem (see [2] and references therein), a celebrated concept from physics, dictates that if the evolution is sufficiently slow, the system will evolve to (approximately) remain in the instantaneous eigenstate of the continuously varying Hamiltonian and thus finish in the desired state. The length of time required for the evolution to succeed depends on the spectral properties of the Hamiltonian path and in particular on the minimum spectral gap. The adiabatic algorithm can be simulated on a gate-based quantum computer with time-dependent Hamiltonian simulation.</p>"},{"location":"quantum-algorithmic-primitives/quantum-adiabatic-algorithm/#rough-overview-in-math","title":"Rough overview (in math)","text":"<p>Let \\(H(s)\\), where \\(s\\) varies as \\(0 \\leq s \\leq 1\\), denote a single-parameter path through the space of Hamiltonians, and let \\(\\ket{\\phi_j(s)}\\) and \\(E_j(s)\\) denote the eigenstates and eigenvalues of \\(H(s)\\), indexed by \\(j\\) in increasing order. The goal of the QAA is to prepare a certain eigenstate \\(\\ket{\\phi_j(1)}\\) of \\(H(1)\\). Let \\(\\ket{\\psi(t)}\\) denote the state of our system at time \\(t\\) and let \\(T\\) be the total evolution time. The procedure calls for beginning in the state \\(\\ket{\\psi(0)} = \\ket{\\phi_j(0)}\\) and allowing \\(\\ket{\\psi(t)}\\) to evolve by the Schr\u00f6dinger equation according to the Hamiltonian \\(H(t/T)\\), that is \\(i\\frac{d}{dt}\\ket{\\psi(t)} = H(t/T)\\ket{\\psi(t)}\\) from \\(t=0\\) to \\(t=T\\). Thus, as \\(T\\) is made larger, the path from \\(H(0)\\) to \\(H(1)\\) is traversed increasingly slowly.</p>"},{"location":"quantum-algorithmic-primitives/quantum-adiabatic-algorithm/#dominant-resource-cost-gatesqubits","title":"Dominant resource cost (gates/qubits)","text":"<p>The main resource for the continuous-time QAA is the total evolution time \\(T\\). The adiabatic theorem suggests that if \\(T\\) is chosen sufficiently large, and as long as eigenvalue \\(E_j\\) is nondegenerate along the entire path, then \\(\\ket{\\psi(T)} \\approx \\ket{\\phi_j(1)}\\) will hold. The often-quoted heuristic condition [2] for success is that </p>\\[\\begin{equation} \\label{eq:adiabatic_condition} T \\gg \\max_{0 \\leq s \\leq 1} \\frac{\\left\\lVert \\frac{dH}{ds}\\right\\rVert}{\\Delta(s)^2} \\end{equation}\\]<p>where \\(\\Delta(s)\\) is the spectral gap, i.e. \\(\\min_{i}|E_i(s)-E_j(s)|\\), and \\(\\lVert \\cdot \\rVert\\) denotes the spectral norm. Thus, the runtime needed for the QAA to have small error is primarily governed by the minimum size of the spectral gap along the adiabatic path. This aspect of the QAA is a common sticking point as it is often difficult to produce lower bounds on \\(\\Delta(s)\\) that would suffice for proving upper bounds on \\(T\\). In practice, the value of \\(T\\) can be chosen heuristically, or by trial-and-error, but a more detailed understanding of \\(\\Delta(s)\\) would inform smarter choices of Hamiltonian path \\(H(s)\\).</p><p>The QAA is typically formulated as a continuous-time procedure, but a gate-based quantum computer can simulate the QAA by discretizing the path and approximately implementing the evolution from time \\(t\\) to \\(t+ \\delta t\\) with product formulae or with more advanced techniques for time-dependent Hamiltonian simulation. This incurs error in addition to the adiabatic error of the continuous-time QAA. The number of gates needed to do this can be made proportional to \\(T\\) (up to logarithmic corrections), polynomial in the number of qubits needed to hold the state \\(\\ket{\\psi(t)}\\), and logarithmic in the approximation error incurred (e.g., [3]).</p>"},{"location":"quantum-algorithmic-primitives/quantum-adiabatic-algorithm/#caveats","title":"Caveats","text":"<p>A technical caveat of the QAA is that rigorous formulations of sufficient conditions for success (e.g., [4, 5]) are more complex than Eq. \\(\\eqref{eq:adiabatic_condition}\\) and likely looser than what is necessary in practice. Also, in most cases, the dependence of the runtime \\(T\\) on the final approximation error \\(\\epsilon = \\lVert \\ket{\\psi(T)}-\\ket{\\phi_j(1)}\\rVert\\) goes as \\(T = \\mathrm{poly}(1/\\epsilon)\\), rather than \\(T = \\mathrm{polylog}(1/\\epsilon)\\). To circumvent this and achieve \\(\\mathrm{polylog}(1/\\epsilon)\\) dependence, one can choose more sophisticated Hamiltonian paths \\(H(s)\\) for which all time derivatives vanish at \\(s=0\\) and \\(s=1\\) [6, 2].</p><p>A practical caveat of the QAA is that the spectral gap\u2014the main determiner of the resource cost for the QAA\u2014is difficult to study theoretically. Numerically, it can often be computed only for small system sizes, and it is unclear whether extrapolations to larger system sizes would be accurate.</p>"},{"location":"quantum-algorithmic-primitives/quantum-adiabatic-algorithm/#nisq-implementations","title":"NISQ implementations","text":"<p>The QAA is closely related to the concept of quantum annealing [7], a term used especially in the context of near-term implementations on existing quantum hardware. In quantum annealing, the system is exposed to a time-dependent Hamiltonian, typically a transverse-field Ising model. The strength of the transverse field is slowly reduced, eventually to zero, where the Hamiltonian is equal to a classical Ising model encoding a hard combinatorial optimization problem. If implemented perfectly and sufficiently slowly, this would be a manifestation of the QAA, and one would obtain the solution to the problem. However, the typical setting of quantum annealing is to consider faster implementations, and to possibly allow for some amount of control noise and finite-temperature effects (rather than evolving under a closed system at zero temperature), which induce transitions from the ground state to excited states. The goal is relaxed from ending in the exact ground state of the final Hamiltonian to ending in a low-energy state that can be considered an approximately optimal solution to the problem. The success metric is often the quality of the solution produced rather than the runtime required to find the best solution. As such, it is a heuristic algorithm and must be compared with classical heuristic algorithms, where evidence of a scalable advantage is mixed. See, e.g., [8] for a perspective on quantum annealing and the most promising related directions.</p><p>Separately, the QAA can be related to variational quantum algorithms, which are NISQ friendly. In particular, by applying product formulae to the QAA, one obtains alternating time evolutions by \\(H(0)\\) and by \\(H(1)\\); in the case that \\(H(0)\\) is a transverse field and \\(H(1)\\) is a classical cost function, this is precisely an instance of the Quantum Approximate Optimization Algorithm (QAOA) [9], a leading NISQ algorithm. In the limit of large depth, the QAOA can fully simulate the QAA to arbitrarily small precision. However, in a NISQ setting, the depth of the QAOA would need to be restricted, and the QAOA would not exactly follow the QAA.</p>"},{"location":"quantum-algorithmic-primitives/quantum-adiabatic-algorithm/#example-use-cases","title":"Example use cases","text":"<ul> <li>Combinatorial optimization: The QAA was first invented [1] as a way to solve hard classical combinatorial optimization problems on a quantum computer. An example is constraint satisfaction problems, where one is given a Hamiltonian \\(H(1)\\) that is diagonal in the computational basis (i.e. \"classical\") and equal to the sum of various constraints on \\(n\\) bits. The ground state of \\(H(1)\\) is the bit string that violates the fewest constraints. One typically chooses the initial Hamiltonian to be \\(H(0) = -\\sum_{i=1}^n X_i\\), where \\(X_i\\) denotes the Pauli-\\(X\\) operator on qubit \\(i\\), whose ground state is an easy-to-prepare product state. The QAA is guaranteed to find the ground state of \\(H(1)\\) if it is run with sufficiently large evolution time. However, in general it is expected that the spectral gaps along the adiabatic path become exponentially small in \\(n\\) [10, 11, 12, 13, 14], indicating that the QAA requires exponentially long runtime.</li> <li>Quantum chemistry and condensed matter physics: A central problem of quantum chemistry and computational condensed matter physics is the problem of finding the ground state energy of a molecule, material, or lattice model. This can be solved efficiently with quantum phase estimation so long as one can prepare a state that has substantial overlap with the ground state of the Hamiltonian. Adiabatic state preparation has been proposed as a method for producing such a state (see, e.g., [15, 16, 17, 18, 19, 20, 21]). This initial state preparation is often the bottleneck in the end-to-end quantum solution, as it can require exponential time for systems of interest (see, e.g., [22]).</li> <li>Quantum linear systems solvers: the state-of-the-art quantum linear systems solvers [23] leverage the QAA to produce a quantum state \\(\\ket{x}\\) corresponding to the solution of a linear system \\(Ax = b\\) (see also [24, 25, 26, 27]). In particular, this method allows the runtime to scale linearly in the condition number of the matrix \\(A\\).</li> </ul>"},{"location":"quantum-algorithmic-primitives/quantum-adiabatic-algorithm/#further-reading","title":"Further reading","text":"<ul> <li>See [2] for a comprehensive 2018 review of the QAA and adiabatic quantum computation more generally.</li> <li>See [28] for a digital version of the QAA for a gate-based quantum computer, but distinct from a direct simulation of the QAA. The idea is to choose a sequence of \\(s\\) values \\(0 = s_0 &lt; s_1 &lt; s_2 &lt; \\ldots &lt; s_T = 1\\) and perform measurements of \\(H(s_t)\\) for \\(t=0, \\ldots, T\\) in sequence using quantum phase estimation (QPE). As long as the difference between consecutive values of \\(s\\) is sufficiently small, the quantum Zeno effect guarantees that each measurement will project onto the correct eigenstate \\(\\ket{\\phi_j(s_t)}\\) with high probability (see also [29]). One can also take larger jumps, and amplify their success probability with fixed-point amplitude amplification. The resource cost has a similar dependence on the spectral gap as the continuous-time QAA: if the \"path length\" traced by the eigenstate \\(\\ket{\\phi_j(s)}\\) is \\(L\\), the minimum gap is \\(\\Delta\\), and the target error is \\(\\epsilon\\), then the gate cost of the algorithm is \\(\\mathcal{O}\\left( L\\log(L/\\epsilon)/\\Delta \\right)\\). The path length \\(L\\) can be upper bounded by \\(\\lVert dH/ds \\rVert/\\Delta\\), which roughly recovers Eq. \\(\\eqref{eq:adiabatic_condition}\\).</li> <li>Along these lines, [30] gives an alternative way to effect adiabatic state preparation on a gate-based computer with \\(\\mathrm{polylog}(1/\\epsilon)\\) overall error dependence, via quasi-adiabatic continuation.</li> </ul>"},{"location":"quantum-algorithmic-primitives/quantum-adiabatic-algorithm/#bibliography","title":"Bibliography","text":"<ol> <li> <p>Edward Farhi, Jeffrey Goldstone, Sam Gutmann, and Michael Sipser. Quantum computation by adiabatic evolution. arXiv: https://arxiv.org/abs/quant-ph/0001106, 2000.</p> </li> <li> <p>Tameem Albash and Daniel A. Lidar. Adiabatic quantum computation. Reviews of Modern Physics, 90:015002, 1 2018. arXiv: https://arxiv.org/abs/1611.04471. doi:10.1103/RevModPhys.90.015002.</p> </li> <li> <p>M\u00e1ria Kieferov\u00e1, Artur Scherer, and Dominic W. Berry. Simulating the dynamics of time-dependent hamiltonians with a truncated dyson series. Physical Review A, 99:042314, 4 2019. arXiv: https://arxiv.org/abs/1805.00582. URL: https://link.aps.org/doi/10.1103/PhysRevA.99.042314, doi:10.1103/PhysRevA.99.042314.</p> </li> <li> <p>Sabine Jansen, Mary-Beth Ruskai, and Ruedi Seiler. Bounds for the adiabatic approximation with applications to quantum computation. Journal of Mathematical Physics, 48(10):102111, 2007. arXiv: https://arxiv.org/abs/quant-ph/0603175. doi:10.1063/1.2798382.</p> </li> <li> <p>Alexander Elgart and George A. Hagedorn. A note on the switching adiabatic theorem. Journal of Mathematical Physics, 53(10):102202, 2012. arXiv: https://arxiv.org/abs/1204.2318. doi:10.1063/1.4748968.</p> </li> <li> <p>Yimin Ge, Andr\u00e1s Moln\u00e1r, and J. Ignacio Cirac. Rapid adiabatic preparation of injective projected entangled pair states and gibbs states. Physical Review Letters, 116:080503, 2 2016. arXiv: https://arxiv.org/abs/1508.00570. doi:10.1103/PhysRevLett.116.080503.</p> </li> <li> <p>Tadashi Kadowaki and Hidetoshi Nishimori. Quantum annealing in the transverse ising model. Physical Review E, 58:5355\u20135363, 11 1998. arXiv: https://arxiv.org/abs/cond-mat/9804280. URL: https://link.aps.org/doi/10.1103/PhysRevE.58.5355, doi:10.1103/PhysRevE.58.5355.</p> </li> <li> <p>EJ Crosson and DA Lidar. Prospects for quantum enhancement with diabatic quantum annealing. Nature Reviews Physics, 3(7):466\u2013489, 2021. arXiv: https://arxiv.org/abs/2008.09913. doi:10.1038/s42254-021-00313-6.</p> </li> <li> <p>Edward Farhi, Jeffrey Goldstone, and Sam Gutmann. A quantum approximate optimization algorithm. arXiv: https://arxiv.org/abs/1411.4028, 2014.</p> </li> <li> <p>Sergey Knysh and Vadim Smelyanskiy. On the relevance of avoided crossings away from quantum critical point to the complexity of quantum adiabatic algorithm. arXiv: https://arxiv.org/abs/1005.3011, 2010. doi:10.48550/arXiv.1005.3011.</p> </li> <li> <p>A. P. Young, S. Knysh, and V. N. Smelyanskiy. First-order phase transition in the quantum adiabatic algorithm. Physical Review Letters, 104:020502, 1 2010. arXiv: https://arxiv.org/abs/0910.1378. URL: https://link.aps.org/doi/10.1103/PhysRevLett.104.020502, doi:10.1103/PhysRevLett.104.020502.</p> </li> <li> <p>Itay Hen and A. P. Young. Exponential complexity of the quantum adiabatic algorithm for certain satisfiability problems. Physical Review E, 84:061152, 2011. arXiv: https://arxiv.org/abs/1109.6872. URL: https://link.aps.org/doi/10.1103/PhysRevE.84.061152, doi:10.1103/PhysRevE.84.061152.</p> </li> <li> <p>Boris Altshuler, Hari Krovi, and J\u00e9r\u00e9mie Roland. Anderson localization makes adiabatic quantum optimization fail. Proceedings of the National Academy of Sciences, 107:12446\u201312450, 2010. arXiv: https://arxiv.org/abs/0912.0746. doi:10.1073/pnas.1002116107.</p> </li> <li> <p>Dave Wecker, Matthew B. Hastings, and Matthias Troyer. Training a quantum optimizer. Physical Review A, 94:022309, 2016. arXiv: https://arxiv.org/abs/1605.05370. doi:10.1103/PhysRevA.94.022309.</p> </li> <li> <p>L.-A. Wu, M. S. Byrd, and D. A. Lidar. Polynomial-time simulation of pairing models on a quantum computer. Physical Review Letters, 89:057904, 7 2002. arXiv: https://arxiv.org/abs/quant-ph/0108110. URL: https://link.aps.org/doi/10.1103/PhysRevLett.89.057904, doi:10.1103/PhysRevLett.89.057904.</p> </li> <li> <p>Markus Reiher, Nathan Wiebe, Krysta M. Svore, Dave Wecker, and Matthias Troyer. Elucidating reaction mechanisms on quantum computers. Proceedings of the National Academy of Sciences, 114(29):7555\u20137560, 2017. arXiv: https://arxiv.org/abs/1605.03590. URL: https://www.pnas.org/doi/abs/10.1073/pnas.1619152114, arXiv:https://www.pnas.org/doi/pdf/10.1073/pnas.1619152114, doi:10.1073/pnas.1619152114.</p> </li> <li> <p>Libor Veis and Ji\u0159\u00ed Pittner. Adiabatic state preparation study of methylene. The Journal of Chemical Physics, 140(21):214111, 2014. arXiv: https://arxiv.org/abs/1401.3186.pdf. URL: https://doi.org/10.1063/1.4880755, arXiv:https://doi.org/10.1063/1.4880755, doi:10.1063/1.4880755.</p> </li> <li> <p>Vladimir Kremenetski, Carlos Mejuto-Zaera, Stephen J. Cotton, and Norm M. Tubman. Simulation of adiabatic quantum computing for molecular ground states. The Journal of Chemical Physics, 155(23):234106, 2021. arXiv: https://arxiv.org/abs/2103.12059. URL: https://doi.org/10.1063/5.0060124, arXiv:https://doi.org/10.1063/5.0060124, doi:10.1063/5.0060124.</p> </li> <li> <p>Kenji Sugisaki, Kazuo Toyota, Kazunobu Sato, Daisuke Shiomi, and Takeji Takui. Adiabatic state preparation of correlated wave functions with nonlinear scheduling functions and broken-symmetry wave functions. Communications Chemistry, 5(1):84, 7 2022. URL: https://doi.org/10.1038/s42004-022-00701-8, doi:10.1038/s42004-022-00701-8.</p> </li> <li> <p>Dave Wecker, Matthew B. Hastings, Nathan Wiebe, Bryan K. Clark, Chetan Nayak, and Matthias Troyer. Solving strongly correlated electron models on a quantum computer. Physical Review A, 92:062318, 12 2015. arXiv: https://arxiv.org/abs/1506.05135. URL: https://link.aps.org/doi/10.1103/PhysRevA.92.062318, doi:10.1103/PhysRevA.92.062318.</p> </li> <li> <p>Hongye Yu, Deyu Lu, Qin Wu, and Tzu-Chieh Wei. Geometric quantum adiabatic methods for quantum chemistry. Physical Review Research, 4:033045, 7 2022. arXiv: https://arxiv.org/abs/2112.15186. URL: https://link.aps.org/doi/10.1103/PhysRevResearch.4.033045, doi:10.1103/PhysRevResearch.4.033045.</p> </li> <li> <p>Seunghoon Lee, Joonho Lee, Huanchen Zhai, Yu Tong, Alexander M. Dalzell, Ashutosh Kumar, Phillip Helms, Johnnie Gray, Zhi-Hao Cui, Wenyuan Liu, Michael Kastoryano, Ryan Babbush, John Preskill, David R. Reichman, Earl T. Campbell, Edward F. Valeev, Lin Lin, and Garnet Kin-Lic Chan. Evaluating the evidence for exponential quantum advantage in ground-state quantum chemistry. Nature Communications, 14(1):1952, 2023. arXiv: https://arxiv.org/abs/2208.02199. URL: https://doi.org/10.1038/s41467-023-37587-6, doi:10.1038/s41467-023-37587-6.</p> </li> <li> <p>Pedro C.S. Costa, Dong An, Yuval R. Sanders, Yuan Su, Ryan Babbush, and Dominic W. Berry. Optimal scaling quantum linear-systems solver via discrete adiabatic theorem. PRX Quantum, 3:040303, 10 2022. arXiv: https://arxiv.org/abs/2111.08152. URL: https://link.aps.org/doi/10.1103/PRXQuantum.3.040303, doi:10.1103/PRXQuantum.3.040303.</p> </li> <li> <p>Yi\u011fit Suba\u015f\u0131, Rolando D. Somma, and Davide Orsucci. Quantum algorithms for systems of linear equations inspired by adiabatic quantum computing. Physical Review Letters, 122(6):060504, 2019. arXiv: https://arxiv.org/abs/1805.10549. doi:10.1103/PhysRevLett.122.060504.</p> </li> <li> <p>Dong An and Lin Lin. Quantum linear system solver based on time-optimal adiabatic quantum computing and quantum approximate optimization algorithm. ACM Transactions on Quantum Computing, 2022. arXiv: https://arxiv.org/abs/1909.05500. doi:10.1145/3498331.</p> </li> <li> <p>Lin Lin and Yu Tong. Optimal polynomial based quantum eigenstate filtering with application to solving quantum linear systems. Quantum, 4:361, 2020. arXiv: https://arxiv.org/abs/1910.14596. doi:10.22331/q-2020-11-11-361.</p> </li> <li> <p>David Jennings, Matteo Lostaglio, Sam Pallister, Andrew T. Sornborger, and Yigit Subasi. Efficient quantum linear solver algorithm with detailed running costs. arXiv: https://arxiv.org/abs/2305.11352, 2023.</p> </li> <li> <p>Sergio Boixo, Emanuel Knill, and Rolando D Somma. Fast quantum algorithms for traversing paths of eigenstates. arXiv: https://arxiv.org/abs/1005.3034, 2010.</p> </li> <li> <p>Rolando Somma, Sergio Boixo, and Howard Barnum. Quantum simulated annealing. arXiv: https://arxiv.org/abs/0712.1008, 2007.</p> </li> <li> <p>Kianna Wan and Isaac Kim. Fast digital methods for adiabatic state preparation. arXiv: https://arxiv.org/abs/2004.04164, 2020.</p> </li> </ol>"},{"location":"quantum-algorithmic-primitives/quantum-fourier-transform/","title":"Quantum Fourier transform","text":""},{"location":"quantum-algorithmic-primitives/quantum-fourier-transform/#rough-overview-in-words","title":"Rough overview (in words)","text":"<p>The quantum Fourier transform (QFT) is a quantum version of the discrete Fourier transform (DFT) and takes quantum states to their Fourier transformed version.</p>"},{"location":"quantum-algorithmic-primitives/quantum-fourier-transform/#rough-overview-in-math","title":"Rough overview (in math)","text":"<p>The QFT is a quantum circuit that takes pure \\(N\\)-dimensional quantum states \\(\\ket{x}=\\sum_{i=0}^{N-1}x_i\\ket{i}\\) to pure quantum states \\(\\ket{y}=\\sum_{i=0}^{N-1}y_i\\ket{i}\\) with the Fourier transformed amplitudes </p>\\[\\begin{align} \\label{eq:Fourier} y_k=\\frac{1}{\\sqrt{N}}\\sum_{l=0}^{N-1}x_l\\exp(2\\pi ikl/N)\\quad\\text{for }k=0,\\cdots,N-1. \\end{align}\\]"},{"location":"quantum-algorithmic-primitives/quantum-fourier-transform/#dominant-resource-cost-gatesqubits","title":"Dominant resource cost (gates/qubits)","text":"<p>The space cost is \\(\\mathcal{O}\\left( \\log(N) \\right)\\) qubits and the quantum complexity of the textbook algorithm is \\(\\mathcal{O}\\left( \\log^2(N) \\right)\\). In terms of Hadamard gates, swap gates, and controlled phase shift gates \\(\\ket{0}\\bra{0}\\otimes I + \\ket{1}\\bra{1}\\otimes R_\\ell\\) with </p>\\[\\begin{align} R_\\ell=\\begin{pmatrix} 1 &amp; 0\\\\ 0 &amp; \\exp\\left(2\\pi i2^{-\\ell}\\right)\\end{pmatrix}\\,, \\end{align}\\]<p>the quantum circuit looks as follows [1, Fig. 5.1], where \\(N=2^n\\):  The swap gates at the end of the circuit are required to reverse the order of the output bits. The complexity can be improved to </p>\\[\\begin{align} \\mathcal{O}\\left( \\log(N)\\log\\left(\\log(N)\\epsilon^{-1}\\right)+\\log^2\\left(\\epsilon^{-1}\\right) \\right) \\end{align}\\]<p>when only asking for \\(\\epsilon\\)-approximate solutions [2]. Finite constants and compilation cost for fault-tolerant quantum architectures are also discussed in the literature. For example [3] gives an implementation with \\(\\mathcal{O}\\left( \\log(N)\\log\\log(N) \\right)\\) \\(T\\)-gates and estimates finite \\(T\\)-gate costs for different instance sizes.</p>"},{"location":"quantum-algorithmic-primitives/quantum-fourier-transform/#caveats","title":"Caveats","text":"<ul> <li>The QFT does not achieve the same task as the classical DFT that takes vectors \\((x_0,\\cdots,x_{N-1})\\in\\mathbb{C}^N\\) to vectors \\((y_0,\\cdots,y_{N-1})\\in\\mathbb{C}^N\\) with \\(y_k\\) defined as in Eq. \\(\\eqref{eq:Fourier}\\). The DFT can be implemented via the fast Fourier transform in classical complexity \\(\\mathcal{O}\\left( N\\log(N) \\right)\\), which is exponentially more costly than the quantum complexity \\(\\mathcal{O}\\left( \\log^2(N) \\right)\\) of the QFT. However, for the QFT to achieve the same task as the DFT, pure state quantum tomography would be required to read out and learn the Fourier-transformed amplitudes, which destroys any quantum speedup for the DFT.</li> <li>When QFT is employed in use cases, e.g., for factoring, one has to be careful in finite size instances when counting resources [4], and for this a semi-classical version of the QFT can be more quantum resource efficient [5].</li> </ul>"},{"location":"quantum-algorithmic-primitives/quantum-fourier-transform/#example-use-cases","title":"Example use cases","text":"<ul> <li>Even though the QFT does not speedup the DFT, QFT is used as a subroutine in more involved quantum routines with large quantum speedup. Examples include quantum algorithms for the discrete logarithm problem, the hidden subgroup problem, the factoring problem, to name a few. QFT can be seen as the crucial quantum ingredient that allows for a super-polynomial end-to-end quantum speedup for these problems. We discuss this in the context of quantum cryptanalysis.</li> <li>The QFT appears in the standard circuit for quantum phase estimation, where it is used to convert accrued phase estimation into a binary value that can be read out.</li> <li>The QFT is used for switching between the position and momentum bases in grid-based simulations of quantum chemistry [6] or quantum field theories [7].</li> </ul>"},{"location":"quantum-algorithmic-primitives/quantum-fourier-transform/#further-reading","title":"Further reading","text":"<ul> <li>Textbook reference [1, Chapter 5]</li> <li>Wikipedia article Quantum Fourier transform</li> <li>The quantum Fourier transform can be generalized to other groups. The version presented above is for the group \\(\\mathbb{Z}/(2^n\\mathbb{Z})\\). Its implementation for other abelian groups as well as non-abelian groups is discussed in [8] and the references therein.</li> </ul>"},{"location":"quantum-algorithmic-primitives/quantum-fourier-transform/#bibliography","title":"Bibliography","text":"<ol> <li> <p>Michael A. Nielsen and Isaac L. Chuang. Quantum computation and quantum information. Cambridge University Press, 2000. doi:10.1017/CBO9780511976667.</p> </li> <li> <p>L. Hales and S. Hallgren. An improved quantum fourier transform algorithm and applications. In Proceedings of the 41st IEEE Symposium on Foundations of Computer Science (FOCS), 515\u2013525. 2000. doi:10.1109/SFCS.2000.892139.</p> </li> <li> <p>Yunseong Nam, Yuan Su, and Dmitri Maslov. Approximate quantum fourier transform with \\(o(n \\log (n))\\) t gates. npj Quantum Information, 6(1):26, 2020. arXiv: https://arxiv.org/abs/1803.04933. URL: https://doi.org/10.1038/s41534-020-0257-5, doi:10.1038/s41534-020-0257-5.</p> </li> <li> <p>John A. Smolin, Graeme Smith, and Alexander Vargo. Oversimplifying quantum factoring. Nature, 499(7457):163\u2013165, 2013. URL: https://doi.org/10.1038/nature12290, doi:10.1038/nature12290.</p> </li> <li> <p>Robert B. Griffiths and Chi-Sheng Niu. Semiclassical fourier transform for quantum computation. Physical Review Letters, 76(17):3228, 1996. arXiv: https://arxiv.org/abs/quant-ph/9511007. doi:10.1103/PhysRevLett.76.3228.</p> </li> <li> <p>Ivan Kassal, Stephen P. Jordan, Peter J. Love, Masoud Mohseni, and Al\u00e1n Aspuru-Guzik. Polynomial-time quantum algorithm for the simulation of chemical dynamics. Proceedings of the National Academy of Sciences, 105(48):18681\u201318686, 2008. arXiv: https://arxiv.org/abs/0801.2986. URL: https://www.pnas.org/doi/abs/10.1073/pnas.0808245105, arXiv:https://www.pnas.org/doi/pdf/10.1073/pnas.0808245105, doi:10.1073/pnas.0808245105.</p> </li> <li> <p>Stephen P. Jordan, Keith S. M. Lee, and John Preskill. Quantum algorithms for quantum field theories. Science, 336(6085):1130\u20131133, 2012. arXiv: https://arxiv.org/abs/1111.3633. URL: https://www.science.org/doi/abs/10.1126/science.1217069, arXiv:https://www.science.org/doi/pdf/10.1126/science.1217069, doi:10.1126/science.1217069.</p> </li> <li> <p>Andrew M. Childs and Wim van Dam. Quantum algorithms for algebraic problems. Reviews of Modern Physics, 82:1\u201352, 1 2010. arXiv: https://arxiv.org/abs/0812.0380. URL: https://link.aps.org/doi/10.1103/RevModPhys.82.1, doi:10.1103/RevModPhys.82.1.</p> </li> </ol>"},{"location":"quantum-algorithmic-primitives/quantum-gradient-estimation/","title":"Quantum gradient estimation","text":""},{"location":"quantum-algorithmic-primitives/quantum-gradient-estimation/#rough-overview-in-words","title":"Rough overview (in words)","text":"<p>Estimating the gradient of a high-dimensional function is a widely useful subroutine of classical and quantum algorithms. The function's gradient at a certain point can be classically estimated by querying the value of the function at many nearby points. However, the number of evaluations will scale with the number of dimensions in the function, which can be very large. By contrast, the quantum gradient estimation algorithm evaluates the function a constant number of times (in superposition over many nearby points) and uses interference effects to produce the estimate of the gradient. While there are caveats related to the precise access model and the classical complexity of gradient estimation in specific applications, this procedure can potentially lead to significant quantum speedups.</p>"},{"location":"quantum-algorithmic-primitives/quantum-gradient-estimation/#rough-overview-in-math","title":"Rough overview (in math)","text":"<p>Let \\(f: \\mathbb{R}^d \\rightarrow \\mathbb{R}\\) be a real function on \\(d\\)-dimensional inputs, and assume that is differentiable at a specific input of interest, taken to be the origin \\(\\mathbf{0} = (0,0,\\ldots,0)\\) for simplicity (the algorithm works equally well elsewhere). Let \\(g = (g_1,\\ldots,g_d)\\) denote the gradient of \\(f\\) at \\(\\mathbf{0}\\), i.e., \\(g = \\nabla f(\\mathbf{0})\\). We wish to produce a classical estimate \\(\\tilde{g}\\) of \\(g\\) that satisfies \\(\\lvert g_j - \\tilde{g}_j \\rvert &lt; \\varepsilon\\) for all \\(j =1,\\ldots, d\\).</p><p>Ignoring higher-order terms, the function may be approximated near the origin as \\(f(x) \\approx f(\\mathbf{0})+\\langle g, x \\rangle\\), where \\(\\langle \\cdot, \\cdot \\rangle\\) denotes the normal inner product. The original gradient estimation algorithm by Jordan [1] then considers a \\(d\\)-dimensional grid of points near the origin denoted by \\(G\\). For simplicity, suppose on each of the \\(d\\) dimensions, the grid has \\(N\\) evenly spaced points on the interval \\([-\\ell/2,\\ell/2]\\), for a certain parameter \\(\\ell\\) related to the precision requirements of the algorithm. The quantum algorithm prepares a superposition of the grid points \\(x \\in G\\) and computes function \\(f(x)\\) (times a constant \\(N/\\ell\\)) into the phase, producing the state </p>\\[\\begin{equation} \\frac{1}{\\sqrt{N^d}} \\sum_{x \\in G} e^{i2\\pi N f(x)/\\ell}\\ket{x} \\approx \\frac{e^{i2\\pi N f(\\mathbf{0})/\\ell}}{\\sqrt{N^d}}\\sum_{x \\in G} e^{i2\\pi N g \\cdot x/\\ell}\\ket{x} \\end{equation}\\]<p>where \\(\\ket{x}\\) denotes the product state \\(\\ket{x_1}\\ket{x_2}\\ldots\\ket{x_d}\\) with \\(x_j\\) the binary representation of the \\(j\\)th dimension of \\(x\\). With this in mind, the latter state is rewritten as the product state </p>\\[\\begin{equation} \\frac{e^{i2\\pi N f(\\mathbf{0})/\\ell}}{\\sqrt{N^d}}\\left(e^{-\\pi i N g_1}\\sum_{l_1 = 0}^{N-1} e^{2\\pi i l_1 g_1}\\ket{l_1}\\right)\\left(e^{-\\pi i N g_2}\\sum_{l_2 = 0}^{N-1} e^{2\\pi i l_2 g_2}\\ket{l_2}\\right)\\ldots \\left(e^{-\\pi i N g_d}\\sum_{l_d = 0}^{N-1} e^{2\\pi i l_d g_d}\\ket{l_d}\\right) \\end{equation}\\]<p>Due to the approximated linearity of \\(f\\), each of the product state constituents is observed to be close to a basis state in the Fourier basis. By performing an inverse quantum Fourier transform (QFT) in parallel for each of the \\(d\\) dimensions and measuring in the computational basis, a computational basis state </p>\\[\\begin{equation} \\ket{\\tilde{g}} = \\ket{\\tilde{g}_1}\\ket{\\tilde{g}_2}\\ldots \\ket{\\tilde{g}_d} \\end{equation}\\]<p>is retrieved (up to an unimportant global phase), where with high probability \\(\\tilde{g}_j\\) approximates \\(g_j\\) to \\(\\log_2(N)\\) bits of precision. Taking \\(N = \\mathcal{O}(1/\\varepsilon)\\) suffices to solve the problem. In a full analysis, one must make sure not to choose \\(\\ell\\) too large (else the linearity approximation breaks down).</p><p>In [1], the unitary \\(U_f\\) sending \\(\\ket{x} \\mapsto e^{i2\\pi N f(x)/\\ell} \\ket{x}\\) was performed using a constant number of calls to the evaluation oracle that computes an approximation to \\(f(x)\\) to precision \\(\\smash{\\mathcal{O}(\\varepsilon^2/\\sqrt{d})}\\) into an ancilla register. In [2], \\(U_f\\) was implemented using \\(\\mathcal{O}(\\sqrt{d}/\\varepsilon)\\) calls to a \"probability oracle\" that (assuming \\(0 \\leq f(x) \\leq 1\\)) performs the map \\(\\ket{x}\\ket{0} \\mapsto \\sqrt{f(x)}\\ket{x}\\ket{1} + \\sqrt{1-f(x)} \\ket{x}\\ket{0}\\). Additionally, [2] improved the algorithm sketched above by explicitly using finite difference formulas in place of evenly spaced grids to put the gradient into the phase.</p><p>The gradient estimation algorithm can be viewed as a generalization of the Bernstein\u2013Vazirani algorithm [3], which considers binary functions \\(f:\\{0,1\\}^n \\rightarrow \\{0,1\\}\\), and, promised that \\(f(x) = \\langle g, x \\rangle \\bmod 2\\) for some unknown vector \\(g\\), determines \\(g\\) with one query to \\(f\\).</p>"},{"location":"quantum-algorithmic-primitives/quantum-gradient-estimation/#dominant-resource-cost-gatesqubits","title":"Dominant resource cost (gates/qubits)","text":"<p>The superposition over grid points can be easily accomplished with Hadamard gates. Likewise, the inverse QFT operation is relatively cheap. The number of qubits is \\(O(d \\log(N))\\), and the number of elementary operations for each of the \\(d\\) parallel QFTs is \\(\\text{polylog}(N)\\). Additionally, an important component of the complexity comes from performing the unitary \\(U_f\\), which requires implementing either an evaluation oracle or a probability oracle for the function \\(f\\). If one has access to an evaluation oracle, the function must be evaluated to precision \\(\\smash{\\mathcal{O}(\\varepsilon^2/\\sqrt{d})}\\). Thus, if function evaluations can be made to precision \\(\\delta\\) in time \\(\\mathrm{polylog}(d,1/\\delta)\\), the overall runtime of the quantum subroutine will be \\(\\mathrm{polylog}(d,1/\\varepsilon)\\), a potentially exponential speedup. In the case that one has access to a probability oracle, a number of calls scaling as \\(\\smash{\\mathcal{O}(\\sqrt{d}/\\varepsilon)}\\) must be made.</p><p>For some functions, it is possible to classically compute \\(f(x)\\) to precision \\(\\delta\\) with complexity \\(\\text{poly}(d,\\log(1/\\delta))\\). This can be turned into a quantum circuit \\(U_f\\) with a comparable gate complexity. For other functions, computing \\(f(x)\\) may be much harder. For example, if \\(f(x)\\) is defined as the output probability of a quantum circuit, then computing \\(f(x)\\) to precision \\(\\delta\\) might be difficult for a classical computer, and even on a quantum computer, it generally requires \\(\\mathcal{O}\\left( 1/\\delta \\right)\\) complexity. However, in this case, implementing a probability oracle is simple, leading to the motivation for the work of [2].</p>"},{"location":"quantum-algorithmic-primitives/quantum-gradient-estimation/#caveats","title":"Caveats","text":"<p>Jordan's formulation of the algorithm [1] appears to offer a large quantum speedup by accomplishing in a single quantum query what requires \\(\\mathcal{O}\\left( d \\right)\\) classical queries. However, this requires a fairly strong access model where one has access to an oracle for computing the value of the function \\(f\\) to high precision. For an exponential speedup to be possible, precision \\(\\varepsilon\\) must be achievable at cost \\(\\mathrm{polylog}(d,1/\\varepsilon)\\). Unfortunately, for actual functions \\(f\\) that show up in applications where this is possible, it is often the case that one can classically compute the gradient much more efficiently than simply querying the value of \\(f\\) at many nearby points. Indeed, the \"cheap gradient principle\" [4, 5] asserts that (in many practical situations) computing the gradient has roughly the same cost as computing the function itself. This principle limits the scope of application of the large speedup of Jordan's algorithm.</p><p>By contrast, [2] shows how the gradient can be computed using a probability oracle rather than an evaluation oracle, which makes the algorithm compatible with computing gradients in the setting of variational quantum algorithms. However, \\(\\mathcal{O}(\\sqrt{d}/\\varepsilon)\\) calls to the oracle are required, which represents a (much less dramatic) quadratic speedup compared to the strategy of using the probability oracle to estimate \\(f(x)\\) at many nearby points and subsequently estimating the gradient classically.</p>"},{"location":"quantum-algorithmic-primitives/quantum-gradient-estimation/#example-use-cases","title":"Example use cases","text":"<ul> <li>Convex optimization: In convex optimization, local optima are also global optima, and thus a global optimum can be found by greedy methods such as gradient descent. When one can efficiently compute the function \\(f\\) much more cheaply than computing its gradient, the quantum gradient estimation algorithm can give rise to a speedup over classical optimization procedures [6, 7].</li> <li>Pure state tomography: Given access to a unitary \\(U\\) that prepares the pure state \\(\\ket{\\psi}\\), [8] utilizes the gradient estimation algorithm to estimate the amplitudes of \\(\\ket{\\psi}\\) in the computational basis using an optimal number of queries to \\(U\\).</li> <li>Estimating multiple expectation values: amplitude estimation can be used to estimate an expectation value to precision \\(\\epsilon\\) at cost \\(\\mathcal{O}\\left( 1/\\epsilon \\right)\\). In [9, 8], it is shown how the gradient estimation algorithm further allows \\(M\\) expectation values to be simultaneously estimated at cost \\(\\smash{\\tilde{\\mathcal{O}}(\\sqrt{M}/\\epsilon)}\\) calls to a state preparation unitary, considered the most expensive part of the circuit.</li> <li>Computing molecular forces: while ground-state energies are the object most often studied in algorithms for quantum chemistry, other interesting quantities such as molecular forces can be related to gradients of molecular energies. Reference [10] studies how the gradient estimation algorithm can be leveraged into a quantum algorithm for computing such quantities.</li> <li>Escaping saddle points: Although not the essential ingredient, the gradient estimation algorithm was used in the algorithm of [11] for escaping saddle points.</li> <li>Variational quantum algorithms: Variational quantum algorithms involve optimizing the parameters of a quantum circuit under some cost function. The ability to estimate the gradient of the cost function with respect to the parameters might allow acceleration of this loop.</li> <li>Financial market risk analysis: In [12], the quantum gradient estimation subroutine was utilized to compute \"the greeks,\" parameters associated with financial market sensitivity.</li> </ul>"},{"location":"quantum-algorithmic-primitives/quantum-gradient-estimation/#further-reading","title":"Further reading","text":"<p>See [2] for a full discussion of the state of the art with respect to the quantum gradient estimation algorithm.</p>"},{"location":"quantum-algorithmic-primitives/quantum-gradient-estimation/#bibliography","title":"Bibliography","text":"<ol> <li> <p>Stephen P. Jordan. Fast quantum algorithm for numerical gradient estimation. Physical Review Letters, 95(5):050501, 2005. arXiv: https://arxiv.org/abs/quant-ph/0405146. doi:10.1103/PhysRevLett.95.050501.</p> </li> <li> <p>Andr\u00e1s Gily\u00e9n, Srinivasan Arunachalam, and Nathan Wiebe. Optimizing quantum optimization algorithms via faster quantum gradient computation. In Proceedings of the 30th ACM-SIAM Symposium on Discrete Algorithms (SODA), 1425\u20131444. 2019. arXiv: https://arxiv.org/abs/1711.00465. doi:10.1137/1.9781611975482.87.</p> </li> <li> <p>Ethan Bernstein and Umesh Vazirani. Quantum complexity theory. SIAM Journal on Computing, 26(5):1411\u20131473, 1997. Earlier version in STOC'93. doi:10.1137/S0097539796300921.</p> </li> <li> <p>Andreas Griewank and Andrea Walther. Evaluating Derivatives: Principles and Techniques of Algorithmic Differentiation. SIAM, 2008. doi:10.1137/1.9780898717761.</p> </li> <li> <p>J\u00e9r\u00f4me Bolte, Ryan Boustany, Edouard Pauwels, and B\u00e9atrice Pesquet-Popescu. Nonsmooth automatic differentiation: a cheap gradient principle and other complexity results. arXiv: https://arxiv.org/abs/2206.01730, 2022.</p> </li> <li> <p>Joran van Apeldoorn, Andr\u00e1s Gily\u00e9n, Sander Gribling, and Ronald de Wolf. Convex optimization using quantum oracles. Quantum, 4:220, 2020. arXiv: https://arxiv.org/abs/1809.00643. doi:10.22331/q-2020-01-13-220.</p> </li> <li> <p>Shouvanik Chakrabarti, Andrew M. Childs, Tongyang Li, and Xiaodi Wu. Quantum algorithms and lower bounds for convex optimization. Quantum, 4:221, 2020. arXiv: https://arxiv.org/abs/1809.01731. doi:10.22331/q-2020-01-13-221.</p> </li> <li> <p>Joran van Apeldoorn, Arjan Cornelissen, Andr\u00e1s Gily\u00e9n, and Giacomo Nannicini. Quantum tomography using state-preparation unitaries. In Proceedings of the 34th ACM-SIAM Symposium on Discrete Algorithms (SODA), 1265\u20131318. 2023. arXiv: https://arxiv.org/abs/2207.08800. doi:10.1137/1.9781611977554.ch47.</p> </li> <li> <p>William J. Huggins, Kianna Wan, Jarrod McClean, Thomas E. O'Brien, Nathan Wiebe, and Ryan Babbush. Nearly optimal quantum algorithm for estimating multiple expectation values. Physical Review Letters, 129:240501, 12 2022. arXiv: https://arxiv.org/abs/2111.09283. URL: https://link.aps.org/doi/10.1103/PhysRevLett.129.240501, doi:10.1103/PhysRevLett.129.240501.</p> </li> <li> <p>Thomas E. O'Brien, Michael Streif, Nicholas C. Rubin, Raffaele Santagati, Yuan Su, William J. Huggins, Joshua J. Goings, Nikolaj Moll, Elica Kyoseva, Matthias Degroote, Christofer S. Tautermann, Joonho Lee, Dominic W. Berry, Nathan Wiebe, and Ryan Babbush. Efficient quantum computation of molecular forces and other energy gradients. Physical Review Research, 4:043210, 12 2022. arXiv: https://arxiv.org/abs/2111.12437. URL: https://link.aps.org/doi/10.1103/PhysRevResearch.4.043210, doi:10.1103/PhysRevResearch.4.043210.</p> </li> <li> <p>Chenyi Zhang, Jiaqi Leng, and Tongyang Li. Quantum algorithms for escaping from saddle points. Quantum, 5:529, 8 2021. arXiv: https://arxiv.org/abs/2007.10253. URL: https://doi.org/10.22331/q-2021-08-20-529, doi:10.22331/q-2021-08-20-529.</p> </li> <li> <p>Nikitas Stamatopoulos, Guglielmo Mazzola, Stefan Woerner, and William J Zeng. Towards quantum advantage in financial market risk using quantum gradient algorithms. Quantum, 6:770, 2022. arXiv: https://arxiv.org/abs/2111.12509. doi:10.22331/q-2022-07-20-770.</p> </li> </ol>"},{"location":"quantum-algorithmic-primitives/quantum-interior-point-methods/","title":"Quantum interior point methods","text":""},{"location":"quantum-algorithmic-primitives/quantum-interior-point-methods/#rough-overview-in-words","title":"Rough overview (in words)","text":"<p>Interior point methods (IPMs) are a type of efficient classical algorithm for solving convex optimization problems such as linear programs (LPs), second-order cone programs (SOCPs), and semidefinite programs (SDPs). IPMs are the basis for effective optimization software tools (e.g., [1, 2]), which are widely used for solving convex optimization problems that arise in industry. They are called interior point methods because, in contrast to the simplex method, they iteratively generate a sequence of points that lie in the interior of the convex region; this sequence of points is guaranteed to rapidly approach the optimal point (which, when it exists and the objective function is convex, is guaranteed to lie at the boundary of the convex region). At each iteration, the next point is produced by solving a system of linear equations. See, e.g., [3, 4] for context on how IPMs fit into the history of methods for optimization.</p><p>Quantum interior point methods (QIPMs), first introduced in [5], are quantum algorithms that are identical to classical IPMs, except that they determine the next point using a quantum linear system solver combined with quantum state tomography.</p><p>Classical IPMs are generally efficient in the sense that they can solve convex optimization problems in time scaling as a polynomial in the number of variables. The exact degree of the polynomial depends on which kind of convex optimization problem is being solved, as well as certain choices about the IPM. Due to the need for quantum state tomography, QIPMs will also require time that scales at least linearly in the number of variables; thus, the best one can hope for is a polynomial speedup over classical IPMs. The exact runtime of the quantum algorithm depends on instance-specific parameters, such as the condition number of matrices that appear during the course of the algorithm, which makes it difficult to determine whether a speedup can exist.</p>"},{"location":"quantum-algorithmic-primitives/quantum-interior-point-methods/#rough-overview-in-math","title":"Rough overview (in math)","text":"<p>For simplicity, we focus on LPs, the simplest kind of optimization problem where QIPMs can be applied. An LP is specified by an \\(m \\times n\\) matrix \\(A\\), an \\(n\\)-dimensional vector \\(c\\), and an \\(m\\)-dimensional vector \\(b\\), and it is given by </p>\\[\\begin{equation} \\label{eq:LP-QIPM} \\begin{align} &amp; \\min_{x \\in \\mathbb{R}^n} \\langle c, x\\rangle \\\\ \\text{subject to } &amp; Ax=b \\\\ &amp; x_i \\geq 0 \\text{ for } i=1,\\ldots,n \\end{align} \\end{equation}\\]<p>where \\(\\langle u,v\\rangle\\) denotes the standard dot product between vectors \\(u\\) and \\(v\\).</p><p>The function \\(\\langle c, x\\rangle\\) is called the objective function, and a point \\(x\\) is called feasible if it satisfies \\(Ax=b\\) and \\(x_i \\geq 0\\) for all \\(i\\). Inequality constraints of the form \\(Ax \\leq b\\) can be handled by introducing slack variables. We denote the feasible point that optimizes the objective function by \\(x^*\\).</p><p>An important concept in mathematical optimization is duality, where given one optimization problem, an equivalent \"dual\" optimization problem can be generated through the method of Lagrange multipliers (see [6, Section 5]). The dual of the LP in Eq. \\(\\eqref{eq:LP-QIPM}\\) is given by </p>\\[\\begin{equation} \\label{eq:dual-LP-QIPM} \\begin{align} &amp; \\max_{y \\in \\mathbb{R}^m} \\langle b, y \\rangle \\\\ \\text{subject to } &amp; A^\\intercal y + s =c \\\\ &amp; s_i \\geq 0 \\text{ for } i=1,\\ldots,n \\end{align}\\,. \\end{equation}\\]<p>Alternatively, one can drop the \\(s\\) variable and constraints that \\(s_i\\) are positive, and simply write \\(A^\\intercal y \\leq c\\). Denote the optimal feasible points for the dual by \\((y^*,s^*)\\).</p><p>It can be shown that the optimal point lies at the boundary of the feasible region and satisfies the relationship \\(x_is_i = 0\\) for all \\(i\\). A key concept in IPMs is the central path, a set of points parameterized by \\(\\mu &gt; 0\\). The central point with parameter \\(\\mu\\) is the feasible point for which \\(x_is_i = \\mu\\) for all \\(i\\). In general, this point will be in the interior of the feasible region, but as \\(\\mu \\rightarrow 0\\), the central path approaches the optimal point on the boundary.</p><p>The most effective classical IPMs are \"primal-dual path-following methods,\" which generate a length-\\(T\\) sequence of primal-dual point pairs \\((x^{(t)},y^{(t)},s^{(t)}) \\in \\mathbb{R}^n \\times \\mathbb{R}^m \\times \\mathbb{R}^n\\) for \\(t=0,\\ldots,T-1\\) that approximately follows the central path toward the optimum. Given \\((x^{(t)},y^{(t)},s^{(t)})\\), the point \\((x^{(t+1)},y^{(t+1)},s^{(t+1)}) = (x^{(t)}+\\Delta x,y^{(t)} + \\Delta y,s^{(t)} + \\Delta s)\\) is formed by solving the following linear system of equations, which is called the Newton system, as it corresponds to one iteration of Newton's method. </p>\\[\\begin{equation} \\label{eq:Newton_system} \\begin{pmatrix} A &amp; 0 &amp; 0 \\\\ 0 &amp; A^\\intercal &amp; I \\\\ S &amp; 0 &amp; X \\end{pmatrix} \\begin{pmatrix} \\Delta x \\\\ \\Delta y \\\\ \\Delta s \\end{pmatrix} = \\begin{pmatrix} b-Ax^{(t)} \\\\ c-A^\\intercal y^{(t)} - s^{(t)} \\\\ \\sigma \\frac{x^{(t)\\intercal} s^{(t)}}{n}\\mathbf{1} - Xs^{(t)} \\end{pmatrix}\\,, \\end{equation}\\]<p>where \\(\\sigma&lt;1\\), \\(\\mathbf{1}\\) denotes the all 1s vector, and \\(S = \\text{diag}(s^{(t)}), X = \\text{diag}(x^{(t)})\\) are diagonal \\(n \\times n\\) matrices formed from the entries of \\(s^{(t)}\\) and \\(x^{(t)}\\). Note that there are alternative ways to formulate the Newton system (see, e.g., [7, 8]). To understand Eq. \\(\\eqref{eq:Newton_system}\\), note that if the point \\((x^{(t)}, y^{(t)}, s^{(t)})\\) is feasible, then the first two entries on the right-hand-side are zero. Furthermore, if it is on the central path, then \\(Xs^{(t)} = \\frac{x^{(t)\\intercal} s^{(t)}}{n} \\mathbf{1}\\), so if we were to choose \\(\\sigma=1\\), then the entire right-hand-side would be zero, and the solution to the system would be \\(\\Delta x = \\Delta y = \\Delta s = 0\\). If instead we set \\(\\sigma = 1-\\delta\\) for sufficiently small \\(\\delta\\), the solution will correspond to taking a small step along the central path in the direction of decreasing \\(\\mu\\). Technically, we do not exactly follow the central path, but it can be guaranteed that the sequence of points stays within a small neighborhood of it. As \\(\\mu \\rightarrow 0\\), the central path approaches the optimal point \\((x^*,y^*,s^*)\\), so by following the path toward \\(\\mu = 0\\), a classical or quantum IPM can guarantee success.</p><p>The classical IPM can solve the Newton system exactly using Gaussian elimination in \\(\\mathcal{O}\\left( n^3 \\right)\\) operations, or it can solve the system approximately using a variety of iterative solvers such as conjugate gradient descent or the Kaczmarz method [9]. In contrast, the QIPM solves the Newton system by using a quantum linear system solver to repeatedly prepare the \\(\\mathcal{O}\\left( \\log(n) \\right)\\)-qubit state \\(\\ket{\\Delta x, \\Delta y, \\Delta s}\\) whose amplitudes encode the solution to the Newton system. By preparing many copies, the algorithm can perform (pure state) quantum state tomography to yield an estimate \\((\\overline{\\Delta x}, \\overline{\\Delta y}, \\overline{\\Delta s})\\) for the amplitudes \\((\\Delta x, \\Delta y, \\Delta s)\\) to some desired precision \\(\\xi\\) (in 2-norm), i.e. </p>\\[\\begin{equation} \\lVert (\\overline{\\Delta x}, \\overline{\\Delta y}, \\overline{\\Delta s})-(\\Delta x, \\Delta y, \\Delta s) \\rVert \\leq \\xi \\lVert (\\Delta x, \\Delta y, \\Delta s) \\rVert \\end{equation}\\]<p>Due to the tomography step, the QIPM is only able to generate solutions to the Newton system that are inexact. There has been some question in the literature whether the fastest IPMs still work even when inexact solutions are used, as this causes intermediate points to be (slightly) infeasible [7]. However, if \\(\\xi\\) is sufficiently small, the method appears to work empirically even using the inexact solutions that would be output by a quantum solver [10]. Alternatively, there exist workarounds [7] that ensure feasibility is maintained even when linear systems are solved inexactly, at the expense of some additional classical cost.</p><p>The IPMs and QIPMs for SOCPs [11, 8] are quite similar to the one for LPs described above: the main difference is that the matrices \\(X\\) and \\(S\\) are no longer strictly diagonal matrices. QIPMs have also been proposed for SDPs [5, 7, 12], which are more complex but have more expressive power; here, additional considerations must be taken to guarantee that the intermediate solutions continue to be symmetric even after experiencing errors due to tomography.</p>"},{"location":"quantum-algorithmic-primitives/quantum-interior-point-methods/#dominant-resource-cost-gatesqubits","title":"Dominant resource cost (gates/qubits)","text":"<p>The outer loop of QIPMs is purely classical; at each iteration a small step is taken to form the next point in the sequence. For LP, SOCP, and SDP, the number of iterations \\(T\\) required to yield a point for which the objective function is within \\(\\epsilon\\) of optimal is \\(\\mathcal{O}(\\sqrt{n}\\log(1/\\epsilon))\\). The main cost of each iteration is solving the Newton system.</p><p>The QIPM solves the Newton system by preparing many copies of the state corresponding to the solution to the linear system. This state can be prepared in time \\(\\text{polylog}(n)\\cdot \\zeta \\kappa\\), where \\(\\kappa\\) is the condition number of the matrix in Eq. \\(\\eqref{eq:Newton_system}\\) and \\(\\zeta\\) is the ratio \\(\\lVert \\cdot \\rVert_F / \\lVert \\cdot \\rVert\\) of the Frobenius and spectral norms of the matrix, assuming that one can perform a block-encoding of the Newton matrix in \\(\\text{polylog}(n)\\) time, a task that requires access to large-scale quantum random access memory (QRAM). For LP and SOCP, the number of copies that must be prepared scales as \\(\\mathcal{O}\\left( n/\\xi^2 \\right)\\) when using the basic version (see [5, Section 4] and [10, Section IVD]) of pure state tomography that simply measures each copy in the computational basis. A more recent and complex version of tomography [13] can achieve this task using \\(\\mathcal{O}\\left( n/\\xi \\right)\\) copies along with additional gates. For SDP, since the variables are matrices rather than vectors, the number of copies is \\(\\mathcal{O}\\left( n^2/\\xi^2 \\right)\\) or \\(\\mathcal{O}\\left( n^2/\\xi \\right)\\). Overall, using the more efficient version of tomography and ignoring the additional gates, the runtime of the QIPM is expected to scale as </p>\\[\\begin{align} \\text{LP, SOCP:} &amp; \\qquad \\widetilde{\\mathcal{O}}\\left( \\frac{n^{1.5}\\zeta \\kappa}{\\xi}\\log(1/\\epsilon) \\right) \\\\ \\text{SDP:} &amp; \\qquad \\widetilde{\\mathcal{O}}\\left( \\frac{n^{2.5}\\zeta \\kappa}{\\xi}\\log(1/\\epsilon) \\right) \\end{align}\\]<p>where \\(\\kappa\\) denotes the maximum condition number, \\(\\zeta\\) the maximum ratio of Frobenius to spectral norm, and \\(\\xi\\) the minimum tomographic precision required across all iterations. In the worst case, it may be necessary to take \\(\\xi\\) as small as \\(\\mathcal{O}\\left( 1/\\kappa \\right)\\), and \\(\\zeta\\) can be as large as \\(\\sqrt{n}\\) (SOCP/LP) or \\(n\\) (SDP). The hidden constant prefactors are dependent primarily on the implementation of the quantum linear system solver and tomography. It is clear that the viability of the QIPM is highly dependent on the value and scaling of the parameters \\(\\kappa\\) and \\(\\xi\\). Unfortunately, it is believed that for some LP/SOCP/SDP instances, the value of \\(\\kappa\\) will diverge as the target precision \\(\\epsilon\\) is made smaller, perhaps as \\(\\mathcal{O}\\left( 1/\\epsilon \\right)\\) [11, 7], although this may not be the case in every instance [12].</p><p>The QIPM only requires a register of \\(\\mathcal{O}\\left( \\log(n) \\right)\\) qubits to hold the solution of the linear system; however, achieving the runtimes quoted requires queries to QRAM. In this case, the explicit QRAM circuits that achieve shallow depths of \\(\\mathcal{O}\\left( \\log(n) \\right)\\) necessarily require \\(\\mathcal{O}\\left( n^2 \\right)\\) total gates across \\(\\mathcal{O}\\left( n^2 \\right)\\) total qubits.</p>"},{"location":"quantum-algorithmic-primitives/quantum-interior-point-methods/#caveats","title":"Caveats","text":"<p>There are several important caveats that must be considered when evaluating a speedup claimed by QIPM.</p><ul> <li>Even in a best case scenario, the quantum speedup is at most polynomial (and even subquadratic). Since quantum computation requires significant constant-factor overheads due to slower clock speeds and error correction, the value of \\(n\\) for which a QIPM would be faster than a classical IPM on actual hardware is likely to be large (see [10] for further discussion).</li> <li>Since \\(n\\) must be large for a quantum speedup to be obtained, a very large QRAM, corresponding to millions or billions of (logical) qubits, would be needed for any speedup to be realized.</li> <li>QIPMs are most effective when the condition number \\(\\kappa\\) is relatively small since they rely on quantum linear system solvers. However, when \\(\\kappa\\) is small, iterative classical methods may also be effective, limiting the advantage of the quantum algorithm. In particular, a linear system with \\(\\mathcal{O}\\left( n \\right)\\) constraints on \\(n\\) variables can be solved to error \\(\\xi\\) in time \\(\\mathcal{O}\\left( n\\zeta^2 \\kappa^2\\log(1/\\xi) \\right)\\) using the randomized Kaczmarz method [9]. The QIPM performs this task in time \\(\\mathcal{O}\\left( n \\zeta \\kappa/\\xi \\right)\\). Even if \\(\\xi = \\Omega(1)\\), this limits the magnitude of the quantum speedup to \\(\\mathcal{O}\\left( \\zeta \\kappa \\right)\\). Thus, for the quantum speedup to be maximized, \\(\\kappa\\) can be neither too small nor too large.</li> <li>If the matrices that define the convex problem have a certain structure (e.g. sparsity), this could be exploited to potentially reduce the overhead from block-encoding\u2014in particular, the value of \\(\\zeta\\) and the size of the QRAM required. However, this can help the quantum algorithm only to a limited extent, as the vectors \\((\\Delta x, \\Delta y, \\Delta s)\\) will still be dense and reading out estimates for all \\(\\mathcal{O}\\left( n \\right)\\) amplitudes with quantum tomography will be necessary.</li> </ul>"},{"location":"quantum-algorithmic-primitives/quantum-interior-point-methods/#example-use-cases","title":"Example use cases","text":"<ul> <li>Portfolio optimization, the canonical optimization problem that appears in finance, can be formulated as an SOCP and solved with a QIPM; a study of the condition number of the matrices that appear in this application was consistent with a small quantum speedup [14]; however, a follow-up study did not replicate this finding [10] and also pointed out that in any case large constant-factor overheads would make achieving practical advantage challenging.</li> <li>Support vector machines, a common task in machine learning, can be reduced to SOCP and solved with a QIPM; a study of the condition number of the matrices that appear in this application was consistent with a small quantum speedup [11].</li> <li>Sample-efficient protocols for mixed-state tomography reduce the problem of reconstructing an estimate of the quantum state to solving an SDP. This SDP could be solved with a QIPM (note that the tomography needed within the QIPM is always on pure states and does not require solving an SDP, thus avoiding an issue of circular logic).</li> <li>Nonconvex optimization is often solved approximately by relaxing the problem into a convex problem like an SDP. For example, the \\(\\mathsf{MAX}\\)-\\(\\mathsf{CUT}\\) problem is acombinatorial optimization problem over the nonconvex space \\(\\{+1,-1\\}^n\\), but by solving the associated SDP relaxation and rounding, an approximate solution can be obtained.</li> </ul>"},{"location":"quantum-algorithmic-primitives/quantum-interior-point-methods/#further-reading","title":"Further reading","text":"<ul> <li>See Boyd and Vandenberghe [6] for an accessible book on convex optimization including (classical) interior point methods.</li> <li>QIPMs are an active area of research. A QIPM for LP and SDP was originally proposed by Kerenidis and Prakash in [5]. This was followed up by a QIPM for SOCP in [11], along with numerical simulations for specific applications [11, 14]. Later, [7] pointed out a potential error in the convergence analysis of previous works, and they presented two possible workarounds called the \"inexact-infeasible\" and \"inexact-feasible\" IPMs. Note also the work in [12] for another way to avoid this issue, giving a QIPM for SDP.</li> </ul>"},{"location":"quantum-algorithmic-primitives/quantum-interior-point-methods/#bibliography","title":"Bibliography","text":"<ol> <li> <p>Alexander Domahidi, Eric Chu, and Stephen Boyd. Ecos: an socp solver for embedded systems. In 2013 European Control Conference (ECC), volume, 3071\u20133076. 2013. doi:10.23919/ECC.2013.6669541.</p> </li> <li> <p>Erling D. Andersen and Knud D. Andersen. The Mosek Interior Point Optimizer for Linear Programming: An Implementation of the Homogeneous Algorithm, pages 197\u2013232. Springer US, Boston, MA, 2000. URL: https://doi.org/10.1007/978-1-4757-3216-0\\_8, doi:10.1007/978-1-4757-3216-0\\_8.</p> </li> <li> <p>Margaret Wright. The interior-point revolution in optimization: history, recent developments, and lasting consequences. Bulletin of the American Mathematical Society, 42(1):39\u201356, 2005. doi:10.1090/S0273-0979-04-01040-7.</p> </li> <li> <p>Arkadi S Nemirovski and Michael J Todd. Interior-point methods for optimization. Acta Numerica, 17:191\u2013234, 2008. doi:10.1017/S0962492906370018.</p> </li> <li> <p>Iordanis Kerenidis and Anupam Prakash. A quantum interior point method for lps and sdps. ACM Transactions on Quantum Computing, 2020. arXiv: https://arxiv.org/abs/1808.09266. doi:10.1145/3406306.</p> </li> <li> <p>S. Boyd and L. Vandenberghe. Convex Optimization. Cambridge University Press, 2004. URL: https://web.stanford.edu/\\textasciitilde boyd/cvxbook/bv\\_cvxbook.pdf.</p> </li> <li> <p>Brandon Augustino, Giacomo Nannicini, Tam\u00e1s Terlaky, and Luis F. Zuluaga. Quantum interior point methods for semidefinite optimization. Quantum, 7:1110, 9 2023. arXiv: https://arxiv.org/abs/2112.06025. URL: https://doi.org/10.22331/q-2023-09-11-1110, doi:10.22331/q-2023-09-11-1110.</p> </li> <li> <p>Brandon Augustino, Tam\u00e1s Terlaky, and Luis F Zuluaga. An inexact-feasible quantum interior point method for second-order cone optimization. Technical Report 21T-009, Department of Industrial and Systems Engineering, Lehigh University, 2022.</p> </li> <li> <p>Thomas Strohmer and Roman Vershynin. A randomized kaczmarz algorithm with exponential convergence. Journal of Fourier Analysis and Applications, 15(2):262\u2013278, 2009. arXiv: https://arxiv.org/abs/math/0702226. doi:10.1007/s00041-008-9030-4.</p> </li> <li> <p>Alexander M Dalzell, B David Clader, Grant Salton, Mario Berta, Cedric Yen-Yu Lin, David A Bader, Nikitas Stamatopoulos, Martin J A Schuetz, Fernando G S L Brand\u00e3o, Helmut G Katzgraber, and others. End-to-end resource analysis for quantum interior point methods and portfolio optimization. PRX Quantum, pages to appear, 2023. arXiv: https://arxiv.org/abs/2211.12489.</p> </li> <li> <p>Iordanis Kerenidis, Anupam Prakash, and D\u00e1niel Szil\u00e1gyi. Quantum algorithms for second-order cone programming and support vector machines. Quantum, 5:427, 2021. arXiv: https://arxiv.org/abs/1908.06720. doi:10.22331/q-2021-04-08-427.</p> </li> <li> <p>Baihe Huang, Shunhua Jiang, Zhao Song, Runzhou Tao, and Ruizhe Zhang. A faster quantum algorithm for semidefinite programming via robust ipm framework. arXiv: https://arxiv.org/abs/2207.11154, 2022.</p> </li> <li> <p>Joran van Apeldoorn, Arjan Cornelissen, Andr\u00e1s Gily\u00e9n, and Giacomo Nannicini. Quantum tomography using state-preparation unitaries. In Proceedings of the 34th ACM-SIAM Symposium on Discrete Algorithms (SODA), 1265\u20131318. 2023. arXiv: https://arxiv.org/abs/2207.08800. doi:10.1137/1.9781611977554.ch47.</p> </li> <li> <p>Iordanis Kerenidis, Anupam Prakash, and D\u00e1niel Szil\u00e1gyi. Quantum algorithms for portfolio optimization. In Proceedings of the 1st ACM Conference on Advances in Financial Technologies, AFT '19, 147\u2013155. New York, NY, USA, 2019. Association for Computing Machinery. arXiv: https://arxiv.org/abs/1908.08040. URL: https://doi.org/10.1145/3318041.3355465, doi:10.1145/3318041.3355465.</p> </li> </ol>"},{"location":"quantum-algorithmic-primitives/quantum-linear-system-solvers/","title":"Quantum linear system solvers","text":""},{"location":"quantum-algorithmic-primitives/quantum-linear-system-solvers/#rough-overview-in-words","title":"Rough overview (in words)","text":"<p>The goal is to solve linear systems of equations with quantum subroutines. More precisely, a quantum linear system solver (QLSS) takes as input an \\(N\\times N\\) complex matrix \\(A\\) together with a complex vector \\(b\\) of size \\(N\\), and outputs a pure quantum state \\(\\ket{\\tilde x}\\) that is an \\(\\varepsilon\\)-approximation of the normalized solution vector of the linear system of equations \\(Ax=b\\). In basic versions, QLSSs do so by loading the normalized entries of the matrix \\(A\\) and the normalized entries of the vector \\(b\\) into a unitary quantum circuit, either from a quantum random access memory (QRAM) data structure, or\u2014if the structure of \\(A\\) and \\(b\\) allows for this\u2014by efficiently computing the corresponding entries on the fly.</p><p>Crucially, the number of algorithmic qubits of the linear system solver itself is only roughly \\(\\log_2(N)\\), which is exponentially smaller than the matrix size. While for general systems the number of QRAM qubits still scales with the matrix/vector size, QRAM encodings can be made more space efficient for sparse systems or can even be avoided when the corresponding entries are efficiently computable. The complexity of QLSSs depends on the condition number \\(\\kappa(A)=\\left\\|A^{-1}\\right\\|\\cdot\\|A\\|\\) of the matrix \\(A\\), and one then aims to give circuits with minimal quantum resource costs\u2014such as ancilla qubits, total gate count, circuit depth, etc.\u2014in terms of \\(\\kappa(A)\\) and the desired accuracy \\(\\varepsilon\\in(0,1)\\).</p>"},{"location":"quantum-algorithmic-primitives/quantum-linear-system-solvers/#rough-overview-in-math","title":"Rough overview (in math)","text":"<p>There are different standard input models on how the classical data from \\((A,b)\\) is loaded into the quantum processing unit, which are equivalent up to small polylogarithmic overhead for general matrices. We state the complexities in terms of query access of a unitary \\(U_b\\) preparing the \\(n=\\lceil\\log_2(N)\\rceil\\)-qubit pure quantum state \\(\\ket{b}=\\|b\\|_2^{-1}\\cdot\\sum_{i=1}^Nb_i\\ket{i}\\) for \\(b=(b_1,\\cdots,b_N)\\), where \\(\\lVert \\cdot \\rVert_2\\) denotes the standard Euclidean vector norm, together with an \\((\\alpha,a,0)\\)-block-encoding \\(U_A\\) of the matrix \\(A\\). The QLSS problem is then stated as follows: for a triple \\((U_A,U_b,\\varepsilon)\\) as above, the goal is to create an \\(n\\)-qubit pure quantum state \\(\\ket{\\tilde x}\\) such that </p>\\[\\begin{align} \\label{eq:regression} \\Big\\|\\ket{\\tilde x}-\\ket{x}\\Big\\|_2\\leq\\varepsilon\\quad\\text{for $\\ket{x}=\\frac{\\sum_{i=1}^Nx_i\\ket{i}}{\\left\\|\\sum_{i=1}^Nx_i\\ket{i}\\right\\|_2}$ defined by $A x=b$ with $x=(x_1,\\ldots,x_N)$,} \\end{align}\\]<p>by employing as few times as possible the unitary operators \\(U_A,U_b\\), their inverses \\(U_A^\\dagger,U_b^\\dagger\\), controlled versions of \\(U_A,U_b\\), and additional quantum gates on potentially additional ancilla qubits.</p><p>One way to think of the QLSS problem is that we seek the matrix inverse \\(A^{-1}\\) and this can, e.g., be implemented by quantum singular value transformation (QSVT) acting on \\(A\\) (via its block-encoding) with a polynomial approximation of the inverse function on the interval \\([\\|A\\|/\\kappa(A),\\|A\\|]\\). The complexity of the corresponding scheme thereby depends on the degree of the polynomial needed for a good approximation of the inverse function on the relevant interval, and as such on the condition number \\(\\kappa(A)\\), the normalization factor \\(\\alpha\\), and the approximation error \\(\\varepsilon\\) of the resulting QLSS. In fact, it turns out that the complexity of most quantum algorithms depends on the following combined quantity </p>\\[\\begin{align} \\label{eq:kappa-prime} \\kappa'(A):=\\kappa(A)\\cdot\\frac{\\alpha}{\\|A\\|}=\\alpha\\cdot\\|A^{-1}\\|, \\end{align}\\]<p>which is no smaller than \\(\\kappa(A)\\), because \\(\\alpha\\geq \\|A\\|\\) due to the unitarity of the block-encoding. Note that in QRAM-based implementations one naturally gets \\(\\alpha=\\|A\\|_F\\), which then leads to linear complexity dependence on the Frobenius norm \\(\\|A\\|_F\\).</p><p>As noted in [1, 2], in general we need not assume that \\(A\\) is invertible nor that it is a square matrix, but can instead use the Moore\u2013Penrose pseudoinverse \\(A^+\\) of the matrix to solve the problem \\(\\eqref{eq:regression}\\) in a least-squares sense, in which case one needs to appropriately change the definition of \\(\\kappa(A)\\) to \\(\\left\\|A^{+}\\right\\|\\cdot\\|A\\|\\). In fact, the above QSVT-based approach directly solves this more general version of the problem [3].</p>"},{"location":"quantum-algorithmic-primitives/quantum-linear-system-solvers/#dominant-resource-cost-gatesqubits","title":"Dominant resource cost (gates/qubits)","text":"<p>The state-of-the-art QLSS from [4] (for invertible matrices) does not directly employ the QSVT for the inverse function. Instead, it is based on discrete adiabatic methods together with quantum eigenstate filtering based on the QSVT for a minimax polynomial [5]. As above, the quantum algorithm assumes access to a block-encoding \\(U_A\\) of the matrix \\(A\\) with normalization factor \\(\\alpha\\), operates on \\(n+5\\) qubits (plus the additional qubits used for the block-encoding, discussed in more detail below), succeeds with probability roughly \\(1/2\\), and uses \\(Q\\) controlled queries to each of \\(U_A\\) and \\(U_A^\\dagger\\), and \\(2Q\\) queries to each of \\(U_b\\) and \\(U_b^\\dagger\\), for </p>\\[\\begin{align} \\label{eq:kappa-scaling} Q &amp; = \\kappa'(A)\\Big(C + \\ln(2\\varepsilon^{-1})\\Big) + \\mathcal{O}\\left( \\sqrt{\\kappa'(A)} \\right)=\\mathcal{O}\\left( \\kappa'(A)\\log(\\varepsilon^{-1}) \\right) \\end{align}\\]<p>where the constant \\(C\\) comes from the quantitative adiabatic analysis, and there is an additional constant quantum gate overhead for each query round. The query complexity is asymptotically optimal in terms of \\(\\kappa(A)\\) [6]. The adiabatic constant \\(C\\) can be rigorously bounded as \\(C \\leq \\num{58617}\\).<sup>1</sup> Note that when \\(C\\) is this large, the corresponding term will actually dominate the \\(\\kappa'(A)\\log(\\varepsilon^{-1})\\) term for practical scenarios. In recent work [7], a version of the adiabatic approach with asymptotic complexity \\(\\mathcal{O}\\left( \\kappa'(A)\\log(\\kappa\\varepsilon^{-1}) \\right)\\) outperforms by close to an order of magnitude the asymptotically optimal scheme for up to \\(\\kappa\\approx10^{32}\\) in terms of finite quantum resource counts.</p><p>Other known QLSSs with asymptotically worse complexities are based on QSVT [3, 8] or linear combination of unitaries (LCU) [9], and are often combined with variable-time amplitude amplification (VTAA) [10, 11] for improved performance. While the known bounds on the asymptotic complexities of these methods are slightly worse with additional polylogarithmic factors, it remains open if finite size performance could be competitive (as the known upper bounds on the adiabatic constant \\(C\\) are quite large). Moreover, to date, these VTAA-based algorithms are the only variants that are proven to solve the generic least squares (pseudoinverse) problem while achieving a close-to-optimal asymptotic scaling.</p><p>Note that if the matrix \\(A\\) is given in a classical data structure in the computational basis, then standard ways to create the block-encoding \\(U_A\\) make use of a QRAM structure. For general (dense) matrices \\(A\\), the requirement is then size \\(\\mathcal{O}\\left( N^2 \\right)\\) (number of qubits) with circuit depth \\(\\mathcal{O}\\left( n \\right)\\) for each query \u2014 or alternatively, as few as \\(\\mathcal{O}\\left( n \\right)\\) ancilla qubits could suffice, but at the expense of using \\(\\mathcal{O}\\left( N^2 \\right)\\) circuit depth [12, 13]. Initializing the depth-efficient QRAM data structure will in general also take \\(\\mathcal{O}\\left( N^2 \\right)\\) time. However, if \\(A\\) is sparse, either in the computational basis [14], Pauli basis [15], or any orthonormal basis with efficiently implementable basis transformation, there are more efficient direct constructions for block-encoding \\(A\\). Moreover, for Pauli basis access, there exist randomized QLSSs with complexity scaling as the \\(L_1\\)-norm of the Pauli coefficients [16], completely avoiding the use of block-encodings (and as such QRAM and ancilla qubits).</p>"},{"location":"quantum-algorithmic-primitives/quantum-linear-system-solvers/#caveats","title":"Caveats","text":"<p>QLSSs are an important subroutine for a variety of application areas of quantum algorithms. However, it is crucial to keep track of all the quantum and classical resources required and to compare these to state-of-the-art classical methods. In particular, the following factors should be taken into account:</p><ul> <li>The classical precomputation complexities for the eigenstate filtering routine are neglected, but can be kept efficient in practice [17].</li> <li>The size of the adiabatic constant \\(C\\) is expected to be about an order of magnitude better than stated above, but at least in the asymptotically optimal approach not more than one order of magnitude [4].</li> <li>When needed, the QRAM cost can be prohibitive, if it requires the full overhead of quantum error correction and fault tolerance [12], especially for QRAMs of maximum size \\(\\mathcal{O}\\left( N^2 \\right)\\) qubits, required for general (dense) matrices.</li> <li>In the formulation of the QLSS problem, the pure quantum state \\(\\ket{x}\\) corresponds to the normalized solution vector of the linear system \\(Ax=b\\). While the normalization factor can be obtained as well, this comes at the price of added complexity scaling as \\(\\widetilde{\\mathcal{O}}\\left( n\\kappa'(A)\\varepsilon^{-1} \\right)\\) [2, Corollary 32].</li> <li>QLSSs do not produce a classical description of the solution vector \\(x\\) or an approximation thereof, but rather the pure quantum state \\(\\ket{\\tilde x}\\). In order to obtain a classical approximation of the vector \\(x\\), one needs to combine QLSSs with pure state quantum tomography, which can be performed using \\(\\mathcal{O}\\left( N\\varepsilon^{-2} \\right)\\) samples. If \\(\\text{poly}(n)\\) query-cost QRAM is also available, then the complexity can be quadratically improved in terms of the precision using optimized pure state tomography [18], or alternatively the overall complexity may be further improved using iterative refinement to \\(\\mathcal{O}\\left( Ns (s+\\frac{\\kappa^2(A)}{\\|A\\|})\\text{polylog}(N/\\varepsilon) \\right)\\) as described in [19], where \\(s\\) is the maximum number of nonzero elements of \\(A\\) in any row or column.</li> <li>The overall complexities \\(\\widetilde{\\mathcal{O}}\\left( N\\kappa'(A)\\varepsilon^{-1} \\right)\\) and \\(\\mathcal{O}\\left( Ns (s+\\frac{\\kappa^2(A)}{\\|A\\|})\\text{polylog}(N/\\varepsilon) \\right)\\) (where we generously allow \\(\\text{poly}(n)\\) query-cost QRAM) to obtain a classical description of the solution can be compared to classical textbook Gaussian elimination\u2013based computation, which leads to complexity \\(\\mathcal{O}\\left( N^3 \\right)\\) or more precisely \\(\\mathcal{O}\\left( N^\\omega \\right)\\) with \\(\\omega\\in[2,2.372)\\) denoting the matrix multiplication exponent. Further, QLSSs should also be compared with state-of-the-art randomized solvers. For example, the randomized Kaczmarz method with standard classical access to the matrix elements returns an \\(\\varepsilon\\)-approximation of the vector \\(x\\), while scaling as \\(\\mathcal{O}\\left( s\\kappa_F^2(A)\\log(\\varepsilon^{-1}) \\right)\\) for \\(s\\) row-sparse matrices and \\(\\kappa_F(A)=\\left\\|A^{-1}\\right\\|\\cdot\\|A\\|_F\\). Moreover, if \\(A\\) is \\(s\\)-sparse and positive semidefinite (PSD), then using the conjugate gradient method one can obtain a solution in time \\(\\mathcal{O}\\left( Ns\\sqrt{\\kappa(A)}\\log(\\varepsilon^{-1}) \\right)\\) [20, Chapter 10.2], which can be generalized to the least-squares problem (and thus non-Hermitian matrices) at the cost of a quadratically worse condition number dependence \\(\\mathcal{O}\\left( Ns\\kappa\\log(\\kappa(A)/\\varepsilon) \\right)\\) by considering the modified equation \\(A^\\dagger A x = A^\\dagger b\\). As such, it seems that the QLSS may not provide a superquadratic speedup when a full classical solution is to be extracted, and even subquadratic speedups seem to be limited to a narrow parameter regime.</li> <li>Quantum-inspired methods [21, 22] that start from a classical data structure intended to mimic QRAM\u2014allowing to sample from probability distributions with probabilities proportional to the squared magnitudes of elements in a given row of \\(A\\)\u2014give samples from an \\(\\varepsilon\\)-approximation to the solution vector in (dimension free) complexity \\(\\mathcal{O}\\left( \\kappa_F^4(A)\\kappa^2(A)\\varepsilon^{-2} \\right)\\) [23, 22], and can be used to compute an approximate solution by repeated sampling. Note that while the required data structure is classical, it might still be prohibitively expensive to build when the matrix \\(A\\) is huge.</li> <li>When it comes to classical methods, solvers that depend on the condition number are useful in practice whenever combined with preconditioners [24]. However, the performance of preconditioners is often only heuristic, and using preconditioners for QLSS is not (yet) explored in-depth [25, 26, 27].</li> </ul>"},{"location":"quantum-algorithmic-primitives/quantum-linear-system-solvers/#example-use-cases","title":"Example use cases","text":"<ul> <li>Quantum interior point methods in convex optimization and its corresponding applications [28, 29]</li> <li>Quantum machine learning applications [1, 30]</li> <li>Solving differential equations and corresponding applications, e.g., for the finite element method that does not require a tomography step [31]</li> </ul>"},{"location":"quantum-algorithmic-primitives/quantum-linear-system-solvers/#further-reading","title":"Further reading","text":"<ul> <li>Original QLSS (termed HHL) [6]</li> <li>For a recent overview discussion of QLSS, see [32]</li> <li>State-of-the-art QLSS based on discrete adiabatic methods [4]</li> </ul>"},{"location":"quantum-algorithmic-primitives/quantum-linear-system-solvers/#bibliography","title":"Bibliography","text":"<ol> <li> <p>Nathan Wiebe, Daniel Braun, and Seth Lloyd. Quantum algorithm for data fitting. Physical Review Letters, 109(5):050505, 2012. arXiv: https://arxiv.org/abs/1204.5242. doi:10.1103/PhysRevLett.109.050505.</p> </li> <li> <p>Shantanav Chakraborty, Andr\u00e1s Gily\u00e9n, and Stacey Jeffery. The power of block-encoded matrix powers: improved regression techniques via faster hamiltonian simulation. In Proceedings of the 46th International Colloquium on Automata, Languages, and Programming (ICALP), 33:1\u201333:14. 2019. arXiv: https://arxiv.org/abs/1804.01973. doi:10.4230/LIPIcs.ICALP.2019.33.</p> </li> <li> <p>Andr\u00e1s Gily\u00e9n, Yuan Su, Guang Hao Low, and Nathan Wiebe. Quantum singular value transformation and beyond: exponential improvements for quantum matrix arithmetics. In Proceedings of the 51st ACM Symposium on the Theory of Computing (STOC), 193\u2013204. 2019. arXiv: https://arxiv.org/abs/1806.01838. doi:10.1145/3313276.3316366.</p> </li> <li> <p>Pedro C.S. Costa, Dong An, Yuval R. Sanders, Yuan Su, Ryan Babbush, and Dominic W. Berry. Optimal scaling quantum linear-systems solver via discrete adiabatic theorem. PRX Quantum, 3:040303, 10 2022. arXiv: https://arxiv.org/abs/2111.08152. URL: https://link.aps.org/doi/10.1103/PRXQuantum.3.040303, doi:10.1103/PRXQuantum.3.040303.</p> </li> <li> <p>Lin Lin and Yu Tong. Optimal polynomial based quantum eigenstate filtering with application to solving quantum linear systems. Quantum, 4:361, 2020. arXiv: https://arxiv.org/abs/1910.14596. doi:10.22331/q-2020-11-11-361.</p> </li> <li> <p>Aram W. Harrow, Avinatan Hassidim, and Seth Lloyd. Quantum algorithm for linear systems of equations. Physical Review Letters, 103(15):150502, 2009. arXiv: https://arxiv.org/abs/0811.3171. doi:10.1103/PhysRevLett.103.150502.</p> </li> <li> <p>David Jennings, Matteo Lostaglio, Sam Pallister, Andrew T. Sornborger, and Yigit Subasi. Efficient quantum linear solver algorithm with detailed running costs. arXiv: https://arxiv.org/abs/2305.11352, 2023.</p> </li> <li> <p>John M. Martyn, Zane M. Rossi, Andrew K. Tan, and Isaac L. Chuang. Grand unification of quantum algorithms. Physical Review X, 2(4):040203, 2021. arXiv: https://arxiv.org/abs/2105.02859. doi:10.1103/PRXQuantum.2.040203.</p> </li> <li> <p>Andrew M. Childs, Robin Kothari, and Rolando D. Somma. Quantum algorithm for systems of linear equations with exponentially improved dependence on precision. SIAM Journal on Computing, 46(6):1920\u20131950, 2017. arXiv: https://arxiv.org/abs/1511.02306. doi:10.1137/16M1087072.</p> </li> <li> <p>Andris Ambainis. Variable time amplitude amplification and quantum algorithms for linear algebra problems. In Proceedings of the 29th Symposium on Theoretical Aspects of Computer Science (STACS), 636\u2013647. 2012. arXiv: https://arxiv.org/abs/1010.4458. doi:10.4230/LIPIcs.STACS.2012.636.</p> </li> <li> <p>Andris Ambainis, Martins Kokainis, and Jevg\u0113nijs Vihrovs. Improved algorithm and lower bound for variable time quantum search. arXiv: https://arxiv.org/abs/2302.06749, 2023.</p> </li> <li> <p>Connor T. Hann, Gideon Lee, S.M. Girvin, and Liang Jiang. Resilience of quantum random access memory to generic noise. PRX Quantum, 2:020311, 4 2021. arXiv: https://arxiv.org/abs/2012.05340. URL: https://link.aps.org/doi/10.1103/PRXQuantum.2.020311, doi:10.1103/PRXQuantum.2.020311.</p> </li> <li> <p>B. David Clader, Alexander M. Dalzell, Nikitas Stamatopoulos, Grant Salton, Mario Berta, and William J. Zeng. Quantum resources required to block-encode a matrix of classical data. IEEE Transactions on Quantum Engineering, 3:1\u201323, 2022. arXiv: https://arxiv.org/abs/2206.03505. doi:10.1109/TQE.2022.3231194.</p> </li> <li> <p>Olivia Di Matteo, Vlad Gheorghiu, and Michele Mosca. Fault-tolerant resource estimation of quantum random-access memories. IEEE Transactions on Quantum Engineering, 1:1\u201313, 2020. arXiv: https://arxiv.org/abs/1902.01329. doi:10.1109/TQE.2020.2965803.</p> </li> <li> <p>Kianna Wan. Exponentially faster implementations of select(h) for fermionic hamiltonians. Quantum, 2021. arXiv: https://arxiv.org/abs/2004.04170. doi:10.22331/q-2021-01-12-380.</p> </li> <li> <p>Samson Wang, Sam McArdle, and Mario Berta. Qubit-efficient randomized quantum algorithms for linear algebra. arXiv: https://arxiv.org/abs/2302.01873, 2023.</p> </li> <li> <p>Yulong Dong, Xiang Meng, K. Birgitta Whaley, and Lin Lin. Efficient phase-factor evaluation in quantum signal processing. Physical Review A, 103:042419, 2021. arXiv: https://arxiv.org/abs/2002.11649. doi:10.1103/PhysRevA.103.042419.</p> </li> <li> <p>Joran van Apeldoorn, Arjan Cornelissen, Andr\u00e1s Gily\u00e9n, and Giacomo Nannicini. Quantum tomography using state-preparation unitaries. In Proceedings of the 34th ACM-SIAM Symposium on Discrete Algorithms (SODA), 1265\u20131318. 2023. arXiv: https://arxiv.org/abs/2207.08800. doi:10.1137/1.9781611977554.ch47.</p> </li> <li> <p>Mohammadhossein Mohammadisiahroudi, Zeguan Wu, Brandon Augustino, Tam\u00e1s Terlaky, and Arielle Carr. Quantum-enhanced regression analysis using state-of-the-art qlsas and qipms. In Proceedings of the IEEE/ACM 7th Symposium on Edge Computing, volume, 375\u2013380. 2022. doi:10.1109/SEC54971.2022.00055.</p> </li> <li> <p>Wolfgang Hackbusch. Iterative solution of large sparse systems of equations. Volume 95 of Applied Mathematical Sciences. Springer, 2nd edition, 2016. doi:10.1007/978-3-319-28483-5.</p> </li> <li> <p>Nai-Hui Chia, Andr\u00e1s Gily\u00e9n, Tongyang Li, Han-Hsuan Lin, Ewin Tang, and Chunhao Wang. Sampling-based sublinear low-rank matrix arithmetic framework for dequantizing quantum machine learning. In Proceedings of the 52nd ACM Symposium on the Theory of Computing (STOC), 387\u2013400. 2020. arXiv: https://arxiv.org/abs/1910.06151. doi:10.1145/3357713.3384314.</p> </li> <li> <p>Andr\u00e1s Gily\u00e9n, Zhao Song, and Ewin Tang. An improved quantum-inspired algorithm for linear regression. Quantum, 6:754, 2022. arXiv: https://arxiv.org/abs/2009.07268. doi:10.22331/q-2022-06-30-754.</p> </li> <li> <p>Changpeng Shao and Ashley Montanaro. Faster quantum-inspired algorithms for solving linear systems. ACM Transactions on Quantum Computing, 2022. arXiv: https://arxiv.org/abs/2103.10309. doi:10.1145/3520141.</p> </li> <li> <p>Yousef Saad. Iterative Methods for Sparse Linear Systems. Society for Industrial and Applied Mathematics, second edition, 2003. doi:10.1137/1.9780898718003.</p> </li> <li> <p>B David Clader, Bryan C Jacobs, and Chad R Sprouse. Preconditioned quantum linear system algorithm. Physical Review Letters, 110(25):250504, 2013. arXiv: https://arxiv.org/abs/1301.2340. doi:10.1103/PhysRevLett.110.250504.</p> </li> <li> <p>Changpeng Shao and Hua Xiang. Quantum circulant preconditioner for a linear system of equations. Physical Review A, 98(6):062321, 2018. arXiv: https://arxiv.org/abs/1807.04563. doi:10.1103/PhysRevA.98.062321.</p> </li> <li> <p>Yu Tong, Dong An, Nathan Wiebe, and Lin Lin. Fast inversion, preconditioned quantum linear system solvers, fast green's-function computation, and fast evaluation of matrix functions. Physical Review A, 104:032422, 2021. arXiv: https://arxiv.org/abs/2008.13295. doi:10.1103/PhysRevA.104.032422.</p> </li> <li> <p>Iordanis Kerenidis and Anupam Prakash. A quantum interior point method for lps and sdps. ACM Transactions on Quantum Computing, 2020. arXiv: https://arxiv.org/abs/1808.09266. doi:10.1145/3406306.</p> </li> <li> <p>Mohammadhossein Mohammadisiahroudi, Ramin Fakhimi, and Tam\u00e1s Terlaky. Efficient use of quantum linear system algorithms in interior point methods for linear optimization. arXiv: https://arxiv.org/abs/2205.01220, 2022.</p> </li> <li> <p>Patrick Rebentrost, Masoud Mohseni, and Seth Lloyd. Quantum support vector machine for big data classification. Physical Review Letters, 113(13):130503, 2014. arXiv: https://arxiv.org/abs/1307.0471. doi:10.1103/PhysRevLett.113.130503.</p> </li> <li> <p>Ashley Montanaro and Sam Pallister. Quantum algorithms and the finite element method. Physical Review A, 93(3):032324, 2016. arXiv: https://arxiv.org/abs/1512.05903. doi:10.1103/PhysRevA.93.032324.</p> </li> <li> <p>Dong An and Lin Lin. Quantum linear system solver based on time-optimal adiabatic quantum computing and quantum approximate optimization algorithm. ACM Transactions on Quantum Computing, 2022. arXiv: https://arxiv.org/abs/1909.05500. doi:10.1145/3498331.</p> </li> </ol> <ol> <li> <p>This number is derived from applying [4, Theorem 9] with \\(\\sqrt{2-\\sqrt{2}}\\times \\num{44864} \\times \\kappa\\) steps, each of which incurs one call to the block-encoding, such that the output is guaranteed to have overlap at least \\(1/\\sqrt{2}\\) with the ideal state. Eigenstate filtering then succeeds with probability at least \\(1/2\\); accounting for the need to repeat twice on average, one arrives at a constant \\(\\num{117235}\\), matching [7, Eq. (L2)].\u00a0\u21a9</p> </li> </ol>"},{"location":"quantum-algorithmic-primitives/quantum-phase-estimation/","title":"Quantum phase estimation","text":""},{"location":"quantum-algorithmic-primitives/quantum-phase-estimation/#rough-overview-in-words","title":"Rough overview (in words)","text":"<p>The quantum phase estimation (QPE) subroutine produces an estimate of an eigenvalue of a unitary operator. It is a cornerstone of quantum algorithms primitives and has numerous applications. For example, Shor's algorithm for factoring can be viewed as an application of QPE together with modular exponentiation. Similarly, when combined with Hamiltonian simulation, QPE can produce an estimate for an eigenvalue of a Hamiltonian (given an appropriate initial state), an important problem in areas such as quantum chemistry. In this context, QPE is the quantum analogue of measuring the value of a real function \\(f\\) of a random variable \\(x\\), where in the quantum case, the function \\(f\\) can include noncommuting terms, and the random variable \\(x\\) is a vector in a Hilbert space.</p>"},{"location":"quantum-algorithmic-primitives/quantum-phase-estimation/#rough-overview-in-math","title":"Rough overview (in math)","text":"<p>Let \\(U\\) be a unitary with eigendecomposition \\(U=\\sum_j e^{i2\\pi\\phi_j}|\\psi_j\\rangle \\langle \\psi_j|\\). Given as input the state \\(|\\psi_j\\rangle\\), the QPE subroutine produces an estimate \\(\\smash{\\hat{\\phi}_j}\\) for \\(\\phi_j\\). The algorithm requires the ability to apply controlled-\\(U^{2^p}\\) for non-negative integers \\(p\\). If \\(\\phi_j\\) is an exact multiple of \\(2^{-P}\\), then an exact estimate of \\(\\phi_j\\) can be learned with certainty using only \\(p\\in \\{0,1,\\ldots,P-1\\}\\). In general, an estimate \\(\\smash{\\hat{\\phi}_j}\\) of \\(\\phi_j\\) satisfying \\(\\smash{|\\phi_j-\\hat{\\phi}_j|\\leq \\epsilon}\\) can be learned with high probability by taking the maximum value of \\(2^p\\) on the order of \\(1/\\epsilon\\). The algorithm also requires application of an inverse quantum Fourier transform to orchestrate the constructive interference near the estimate for \\(\\phi_j\\).</p><p>Phase estimation can also be applied coherently onto a superposition of eigenstates. Suppose that the input state is \\(|\\psi \\rangle = \\sum_j\\alpha_j|\\psi_j\\rangle\\). By linearity, if each phase \\(\\phi_j\\) is a multiple of \\(2^{-P}\\) and phase estimation is run with sufficient resolution, then QPE enacts the following unitary </p>\\[\\begin{equation} \\label{eq:coherent_QPE} |\\psi \\rangle |0\\rangle \\mapsto \\sum_j \\alpha_j |\\psi_j \\rangle |\\phi_j \\rangle, \\end{equation}\\]<p>where \\(\\ket{\\phi_j}\\) holds a \\(P\\)-bit binary representation of \\(\\phi_j\\). If the auxiliary register is measured, then with probability \\(|\\alpha_j|^2\\) (consistent with the Born rule) the estimate \\(\\phi_j\\) is obtained and the state collapses to the corresponding eigenstate \\(|\\psi_j\\rangle\\).<sup>1</sup> If the phases \\(\\phi_j\\) are not multiples of \\(2^{-P}\\), an approximate version of this operation can still be accomplished as long as the precision is sufficiently small to resolve the eigenvalues, subject to some caveats (discussed below).</p><p></p>"},{"location":"quantum-algorithmic-primitives/quantum-phase-estimation/#dominant-resource-cost-gatesqubits","title":"Dominant resource cost (gates/qubits)","text":"<p>The QPE subroutine is typically dominated by calls to the controlled unitary \\(U\\). If resolution \\(\\epsilon\\) is desired, one must perform controlled-\\(U^{2^p}\\) operations for \\(p\\in \\{0,1,\\ldots, \\lceil \\log_2(1/\\epsilon) \\rceil + \\mathcal{O}\\left( 1 \\right)\\}\\); thus, the number of calls to a controlled-\\(U\\) oracle will be \\(\\mathcal{O}\\left( 1/\\epsilon \\right)\\). This dependence on \\(\\epsilon\\) is optimal; the \\(\\mathcal{O}\\left( 1/\\epsilon \\right)\\) scaling is known as the Heisenberg limit.</p><p>In the context of estimating the eigenenergy of a Hamiltonian \\(H\\), one can choose \\(U = e^{iH}\\), and then implement controlled-\\(U^t\\), i.e., controlled-\\(e^{iHt}\\), with Hamiltonian simulation. In this case, given the ability to prepare an eigenstate of \\(H\\), an \\(\\epsilon\\)-approximation of the eigenvalue requires values of \\(t\\) up to \\(\\mathcal{O}\\left( 1/\\epsilon \\right)\\).<sup>2</sup> However, one must also factor in the error in the Hamiltonian simulation. In a typical setting, access to the \\(n\\)-qubit Hamiltonian is given through a linear combination of \\(L\\) unitaries. Let \\(\\lVert H \\rVert_1\\) denote the sum of the coefficients in the combination. Then, methods for Hamiltonian simulation based on quantum signal processing can approximate \\(e^{iHt}\\) to error \\(\\mathcal{O}\\left( \\epsilon \\right)\\) with \\(\\mathcal{O}\\left( nL(\\lVert H \\rVert_1 t + \\log(1/\\epsilon)) \\right)\\) gate complexity, whereas methods based on product formulae incur cost \\(\\mathcal{O}\\left( nL(\\lVert H \\rVert_1 t)^{1+1/2k}\\epsilon^{-1/2k} \\right)\\) for \\((2k)\\)th-order product formulas, although the actual cost can be lower after accounting for structure in the Hamiltonian terms. Balancing the error from phase estimation against the error from Hamiltonian simulation can cause sub-Heisenberg-limited performance, such as in the case of the product formulae approach. The overhead associated with imperfect Hamiltonian simulation can be avoided by applying QPE to different functions of \\(H\\); for example, a promising choice is the qubitization operator, which acts in a similar way to \\(U = e^{i \\arccos(H)}\\). The reason this is advantageous is that the qubitization operator can be implemented exactly given access to a block-encoding of \\(H\\) [1, 2, 3].</p><p>The number of qubits for QPE is simply the size of the register needed to hold the input state \\(\\ket{\\psi_j}\\) plus the size of the register needed to hold the estimate \\(\\hat{\\phi}_j\\) (that is, roughly \\(\\lceil \\log_2(1/\\epsilon) \\rceil\\) bits). Additionally, QPE requires an inverse quantum Fourier transform (QFT), which adds only \\(\\smash{\\mathcal{O}(\\log^2(1/\\epsilon))}\\) additional gates to the protocol.</p><p>Another version of QPE [4] achieves the same task with only a single ancilla qubit, but, as a result, learns only one bit of the output at a time. Additionally, it requires an exact eigenstate as input. The latter problem can be avoided using a statistical approach [5, 6].</p>"},{"location":"quantum-algorithmic-primitives/quantum-phase-estimation/#caveats","title":"Caveats","text":"<p>The main caveats of QPE are related to the fact that eigenphases are not always exact integer multiples of \\(2^{-P}\\), resulting in noncertain outcomes of QPE, which can lead to complications in certain applications.</p><ul> <li>Fat tails and boosting of success probability: Whenever the phases \\(\\phi_j\\) are not exact integer multiples of \\(2^{-P}\\) for some integer \\(P\\), phase estimation will not return the answer \\(\\phi_j\\) with certainty. Rather, there will be a distribution of possible estimates \\(\\smash{\\hat{\\phi}_j}\\) that is peaked near \\(\\phi_j\\). If one chooses \\(P = \\lceil \\log_2(1/\\epsilon) \\rceil + \\mathcal{O}\\left( 1 \\right)\\), then most of the probability mass of this distribution lies within \\(\\epsilon\\) of \\(\\phi_j\\). As \\(P\\) is increased further, the distribution becomes more sharply peaked near \\(\\phi_j\\), and if an \\(\\epsilon\\)-accurate estimate with \\(1-\\delta\\) probability is desired, one must take \\(P = \\lceil \\log_2(1/\\epsilon) \\rceil + \\mathcal{O}\\left( \\log(1/\\delta) \\right)\\), corresponding to a multiplicative \\(\\mathcal{O}\\left( 1/\\delta \\right)\\) overhead in the query complexity to \\(U\\) and \\(\\mathcal{O}\\left( \\log(1/\\delta) \\right)\\) additional ancilla qubits. This poor \\(\\delta\\) dependence is due to \"fat tails\" on the distribution of estimates of \\(\\hat{\\phi_j}\\). One way to avoid this overhead is to take the median of estimates obtained from \\(\\mathcal{O}\\left( \\log(1/\\delta) \\right)\\) repetitions of QPE [7, Lemma 1]. A downside of this approach is that it may be difficult to implement coherently on a superposition of eigenstates, in the sense of Eq. \\(\\eqref{eq:coherent_QPE}\\), since computing the median would require a coherent quantum sorting network. An alternative way to circumvent the fat tails problem is to modify the QPE protocol to have a nonuniform superposition in the register that controls applications of \\(U\\); a judicious choice of superposition leads the distribution over estimates \\(\\smash{\\hat{\\phi}_j}\\) to be a Kaiser window distribution, which minimizes the probability of deviating from \\(\\phi_j\\) by more than \\(\\epsilon\\); boosting the success probability to \\(1-\\delta\\) incurs multiplicative \\(\\mathcal{O}\\left( \\log(1/\\delta) \\right)\\) cost, rather than \\(\\mathcal{O}\\left( 1/\\delta \\right)\\) [8, Appendix C]. See also [9], where a Gaussian profile is used to suppress the tails.</li> <li>Performing coherent QPE: When \\(\\phi_j\\) are noninteger multiples of \\(2^{-P}\\), the coherent operation in Eq. \\(\\eqref{eq:coherent_QPE}\\) cannot be straightforwardly performed with exact fidelity. This is because for each value of \\(j\\), the second register will be in a superposition of many values of \\(\\smash{\\hat{\\phi}_j}\\) (most but not all of the amplitude will lie on estimates close to \\(\\phi_j\\)). To restore coherence, one might try coherently rounding the estimate \\(\\smash{\\hat{\\phi}_j}\\) onto a coarser net of grid points (and then uncomputing the original estimate \\(\\hat{\\phi_j}\\)); however, there will always be edge cases where \\(\\phi_j\\) falls very near the midpoint between two grid points and rounding destroys some of the coherence in the input. This is true even as the precision of QPE is taken to zero (\\(\\epsilon \\rightarrow 0\\)). See [10] for a discussion. One possible way to mitigate this issue is presented in the \"consistent phase estimation\" protocol of [11, Section 5.2], where a random shift is applied to the grid points to avoid this situation for any particular eigenphase with high probability. However, this does not generically work simultaneously for all eigenphases. In [10], it is shown that performing Eq. \\(\\eqref{eq:coherent_QPE}\\) is impossible without a \"rounding promise\" on the set of eigenphases \\(\\{\\phi_j\\}\\).</li> <li>Biased estimator: a further consequence of the noncertainty of the QPE output is that the estimate \\(\\smash{\\hat{\\phi}_j}\\) is biased; that is, its expectation value is not exactly equal to \\(\\phi_j\\). This issue can also be fixed with a random shift idea, yielding an unbiased (and symmetrically distributed) version of QPE [12, 13].</li> </ul>"},{"location":"quantum-algorithmic-primitives/quantum-phase-estimation/#example-use-cases","title":"Example use cases","text":"<ul> <li>In quantum chemistry and condensed matter physics, QPE is used to measure the eigenvalues (and especially the ground state energy) of the Hamiltonian \\(H\\), which gives knowledge about reaction mechanisms, stable configurations, and other equilibrium properties. For QPE to succeed, a trial state \\(|\\psi\\rangle\\) with substantial overlap with the eigenstate of interest must be input to QPE, which is challenging in the general case.</li> <li>In Shor's algorithm, given a composite integer \\(N\\) and a (randomly chosen) base \\(g &lt; N\\), QPE is used to determine the order of \\(g\\), that is, the minimum integer \\(r\\) for which \\(g^r \\equiv 1 \\mod N\\), which is in turn used to infer the prime factors of \\(N\\). Here, the unitary \\(U\\) is the modular multiplication unitary that sends \\(\\ket{x} \\mapsto \\ket{gx \\mod N}\\).</li> <li>In amplitude estimation, given a unitary \\(U\\) that prepares a state \\(U\\ket{\\psi_0} = a\\ket{\\psi_g} + b\\ket{\\psi_b}\\), QPE is used to estimate \\(|a|\\) or \\(|a|^2\\).</li> <li>In the Monte Carlo\u2013style quantum algorithms for Gibbs sampling, roughly speaking, the quantum state undergoes a random walk on the eigenbasis of the Hamiltonian. Steps of this random walk are accepted or rejected according to how much the energy changes at each step. The QPE subroutine is used to simultaneously (approximately) project onto the eigenbasis of the Hamiltonian and to produce an estimate of the energy, used to determine whether the step should be accepted or rejected. Early studies [14, 15, 16] of this approach were hampered by the caveats related to rejecting quantum states and imperfect energy estimates, but recent works [17, 9] circumvent these problems (by randomizing the grid points or completely abandoning phase estimation).</li> <li>To follow the ground-state \\(|\\psi_0(s)\\rangle\\) of a Hamiltonian \\(H(s)\\) as some parameter \\(s\\) is varied from 0 to 1, one can run the adiabatic algorithm. Alternatively, one can consider a discretization of steps \\(s_t \\in \\{s_0,\\ldots,s_T\\}\\), where \\(0=s_0&lt;s_1&lt;s_2&lt;\\ldots&lt;s_{T-1}&lt;s_T=1\\), and run QPE on \\(H(s_t)\\) in succession, each time causing a measurement into the instantaneous eigenbasis of \\(H(s_t)\\). Due to the quantum Zeno effect, as long as sufficiently small steps are taken, each projection will be onto the ground space with high probability (see, e.g., [18]). Larger steps can be tolerated if one boosts the probability that each step succeeds with amplitude amplification [19]. This approach is similar to the idea in Hastings' short-path algorithm [20, 21], which solves combinatorial optimization problems.</li> <li>While state-of-the-art quantum linear systems solvers (QLSS) do not explicitly use QPE, the original QLSS by Harrow, Hassidim, and Lloyd [22] uses QPE to coherently measure the eigenvalues of a matrix \\(A\\) into an auxiliary register. These eigenvalue estimates are subsequently inverted with coherent classical arithmetic in order to produce the state \\(A^{-1}\\ket{b}\\) corresponding to the solution to the system \\(Ax=b\\).</li> </ul>"},{"location":"quantum-algorithmic-primitives/quantum-phase-estimation/#further-reading","title":"Further reading","text":"<ul> <li>The standard circuit and analysis of QPE appears in Nielsen and Chuang [23]. See also [24].</li> <li>Many variants of the QPE algorithm have been explored, which can be superior to the standard version in certain settings. See, e.g., [10, 5] for additional references and informative overviews of various methods, along with their advantages and drawbacks.</li> <li>Reference [25] contains a pedagogical overview of QPE including some of its variants and applications.</li> </ul>"},{"location":"quantum-algorithmic-primitives/quantum-phase-estimation/#bibliography","title":"Bibliography","text":"<ol> <li> <p>Guang Hao Low and Isaac L. Chuang. Hamiltonian simulation by qubitization. Quantum, 3:163, 2019. arXiv: https://arxiv.org/abs/1610.06546. doi:10.22331/q-2019-07-12-163.</p> </li> <li> <p>David Poulin, Alexei Kitaev, Damian S. Steiger, Matthew B. Hastings, and Matthias Troyer. Quantum algorithm for spectral measurement with a lower gate count. Physical Review Letters, 121:010501, 7 2018. arXiv: https://arxiv.org/abs/1711.11025. URL: https://link.aps.org/doi/10.1103/PhysRevLett.121.010501, doi:10.1103/PhysRevLett.121.010501.</p> </li> <li> <p>Dominic W. Berry, M\u00e1ria Kieferov\u00e1, Artur Scherer, Yuval R. Sanders, Guang Hao Low, Nathan Wiebe, Craig Gidney, and Ryan Babbush. Improved techniques for preparing eigenstates of fermionic hamiltonians. npj Quantum Information, 4(1):22, 5 2018. arXiv: https://arxiv.org/abs/1711.10460. URL: https://doi.org/10.1038/s41534-018-0071-5, doi:10.1038/s41534-018-0071-5.</p> </li> <li> <p>Alexei Yu Kitaev, Alexander Shen, Mikhail N Vyalyi, and Mikhail N Vyalyi. Classical and quantum computation. Number 47. American Mathematical Soc., 2002.</p> </li> <li> <p>Lin Lin and Yu Tong. Heisenberg-limited ground-state energy estimation for early fault-tolerant quantum computers. PRX Quantum, 3:010318, 2 2022. arXiv: https://arxiv.org/abs/2102.11340. doi:10.1103/PRXQuantum.3.010318.</p> </li> <li> <p>Kianna Wan, Mario Berta, and Earl T. Campbell. Randomized quantum algorithm for statistical phase estimation. Physical Review Letters, 129:030503, 7 2022. arXiv: https://arxiv.org/abs/2110.12071. URL: https://link.aps.org/doi/10.1103/PhysRevLett.129.030503, doi:10.1103/PhysRevLett.129.030503.</p> </li> <li> <p>Daniel Nagaj, Pawel Wocjan, and Yong Zhang. Fast amplification of qma. Quantum Information and Computation, 9(11&amp;12):1053\u20131068, 2009. arXiv: https://arxiv.org/abs/0904.1549. doi:10.26421/QIC9.11-12.</p> </li> <li> <p>Dominic W Berry, Yuan Su, Casper Gyurik, Robbie King, Joao Basso, Alexander Del Toro Barba, Abhishek Rajput, Nathan Wiebe, Vedran Dunjko, and Ryan Babbush. Quantifying quantum advantage in topological data analysis. arXiv: https://arxiv.org/abs/2209.13581, 2022.</p> </li> <li> <p>Chi-Fang Chen, Michael J. Kastoryano, Fernando G. S. L. Brand\u00e3o, and Andr\u00e1s Gily\u00e9n. Quantum thermal state preparation. arXiv: https://arxiv.org/abs/2303.18224, 2023.</p> </li> <li> <p>Patrick Rall. Faster coherent quantum algorithms for phase, energy, and amplitude estimation. Quantum, 5:566, 10 2021. arXiv: https://arxiv.org/abs/2103.09717. URL: https://doi.org/10.22331/q-2021-10-19-566, doi:10.22331/q-2021-10-19-566.</p> </li> <li> <p>Amnon Ta-Shma. Inverting well conditioned matrices in quantum logspace. In Proceedings of the 45th ACM Symposium on the Theory of Computing (STOC), STOC '13, 881\u2013890. New York, NY, USA, 2013. Association for Computing Machinery. URL: https://doi.org/10.1145/2488608.2488720, doi:10.1145/2488608.2488720.</p> </li> <li> <p>Noah Linden and Ronald de Wolf. Average-case verification of the quantum fourier transform enables worst-case phase estimation. arXiv: https://arxiv.org/abs/2109.10215, 2021.</p> </li> <li> <p>Joran van Apeldoorn, Arjan Cornelissen, Andr\u00e1s Gily\u00e9n, and Giacomo Nannicini. Quantum tomography using state-preparation unitaries. In Proceedings of the 34th ACM-SIAM Symposium on Discrete Algorithms (SODA), 1265\u20131318. 2023. arXiv: https://arxiv.org/abs/2207.08800. doi:10.1137/1.9781611977554.ch47.</p> </li> <li> <p>K. Temme, T. J. Osborne, K. G. Vollbrecht, D. Poulin, and F. Verstraete. Quantum metropolis sampling. Nature, 471(7336):87\u201390, 3 2011. arXiv: https://arxiv.org/abs/0911.3635. doi:10.1038/nature09770.</p> </li> <li> <p>Man-Hong Yung and Al\u00e1n Aspuru-Guzik. A quantum-quantum metropolis algorithm. Proceedings of the National Academy of Sciences, 109(3):754\u2013759, 2012. arXiv: https://arxiv.org/abs/1011.1468. doi:10.1073/pnas.1111758109.</p> </li> <li> <p>Pawel Wocjan and Kristan Temme. Szegedy walk unitaries for quantum maps. Communications in Mathematical Physics, 2023. arXiv: https://arxiv.org/abs/2107.07365. URL: https://doi.org/10.1007/s00220-023-04797-4, doi:10.1007/s00220-023-04797-4.</p> </li> <li> <p>Patrick Rall, Chunhao Wang, and Pawel Wocjan. Thermal state preparation via rounding promises. arXiv: https://arxiv.org/abs/2210.01670, 2022.</p> </li> <li> <p>Rolando Somma, Sergio Boixo, and Howard Barnum. Quantum simulated annealing. arXiv: https://arxiv.org/abs/0712.1008, 2007.</p> </li> <li> <p>Sergio Boixo, Emanuel Knill, and Rolando D Somma. Fast quantum algorithms for traversing paths of eigenstates. arXiv: https://arxiv.org/abs/1005.3034, 2010.</p> </li> <li> <p>M. B. Hastings. A short path quantum algorithm for exact optimization. Quantum, 2:78, 7 2018. arXiv: https://arxiv.org/abs/1802.10124. URL: https://doi.org/10.22331/q-2018-07-26-78, doi:10.22331/q-2018-07-26-78.</p> </li> <li> <p>Alexander M. Dalzell, Nicola Pancotti, Earl T. Campbell, and Fernando G.S.L. Brand\u00e3o. Mind the gap: achieving a super-grover quantum speedup by jumping to the end. In Proceedings of the 55th ACM Symposium on the Theory of Computing (STOC), 1131\u20131144. New York, NY, USA, 2023. Association for Computing Machinery. arXiv: https://arxiv.org/abs/2212.01513. URL: https://doi.org/10.1145/3564246.3585203, doi:10.1145/3564246.3585203.</p> </li> <li> <p>Aram W. Harrow, Avinatan Hassidim, and Seth Lloyd. Quantum algorithm for linear systems of equations. Physical Review Letters, 103(15):150502, 2009. arXiv: https://arxiv.org/abs/0811.3171. doi:10.1103/PhysRevLett.103.150502.</p> </li> <li> <p>Michael A. Nielsen and Isaac L. Chuang. Quantum computation and quantum information. Cambridge University Press, 2000. doi:10.1017/CBO9780511976667.</p> </li> <li> <p>Richard Cleve, Artur Ekert, Chiara Macchiavello, and Michele Mosca. Quantum algorithms revisited. Proceedings of the Royal Society A, 454(1969):339\u2013354, 1998. arXiv: https://arxiv.org/abs/quant-ph/9708016. doi:10.1098/rspa.1998.0164.</p> </li> <li> <p>Lin Lin. Lecture notes on quantum algorithms for scientific computation. arXiv: https://arxiv.org/abs/2201.08309, 2022.</p> </li> </ol> <ol> <li> <p>Alternatively, if \\(\\phi_j\\) is known ahead of time (to sufficient precision), QPE can be wrapped inside of amplitude amplification and the state \\(\\ket{\\psi_j}\\) can be prepared using \\(\\mathcal{O}\\left( |\\alpha_j|^{-1} \\right)\\) applications of the QPE circuit, rather than \\(\\mathcal{O}\\left( |\\alpha_j|^{-2} \\right)\\).\u00a0\u21a9</p> </li> <li> <p>The fact that learning energies to greater precision requires a proportionally greater amount of time \\(t\\) is a manifestation of the energy-time Heisenberg uncertainty principle, and forms the origin of the term \"Heisenberg limit.\"\u00a0\u21a9</p> </li> </ol>"},{"location":"quantum-algorithmic-primitives/quantum-tomography/","title":"Quantum tomography","text":""},{"location":"quantum-algorithmic-primitives/quantum-tomography/#rough-overview-in-words","title":"Rough overview (in words)","text":"<p>In quantum tomography we are given repeated copies of an unknown quantum state (or quantum channel) and the goal is to find a full classical description of the quantum state (or quantum channel) by extracting information by means of repeated measurements. Here, we focus on quantum state tomography, with multiple independent and identical copies of an unknown quantum state \\(\\rho\\) provided\u2014that is of fixed and known dimension\u2014and the task is to find an estimate of the density matrix of the quantum state up to an approximation error in some distance measure (and up to some failure probability). We are then typically interested in the optimal sample complexity in terms of the number of copies \\(n\\), the quantum state dimension \\(d\\), the approximation error \\(\\varepsilon\\), and the overall failure probability \\(\\delta\\). Additionally, algorithmic complexity aspects of the used schemes might be of importance as well.</p>"},{"location":"quantum-algorithmic-primitives/quantum-tomography/#rough-overview-in-math","title":"Rough overview (in math)","text":"<p>Given (many copies of) an unknown quantum state \\(\\rho\\) of known dimension \\(d\\), the goal is to give a description of \\(\\tilde{\\rho}\\) with the statistical estimate \\(\\|\\tilde{\\rho}-\\rho\\|\\leq\\varepsilon\\), up to some approximation parameter \\(\\varepsilon\\geq0\\) and distance measure \\(\\|\\cdot\\|\\). This is achieved by extracting classical information by applying measurements \\(\\mathcal{M}^n(\\cdot)\\) via \\(\\rho^{\\otimes n}\\). To start with, one has to distinguish tomography schemes based on different types of measurements used. This includes in particular:</p><ol> <li>Independent and identical (IID) measurements, where the choice of measurement \\(\\mathcal{M}^n=\\mathcal{M}^{\\otimes n}\\) is fixed and the same for each copy.</li> <li>Adapative measurements, where the choice of measurement \\(\\mathcal{M}_2\\) on the second copy can depend on the outcomes of measurement \\(\\mathcal{M}_1\\) on the first copy, and so on.</li> <li>Entangled measurements, where one measurement \\(\\mathcal{M}_k\\) with \\(1&lt;k\\leq n\\) is performed on \\(k\\) copies at once.</li> </ol><p>Further, if one has some information about the type of quantum state provided, then tomography schemes can become more efficient. This includes for example pure state tomography, low-rank-\\(k\\) state tomography, matrix product state tomography, or ground/thermal state tomography of Hamiltonians (some references on tight schemes are given later on). For some schemes, one a priori has certain information about the state in question and under this assumption the scheme is then promised to work (e.g., low-rank tomography [1]). Other schemes work generally, but are only a posteriori guaranteed to be more efficient if the unknown state happens to be approximately of the type sought after (e.g., matrix product state tomography [2]). Finally, for maximum likelihood estimates or Bayesian statistical estimates and alike, priors could be added as well.</p><p>Note that the best understood case of pure state tomography can also be used for general quantum states, if one has access to the relevant purification. Specifically for pure state tomography, one then also needs to specify in what form access is given to the quantum state. Possible access models include:</p><ul> <li>Via samples of computational basis measurements \\(p(x) = \\langle x |\\rho|x \\rangle\\)</li> <li>Via the state preparation unitary \\(U\\ket{0^n}\\bra{0^n}U^\\dagger = \\rho\\) (with \\(\\rho\\) pure)</li> <li>Via the controlled version of aforementioned state preparation unitary \\(U\\)</li> <li>Via aforementioned state preparation unitary \\(U\\) and its inverse \\(U^\\dagger\\).</li> </ul><p>Finally, typically studied distance functions to measure closeness of the statistical estimate to the true quantum state are the trace distance \\(T(\\rho,\\sigma)=\\frac{1}{2}\\mathrm{Tr}\\left[\\sqrt{(\\rho-\\sigma)^\\dagger(\\rho-\\sigma)}\\right]\\), the quantum fidelity \\(F(\\rho,\\sigma)=\\left(\\mathrm{Tr}\\left[\\sqrt{\\sqrt{\\rho}\\sigma\\sqrt{\\rho}}\\right]\\right)^2\\), and for pure quantum states also the vector two-norm \\(\\|\\vec{\\rho}-\\vec{\\sigma}\\|_2=\\sqrt{(\\vec{\\rho}-\\vec{\\sigma})\\cdot(\\vec{\\rho}-\\vec{\\sigma})}\\).</p>"},{"location":"quantum-algorithmic-primitives/quantum-tomography/#dominant-resource-cost-gatesqubits","title":"Dominant resource cost (gates/qubits)","text":"<p>Besides some potential ancilla qubits (few for typical tomographic schemes), the number of qubits is fixed by the dimension of the quantum state (of course, whenever entangled measurements are used, the corresponding number of copies is needed). As such, the sample complexity is typically the relevant figure of merit. Tight query complexity characterizations, in terms of an approximation error \\(\\varepsilon\\in[0,1]\\), include the following noteworthy results (expressed in the asymptotic notation \\(\\Theta(\\cdot)\\) and \\(\\widetilde{\\Theta}(\\cdot)\\), see below for definitions):</p><ul> <li>\\(\\widetilde{\\Theta}(d\\varepsilon^{-2})\\) for pure state tomography in vector two-norm with access to controlled state preparation unitary [3, 4]. The achievability results are based on the subroutine of quantum gradient estimation via an unbiased version of quantum phase estimation.</li> <li>\\(\\widetilde{\\Theta}(d\\varepsilon^{-1})\\) for pure state tomography in vector two-norm with access to controlled state preparation unitary and its inverse [4], featuring the quadratic speedup \\(1/\\varepsilon\\) reminiscent of amplitude amplification.</li> <li>\\(\\Theta(dk^2\\varepsilon^{-2})\\) for rank-\\(k\\) state tomography in trace distance for IID measurements [1, 5, 6]. The achievability results are based on low rank matrix recovery techniques, where semi-definite programs have to be solved for reconstructing the quantum state from the collected measurement statistics.</li> <li>\\(\\widetilde{\\Theta}(dk\\varepsilon^{-2})\\) for rank-\\(k\\) state tomography in trace distance for entanglement measurements [7, 1, 8]. The achievability results are based on representation-theoretic techniques around the Schur transform.</li> <li>\\(\\widetilde{\\Theta}(dk\\varepsilon^{-1})\\) for rank-\\(k\\) state tomography in trace distance given controlled unitary access to a purification and its inverse unitary [4], featuring the quadratic speedup \\(1/\\varepsilon\\) reminiscent of amplitude amplification.</li> </ul><p>Here, the notation \\(\\Theta(\\cdot)\\) stands for simultaneous upper \\(\\mathcal{O}\\left( \\cdot \\right)\\) and lower \\(\\Omega(\\cdot)\\) bounds on the asymptotic complexity. The variant \\(\\widetilde{\\Theta}(\\cdot)\\) then denotes the same up to factors that scale polylogarithmically in the relevant parameters. The derivations of the lower bounds are often based on information-theoretic methods, exploiting the monotonicity of quantum-entropy-based measures.</p><p>For variations of the above, additional results in terms of lower and upper bounds are known. Sample complexity lower bounds are typically obtained using information-theoretic methods. For sample complexity upper bounds, it is in practice additionally important that the algorithmic complexities of the underlying schemes become efficient (in particular for entangled measurements performed on all \\(n\\) copies at once). Relevant metrics for the algorithmic complexity include, e.g., quantum gate depth, number of measurement outcomes needed, or the efficiency of classical postprocessing. We refer to [9] for a recent discussion on these computational aspects.</p>"},{"location":"quantum-algorithmic-primitives/quantum-tomography/#caveats","title":"Caveats","text":"<p>As shown by the presented information-theoretic lower bounds, the sample complexity for general quantum state tomography grows exponentially in the number of qubits. As such, whenever quantum tomography is invoked as a subroutine in quantum algorithms, one has to carefully analyze if this step does not eliminate any claimed speedups of the quantum algorithm compared to state-of-the-art classical methods. One also has the inverse polynomial scaling in terms of the approximation parameter from the finite statistics, which is often prohibitively expensive for certain applications.</p><p>Additionally, on top of sample complexity for tomography schemes, the accompanying gate complexity should be considered as well. We refer to [4] for a discussion.</p><p>An alternative is to resort to only revealing partial classical information about quantum states, which might still be informative for the (algorithmic) task at hand. One such example with favorable scaling is shadow tomography, achieving exponentially improved sample complexities in terms of certain parameters [10, 11, 12]. In more detail, there exist algorithmically efficient and universal schemes that can simultaneously \\(\\varepsilon\\)-approximate \\(M\\) linear functions \\(\\mathrm{tr}[O_i\\rho]\\) of an unknown quantum state \\(\\rho\\) by only using \\(\\mathcal{O}\\left( \\log(M)\\cdot\\max_i\\|O_i\\|^2_{s}\\varepsilon^{-2} \\right)\\) IID measurements. Note the scaling with \\(\\log(M)\\) instead of the standard \\(M\\) scaling. The shadow norm term \\(\\|O_i\\|^2_{s}\\) scales in general as \\(d\\), leading to the worst case query complexity \\(O\\left(d\\log(M)\\varepsilon^{-2}\\right)\\). However, for observables with bounded Hilbert\u2013Schmidt norm or for local observables, the overall dimension-free query complexity \\(\\mathcal{O}\\left( \\log(M)\\varepsilon^{-2} \\right)\\) is achievable.</p>"},{"location":"quantum-algorithmic-primitives/quantum-tomography/#example-use-cases","title":"Example use cases","text":"<p>Quantum tomographic or related data collection schemes are omnipresent in quantum algorithms. Some applications include:</p><ul> <li>Quantum linear system solvers that output full classical solution vector, where such solvers are, e.g., employed for quantum interior point methods or for solving differential equations</li> <li>Classical data about quantum states for variational quantum algorithms</li> <li>Characterizing the performance of physical devices</li> <li>Characterizing quantum processes.</li> </ul>"},{"location":"quantum-algorithmic-primitives/quantum-tomography/#further-reading","title":"Further reading","text":"<ul> <li>Wikipedia article on quantum tomography</li> <li>Recent overview on query complexity aspects [4]</li> <li>Recent overview on computational complexity aspects [9]</li> <li>Shadow tomography of quantum states [10]</li> <li>Predicting many properties of a quantum system from very few measurements [12], that it is a more experimentally accessible version of shadows which works for efficiently extracting certain information from (unknown) quantum states</li> </ul>"},{"location":"quantum-algorithmic-primitives/quantum-tomography/#bibliography","title":"Bibliography","text":"<ol> <li> <p>Jeongwan Haah, Aram W. Harrow, Zhengfeng Ji, Xiaodi Wu, and Nengkun Yu. Sample-optimal tomography of quantum states. IEEE Transactions on Information Theory, 63(9):5628\u20135641, 2017. arXiv: https://arxiv.org/abs/1508.01797. doi:10.1109/TIT.2017.2719044.</p> </li> <li> <p>Marcus Cramer, Martin B. Plenio, Steven T. Flammia, Rolando Somma, David Gross, Stephen D Bartlett, Olivier Landon-Cardinal, David Poulin, and Yi-Kai Liu. Efficient quantum state tomography. Nature Communications, 1:149, 2010. arXiv: https://arxiv.org/abs/1101.4366. doi:10.1038/ncomms1147.</p> </li> <li> <p>Iordanis Kerenidis and Anupam Prakash. A quantum interior point method for lps and sdps. ACM Transactions on Quantum Computing, 2020. arXiv: https://arxiv.org/abs/1808.09266. doi:10.1145/3406306.</p> </li> <li> <p>Joran van Apeldoorn, Arjan Cornelissen, Andr\u00e1s Gily\u00e9n, and Giacomo Nannicini. Quantum tomography using state-preparation unitaries. In Proceedings of the 34th ACM-SIAM Symposium on Discrete Algorithms (SODA), 1265\u20131318. 2023. arXiv: https://arxiv.org/abs/2207.08800. doi:10.1137/1.9781611977554.ch47.</p> </li> <li> <p>Sitan Chen, Brice Huang, Jerry Li, Allen Liu, and Mark Slelke. Tight bounds for state tomography with incoherent measurements. arXiv: https://arxiv.org/abs/2206.05265, 2022.</p> </li> <li> <p>David Gross, Yi-Kai Liu, Steven T. Flammia, Stephen Becker, and Jens Eisert. Quantum state tomography via compressed sensing. Physical Review Letters, 105:150401, 2010. arXiv: https://arxiv.org/abs/0909.3304. doi:10.1103/PhysRevLett.105.150401.</p> </li> <li> <p>Ryan O'Donnell and John Wright. Efficient quantum tomography. In Proceedings of the 48th ACM Symposium on the Theory of Computing (STOC), 899\u2013912. 2016. arXiv: https://arxiv.org/abs/1508.01907. doi:10.1145/2897518.2897544.</p> </li> <li> <p>Henry Yuen. An improved sample complexity lower bound for (fidelity) quantum state tomography. Quantum, 7:890, 2023. arXiv: https://arxiv.org/abs/2206.11185. doi:10.22331/q-2023-01-03-890.</p> </li> <li> <p>Angus Lowe and Ashwin Nayak. Lower bounds for learning quantum states with single-copy measurements. arXiv: https://arxiv.org/abs/2207.14438, 2022.</p> </li> <li> <p>Scott Aaronson. Shadow tomography of quantum states. In Proceedings of the 50th ACM Symposium on the Theory of Computing (STOC), 325\u2013338. 2018. arXiv: https://arxiv.org/abs/1711.01053. doi:10.1145/3188745.3188802.</p> </li> <li> <p>Scott Aaronson, Xinyi Chen, Elad Hazan, Satyen Kale, and Ashwin Nayak. Online learning of quantum states. Journal of Statistical Mechanics: Theory and Experiment, 2019:124019, 2019. arXiv: https://arxiv.org/abs/1802.09025. doi:10.1088/1742-5468/ab3988.</p> </li> <li> <p>Hsin-Yuan Huang, Richard Kueng, and John Preskill. Predicting many properties of a quantum system from very few measurements. Nature Physics, 16(10):1050\u20131057, 2020. arXiv: https://arxiv.org/abs/2002.08953. doi:10.1038/s41567-020-0932-7.</p> </li> </ol>"},{"location":"quantum-algorithmic-primitives/variational-quantum-algorithms/","title":"Variational quantum algorithms","text":""},{"location":"quantum-algorithmic-primitives/variational-quantum-algorithms/#rough-overview-in-words","title":"Rough overview (in words)","text":"<p>The so-called Noisy Intermediate-Scale Quantum (NISQ) era is a term used to describe the regime in which the best quantum processors have fifty to a few hundred noisy qubits [1]. In this regime, one does not have enough qubits or low enough error rates to carry out fault-tolerant quantum computation, and so one is constrained to run low-depth quantum circuits. Under these constraints, structured quantum algorithms with prescribed circuits and provable guarantees are unknown. In light of this, variational quantum algorithms (VQAs) have been proposed. We remark that, despite this original setting, it would also be possible to run VQAs on fault-tolerant devices. Whilst many VQAs have been proposed for a wide range of applications, they all share the same core primitive which we describe below.</p><p>The main idea is to encode the target problem into an optimization task of minimizing the expectation value of some parametrized quantum circuit, or a function thereof. In each optimization step, a quantum computer is used to evaluate expectation values at chosen parameter values, which are read by a classical optimizer that updates the parameters for the next step. The motivation for this framework is to offload some of the computational complexity onto the classical optimization algorithm, with an aim for the quantum subroutines to perform classically intractable calculations.</p>"},{"location":"quantum-algorithmic-primitives/variational-quantum-algorithms/#rough-overview-in-math","title":"Rough overview (in math)","text":"<p>Given some parametrized unitary \\(U(\\boldsymbol{\\theta})\\) with adjustable parameters \\(\\boldsymbol{\\theta}\\), input state \\(\\rho\\), measurement operator \\(O\\), and function \\(f(\\cdot)\\), one evaluates \\(C(\\boldsymbol{\\theta})=f\\left(\\operatorname{Tr}\\left[O U(\\boldsymbol{\\theta}) \\rho U^{\\dagger}(\\boldsymbol{\\theta})\\right] \\right)\\) on a quantum computer, which is known as a cost function. A classical optimizer is then tasked to solve the problem \\(\\boldsymbol{\\theta}_*=\\textrm{argmin}_{\\boldsymbol{\\theta}}f\\left(\\operatorname{Tr}[O U(\\boldsymbol{\\theta}) \\rho U^{\\dagger}(\\boldsymbol{\\theta})]\\right)\\). By careful choice of \\(f(\\cdot)\\), \\(\\rho\\), and \\(O\\), one can encode a problem of interest such that \\(U(\\boldsymbol{\\theta}_*)\\) enables an (approximate) solution to the problem. For instance, the solution could correspond to the projection of the output state \\(U(\\boldsymbol{\\theta}_*)\\rho U(\\boldsymbol{\\theta}_*)^{\\dagger}\\) to the computational basis, or to the value of \\(f(\\operatorname{Tr}[O U(\\boldsymbol{\\theta}_*) \\rho U(\\boldsymbol{\\theta}_*)^{\\dagger}])\\) itself. In general, one can also construct a more elaborate cost function comprising a sum of observable-dependent functions with different input states and measurement operators.</p><p>The parametrized circuit \\(U(\\boldsymbol{\\theta})\\) is commonly referred to as the \"ansatz circuit.\" The choice of cost function and ansatz are key components in designing a VQA. Namely, they should ideally satisfy the following properties:</p><ol> <li>Smaller values of the cost function should correspond to better quality of solution.</li> <li>The ansatz should be sufficiently expressible to contain a unitary \\(U(\\boldsymbol{\\theta}_*)\\) which yields an acceptable solution.</li> <li>The ansatz should lead to a trainable cost landscape in parameter space, such that a sufficiently good solution can be found efficiently by the classical optimizer.</li> <li>The cost function should be classically hard to simulate, given the choice of ansatz.</li> </ol><p>It should be noted that whilst one would expect any VQA to satisfy the first point by design, in general it can be hard to satisfy all of the above requirements simultaneously via theoretical guarantees or even heuristically in practice. These caveats are discussed in more detail below.</p>"},{"location":"quantum-algorithmic-primitives/variational-quantum-algorithms/#dominant-resource-cost-gatesqubits","title":"Dominant resource cost (gates/qubits)","text":"<p>The gate complexity is wholly dependent on the choice of ansatz. Satisfying properties (2) and (4) may place lower bounds on the required circuit depth. In addition, the connectivity of the device may also significantly affect the depth of the circuit. For instance, compilation of a single generic (multiqubit) gate on hardware with \\(1\\)D connectivity incurs \\(\\mathcal{O}\\left( n \\right)\\) circuit depth, where \\(n\\) is the number of qubits.</p><p>Throughout the optimization, the cost function is evaluated at different parameter settings \\(\\boldsymbol{\\theta}\\), chosen adaptively based on the outcome of prior evaluations (in the case of gradient-based optimization, one can use the parameter shift rule [2, 3, 4, 5] or finite-difference methods). Each evaluation of the cost function corresponds to approximating an expectation value to some additive error \\(\\varepsilon\\) using finite measurement shots, where \\(\\varepsilon\\) should be chosen to be sufficiently small for accurate optimization over the landscape. Specifically, it should be expected that \\(\\varepsilon\\) is at most \\(\\smash{\\mathcal{O}\\left(\\sqrt{\\operatorname{Var}_{\\boldsymbol{\\theta}}C(\\boldsymbol{\\theta})}\\right)}\\) in order to distinguish different points in the parameter landscape, where \\(\\operatorname{Var}_{\\boldsymbol{\\theta}}\\) denotes the variance over uniformly distributed parameter settings.</p>"},{"location":"quantum-algorithmic-primitives/variational-quantum-algorithms/#caveats","title":"Caveats","text":"<p>The optimization of certain parametrized quantum circuits is known to be subject to the detrimental phenomena of \"barren plateaus,\" in which deviations between different cost values with high probability (or deterministically, depending on the setting) vanish exponentially with increasing number of qubits [6, 7, 8, 9, 10, 11, 12, 13]. This is often characterized by observing that \\(\\operatorname{Var}_{\\boldsymbol{\\theta}}C(\\boldsymbol{\\theta}) = \\mathcal{O}\\left( 2^{-\\beta n} \\right)\\) for some \\(\\beta \\geq 0\\) [14]. This mandates an exponential shot complexity for each evaluation of a cost value in order to reliably navigate the cost landscape. Note that this affects both gradient-based and gradient-free optimization strategies.</p><p>If VQAs are run on noisy devices, the effects of noise are known to severely restrict the scope for computation [15, 16, 17, 18, 19]. This effect is amplified on devices with limited hardware connectivity, where one has to use additional circuit depth to compile generic gates [18, 17].</p><p>Finally, in general there is a lack of end-to-end theoretical guarantees for variational quantum algorithms. In order to show advantage over classical algorithms, at minimum one has to satisfy all of the properties laid out above. In particular the classical parameter optimization is generally left as a heuristic subroutine. This optimization task is in general NP-hard, and can be burdened by many local minima of poor quality [20, 21]. This leads to a slow optimization process and many cost values may need to be evaluated.</p>"},{"location":"quantum-algorithmic-primitives/variational-quantum-algorithms/#example-use-cases","title":"Example use cases","text":"<ul> <li>Quantum chemistry and condensed matter physics: The ground state and ground state energy of a given Hamiltonian \\(H\\) can be found by minimizing the cost \\(\\langle\\psi(\\boldsymbol{\\theta})|H| \\psi(\\boldsymbol{\\theta})\\rangle\\), where \\(\\ket{\\psi(\\boldsymbol{\\theta})}=U(\\boldsymbol{\\theta})\\ket{\\psi_0}\\) for some input state \\(\\ket{\\psi_0}\\) [22]. This is known as the Variational Quantum Eigensolver (VQE) algorithm. A widely used ansatz for fermionic Hamiltonians is the Unitary Coupled Cluster (UCC) ansatz [23, 22, 24, 25, 26, 27, 28, 29].</li> <li>Combinatorial optimization: In the Quantum Approximate Optimization Algorithm (QAOA), combinatorial problems on bitstrings can be encoded in the Pauli-\\(Z\\) basis with Hamiltonian \\(H_P\\) [30]. By finding the state that minimizes \\(\\langle\\phi(\\boldsymbol{\\theta})|H_P| \\phi(\\boldsymbol{\\theta})\\rangle\\), where \\(\\ket{\\phi(\\boldsymbol{\\theta})} = U(\\boldsymbol{\\theta})\\ket{0}\\), the optimal bit-string can be extracted by sampling the optimized state in the computational basis. A widely studied ansatz for this problem is the Quantum Alternating Operator Ansatz (which bears the same acronym as the algorithm), inspired by Trotterized adiabatic evolution [31]. The ansatz takes the form \\(U(\\boldsymbol{\\gamma}, \\boldsymbol{\\beta})=\\prod_{l=1}^{p} e^{-i \\beta_{l} H_{M}} e^{-i \\gamma_{l} H_{P}}\\) where \\(H_M\\) is a specific \"mixing\\\" Hamiltonian. This ansatz is known to be computationally universal (when \\(p\\rightarrow \\infty\\)) for certain classes of Hamiltonians [32, 33]. Moreover, under reasonable complexity-theoretic assumptions, it is known that sampling from the output of the QAOA at \\(p=1\\) is classically hard [34]. On the other hand, there is evidence that shallow (small \\(p\\)) QAOA does not perform well [35, 36, 37, 38], leading to intuition that \\(p\\) may need to grow with problem size to produce better approximate solutions than what can be easily found classically. Alternatively, there is some evidence that an exponential number of samples from shallow QAOA circuits may yield polynomial speedups over classical methods for finding exactly optimal solutions [39, 40], see the page on beyond-quadratic speedups for combinatorial optimization.</li> <li>Linear systems solvers: Given matrix \\(A\\) and vector \\(b\\) encoded in a quantum state \\(\\ket{b}\\), the goal is to variationally prepare a quantum state \\(\\ket{x}\\) with amplitudes proportional to elements of the vector \\(x=A^{-1}b\\) [41, 42, 43]. The strategy employed is to minimize the cost \\(\\bra{\\tilde{x}(\\boldsymbol{\\theta})}H_L\\ket{\\tilde{x}(\\boldsymbol{\\theta})}\\), where \\(\\ket{\\tilde{x}(\\boldsymbol{\\theta})} = U(\\boldsymbol{\\theta})\\ket{0}\\) and \\(H_L=A^{\\dag}(I-|b\\rangle\\langle b|)A\\). These approaches require the assumption that \\(A\\) has a decomposition into a sum of a small number of efficiently implementable unitaries. Here the absolute value of the cost function bounds the approximation error. A numerical study up to \\(30\\) qubits showed favourable scaling in the time to solution with respect to the matrix size, condition number and precision [41].</li> <li>Factoring: Variational methods for factoring have been proposed which exploit a mapping between the factoring problem and that of finding the ground state of an Ising Hamiltonian [44]. The authors use the QAOA ansatz and heuristically find that \\(p=\\mathcal{O}(n)\\) rounds of the ansatz can lead to a good solution overlap for small system sizes.</li> <li>Compiling: An interesting near-term application could be to approximate a given unitary \\(V\\) with native gate sequence \\(U(\\boldsymbol{\\theta})\\). One can construct a cost function via the Hilbert-Schmidt test circuit to evaluate \\(1-\\left|\\bra{\\Phi}V^*\\otimes U(\\boldsymbol{\\theta})\\ket{\\Phi}\\right|^2=1-\\left|\\frac{1}{2^{n}}\\mathrm{Tr}[V^{\\dag}U(\\boldsymbol{\\theta})]\\right|^2\\), where \\(\\ket{\\Phi}\\) is the maximally entangled state [45].</li> <li>Machine learning: Here one employs a parametrized quantum circuit to construct a hypothesis family. Variational methods have been proposed for both classical and quantum data for classification [46, 2, 47, 48, 49], generative models [50, 51, 52], autoencoders [53, 54, 55] and beyond [56, 57]. Specific ans\u00e4tze have been proposed in these contexts, sometimes referred to as quantum neural networks, in analogue with their classical counterparts. \"Classically inspired\\\" quantum neural networks have been proposed, such as perceptron-based QNNs [58, 54, 59, 60] and a quantum analogue to the convolutional neural network [49], as well as approaches based on tensor networks [61, 62].</li> </ul>"},{"location":"quantum-algorithmic-primitives/variational-quantum-algorithms/#further-reading","title":"Further reading","text":"<ul> <li>See [63, 64] for extensive reviews of VQAs, including a summary of different widely studied ansatzes, applications, and challenges.</li> </ul>"},{"location":"quantum-algorithmic-primitives/variational-quantum-algorithms/#bibliography","title":"Bibliography","text":"<ol> <li> <p>John Preskill. Quantum computing in the nisq era and beyond. Quantum, 2:79, 2018. arXiv: https://arxiv.org/abs/1801.00862. doi:10.22331/q-2018-08-06-79.</p> </li> <li> <p>Kosuke Mitarai, Makoto Negoro, Masahiro Kitagawa, and Keisuke Fujii. Quantum circuit learning. Physical Review A, 98(3):032309, 2018. arXiv: https://arxiv.org/abs/1803.00745. URL: https://journals.aps.org/pra/abstract/10.1103/PhysRevA.98.032309, doi:10.1103/PhysRevA.98.032309.</p> </li> <li> <p>Maria Schuld, Ville Bergholm, Christian Gogolin, Josh Izaac, and Nathan Killoran. Evaluating analytic gradients on quantum hardware. Physical Review A, 99(3):032331, 2019. arXiv: https://arxiv.org/abs/1811.11184. URL: https://journals.aps.org/pra/abstract/10.1103/PhysRevA.99.032331, doi:10.1103/PhysRevA.99.032331.</p> </li> <li> <p>Gavin E Crooks. Gradients of parameterized quantum gates using the parameter-shift rule and gate decomposition. arXiv: https://arxiv.org/abs/1905.13311, 2019.</p> </li> <li> <p>David Wierichs, Josh Izaac, Cody Wang, and Cedric Yen-Yu Lin. General parameter-shift rules for quantum gradients. Quantum, 2022. arXiv: https://arxiv.org/abs/2107.12390. URL: https://quantum-journal.org/papers/q-2022-03-30-677/, doi:https://doi.org/10.22331/q-2022-03-30-677.</p> </li> <li> <p>Jarrod R McClean, Sergio Boixo, Vadim N Smelyanskiy, Ryan Babbush, and Hartmut Neven. Barren plateaus in quantum neural network training landscapes. Nature Communications, 9(1):1\u20136, 2018. arXiv: https://arxiv.org/abs/1803.11173. URL: https://www.nature.com/articles/s41467-018-07090-4, doi:10.1038/s41467-018-07090-4.</p> </li> <li> <p>M. Cerezo, Akira Sone, Tyler Volkoff, Lukasz Cincio, and Patrick J Coles. Cost function dependent barren plateaus in shallow parametrized quantum circuits. Nature Communications, 12(1):1\u201312, 2021. arXiv: https://arxiv.org/abs/2001.00550. URL: https://www.nature.com/articles/s41467-021-21728-w, doi:10.1038/s41467-021-21728-w.</p> </li> <li> <p>Zo\u00eb Holmes, Kunal Sharma, M. Cerezo, and Patrick J Coles. Connecting ansatz expressibility to gradient magnitudes and barren plateaus. PRX Quantum, 3:010313, 1 2022. arXiv: https://arxiv.org/abs/2101.02138. URL: https://link.aps.org/doi/10.1103/PRXQuantum.3.010313, doi:10.1103/PRXQuantum.3.010313.</p> </li> <li> <p>Carlos Ortiz Marrero, M\u00e1ria Kieferov\u00e1, and Nathan Wiebe. Entanglement-induced barren plateaus. PRX Quantum, 2(4):040316, 2021. arXiv: https://arxiv.org/abs/2010.15968. URL: https://journals.aps.org/prxquantum/abstract/10.1103/PRXQuantum.2.040316, doi:10.1103/PRXQuantum.2.040316.</p> </li> <li> <p>Kunal Sharma, M. Cerezo, Lukasz Cincio, and Patrick J Coles. Trainability of dissipative perceptron-based quantum neural networks. Physical Review Letters, 128(18):180505, 2022. arXiv: https://arxiv.org/abs/2005.12458. doi:10.1103/PhysRevLett.128.180505.</p> </li> <li> <p>Martin Larocca, Piotr Czarnik, Kunal Sharma, Gopikrishnan Muraleedharan, Patrick J Coles, and Marco Cerezo. Diagnosing barren plateaus with tools from quantum optimal control. Quantum, 6:824, 2022. arXiv: https://arxiv.org/abs/2105.14377. doi:https://doi.org/10.22331/q-2022-09-29-824.</p> </li> <li> <p>Enrico Fontana, Dylan Herman, Shouvanik Chakrabarti, Niraj Kumar, Romina Yalovetzky, Jamie Heredge, Shree Hari Sureshbabu, and Marco Pistoia. The adjoint is all you need: characterizing barren plateaus in quantum ans\u00e4tze. arXiv: https://arxiv.org/abs/2309.07902, 2023.</p> </li> <li> <p>Michael Ragone, Bojko N Bakalov, Fr\u00e9d\u00e9ric Sauvage, Alexander F Kemper, Carlos Ortiz Marrero, Martin Larocca, and M Cerezo. A unified theory of barren plateaus for deep parametrized quantum circuits. arXiv: https://arxiv.org/abs/2309.09342, 2023.</p> </li> <li> <p>Andrew Arrasmith, Zo\u00eb Holmes, Marco Cerezo, and Patrick J Coles. Equivalence of quantum barren plateaus to cost concentration and narrow gorges. Quantum Science and Technology, 7(4):045015, 2022. arXiv: https://arxiv.org/abs/2104.05868. URL: https://iopscience.iop.org/article/10.1088/2058-9565/ac7d06, doi:10.1088/2058-9565/ac7d06.</p> </li> <li> <p>Dorit Aharonov, Michael Ben-Or, Russell Impagliazzo, and Noam Nisan. Limitations of noisy reversible computation. arXiv: https://arxiv.org/abs/quant-ph/9611028, 1996.</p> </li> <li> <p>Michael Ben-Or, Daniel Gottesman, and Avinatan Hassidim. Quantum refrigerator. arXiv: https://arxiv.org/abs/1301.1995, 2013. URL: https://arxiv.org/abs/1301.1995.</p> </li> <li> <p>Samson Wang, Enrico Fontana, M. Cerezo, Kunal Sharma, Akira Sone, Lukasz Cincio, and Patrick J Coles. Noise-induced barren plateaus in variational quantum algorithms. Nature Communications, 12(1):1\u201311, 2021. arXiv: https://arxiv.org/abs/2007.14384. URL: https://www.nature.com/articles/s41467-021-27045-6, doi:10.1038/s41467-021-27045-6.</p> </li> <li> <p>Daniel Stilck Fran\u00e7a and Raul Garcia-Patron. Limitations of optimization algorithms on noisy quantum devices. Nature Physics, 17(11):1221\u20131227, 2021. arXiv: https://arxiv.org/abs/2009.05532. doi:10.1038/s41567-021-01356-3.</p> </li> <li> <p>Giacomo De Palma, Milad Marvian, Cambyse Rouz\u00e9, and Daniel Stilck Fran\u00e7a. Limitations of variational quantum algorithms: a quantum optimal transport approach. PRX Quantum, 4:010309, 1 2023. arXiv: https://arxiv.org/abs/2204.03455. URL: https://link.aps.org/doi/10.1103/PRXQuantum.4.010309, doi:10.1103/PRXQuantum.4.010309.</p> </li> <li> <p>Lennart Bittel and Martin Kliesch. Training variational quantum algorithms is np-hard. Physical Review Letters, 127:120502, 9 2021. arXiv: https://arxiv.org/abs/2101.07267. URL: https://link.aps.org/doi/10.1103/PhysRevLett.127.120502, doi:10.1103/PhysRevLett.127.120502.</p> </li> <li> <p>Eric R Anschuetz and Bobak T Kiani. Quantum variational algorithms are swamped with traps. Nature Communications, 13(1):7760, 2022. arXiv: https://arxiv.org/abs/2205.05786. doi:https://doi.org/10.1038/s41467-022-35364-5.</p> </li> <li> <p>Alberto Peruzzo, Jarrod McClean, Peter Shadbolt, Man-Hong Yung, Xiao-Qi Zhou, Peter J Love, Al\u00e1n Aspuru-Guzik, and Jeremy L. O'Brien. A variational eigenvalue solver on a photonic quantum processor. Nature Communications, 2014. arXiv: https://arxiv.org/abs/1304.3061. doi:10.1038/ncomms5213.</p> </li> <li> <p>Andrew G Taube and Rodney J Bartlett. New perspectives on unitary coupled-cluster theory. International journal of quantum chemistry, 106(15):3393\u20133401, 2006. URL: https://onlinelibrary.wiley.com/doi/full/10.1002/qua.21198, doi:10.1002/qua.21198.</p> </li> <li> <p>Sergey B Bravyi and Alexei Yu Kitaev. Fermionic quantum computation. Annals of Physics, 298(1):210\u2013226, 2002. arXiv: https://arxiv.org/abs/quant-ph/0003137. doi:https://doi.org/10.1006/aphy.2002.6254.</p> </li> <li> <p>Joonho Lee, William J Huggins, Martin Head-Gordon, and K Birgitta Whaley. Generalized unitary coupled cluster wave functions for quantum computation. Journal of Chemical Theory and Computation, 15(1):311\u2013324, 2018. arXiv: https://arxiv.org/abs/1810.02327. URL: https://pubs.acs.org/doi/10.1021/acs.jctc.8b01004, doi:https://doi.org/10.1021/acs.jctc.8b01004.</p> </li> <li> <p>Mario Motta, Erika Ye, Jarrod R McClean, Zhendong Li, Austin J Minnich, Ryan Babbush, and Garnet Kin Chan. Low rank representations for quantum simulation of electronic structure. npj Quantum Information, 7(1):1\u20137, 2021. arXiv: https://arxiv.org/abs/1808.02625. URL: https://www.nature.com/articles/s41534-021-00416-z, doi:https://doi.org/10.1038/s41534-021-00416-z.</p> </li> <li> <p>Yuta Matsuzawa and Yuki Kurashige. Jastrow-type decomposition in quantum chemistry for low-depth quantum circuits. Journal of Chemical Theory and Computation, 16(2):944\u2013952, 2020. arXiv: https://arxiv.org/abs/1909.12410. URL: https://pubs.acs.org/doi/10.1021/acs.jctc.9b00963, doi:https://doi.org/10.1021/acs.jctc.9b00963.</p> </li> <li> <p>Ian D Kivlichan, Jarrod McClean, Nathan Wiebe, Craig Gidney, Al\u00e1n Aspuru-Guzik, Garnet Kin-Lic Chan, and Ryan Babbush. Quantum simulation of electronic structure with linear depth and connectivity. Physical Review Letters, 120(11):110501, 2018. arXiv: https://arxiv.org/abs/1711.04789. URL: https://journals.aps.org/prl/abstract/10.1103/PhysRevLett.120.110501, doi:10.1103/PhysRevLett.120.110501.</p> </li> <li> <p>Kanav Setia, Sergey Bravyi, Antonio Mezzacapo, and James D. Whitfield. Superfast encodings for fermionic quantum simulation. Physical Review Research, 1:033033, 10 2019. arXiv: https://arxiv.org/abs/1810.05274. URL: https://link.aps.org/doi/10.1103/PhysRevResearch.1.033033, doi:10.1103/PhysRevResearch.1.033033.</p> </li> <li> <p>Edward Farhi, Jeffrey Goldstone, and Sam Gutmann. A quantum approximate optimization algorithm. arXiv: https://arxiv.org/abs/1411.4028, 2014.</p> </li> <li> <p>Stuart Hadfield, Zhihui Wang, Bryan O'Gorman, Eleanor G Rieffel, Davide Venturelli, and Rupak Biswas. From the quantum approximate optimization algorithm to a quantum alternating operator ansatz. Algorithms, 12(2):34, 2019. arXiv: https://arxiv.org/abs/1709.03489. URL: https://www.mdpi.com/1999-4893/12/2/34, doi:https://doi.org/10.3390/a12020034.</p> </li> <li> <p>Seth Lloyd. Quantum approximate optimization is computationally universal. arXiv: https://arxiv.org/abs/1812.11075, 2018. URL: https://arxiv.org/abs/1812.11075.</p> </li> <li> <p>Mauro ES Morales, JD Biamonte, and Zolt\u00e1n Zimbor\u00e1s. On the universality of the quantum approximate optimization algorithm. Quantum Information Processing, 19(9):1\u201326, 2020. arXiv: https://arxiv.org/abs/1909.03123. URL: https://link.springer.com/article/10.1007/s11128-020-02748-9, doi:10.1007/s11128-020-02748-9.</p> </li> <li> <p>Edward Farhi and Aram W Harrow. Quantum supremacy through the quantum approximate optimization algorithm. arXiv: https://arxiv.org/abs/1602.07674, 2016. URL: https://arxiv.org/abs/1602.07674.</p> </li> <li> <p>Sergey Bravyi, Alexander Kliesch, Robert Koenig, and Eugene Tang. Obstacles to variational quantum optimization from symmetry protection. Physical Review Letters, 125(26):260505, 2020. arXiv: https://arxiv.org/abs/1910.08980. doi:10.1103/PhysRevLett.125.260505.</p> </li> <li> <p>Matthew B Hastings. Classical and quantum bounded depth approximation algorithms. arXiv: https://arxiv.org/abs/1905.07047, 2019.</p> </li> <li> <p>Edward Farhi, David Gamarnik, and Sam Gutmann. The quantum approximate optimization algorithm needs to see the whole graph: a typical case. arXiv: https://arxiv.org/abs/2004.09002, 2020.</p> </li> <li> <p>Edward Farhi, David Gamarnik, and Sam Gutmann. The quantum approximate optimization algorithm needs to see the whole graph: worst case examples. arXiv: https://arxiv.org/abs/2005.08747, 2020.</p> </li> <li> <p>Sami Boulebnane and Ashley Montanaro. Solving boolean satisfiability problems with the quantum approximate optimization algorithm. arXiv: https://arxiv.org/abs/2208.06909, 2022.</p> </li> <li> <p>Ruslan Shaydulin, Changhao Li, Shouvanik Chakrabarti, Matthew DeCross, Dylan Herman, Niraj Kumar, Jeffrey Larson, Danylo Lykov, Pierre Minssen, Yue Sun, Yuri Alexeev, Joan M. Dreiling, John P. Gaebler, Thomas M. Gatterman, Justin A. Gerber, Kevin Gilmore, Dan Gresh, Nathan Hewitt, Chandler V. Horst, Shaohan Hu, Jacob Johansen, Mitchell Matheny, Tanner Mengle, Michael Mills, Steven A. Moses, Brian Neyenhuis, Peter Siegfried, Romina Yalovetzky, and Marco Pistoia. Evidence of scaling advantage for the quantum approximate optimization algorithm on a classically intractable problem. arXiv: https://arxiv.org/abs/2308.02342, 2023.</p> </li> <li> <p>Carlos Bravo-Prieto, Ryan LaRose, M. Cerezo, Yigit Subasi, Lukasz Cincio, and Patrick Coles. Variational quantum linear solver. arXiv: https://arxiv.org/abs/1909.05820, 2019. URL: https://arxiv.org/abs/1909.05820.</p> </li> <li> <p>Xiaosi Xu, Jinzhao Sun, Suguru Endo, Ying Li, Simon C Benjamin, and Xiao Yuan. Variational algorithms for linear algebra. Science Bulletin, 66(21):2181\u20132188, 2021. arXiv: https://arxiv.org/abs/1909.03898. URL: https://www.sciencedirect.com/science/article/pii/S2095927321004631, doi:https://doi.org/10.1016/j.scib.2021.06.023.</p> </li> <li> <p>Hsin-Yuan Huang, Kishor Bharti, and Patrick Rebentrost. Near-term quantum algorithms for linear systems of equations with regression loss functions. New Journal of Physics, 23(11):113021, 11 2021. arXiv: https://arxiv.org/abs/1909.07344. URL: https://dx.doi.org/10.1088/1367-2630/ac325f, doi:10.1088/1367-2630/ac325f.</p> </li> <li> <p>Eric Anschuetz, Jonathan Olson, Al\u00e1n Aspuru-Guzik, and Yudong Cao. Variational quantum factoring. In Quantum Technology and Optimization Problems, 74\u201385. Springer, 2019. arXiv: https://arxiv.org/abs/1808.08927. URL: https://link.springer.com/chapter/10.1007/978-3-030-14082-3\\_7, doi:10.1007/978-3-030-14082-3\\_7.</p> </li> <li> <p>Sumeet Khatri, Ryan LaRose, Alexander Poremba, Lukasz Cincio, Andrew T Sornborger, and Patrick J Coles. Quantum-assisted quantum compiling. Quantum, 3:140, 2019. arXiv: https://arxiv.org/abs/1807.00800. URL: https://quantum-journal.org/papers/q-2019-05-13-140/, doi:https://doi.org/10.22331/q-2019-05-13-140.</p> </li> <li> <p>Maria Schuld, Alex Bocharov, Krysta M. Svore, and Nathan Wiebe. Circuit-centric quantum classifiers. arXiv: https://arxiv.org/abs/1804.00633, 2018.</p> </li> <li> <p>Maria Schuld and Nathan Killoran. Quantum machine learning in feature hilbert spaces. Physical Review Letters, 122(4):040504, 2019. arXiv: https://arxiv.org/abs/1803.07128. URL: https://journals.aps.org/prl/abstract/10.1103/PhysRevLett.122.040504, doi:10.1103/PhysRevLett.122.040504.</p> </li> <li> <p>Vojt\u011bch Havl\u00ed\u010dek, Antonio D C\u00f3rcoles, Kristan Temme, Aram W Harrow, Abhinav Kandala, Jerry M Chow, and Jay M Gambetta. Supervised learning with quantum-enhanced feature spaces. Nature, 567(7747):209\u2013212, 2019. arXiv: https://arxiv.org/abs/1804.11326. URL: https://www.nature.com/articles/s41586-019-0980-2, doi:10.1038/s41586-019-0980-2.</p> </li> <li> <p>Iris Cong, Soonwon Choi, and Mikhail D Lukin. Quantum convolutional neural networks. Nature Physics, 15(12):1273\u20131278, 2019. arXiv: https://arxiv.org/abs/1810.03787. URL: https://www.nature.com/articles/s41567-019-0648-8, doi:10.1038/s41567-019-0648-8.</p> </li> <li> <p>Guillaume Verdon, Michael Broughton, and Jacob Biamonte. A quantum algorithm to train neural networks using low-depth circuits. arXiv: https://arxiv.org/abs/1712.05304, 2017. URL: https://arxiv.org/abs/1712.05304.</p> </li> <li> <p>Marcello Benedetti, Delfina Garcia-Pintos, Oscar Perdomo, Vicente Leyton-Ortega, Yunseong Nam, and Alejandro Perdomo-Ortiz. A generative modeling approach for benchmarking and training shallow quantum circuits. npj Quantum Information, 5(1):1\u20139, 2019. arXiv: https://arxiv.org/abs/1801.07686. URL: https://www.nature.com/articles/s41534-019-0157-8, doi:10.1038/s41534-019-0157-8.</p> </li> <li> <p>Yuxuan Du, Min-Hsiu Hsieh, Tongliang Liu, and Dacheng Tao. Expressive power of parametrized quantum circuits. Physical Review Research, 2(3):033125, 2020. arXiv: https://arxiv.org/abs/1810.11922. URL: https://journals.aps.org/prresearch/abstract/10.1103/PhysRevResearch.2.033125, doi:10.1103/PhysRevResearch.2.033125.</p> </li> <li> <p>Jonathan Romero, Jonathan P. Olson, and Alan Aspuru-Guzik. Quantum autoencoders for efficient compression of quantum data. Quantum Science and Technology, 2(4):045001, 2017. arXiv: https://arxiv.org/abs/1612.02806. doi:10.1088/2058-9565/aa8072.</p> </li> <li> <p>Kwok Ho Wan, Oscar Dahlsten, Hl\u00e9r Kristj\u00e1nsson, Robert Gardner, and MS Kim. Quantum generalisation of feedforward neural networks. npj Quantum Information, 3(1):36, 2017. arXiv: https://arxiv.org/abs/1612.01045. URL: https://www.nature.com/articles/s41534-017-0032-4, doi:https://doi.org/10.1038/s41534-017-0032-4.</p> </li> <li> <p>Guillaume Verdon, Jason Pye, and Michael Broughton. A universal training algorithm for quantum deep learning. arXiv: https://arxiv.org/abs/1806.09729, 2018. URL: https://arxiv.org/abs/1806.09729.</p> </li> <li> <p>Jonathan Romero and Al\u00e1n Aspuru-Guzik. Variational quantum generators: generative adversarial quantum machine learning for continuous distributions. Advanced Quantum Technologies, 4(1):2000003, 2021. arXiv: https://arxiv.org/abs/1901.00848. doi:10.1002/qute.202000003.</p> </li> <li> <p>Thomas Hubregtsen, David Wierichs, Elies Gil-Fuster, Peter-Jan H. S. Derks, Paul K. Faehrmann, and Johannes Jakob Meyer. Training quantum embedding kernels on near-term quantum computers. Physical Review A, 106:042431, 10 2022. arXiv: https://arxiv.org/abs/2105.02276. URL: https://link.aps.org/doi/10.1103/PhysRevA.106.042431, doi:10.1103/PhysRevA.106.042431.</p> </li> <li> <p>MV Altaisky. Quantum neural network. arXiv: https://arxiv.org/abs/quant-ph/0107012, 2001. URL: https://arxiv.org/abs/quant-ph/0107012.</p> </li> <li> <p>Edward Farhi and Hartmut Neven. Classification with quantum neural networks on near term processors. arXiv: https://arxiv.org/abs/1802.06002, 2018.</p> </li> <li> <p>Kerstin Beer, Dmytro Bondarenko, Terry Farrelly, Tobias J Osborne, Robert Salzmann, Daniel Scheiermann, and Ramona Wolf. Training deep quantum neural networks. Nature Communications, 11(1):808, 2020. arXiv: https://arxiv.org/abs/1902.10445. URL: https://www.nature.com/articles/s41467-020-14454-2, doi:https://doi.org/10.1038/s41467-020-14454-2.</p> </li> <li> <p>Edward Grant, Marcello Benedetti, Shuxiang Cao, Andrew Hallam, Joshua Lockhart, Vid Stojevic, Andrew G Green, and Simone Severini. Hierarchical quantum classifiers. npj Quantum Information, 4(1):65, 2018. arXiv: https://arxiv.org/abs/1804.03680. URL: https://www.nature.com/articles/s41534-018-0116-9, doi:https://doi.org/10.1038/s41534-018-0116-9.</p> </li> <li> <p>William Huggins, Piyush Patil, Bradley Mitchell, K Birgitta Whaley, and E Miles Stoudenmire. Towards quantum machine learning with tensor networks. Quantum Science and Technology, 4(2):024001, 2019. arXiv: https://arxiv.org/abs/1803.11537. URL: https://iopscience.iop.org/article/10.1088/2058-9565/aaea94, doi:10.1088/2058-9565/aaea94.</p> </li> <li> <p>M. Cerezo, Andrew Arrasmith, Ryan Babbush, Simon C Benjamin, Suguru Endo, Keisuke Fujii, Jarrod R McClean, Kosuke Mitarai, Xiao Yuan, Lukasz Cincio, and Patrick J. Coles. Variational quantum algorithms. Nature Reviews Physics, pages 625\u2013644, 2021. arXiv: https://arxiv.org/abs/2012.09265. doi:10.1038/s42254-021-00348-9.</p> </li> <li> <p>Kishor Bharti, Alba Cervera-Lierta, Thi Ha Kyaw, Tobias Haug, Sumner Alperin-Lea, Abhinav Anand, Matthias Degroote, Hermanni Heimonen, Jakob S Kottmann, Tim Menke, and others. Noisy intermediate-scale quantum algorithms. Reviews of Modern Physics, 94(1):015004, 2022. arXiv: https://arxiv.org/abs/2101.08448. URL: https://journals.aps.org/rmp/abstract/10.1103/RevModPhys.94.015004, doi:10.1103/RevModPhys.94.015004.</p> </li> </ol>"},{"location":"quantum-algorithmic-primitives/amplitude-amplification-and-estimation/amplitude-amplification/","title":"Amplitude amplification","text":""},{"location":"quantum-algorithmic-primitives/amplitude-amplification-and-estimation/amplitude-amplification/#rough-overview-in-words","title":"Rough overview (in words)","text":"<p>Given a quantum subroutine that succeeds with a probability less than 1, amplitude amplification can be used to boost the success probability to 1 by making repeated calls to the subroutine and to a unitary that determines if the subroutine has succeeded. Amplitude amplification can be viewed as a generalization of Grover's search algorithm [1] and offers a quadratic speedup compared to classical methods in many instances.</p>"},{"location":"quantum-algorithmic-primitives/amplitude-amplification-and-estimation/amplitude-amplification/#rough-overview-in-math","title":"Rough overview (in math)","text":"<p>We are given an initial state \\(\\ket{\\psi_0}\\), a target state \\(\\ket{\\psi_g}\\) that we can mark (i.e., the ability to reflect about the state), and a unitary \\(U\\) (and its inverse \\(U^\\dag\\)) such that </p>\\[\\begin{equation} U\\ket{\\psi_0} = \\ket{\\psi} = a \\ket{\\psi_g} + b\\ket{\\psi_b}\\label{eq:U=a+b} \\end{equation}\\]<p>where \\(\\ket{\\psi_b}\\) is a state orthogonal to the target state. In other words, \\(|a|^2\\) is the probability of success of applying \\(U\\) and measuring \\(\\ket{\\psi_g}\\). In addition, we are given the ability to implement the reflection operator around the initial state \\(R_{\\psi_0} = I - 2\\ket{\\psi_0}\\bra{\\psi_0}\\) and an operation that, when restricted to the subspace spanned by \\(\\{ \\ket{\\psi_g}, \\ket{\\psi_b} \\}\\), acts as the reflection around the target state \\(R_{\\psi_g} = I - 2\\ket{\\psi_g}\\bra{\\psi_g}\\).</p><p>Then, amplitude amplification allows us to boost the success probability to 1 through repeated calls to an operator \\(W = - U R_{\\psi_0} U^\\dag R_{\\psi_g}\\), from the initial state \\(U \\ket{\\psi_0} = \\ket{\\psi}\\). The standard analysis [2] proceeds by letting \\(a=\\sin(\\theta)\\) and \\(b=\\cos(\\theta)\\), and showing that the 2D subspace spanned by \\(\\ket{\\psi_g}, \\ket{\\psi_b}\\) is invariant under \\(W\\), which acts as a rotation operator such that \\(\\ket{\\psi_g}\\bra{\\psi_g} W^m \\ket{\\psi} = \\sin((2m+1)\\theta) \\ket{\\psi_g}\\).</p><p>The algorithm can also be viewed through the lens of quantum singular value transformation (QSVT) whereby \\(U\\) provides a generalized block-encoding (known as a projected unitary encoding) of the amplitude \\(a\\). We can see this from \\(\\ket{\\psi_g}\\bra{\\psi_g} U \\ket{\\psi_0}\\bra{\\psi_0} = a\\ket{\\psi_g}\\bra{\\psi_0}\\). We choose to apply a polynomial \\(f(\\cdot)\\) satisfying the quantum signal processing conditions and \\(f(a)=1\\) to the block-encoded amplitude [3, Theorem 27 &amp; 28]. For example, the textbook version of amplitude amplification is recovered by setting the QSVT rotation angles to \\(\\pm \\frac{\\pi}{2}\\).<sup>1</sup> This QSVT circuit applies a degree \\(2m+1\\) Chebyshev polynomial of the first kind \\(T_{2m+1}\\) to the amplitude \\(a\\), such that \\(\\ket{\\psi_g}\\bra{\\psi_g} W^m \\ket{\\psi} = T_{2m+1}(a) \\ket{\\psi_g} = (-1)^m \\sin((2m+1)\\theta) \\ket{\\psi_g}\\) for \\(a=\\sin(\\theta)\\).</p>"},{"location":"quantum-algorithmic-primitives/amplitude-amplification-and-estimation/amplitude-amplification/#dominant-resource-cost-gatesqubits","title":"Dominant resource cost (gates/qubits)","text":"<p>The number of calls to \\(W\\) is \\(m = \\frac{\\pi}{4\\arcsin(a)} - \\frac{1}{2} = \\mathcal{O}\\left( 1/a \\right)\\) for small \\(a\\). Each call to \\(W\\) requires a call to each of \\(U, U^\\dag, R_{\\psi_0}, R_{\\psi_g}\\). Often we have \\(\\ket{\\psi_0} = \\ket{\\bar{0}}\\), and \\(U\\) acts on \\(n\\) register qubits and \\(k\\) ancilla qubits such that \\(U\\ket{\\bar{0}} = a\\ket{\\psi_g}_n\\ket{\\bar{0}}_k + b \\ket{\\perp}_{n,k}\\), where \\(\\ket{\\perp}_{n,k}\\) denotes a state orthogonal to \\(\\ket{\\bar{0}}_k\\). In this case the reflection operators are simple to implement using multi-controlled Toffoli gates.</p>"},{"location":"quantum-algorithmic-primitives/amplitude-amplification-and-estimation/amplitude-amplification/#caveats","title":"Caveats","text":"<p>The textbook version of amplitude amplification assumes that the success amplitude \\(a\\) exactly equals \\(\\sin\\left(\\pi/(4m+2)\\right)\\) for an integer \\(m\\). If this is not the case (e.g., when \\(a= 1/\\sqrt{2}\\)), we can introduce a new qubit in \\(\\ket{0}\\) and apply an \\(R_y(2\\phi)\\) gate to reduce the success probability (now defined by measuring \\(\\ket{\\psi_g}\\ket{0}\\)) to \\(a \\cos(\\phi) = \\sin\\left(\\pi/(4m'+2) \\right)\\) for an integer \\(m'\\).</p><p>In cases where we can only lower bound the success amplitude \\(a \\ge a_0\\), it is common to use fixed-point amplitude amplification [4]. This is best understood through QSVT [3, Theorem 27], where the reflection operators are replaced by parametrized phase operators \\(e^{i \\theta \\ket{\\psi_g}\\bra{\\psi_g}}\\) and \\(e^{i \\phi \\ket{\\psi_0}\\bra{\\psi_0}}\\) (it is shown in [5, Section 8.5] how these phase operators can be constructed using the corresponding controlled reflection operator. If only the uncontrolled reflection is available, a control can be added using e.g., [6, Fig.5]). The QSVT rotation angles are chosen to implement a polynomial that maps all amplitudes taking value at least \\(a_0\\) to at least \\((1-\\epsilon)\\). The fixed-point amplitude amplification circuit uses a QSVT circuit that makes \\(\\mathcal{O}\\left( \\frac{1}{a_0} \\log\\left(\\frac{1}{\\epsilon}\\right) \\right)\\) calls to \\(U, U^\\dag, e^{i \\theta \\ket{\\psi_g}\\bra{\\psi_g}}\\) and \\(e^{i \\phi \\ket{\\psi_0}\\bra{\\psi_0}}\\).</p>"},{"location":"quantum-algorithmic-primitives/amplitude-amplification-and-estimation/amplitude-amplification/#example-use-cases","title":"Example use cases","text":"<ul> <li>Combinatorial optimization.</li> <li>Convex optimization via \"minimum finding\" subroutine (see [7, Appendix C])</li> <li>Weakening cryptosystems.</li> <li>Tensor principal component analysis.</li> <li>Hamiltonian simulation using linear combinations of unitaries.</li> </ul>"},{"location":"quantum-algorithmic-primitives/amplitude-amplification-and-estimation/amplitude-amplification/#further-reading","title":"Further reading","text":"<ul> <li>Both amplitude amplification and Grover search can be viewed through the lens of quantum walks on suitably constructed graphs. The quantum walks also take the form of a product of two reflections and more generally can be understood as quantizing a Markov chain describing a classical random walk [8]. We refer the interested reader to [9, 10, 11, 12].</li> <li>Oblivious amplitude amplification: Amplitude amplification can be extended to the case of oblivious amplitude amplification (OAA) [13]. The original formulation considered a setting where one is given unitary \\(U\\) such that for any state \\(\\ket{\\psi}\\), we have  \\[\\begin{align} U \\ket{\\bar{0}_m} \\ket{\\psi} = a \\ket{\\bar{0}_m} V \\ket{\\psi} + b \\ket{\\bar{0}_m^\\perp \\phi} \\end{align}\\] <p>for a unitary operator \\(V\\). The goal is to amplify the probability for the state \\(\\ket{\\bar{0}_m} V \\ket{\\psi}\\) to 1. This is achieved through \\(\\mathcal{O}\\left( 1/a \\right)\\) applications of an operator \\(W = U (I - 2\\ket{\\bar{0}_m}\\bra{\\bar{0}_m}) U^\\dag (I - 2\\ket{\\bar{0}_m}\\bra{\\bar{0}_m})\\) applied to \\(U \\ket{\\bar{0}_m} \\ket{\\psi}\\). We see that \\(W\\) does not require reflections around the initial state \\(\\ket{\\psi}\\). We can recognize \\(U\\) as an \\(m\\)-qubit block-encoding of the operator \\(a V\\), which can be transformed to a block-encoding of \\(V\\) using quantum singular value transformation (QSVT).<sup>2</sup> The OAA subroutine is used in the context of Hamiltonian simulation via Taylor series, where it would be problematic to have to reflect around the initial state during amplification.<sup>3</sup> It is also used in [14] (applied to isometries) for simulation of open quantum systems. OAA requires the block-encoded operator being amplified to preserve state norms (i.e. it must be an isometry), as this ensures that the success probability of the operation is independent of the state to which it is applied, which in turn enables amplification without reflection around the initial state. While a block-encoding of a non-isometric operator \\(A\\) can also be amplified using QSVT [3, Theorem 30],[15], it is not possible to boost the success probability of applying \\(A\\) to unity for all input states. In the worst case, the success probability can be improved from \\(\\sigma_{\\mathrm{min}}^2\\) to \\(\\sigma_{\\mathrm{min}}^2/\\sigma_{\\mathrm{max}}^2\\), where \\(\\sigma_{\\mathrm{min}}, \\sigma_{\\mathrm{max}} \\in [0,1]\\) are the smallest and largest singular values of \\(A\\). As a result, to boost the success probability of applying \\(A\\) to unity for a general input state, we require regular amplitude amplification, involving reflections around the initial state. - While we are unaware of a standard reference for the \"exact\\\" version of amplitude amplification using an additional ancilla qubit, discussed in the caveats above, it is explained more fully in these video lectures and also in [16, Appendix A].</p> </li> </ul>"},{"location":"quantum-algorithmic-primitives/amplitude-amplification-and-estimation/amplitude-amplification/#bibliography","title":"Bibliography","text":"<ol> <li> <p>Lov K. Grover. A fast quantum mechanical algorithm for database search. In Proceedings of the 28th ACM Symposium on the Theory of Computing (STOC), 212\u2013219. 1996. arXiv: https://arxiv.org/abs/quant-ph/9605043. doi:10.1145/237814.237866.</p> </li> <li> <p>Gilles Brassard, Peter H\u00f8yer, Michele Mosca, and Alain Tapp. Quantum amplitude amplification and estimation. In Quantum Computation and Quantum Information: A Millennium Volume, volume 305 of Contemporary Mathematics Series, pages 53\u201374. AMS, 2002. doi:10.1090/conm/305/05215.</p> </li> <li> <p>Andr\u00e1s Gily\u00e9n, Yuan Su, Guang Hao Low, and Nathan Wiebe. Quantum singular value transformation and beyond: exponential improvements for quantum matrix arithmetics [full version]. arXiv: https://arxiv.org/abs/1806.01838, 2018.</p> </li> <li> <p>Theodore J. Yoder, Guang Hao Low, and Isaac L. Chuang. Fixed-point quantum search with an optimal number of queries. Physical Review Letters, 113(21):210501, 2014. arXiv: https://arxiv.org/abs/1409.3305. doi:10.1103/PhysRevLett.113.210501.</p> </li> <li> <p>Lin Lin. Lecture notes on quantum algorithms for scientific computation. arXiv: https://arxiv.org/abs/2201.08309, 2022.</p> </li> <li> <p>John M. Martyn, Zane M. Rossi, Andrew K. Tan, and Isaac L. Chuang. Grand unification of quantum algorithms. Physical Review X, 2(4):040203, 2021. arXiv: https://arxiv.org/abs/2105.02859. doi:10.1103/PRXQuantum.2.040203.</p> </li> <li> <p>Joran van Apeldoorn, Andr\u00e1s Gily\u00e9n, Sander Gribling, and Ronald de Wolf. Quantum sdp-solvers: better upper and lower bounds. Quantum, 4:230, 2020. Earlier version in FOCS'17. arXiv: https://arxiv.org/abs/1705.01843. doi:10.22331/q-2020-02-14-230.</p> </li> <li> <p>M\u00e1ri\u00f3 Szegedy. Quantum speed-up of markov chain based algorithms. In Proceedings of the 45th IEEE Symposium on Foundations of Computer Science (FOCS), 32\u201341. 2004. arXiv: https://arxiv.org/abs/quant-ph/0401053. doi:10.1109/FOCS.2004.53.</p> </li> <li> <p>Andrew M. Childs. Lecture notes on quantum algorithms. 2022. http://www.cs.umd.edu/~amchilds/qa/, accessed: 2023-05-17.</p> </li> <li> <p>Fr\u00e9d\u00e9ric Magniez, Ashwin Nayak, J\u00e9r\u00e9mie Roland, and Miklos Santha. Search via quantum walk. SIAM Journal on Computing, 40(1):142\u2013164, 2011. Earlier version in STOC'07. arXiv: https://arxiv.org/abs/quant-ph/0608026. doi:10.1137/090745854.</p> </li> <li> <p>Simon Apers, Andr\u00e1s Gily\u00e9n, and Stacey Jeffery. A unified framework of quantum walk search. In Proceedings of the 38th Symposium on Theoretical Aspects of Computer Science (STACS), 6:1\u20136:13. 2021. arXiv: https://arxiv.org/abs/1912.04233. doi:10.4230/LIPIcs.STACS.2021.6.</p> </li> <li> <p>Andr\u00e1s Gily\u00e9n. Quantum walk based search methods and algorithmic applications. Master's thesis, E\u00f6tv\u00f6s Lor\u00e1nd University, 2014. URL: http://web.cs.elte.hu/blobs/diplomamunkak/msc\\_mat/2014/gilyen\\_andras\\_pal.pdf.</p> </li> <li> <p>Dominic W. Berry, Andrew M. Childs, Richard Cleve, Robin Kothari, and Rolando D. Somma. Exponential improvement in precision for simulating sparse hamiltonians. In Proceedings of the 46th ACM Symposium on the Theory of Computing (STOC), 283\u2013292. 2014. arXiv: https://arxiv.org/abs/1312.1414. doi:10.1145/2591796.2591854.</p> </li> <li> <p>Richard Cleve and Chunhao Wang. Efficient quantum algorithms for simulating lindblad evolution. In Proceedings of the 44th International Colloquium on Automata, Languages, and Programming (ICALP), 17:1\u201317:14. 2017. arXiv: https://arxiv.org/abs/1612.09512. doi:10.4230/LIPIcs.ICALP.2017.17.</p> </li> <li> <p>Guang Hao Low and Isaac L. Chuang. Hamiltonian simulation by uniform spectral amplification. arXiv: https://arxiv.org/abs/1707.05391, 2017.</p> </li> <li> <p>Sam McArdle, Andr\u00e1s Gily\u00e9n, and Mario Berta. Quantum state preparation without coherent arithmetic. arXiv: https://arxiv.org/abs/2210.14892, 2022.</p> </li> <li> <p>Dominic W. Berry, Andrew M. Childs, Richard Cleve, Robin Kothari, and Rolando D. Somma. Simulating hamiltonian dynamics with a truncated taylor series. Physical Review Letters, 114(9):090502, 2015. arXiv: https://arxiv.org/abs/1412.4687. doi:10.1103/PhysRevLett.114.090502.</p> </li> <li> <p>Dominic W. Berry, Andrew M. Childs, and Robin Kothari. Hamiltonian simulation with nearly optimal dependence on all parameters. In Proceedings of the 56th IEEE Symposium on Foundations of Computer Science (FOCS), 792\u2013809. 2015. arXiv: https://arxiv.org/abs/1501.01715. doi:10.1109/FOCS.2015.54.</p> </li> </ol> <ol> <li> <p>These rotation angles enable a gate compilation that removes the need for the QSVT ancilla qubit.\u00a0\u21a9</p> </li> <li> <p>We note that in this interpretation, one may be concerned that the phase information of the unitary \\(V\\) is lost by transforming the singular values. This turns out not to be problematic, as the phase information of \\(V\\) can be considered stored in the basis transformation matrices present in the singular value decomposition, rather than in the diagonal singular values matrix. This is taken care of automatically using QSVT. Phases are preserved when using an odd polynomial.\u00a0\u21a9</p> </li> <li> <p>More precisely, a robust version of OAA is used which is applicable to an operator that is \\(\\epsilon\\) close to being unitary [17, 18].\u00a0\u21a9</p> </li> </ol>"},{"location":"quantum-algorithmic-primitives/amplitude-amplification-and-estimation/amplitude-estimation/","title":"Amplitude estimation","text":""},{"location":"quantum-algorithmic-primitives/amplitude-amplification-and-estimation/amplitude-estimation/#rough-overview-in-words","title":"Rough overview (in words)","text":"<p>Given a quantum subroutine that succeeds with unknown success probability, amplitude estimation performs quantum phase estimation on the operator used in amplitude amplification to learn the magnitude of the success amplitude. While the algorithm is referred to as amplitude estimation, it is often the success probability that we wish to compute, and the complexity of the algorithm is often presented accordingly. For example, the original paper introducing amplitude estimation [1] uses the variable \\(a\\) to denote the success probability. Here we denote the amplitude by \\(a\\) and the success probability \\(p = |a|^2\\). The algorithm provides a quadratic speedup over classical methods for estimating \\(p\\).</p>"},{"location":"quantum-algorithmic-primitives/amplitude-amplification-and-estimation/amplitude-estimation/#rough-overview-in-math","title":"Rough overview (in math)","text":"<p>We are given an initial state \\(\\ket{\\psi_0}\\), a target state \\(\\ket{\\psi_g}\\), and a unitary \\(U\\) (and its inverse \\(U^\\dag\\)) such that </p>\\[\\begin{equation} U\\ket{\\psi_0} = \\ket{\\psi} = a \\ket{\\psi_g} + b\\ket{\\psi_b} \\end{equation}\\]<p>where \\(\\ket{\\psi_b}\\) is a state orthogonal to the target state. We assume that we can mark the target state \\(\\ket{\\psi_g}\\) (i.e., the ability to reflect about the state). Thus, \\(|a|^2\\) is the success probability of applying \\(U\\) and measuring \\(\\ket{\\psi_g}\\). We are given the ability to implement the reflection operator around the initial state \\(R_{\\psi_0} = I - 2\\ket{\\psi_0}\\bra{\\psi_0}\\) and an operation that, when restricted to the subspace spanned by \\(\\{ \\ket{\\psi_g}, \\ket{\\psi_b} \\}\\), acts as the reflection around the target state \\(R_{\\psi_g} = I - 2\\ket{\\psi_g}\\bra{\\psi_g}\\). We can then estimate the success probability by performing quantum phase estimation on an operator \\(W = - U R_{\\psi_0} U^\\dag R_{\\psi_g}\\), from the initial state \\(U \\ket{\\psi_0} = \\ket{\\psi}\\). The standard analysis [1] proceeds by letting \\(|a|=\\sin(\\theta)\\) and \\(|b|=\\cos(\\theta)\\) (thus the phases of \\(a\\) and \\(b\\) are absorbed into \\(\\ket{\\psi_g}\\) and \\(\\ket{\\psi_b}\\) and are not determined by the following procedure) and showing that the 2D subspace spanned by \\(\\{\\ket{\\psi_g}, \\ket{\\psi_b}\\}\\) is invariant under \\(W\\), where it acts as a rotation operator </p>\\[\\begin{equation} W = \\left[\\begin{array}{cc} \\cos(2\\theta) &amp; -\\sin(2\\theta) \\\\ \\sin(2\\theta) &amp; \\cos(2\\theta) \\end{array}\\right]. \\end{equation}\\]<p>This operator has eigenvalues \\(e^{\\pm 2 i \\theta}\\), and we can estimate \\(\\theta\\) to additive error \\(\\epsilon\\) through quantum phase estimation. The estimate for \\(\\theta\\) can be converted into an estimate for \\(|a|\\), or for the success probability \\(p=|a|^2\\), which is often the quantity of interest.</p>"},{"location":"quantum-algorithmic-primitives/amplitude-amplification-and-estimation/amplitude-estimation/#dominant-resource-cost-gatesqubits","title":"Dominant resource cost (gates/qubits)","text":"<p>The classical approach for learning the probability \\(p\\) to precision \\(\\epsilon\\) has time complexity \\(M = \\mathcal{O}\\left( 1/\\epsilon^2 \\right)\\), where the basic idea is to perform \\(M\\) incoherent repetitions of applying \\(U\\) and measuring in the \\(\\ket{\\psi_g}, \\ket{\\psi_b}\\) basis. Amplitude estimation provides a quadratic speedup, learning the probability (and amplitude) with time complexity \\(M = \\mathcal{O}\\left( 1/\\epsilon \\right)\\). The textbook variant has a constant success probability, which can be boosted to \\(1-\\delta\\) with \\(\\mathcal{O}\\left( \\log(1/\\delta) \\right)\\) overhead through standard methods (e.g., probability amplification by majority voting).</p><p>More precisely, we can follow the analysis in [1] to show that to learn \\(|a|\\) to error \\(\\epsilon\\) we require \\(M\\) controlled applications of the walk operator \\(W\\) where \\(M\\) satisfies<sup>1</sup> </p>\\[\\begin{equation} \\label{eq:AE_amplitude_bound} \\epsilon \\leq \\frac{\\pi \\sqrt{1-a^2}}{M} + \\frac{a\\pi^2}{2M^2}. \\end{equation}\\]<p>The algorithm succeeds with probability \\(8/\\pi^2\\). We see that for \\(a \\approx 1-\\mathcal{O}\\left( \\epsilon \\right)\\), a further quadratic improvement is obtained (i.e., \\(M = \\mathcal{O}\\left( 1/\\sqrt{\\epsilon} \\right)\\)).</p><p>To learn the success probability \\(p=|a|^2\\) to error \\(\\epsilon\\) we require \\(M\\) controlled applications of the walk operator \\(W\\) where \\(M\\) satisfies [1] </p>\\[\\begin{equation} \\label{eq:AE_probability_bound} \\epsilon \\leq \\frac{2\\pi \\sqrt{p(1-p)}}{M} + \\frac{\\pi^2}{M^2}. \\end{equation}\\]<p>The algorithm succeeds with probability \\(8/\\pi^2\\). Similar to above, if \\(p \\approx \\mathcal{O}\\left( \\epsilon \\right)\\) or \\(p \\approx 1-\\mathcal{O}\\left( \\epsilon \\right)\\), we have that \\(M = \\mathcal{O}\\left( 1/\\sqrt{\\epsilon} \\right)\\).<sup>2</sup></p><p>A common setting is the case where \\(\\ket{\\psi_0} = \\ket{\\bar{0}}\\), and \\(U\\) acts on \\(n\\) register qubits and \\(k\\) ancilla qubits such that \\(U\\ket{\\bar{0}} = a\\ket{\\psi_g}\\ket{\\bar{0}}_k + b \\ket{\\psi_b}\\ket{\\bar{0}^\\perp}_k\\). In this case, the reflection operators are simple to implement, and \\(W\\) can be controlled by making these reflections controlled (adding another control qubit to a multicontrol-CZ gate). We require \\(\\log(M)\\) ancilla qubits for phase estimation (which can be reduced using modern variants, see below and [2]).</p>"},{"location":"quantum-algorithmic-primitives/amplitude-amplification-and-estimation/amplitude-estimation/#caveats","title":"Caveats","text":"<p>The textbook version of amplitude estimation described above produces biased estimates of \\(|a|\\) and \\(p\\). This is partly inherited from the biased nature of textbook quantum phase estimation (see caveats). However, even if unbiased variants of phase estimation are used, the amplitude and probability estimates are not immediately unbiased, as they are obtained by applying nonlinear functions to the estimate of the phase. Unbiased variants of amplitude [2] and probability estimation [3] have been developed to address this.</p><p>The variant of amplitude estimation described above is also \"destructive\" in the sense that the output state is collapsed into a state \\(\\frac{1}{\\sqrt{2}}(\\pm i \\ket{\\psi_g} + \\ket{\\psi_b}) \\neq \\ket{\\psi_0}, \\ket{\\psi}\\). A nondestructive variant may be desired if the initial state is expensive to prepare and we require coherent or incoherent repetitions of amplitude estimation. Nondestructive variants have been developed in [4, 5, 2].</p>"},{"location":"quantum-algorithmic-primitives/amplitude-amplification-and-estimation/amplitude-estimation/#example-use-cases","title":"Example use cases","text":"<ul> <li>Approximate counting of solutions marked by an oracle (e.g., topological data analysis, combinatorial optimization).</li> <li>Amplitude estimation provides a quadratic speedup for Monte Carlo estimation [6, 7] with uses in pricing financial assets. The general idea is to prepare a state \\(\\ket{\\psi} = \\sum_x \\sqrt{p(x) f(x)} \\ket{x}\\ket{0} + \\ket{\\phi 0^\\perp}\\) where \\(\\mathbb{E}[f(x)] = \\sum_x p(x) f(x)\\) represents the expectation value we wish to evaluate using Monte Carlo sampling and corresponds to the probability that we measure the second register in state \\(\\ket{0}\\). Hence, amplitude estimation provides a quadratic speedup for estimating this quantity.</li> <li>A special case of amplitude estimation is overlap estimation [8], where the goal is to measure \\(\\bra{\\psi_0} U \\ket{\\psi_0} = \\braket{\\psi}{\\psi_0}\\). This can be viewed as an application of amplitude amplification, where \\(\\ket{\\psi_g} = \\ket{\\psi_0}\\). As a result, we only require the ability to implement \\(R_{\\psi_0} = I - 2\\ket{\\psi_0}\\bra{\\psi_0}\\), \\(U, U^\\dag\\) (or equivalently \\(R_{\\psi_0}\\) and \\(R_{\\psi}\\)). Note that in overlap estimation, one additionally wants to determine the phase of \\(a\\), which can be obtained by applying amplitude estimation on a controlled variant of \\(U\\), as outlined in [8]. Overlap estimation can be used for estimating observables, e.g., in quantum chemistry.</li> <li>A generalization of amplitude estimation, via the quantum gradient algorithm, forms a core subroutine in some approaches for quantum state tomography [3]. Pure state tomography can be thought of as a generalization of amplitude estimation, in which we seek to learn all amplitudes individually, rather than only a single aggregate quantity.</li> </ul>"},{"location":"quantum-algorithmic-primitives/amplitude-amplification-and-estimation/amplitude-estimation/#further-reading","title":"Further reading","text":"<ul> <li>Variants of amplitude estimation using fewer ancilla qubits (including ancilla-free approaches), or with depth-repetition tradeoffs have been proposed. For a summary of these approaches and their unification within the QSVT framework, see [2].</li> </ul>"},{"location":"quantum-algorithmic-primitives/amplitude-amplification-and-estimation/amplitude-estimation/#bibliography","title":"Bibliography","text":"<ol> <li> <p>Gilles Brassard, Peter H\u00f8yer, Michele Mosca, and Alain Tapp. Quantum amplitude amplification and estimation. In Quantum Computation and Quantum Information: A Millennium Volume, volume 305 of Contemporary Mathematics Series, pages 53\u201374. AMS, 2002. doi:10.1090/conm/305/05215.</p> </li> <li> <p>Patrick Rall and Bryce Fuller. Amplitude estimation from quantum signal processing. Quantum, 7:937, 3 2023. arXiv: https://arxiv.org/abs/2207.08628. URL: https://doi.org/10.22331/q-2023-03-02-937, doi:10.22331/q-2023-03-02-937.</p> </li> <li> <p>Joran van Apeldoorn, Arjan Cornelissen, Andr\u00e1s Gily\u00e9n, and Giacomo Nannicini. Quantum tomography using state-preparation unitaries. In Proceedings of the 34th ACM-SIAM Symposium on Discrete Algorithms (SODA), 1265\u20131318. 2023. arXiv: https://arxiv.org/abs/2207.08800. doi:10.1137/1.9781611977554.ch47.</p> </li> <li> <p>Aram W. Harrow and Annie Y. Wei. Adaptive quantum simulated annealing for bayesian inference and estimating partition functions. In Proceedings of the 31st ACM-SIAM Symposium on Discrete Algorithms (SODA), 193\u2013212. 2020. arXiv: https://arxiv.org/abs/1907.09965. URL: https://epubs.siam.org/doi/abs/10.1137/1.9781611975994.12, arXiv:https://epubs.siam.org/doi/pdf/10.1137/1.9781611975994.12, doi:10.1137/1.9781611975994.12.</p> </li> <li> <p>Arjan Cornelissen and Yassine Hamoudi. A sublinear-time quantum algorithm for approximating partition functions. In Proceedings of the 34th ACM-SIAM Symposium on Discrete Algorithms (SODA), 1245\u20131264. 2023. arXiv: https://arxiv.org/abs/2207.08643. URL: https://epubs.siam.org/doi/abs/10.1137/1.9781611977554.ch46, doi:10.1137/1.9781611977554.ch46.</p> </li> <li> <p>Ashley Montanaro. Quantum speedup of monte carlo methods. Proceedings of the Royal Society A, 2015. arXiv: https://arxiv.org/abs/1504.06987. doi:10.1098/rspa.2015.0301.</p> </li> <li> <p>Robin Kothari and Ryan O'Donnell. Mean estimation when you have the source code; or, quantum monte carlo methods. In Proceedings of the 34th ACM-SIAM Symposium on Discrete Algorithms (SODA), 1186\u20131215. 2023. arXiv: https://arxiv.org/abs/2208.07544. URL: https://epubs.siam.org/doi/abs/10.1137/1.9781611977554.ch44, doi:10.1137/1.9781611977554.ch44.</p> </li> <li> <p>Emanuel Knill, Gerardo Ortiz, and Rolando D. Somma. Optimal quantum measurements of expectation values of observables. Physical Review A, 75:012328, 1 2007. arXiv: https://arxiv.org/abs/quant-ph/0607019. URL: https://link.aps.org/doi/10.1103/PhysRevA.75.012328, doi:10.1103/PhysRevA.75.012328.</p> </li> </ol> <ol> <li> <p>Specifically, Lemma 7 of [1] shows that if \\(\\theta = \\arcsin(|a|)\\) and \\(\\tilde{\\theta} = \\arcsin(|\\tilde{a}|)\\), then \\(|\\theta-\\tilde{\\theta}|\\leq \\eta\\) implies \\(|a^2-\\tilde{a}^2| \\leq 2\\eta\\sqrt{a^2(1-a^2)}+\\eta^2\\). This is easily adapted to show that it also implies \\(|a-\\tilde{a}|\\leq \\eta\\sqrt{1-a^2} + a\\eta^2/2\\). They show that with probability at least \\(8/\\pi^2\\), \\(\\theta\\) is learned up to additive error at most \\(\\eta = \\pi/M\\) with \\(M\\) calls to \\(W\\), which together with the above expressions implies Eqs. [eq:AE_amplitude_bound] and [eq:AE_probability_bound].\u00a0\u21a9</p> </li> <li> <p>We can compare to the classical approach of estimating \\(p\\) by flipping a \\(p\\)-biased coin \\(M\\) times. Letting \\(\\tilde{p}\\) denote the estimate, which has mean \\(p\\) and variance \\(p(1-p)/M\\), Chebyshev's inequality implies that \\(|p-\\tilde{p}|\\leq \\epsilon\\) with probability at least \\(8/\\pi^2\\) as long as \\(M \\geq C p(1-p)/\\epsilon^2\\) where \\(C = 1/(1-8/\\pi^2)\\). Thus, when \\(p \\approx \\mathcal{O}\\left( \\epsilon \\right)\\) or \\(p\\approx 1-\\mathcal{O}\\left( \\epsilon \\right)\\), the classical approach achieves \\(M \\sim 1/\\epsilon\\), and the quantum speedup is never more than quadratic.\u00a0\u21a9</p> </li> </ol>"},{"location":"quantum-algorithmic-primitives/amplitude-amplification-and-estimation/introduction/","title":"Amplitude amplification and estimation","text":"<p>Quantum amplitude amplification and estimation provide means to boost or extract the amplitude of a marked quantum state that is produced in superposition with orthogonal state(s) by a unitary matrix. They are among the most widely used quantum primitives, providing quadratic speedups over classical algorithms in many settings.</p>"},{"location":"quantum-algorithmic-primitives/hamiltonian-simulation/introduction/","title":"Hamiltonian simulation","text":"<p>The task of Hamiltonian simulation is to approximately compile the evolution under a Hamiltonian \\(H(t)\\), for time \\(t\\), into a sequence of quantum gates. For a time-independent Hamiltonian, solving the Schr\u00f6dinger equation yields a time evolution operator \\(U(t)=e^{-iHt}\\). In this section we will discuss the equivalent operator \\(U(t) = e^{iHt}\\), which is the more common definition in an algorithmic setting. The Hamiltonian of interest can arise from physical systems (e.g., quantum chemistry, condensed matter systems, or quantum field theories) but may also be constructed for other applications, such as differential equation simulation. Quantum simulation does not give full access to the amplitudes of the wavefunction during the simulation, unlike classical approaches based on exact diagonalization (or similar methods). Instead, we are only able to measure observables with respect to the time-evolved state, or use the state as an input to other quantum subroutines. Nevertheless, there are no known efficient classical methods that achieve this for general local or sparse Hamiltonians, suggesting an exponential quantum speedup. In fact, as a quantum computation can be expressed as a time evolution under a sequence of local (time-dependent) Hamiltonians, quantum simulation (i.e. time evolution and measurement of a given observable) is a BQP-complete problem.</p><p>Hamiltonian simulation algorithms require access to the Hamiltonian. There are three commonly used input models. The Pauli input model assumes that the Hamiltonian is given classically as a sum of products of Pauli operators, e.g. \\(H = \\sum_l h_l H_l\\), where \\(h_l\\) are coefficients and \\(H_l\\) are multiqubit Pauli products. The \\(d\\)-sparse access model assumes that the Hamiltonian is a sparse matrix with at most \\(d\\) nonzero elements per row or column. We require that the locations of the nonzero elements and their values are efficient to compute classically. The density matrix access model assumes that the Hamiltonian corresponds to a density matrix, which we are either provided access to copies of [1] or given a unitary that prepares a purification of the density matrix [2]. All of these input models can be used to prepare block-encodings of the Hamiltonian, which provides a standard form access model favored by some algorithms for Hamiltonian simulation (e.g. qubitization with quantum signal processing) [2].</p><p>Hamiltonian simulation can be used as a subroutine in a range of algorithms including: quantum phase estimation, quantum linear system solvers, Gibbs state preparation, and the quantum adiabatic algorithm. We remark that some of these algorithms are implicitly using Hamiltonian simulation to provide coherent, unitary access to the Hamiltonian. This can be particularly useful if few ancilla qubits are available, which may inhibit the use of some approaches to coherently access the Hamiltonian (e.g. block-encodings based on linear-combinations of unitaries) but does not prevent the use of Hamiltonian simulation based on product formulae.</p><p>Each algorithm has its own advantages and disadvantages, as described at a high level in Table 0.7. Specific optimizations of each algorithm may be available for a given Hamiltonian. One can also consider hybridized methods combining two or more of the algorithms [3, 4, 5, 6, 7, 8]. There are also other methods for Hamiltonian simulation, such as quantum walks [9, 10, 11] or density matrix\u2013based Hamiltonian simulation [1, 12], which we do not discuss, due to their less widespread use as algorithmic primitives for the applications discussed elsewhere in this document.</p> <p></p> <p>|                                       |                                                                                                         |                         qDRIFT                          |                          Taylor and Dyson series                          |              QSP/QSVT               | | :-\u2014\u2013\u2014--\u2014\u2013\u2014--\u2014\u2013\u2014--\u2014-: | :-\u2014\u2013\u2014--\u2014\u2013\u2014--\u2014\u2013\u2014--\u2014\u2013\u2014--\u2014\u2013\u2014--\u2014\u2013\u2014--\u2014\u2013\u2014--\u2014\u2013\u2014--\u2014\u2013\u2014--\u2014\u2013\u2014--: | :-\u2014\u2013\u2014--\u2014\u2013\u2014--\u2014\u2013\u2014--\u2014\u2013\u2014--\u2014\u2013\u2014--\u2014\u2013-: | :-\u2014\u2013\u2014--\u2014\u2013\u2014--\u2014\u2013\u2014--\u2014\u2013\u2014--\u2014\u2013\u2014--\u2014\u2013\u2014--\u2014\u2013\u2014--\u2014-: | :-\u2014\u2013\u2014--\u2014\u2013\u2014--\u2014\u2013\u2014--\u2014\u2013-: | |             # Qubits             |                                      \\(\\mathcal{O}\\left( n \\right)\\)                                      |                \\(\\mathcal{O}\\left( n \\right)\\)                |     \\(\\mathcal{O}\\left( n + \\log(\\nrm{H}_1 t\\epsilon^{-1})\\log(L) \\right)\\)     | \\(\\mathcal{O}\\left( n + \\log(L) \\right)\\) | |                                       |                                                                                                         |                                                             |                                                                               |                                         | |                 model                 |                                                                                                         |                                                             |                                                                               |                                         | |                Sparse                 |                                                                                                         |                                                             |                                                                               |                                         | |                Sparse                 |                                                                                                         |                                                             |                                                                               |                                         | |                Sparse                 |                                                                                                         |                                                             |                                                                               |                                         | |        Purified density matrix        |                                                                                                         |                                                             |                                                                               |                                         | |              Scaling              | \\(\\mathcal{O}\\left( 5^{2k}nL \\nrm{H}_1 t \\left(\\nrm{H}_1 t \\epsilon^{-1} \\right)^{\\frac{1}{2k}} \\right)\\) | \\(\\mathcal{O}\\left(  n\\nrm{H}_1^2 t^2\\epsilon^{-1}  \\right)\\) | \\(\\widetilde{\\mathcal{O}}\\left(  \\nrm{H}_1 t n L \\log(\\epsilon^{-1})  \\right)\\) |                                         | |               Pros                |                                                                                                         |                                                             |                                                                               |                                         | |        Simple implementation.         |                                                                                                         |                                                             |                                                                               |                                         | |        Empirical performance.         |                                                                                                         |                                                             |                                                                               |                                         | |        Minimal ancilla qubits.        |                                                                                                         |                                                             |                                                                               |                                         | |          No ancilla qubits.           |                                                                                                         |                                                             |                                                                               |                                         | |      Time-dependent simulations.      |                                                                                                         |                                                             |                                                                               |                                         | |   Few ancilla qubits for algorithm.   |                                                                                                         |                                                             |                                                                               |                                         | |               Cons                |                                                                                                         |                                                             |                                                                               |                                         | | Exponential prefactor (in order \\(k\\)). |                                       Scaling with \\(t, \\epsilon\\).                                       |                    Many ancilla qubits.                     |                                                                               |                                         | | Ancilla/gate cost of block-encoding.  |                                                                                                         |                                                             |                                                                               |                                         |</p> <p>Table: High-level comparison of Hamiltonian simulation techniques. For the stated complexity, we consider evolution \\(U(t)=e^{iHt}\\) for time \\(t\\) under a time-independent Hamiltonian \\(H\\) on \\(n\\) qubits, given as a sum of \\(L\\) Pauli products \\(H = \\sum_{j=1}^L h_j P_j\\). The evolution is approximate to error \\(\\epsilon\\) in the spectral norm (diamond norm for qDRIFT). We define \\(\\smash{\\nrm{H}_1 = \\sum_{j=1}^L |h_j|}\\). In specific applications it may be possible to reduce the number of qubits and/or gate complexity further by exploiting knowledge of the system, such as symmetries, commutation structure, or energy scales. For example, the factor of \\(n\\) present in the above complexities may be reduced by exploiting locality in the Pauli product terms of the Hamiltonian. </p>"},{"location":"quantum-algorithmic-primitives/hamiltonian-simulation/introduction/#bibliography","title":"Bibliography","text":"<ol> <li> <p>Seth Lloyd, Masoud Mohseni, and Patrick Rebentrost. Quantum principal component analysis. Nature Physics, 10:631\u2013633, 2014. arXiv: https://arxiv.org/abs/1307.0401. doi:10.1038/nphys3029.</p> </li> <li> <p>Guang Hao Low and Isaac L. Chuang. Hamiltonian simulation by qubitization. Quantum, 3:163, 2019. arXiv: https://arxiv.org/abs/1610.06546. doi:10.22331/q-2019-07-12-163.</p> </li> <li> <p>Guang Hao Low and Nathan Wiebe. Hamiltonian simulation in the interaction picture. arXiv: https://arxiv.org/abs/1805.00675, 2018.</p> </li> <li> <p>Guang Hao Low, Vadym Kliuchnikov, and Nathan Wiebe. Well-conditioned multiproduct hamiltonian simulation. arXiv: https://arxiv.org/abs/1907.11679, 2019.</p> </li> <li> <p>Yingkai Ouyang, David R. White, and Earl T. Campbell. Compilation by stochastic hamiltonian sparsification. Quantum, 4:235, 2 2020. arXiv: https://arxiv.org/abs/1910.06255. URL: https://doi.org/10.22331/q-2020-02-27-235, doi:10.22331/q-2020-02-27-235.</p> </li> <li> <p>Matthew Hagan and Nathan Wiebe. Composite quantum simulations. arXiv: https://arxiv.org/abs/2206.06409, 2022.</p> </li> <li> <p>Abhishek Rajput, Alessandro Roggero, and Nathan Wiebe. Hybridized methods for quantum simulation in the interaction picture. Quantum, 6:780, 2022. arXiv: https://arxiv.org/abs/2109.03308. doi:10.22331/q-2022-08-17-780.</p> </li> <li> <p>Jacob Watkins, Nathan Wiebe, Alessandro Roggero, and Dean Lee. Time-dependent hamiltonian simulation using discrete clock constructions. arXiv: https://arxiv.org/abs/2203.11353, 2022.</p> </li> <li> <p>Andrew M. Childs. On the relationship between continuous- and discrete-time quantum walk. Communications in Mathematical Physics, 294(2):581\u2013603, 2010. arXiv: https://arxiv.org/abs/0810.0312. doi:10.1007/s00220-009-0930-1.</p> </li> <li> <p>Dominic W. Berry and Andrew M. Childs. Black-box hamiltonian simulation and unitary implementation. Quantum Information and Computation, 12(1&amp;2):29\u201362, 2012. arXiv: https://arxiv.org/abs/0910.4157. doi:10.26421/QIC12.1-2.</p> </li> <li> <p>Dominic W. Berry, Andrew M. Childs, and Robin Kothari. Hamiltonian simulation with nearly optimal dependence on all parameters. In Proceedings of the 56th IEEE Symposium on Foundations of Computer Science (FOCS), 792\u2013809. 2015. arXiv: https://arxiv.org/abs/1501.01715. doi:10.1109/FOCS.2015.54.</p> </li> <li> <p>Shelby Kimmel, Cedric Yen-Yu Lin, Guang Hao Low, Maris Ozols, and Theodore J. Yoder. Hamiltonian simulation with optimal sample complexity. npj Quantum Information, 3(1):13, 2017. arXiv: https://arxiv.org/abs/1608.00281. doi:10.1038/s41534-017-0013-7.</p> </li> </ol>"},{"location":"quantum-algorithmic-primitives/hamiltonian-simulation/product-formulae/","title":"Product formulae","text":""},{"location":"quantum-algorithmic-primitives/hamiltonian-simulation/product-formulae/#rough-overview-in-words","title":"Rough overview (in words)","text":"<p>Product formulae (or Trotter\u2013Suzuki formulae/Trotterization) [1], are the most commonly used approach for Hamiltonian simulation and are applicable to Hamiltonians in the Pauli and sparse access models (see below for definitions of these models). Product formulae divide the evolution into a repeating sequence of short unitary evolutions under subterms of the Hamiltonian. These subterm evolutions have a known decomposition into elementary quantum gates. The error in product formulae depends on the commutators between different terms in the decomposition; if all of the terms in the Hamiltonian commute, product formulae are exact.</p><p>Product formula approaches have also been extended to treat time-dependent Hamiltonians [2, 3, 4, 5, 6]. In the following discussion, we will restrict our focus to the time-independent case, noting that the time-dependent approaches are executed in the same way, but have a slightly more complex error analysis.</p>"},{"location":"quantum-algorithmic-primitives/hamiltonian-simulation/product-formulae/#rough-overview-in-math","title":"Rough overview (in math)","text":"<p>Given a Hamiltonian \\(H\\), desired evolution time \\(t\\), and error \\(\\epsilon\\), return a circuit \\(U(t)\\) made of elementary gates such that </p>\\[\\begin{align} \\nrm{ U(t) - \\mathrm{e}^{\\mathrm{i} H t} } \\le \\epsilon\\,, \\end{align}\\]<p>In the above, we use the operator norm \\(\\nrm{\\cdot}\\) (the maximal singular value) to quantify the quality of approximation, which controls the error for arbitrary input states (in trace distance) and for observables. This worst-case metric is mathematically convenient, but, as discussed below, tighter bounds may be obtained by using error metrics more closely aligned with the specification of the problem.</p><p>A product formula generates \\(U(t)\\) through a product of easy-to-implement evolutions under terms in the Hamiltonian. For a Hamiltonian decomposition \\(H = \\sum_{j=1}^L H_j\\) with \\(L\\) terms, the first-order product formula with \\(r\\) steps is </p>\\[\\begin{equation} S_1(t) = \\left( \\prod\\nolimits_{j=1}^L e^{iH_jt/r } \\right)^r. \\end{equation}\\]<p>The error in the first-order product formula is upper bounded as [7] </p>\\[\\begin{equation} \\nrm{S_1(t) - e^{iHt} } \\leq \\frac{t^2}{2r} \\sum_i^L \\left\\lVert \\sum_{j&gt;i}^L [H_i, H_j] \\right\\rVert \\leq \\frac{\\nrm{H}_1^2 t^2}{2r} \\end{equation}\\]<p>where \\(\\nrm{H}_1 := \\sum_{j=1}^L \\nrm{H_j}\\). Higher-order formulae can be defined recursively and are referred to as \\((2k)\\)th-order product formulae. The error in a recursively defined \\((2k)\\)th-order product formula is bounded by [7] </p>\\[\\begin{equation} \\nrm{S_{2k}(t) - e^{iHt} } = \\mathcal{O}\\left( \\frac{\\nrm{H}_1^{2k+1} t^{2k+1}}{r^{2k}} \\right). \\end{equation}\\]<p>Product formulae can be applied to \\(d\\)-sparse Hamiltonians (at most \\(d\\) nonzero elements per row/column) with efficiently row-computable nonzero elements [8]. Access to the nonzero elements of the Hamiltonian is provided via oracles \\(O_f\\) and \\(O_H\\). The oracle \\(O_f\\) returns the column index (\\(j\\)) of the \\(k \\in \\{1,...,d\\}\\)th nonzero element in row \\(i\\). The oracle \\(O_H\\) returns the value of the matrix element \\(H_{ij}\\). </p>\\[\\begin{align} O_f &amp; : O_f \\ket{k} \\ket{i} \\ket{0} = \\ket{k} \\ket{i} \\ket{j} \\\\ O_H &amp; : O_H \\ket{i}\\ket{j}\\ket{0} = \\ket{i}\\ket{j}\\ket{H_{ij}} \\end{align}\\]<p>Using graph-coloring algorithms, a \\(d\\)-sparse Hamiltonian \\(H\\) can be efficiently decomposed into a sum of efficiently simulable Hamiltonians [9, 10].</p><p>As a special case of the \\(d\\)-sparse access model, one can consider Hamiltonians given as a linear combination of \\(L\\) Pauli terms \\(H = \\sum_{j=1}^L H_j = \\sum_{j=1}^L \\alpha_j P_j\\), as each Pauli tensor product is already a \\(1\\)-sparse matrix (so in this case, \\(d\\leq L\\)). Time evolution under each Pauli term (or in some cases, groups of Pauli terms) can be simulated efficiently, thus simplifying the \\(d\\)-sparse construction by removing the need for oracles \\(O_f\\) and \\(O_H\\).</p>"},{"location":"quantum-algorithmic-primitives/hamiltonian-simulation/product-formulae/#dominant-resource-cost-gatesqubits","title":"Dominant resource cost (gates/qubits)","text":"<p>For an \\(n\\)-qubit Hamiltonian, product formulae act on \\(n\\) qubits. In the Pauli access model, no additional ancilla qubits are required. In the sparse access model, ancilla qubits may be required to implement the oracles \\(O_f\\) and \\(O_H\\) and to implement time evolution under \\(1\\)-sparse Hamiltonians \\(H_j\\).</p><p>The gate complexity is obtained by choosing the number of Trotter steps \\(r\\) sufficiently large to obtain an error \\(\\epsilon\\) and multiplying by the complexity of implementing each step of the product formula. It is necessary to balance the improved asymptotic scaling with \\(t\\) (approaches linear dependence) and \\(\\epsilon\\) of higher-order Trotter formulae against the exponentially growing prefactor of the higher-order formulae. In practical simulations of chemistry, condensed matter systems, or quantum field theories, a low-order formula (2nd\u20136th) typically minimizes the gate count.</p><p>A recursively defined \\((2k)\\)th-order product formula (the first-order formula is given by \\(k=1/2\\), and is the base case) for simulating a \\(d\\)-sparse Hamiltonian for time \\(t\\) to accuracy \\(\\epsilon\\) requires [10] </p>\\[\\begin{equation} \\mathcal{O}\\left( 5^{2k} d^2 (d + \\log^*n) \\nrm{H}t \\left(\\frac{d \\nrm{H} t}{\\epsilon} \\right)^{1/2k} \\right) \\end{equation}\\]<p>calls to the oracles \\(O_f\\) and \\(O_H\\), where \\(\\log^*\\) is the iterated logarithm.<sup>1</sup></p><p>A recursively defined \\((2k)\\)th-order product formula for simulating an \\(L\\)-term Hamiltonian in the Pauli access model for time \\(t\\) to accuracy \\(\\epsilon\\) requires [7] </p>\\[\\begin{equation} \\mathcal{O}\\left( 5^{2k} nLt\\left(\\frac{t \\alpha_{\\mathrm{comm},k}}{\\epsilon} \\right)^{1/2k} \\right) \\end{equation}\\]<p>elementary single and two-qubit gates, where \\(\\alpha_{\\mathrm{comm},k} := \\sum_{i_1, i_2,\\ldots, i_{2k+1}} \\nrm{[H_{i_{2k+1}},\\ldots [H_{i_2}, H_{i_1}]]}\\). The dependence on \\(\\alpha_{\\mathrm{comm},k}\\) can be tightened and calculated for lower-order formulae (see [7] for full calculations). The dependence on \\(n\\) can be reduced to \\(w\\) for local Hamiltonians with Pauli terms that each act on at most \\(w\\) qubits.</p>"},{"location":"quantum-algorithmic-primitives/hamiltonian-simulation/product-formulae/#caveats","title":"Caveats","text":"<p>The error bounds of product formulae in the Pauli access model have been the object of significant investigation. Evaluating the tightest spectral norm bounds requires computing a large number of commutators between the terms in the Hamiltonian, which can be computationally intensive. Numerical simulations have shown that the commutator bounds can be loose by several orders of magnitude for chemical [11, 12] or spin [13] systems.</p><p>The spectral norm is the worst-case metric; it is an active area of research to find error metrics better suited to the problem at hand. For example, one may consider the average-case error over random input states [14, 15] by the normalized Frobenius norm \\(\\nrm{U(t) - \\mathrm{e}^{\\mathrm{i} H t}}_{F}/\\sqrt{2^n}\\). Recently, in [14] it was shown that the average-case error can be much smaller than the worst-case error for systems with large connectivity. More directly, one can also compute the Trotter error associated with input states from the low-energy [16] or low-particle-number subspace [17, 18].</p><p>The gate counts of product formulae approaches can also be reduced by grouping together mutually commuting terms such that they can be implemented using fewer gates than would be required to implement all the terms individually [19, 20, 21]. One can also reduce the number of Trotter steps required by randomizing the ordering of the terms [22, 23, 6] (although this must be balanced against any compilation benefits that may be obtained from a fixed ordering).</p>"},{"location":"quantum-algorithmic-primitives/hamiltonian-simulation/product-formulae/#example-use-cases","title":"Example use cases","text":"<ul> <li>Physical systems simulation: quantum chemistry, condensed matter systems, quantum field theories.</li> <li>Algorithms: quantum phase estimation, quantum linear system solvers, Gibbs state preparation, quantum adiabatic algorithm.</li> </ul>"},{"location":"quantum-algorithmic-primitives/hamiltonian-simulation/product-formulae/#further-reading","title":"Further reading","text":"<ul> <li>A rigorous derivation of the error in product formulae [7].</li> <li>A comparison of product formula methods with other approaches to Hamiltonian simulation for a concrete problem of interest [13].</li> <li>Video lectures on Product formulae for Hamiltonians in the Pauli access model and Product formulae for \\(d\\)-sparse Hamiltonians.</li> </ul>"},{"location":"quantum-algorithmic-primitives/hamiltonian-simulation/product-formulae/#bibliography","title":"Bibliography","text":"<ol> <li> <p>Seth Lloyd. Universal quantum simulators. Science, 273(5278):1073\u20131078, 1996. doi:10.1126/science.273.5278.1073.</p> </li> <li> <p>J Huyghebaert and H De Raedt. Product formula methods for time-dependent schrodinger problems. Journal of Physics A: Mathematical and Theoretical, 23(24):5777, 1990. doi:10.1088/0305-4470/23/24/019.</p> </li> <li> <p>Nathan Wiebe, Dominic Berry, Peter H\u00f8yer, and Barry C Sanders. Higher order decompositions of ordered operator exponentials. Journal of Physics A: Mathematical and Theoretical, 43(6):065203, 1 2010. arXiv: https://arxiv.org/abs/0812.0562. URL: https://dx.doi.org/10.1088/1751-8113/43/6/065203, doi:10.1088/1751-8113/43/6/065203.</p> </li> <li> <p>Dave Wecker, Matthew B. Hastings, Nathan Wiebe, Bryan K. Clark, Chetan Nayak, and Matthias Troyer. Solving strongly correlated electron models on a quantum computer. Physical Review A, 92:062318, 12 2015. arXiv: https://arxiv.org/abs/1506.05135. URL: https://link.aps.org/doi/10.1103/PhysRevA.92.062318, doi:10.1103/PhysRevA.92.062318.</p> </li> <li> <p>Dong An, Di Fang, and Lin Lin. Time-dependent unbounded hamiltonian simulation with vector norm scaling. Quantum, 5:459, 5 2021. arXiv: https://arxiv.org/abs/2012.13105. URL: https://doi.org/10.22331/q-2021-05-26-459, doi:10.22331/q-2021-05-26-459.</p> </li> <li> <p>David Poulin, Angie Qarry, Rolando Somma, and Frank Verstraete. Quantum simulation of time-dependent hamiltonians and the convenient illusion of hilbert space. Physical Review Letters, 106:170501, 4 2011. arXiv: https://arxiv.org/abs/1102.1360. URL: https://link.aps.org/doi/10.1103/PhysRevLett.106.170501, doi:10.1103/PhysRevLett.106.170501.</p> </li> <li> <p>Andrew M. Childs, Yuan Su, Minh C. Tran, Nathan Wiebe, and Shuchen Zhu. Theory of trotter error with commutator scaling. Physical Review X, 2 2021. arXiv: https://arxiv.org/abs/1912.08854. doi:10.1103/physrevx.11.011020.</p> </li> <li> <p>Dorit Aharonov and Amnon Ta\u2010Shma. Adiabatic quantum state generation. SIAM Journal on Computing, 37(1):47\u201382, 2007. Earlier version in STOC'03, arXiv: https://arxiv.org/abs/quant-ph/0301023. doi:10.1137/060648829.</p> </li> <li> <p>Dominic W. Berry, Graeme Ahokas, Richard Cleve, and Barry C. Sanders. Efficient quantum algorithms for simulating sparse hamiltonians. Communications in Mathematical Physics, 270(2):359\u2013371, 2007. arXiv: https://arxiv.org/abs/quant-ph/0508139. doi:10.1007/s00220-006-0150-x.</p> </li> <li> <p>Andrew M. Childs and Robin Kothari. Simulating sparse hamiltonians with star decompositions. In Wim van Dam, Vivien M. Kendon, and Simone Severini, editors, Proceedings of the 5th Conference on the Theory of Quantum Computation, Communication, and Cryptography (TQC), 94\u2013103. Berlin, Heidelberg, 2011. Springer Berlin Heidelberg. arXiv: https://arxiv.org/abs/1003.3683. doi:10.1007/978-3-642-18073-6\\_8.</p> </li> <li> <p>Ryan Babbush, Jarrod McClean, Dave Wecker, Al\u00e1n Aspuru-Guzik, and Nathan Wiebe. Chemical basis of trotter-suzuki errors in quantum chemistry simulation. Physical Review A, 91:022311, 2 2015. arXiv: https://arxiv.org/abs/1410.8159. doi:10.1103/PhysRevA.91.022311.</p> </li> <li> <p>David Poulin, Matthew B. Hastings, Dave Wecker, Nathan Wiebe, Andrew C. Doberty, and Matthias Troyer. The trotter step size required for accurate quantum simulation of quantum chemistry. Quantum Info. Comput., 15(5\u20136):361\u2013384, 4 2015. arXiv: https://arxiv.org/abs/1406.4920. doi:10.26421/QIC15.5-6-1.</p> </li> <li> <p>Andrew M. Childs, Dmitri Maslov, Yunseong Nam, Neil J. Ross, and Yuan Su. Toward the first quantum simulation with quantum speedup. Proceedings of the National Academy of Sciences, 115(38):9456\u20139461, 2018. arXiv: https://arxiv.org/abs/1711.10980. doi:10.1073/pnas.1801723115.</p> </li> <li> <p>Chi-Fang Chen and Fernando G. S. L. Brand\u00e3o. Average-case speedup for product formulas. arXiv: https://arxiv.org/abs/2111.05324, 2021.</p> </li> <li> <p>Qi Zhao, You Zhou, Alexander F. Shaw, Tongyang Li, and Andrew M. Childs. Hamiltonian simulation with random inputs. Physical Review Letters, 129:270502, 12 2022. arXiv: https://arxiv.org/abs/2111.04773. URL: https://link.aps.org/doi/10.1103/PhysRevLett.129.270502, doi:10.1103/PhysRevLett.129.270502.</p> </li> <li> <p>Burak \u015eahino\u011flu and Rolando D. Somma. Hamiltonian simulation in the low-energy subspace. npj Quantum Information, 7 2021. arXiv: https://arxiv.org/abs/2006.02660. URL: https://doi.org/10.1038\\%2Fs41534-021-00451-w, doi:10.1038/s41534-021-00451-w.</p> </li> <li> <p>Yu Tong, Victor V. Albert, Jarrod R. McClean, John Preskill, and Yuan Su. Provably accurate simulation of gauge theories and bosonic systems. Quantum, 6:816, 9 2022. arXiv: https://arxiv.org/abs/2110.06942. URL: https://doi.org/10.22331/q-2022-09-22-816, doi:10.22331/q-2022-09-22-816.</p> </li> <li> <p>Yuan Su, Hsin Yuan Huang, and Earl T. Campbell. Nearly tight trotterization of interacting electrons. Quantum, 5(1):1\u201358, 2021. arXiv: https://arxiv.org/abs/2012.09194. arXiv:2012.09194, doi:10.22331/Q-2021-07-05-495.</p> </li> <li> <p>Ewout van den Berg and Kristan Temme. Circuit optimization of hamiltonian simulation by simultaneous diagonalization of pauli clusters. Quantum, 4:322, 9 2020. arXiv: https://arxiv.org/abs/2003.13599. URL: https://doi.org/10.22331/q-2020-09-12-322, doi:10.22331/q-2020-09-12-322.</p> </li> <li> <p>Ian D. Kivlichan, Craig Gidney, Dominic W. Berry, Nathan Wiebe, Jarrod McClean, Wei Sun, Zhang Jiang, Nicholas Rubin, Austin Fowler, Al\u00e1n Aspuru-Guzik, Hartmut Neven, and Ryan Babbush. Improved fault-tolerant quantum simulation of condensed-phase correlated electrons via trotterization. Quantum, 4:296, 7 2020. arXiv: https://arxiv.org/abs/1902.10673. URL: https://doi.org/10.22331/q-2020-07-16-296, doi:10.22331/q-2020-07-16-296.</p> </li> <li> <p>Earl T Campbell. Early fault-tolerant simulations of the hubbard model. Quantum Science and Technology, 7(1):015007, 11 2021. arXiv: https://arxiv.org/abs/2012.09238. URL: https://dx.doi.org/10.1088/2058-9565/ac3110, doi:10.1088/2058-9565/ac3110.</p> </li> <li> <p>Andrew M. Childs, Aaron Ostrander, and Yuan Su. Faster quantum simulation by randomization. Quantum, 3:182, 9 2019. arXiv: https://arxiv.org/abs/1805.08385. URL: https://doi.org/10.22331/q-2019-09-02-182, doi:10.22331/q-2019-09-02-182.</p> </li> <li> <p>Chien Hung Cho, Dominic W Berry, and Min-Hsiu Hsieh. Doubling the order of approximation via the randomized product formula. arXiv: https://arxiv.org/abs/2210.11281, 2022.</p> </li> </ol> <ol> <li> <p>For practical purposes, the iterated logarithm is essentially constant, since \\(\\log^*(n) \\leq 5\\) for all \\(n \\leq 2^{65536}\\).\u00a0\u21a9</p> </li> </ol>"},{"location":"quantum-algorithmic-primitives/hamiltonian-simulation/qdrift/","title":"qDRIFT","text":""},{"location":"quantum-algorithmic-primitives/hamiltonian-simulation/qdrift/#rough-overview-in-words","title":"Rough overview (in words)","text":"<p>qDRIFT (the quantum stochastic drift protocol) [1] assumes a Pauli access model and approximates the Hamiltonian simulation channel (as opposed to the unitary) by randomly sampling a term from the Hamiltonian (according to the coefficient magnitudes) and then evolving under the chosen term. This process is repeated for a number of steps. Because it approximates the channel, rather than the unitary, it can be more difficult to use qDRIFT as a coherent subroutine in other algorithms (see caveats below).</p><p>The error in qDRIFT depends on the 1-norm of Hamiltonian coefficients. Its main advantage is that it does not explicitly depend on the number of terms in the Hamiltonian and has small constant overheads. This may make it well suited to systems with rapidly decaying interaction strengths, dominated by a few large terms. However, its time and error dependence is asymptotically worse than other methods. This seems to originate from its randomized nature [2]. qDRIFT can also be extended to time-dependent Hamiltonian simulation, where it has the benefit of scaling as \\(\\int_0^t \\nrm{H(t')} dt'\\), rather than as \\(t \\max_{t'} \\nrm{H(t')}\\) common to some other Hamiltonian simulation algorithms [3]. We will restrict our discussion below to the time-independent case.</p>"},{"location":"quantum-algorithmic-primitives/hamiltonian-simulation/qdrift/#rough-overview-in-math","title":"Rough overview (in math)","text":"<p>Given a Hamiltonian in the Pauli decomposition \\(H = \\sum_i h_i H_i\\) (with \\(\\nrm{H_i}=1\\)), qDRIFT provides a stochastic channel \\(\\mathcal{N}\\) which when applied for \\(N\\) steps, approximates the Hamiltonian simulation channel </p>\\[\\begin{equation} \\nrm{\\mathcal{N}^N - e^{iHt} (\\cdot)e^{-iHt}}_{\\diamond} \\le \\epsilon \\end{equation}\\]<p>to within diamond-norm error \\(\\epsilon\\).</p><p>qDRIFT proceeds by randomly sampling a term according to its importance </p>\\[\\begin{align} X_k \\stackrel{i.i.d.}{\\sim} \\quad \\frac{\\mathrm{sign}(h_i) H_i}{p_i} \\quad \\text{where} \\quad p_i = \\frac{|h_i|}{\\nrm{H}_1} \\end{align}\\]<p>and \\(\\nrm{H}_1: = \\sum_i |h_i|\\) is the sum of the strengths. Each step of qDRIFT then evolves the randomly sampled term \\(X_k\\) for a short period of time \\(t/N\\), where \\(N\\) is a free parameter determining the number of qDRIFT steps, which controls the error in the simulation. This implements the following quantum channel </p>\\[\\begin{align} \\mathcal{N}[\\rho]: = \\mathbb{E}[e^{i(t/N)X_k}\\rho e^{-i(t/N)X_k}]. \\end{align}\\]<p>As discussed above, this channel is repeated for \\(N\\) steps, in order to approximate the Hamiltonian simulation channel.</p>"},{"location":"quantum-algorithmic-primitives/hamiltonian-simulation/qdrift/#dominant-resource-cost-gatesqubits","title":"Dominant resource cost (gates/qubits)","text":"<p>For an \\(n\\)-qubit Hamiltonian, qDRIFT acts on \\(n\\) register qubits, and no additional ancilla qubits are required.</p><p>In order to simulate the Hamiltonian evolution channel to within diamond-norm error \\(\\epsilon\\), we require </p>\\[\\begin{align} N = \\mathcal{O}\\left( \\frac{\\nrm{H}_1^2 t^2}{\\epsilon} \\right) \\end{align}\\]<p>steps of qDRIFT [1, 2]. While the diamond-norm is a different error metric to the spectral norm used in other articles in this section, both provide upper bounds on the error in an observable measured with respect to the time-evolved state [1]. For unitary channels, the diamond norm is effectively equal to the spectral norm (see, e.g., discussion in [4], up to constant factors).</p><p>The gate complexity is the number of steps multiplied by the individual costs of the elementary evolution \\(e^{i(t/N)X_k}\\), which scales linearly with the locality of the Pauli operator \\(X_k\\). When using qDRIFT to time evolve a state (e.g., for the purpose of measuring an observable), it is important to average the results over a sufficient number of independently sampled qDRIFT circuits [1].</p>"},{"location":"quantum-algorithmic-primitives/hamiltonian-simulation/qdrift/#caveats","title":"Caveats","text":"<p>The qDRIFT algorithm has a quadratic dependence on time and linear dependence on the error \\(\\epsilon\\), while other Hamiltonian simulation methods can achieve linear time dependence and logarithmic error dependence. A higher-order variant of qDRIFT was recently developed which improves the error dependence [5]. It is currently unclear how to design higher-order variants of qDRIFT that improve the time dependence, which appears to result from the randomized nature of the algorithm [2].</p><p>As discussed above, qDRIFT approximates the time evolution channel, rather than the unitary \\(e^{iHt}\\). As a result, it can be difficult to incorporate as a subroutine in algorithms that seek to manipulate the unitary directly\u2014for example, measuring \\(\\mathrm{Tr}\\left(U(t) \\rho \\right)\\). Tasks of this form feature in some approaches for phase estimation [6], motivating alternate, qDRIFT-inspired approaches, in order to exploit qDRIFT-like benefits [7].</p>"},{"location":"quantum-algorithmic-primitives/hamiltonian-simulation/qdrift/#example-use-cases","title":"Example use cases","text":"<ul> <li>Physical systems simulation: quantum chemistry, condensed matter systems, quantum field theories.</li> <li>Algorithms: quantum phase estimation, quantum linear system solvers, Gibbs state preparation, quantum adiabatic algorithm.</li> <li>Hybridization with other quantum simulation methods [8, 9, 10].</li> <li>Using importance sampling to incorporate variable gate costs for simulating different terms \\(X_k\\) [11].</li> </ul>"},{"location":"quantum-algorithmic-primitives/hamiltonian-simulation/qdrift/#bibliography","title":"Bibliography","text":"<ol> <li> <p>Earl Campbell. Random compiler for fast hamiltonian simulation. Physical Review Letters, 8 2019. arXiv: https://arxiv.org/abs/1811.08017. doi:10.1103/physrevlett.123.070503.</p> </li> <li> <p>Chi-Fang Chen, Hsin-Yuan Huang, Richard Kueng, and Joel A. Tropp. Concentration for random product formulas. PRX Quantum, 10 2021. arXiv: https://arxiv.org/abs/2008.11751. doi:10.1103/prxquantum.2.040305.</p> </li> <li> <p>Dominic W. Berry, Andrew M. Childs, Yuan Su, Xin Wang, and Nathan Wiebe. Time-dependent hamiltonian simulation with \\(l^1\\)-norm scaling. Quantum, 4:254, 2020. arXiv: https://arxiv.org/abs/1906.07115. doi:10.22331/q-2020-04-20-254.</p> </li> <li> <p>Jeongwan Haah, Robin Kothari, Ryan O'Donnell, and Ewin Tang. Query-optimal estimation of unitary channels in diamond distance. arXiv: https://arxiv.org/abs/2302.14066, 2023.</p> </li> <li> <p>Kouhei Nakaji, Mohsen Bagherimehrab, and Alan Aspuru-Guzik. Qswift: high-order randomized compiler for hamiltonian simulation. arXiv: https://arxiv.org/abs/2302.14811, 2023.</p> </li> <li> <p>Lin Lin and Yu Tong. Heisenberg-limited ground-state energy estimation for early fault-tolerant quantum computers. PRX Quantum, 3:010318, 2 2022. arXiv: https://arxiv.org/abs/2102.11340. doi:10.1103/PRXQuantum.3.010318.</p> </li> <li> <p>Kianna Wan, Mario Berta, and Earl T. Campbell. Randomized quantum algorithm for statistical phase estimation. Physical Review Letters, 129:030503, 7 2022. arXiv: https://arxiv.org/abs/2110.12071. URL: https://link.aps.org/doi/10.1103/PhysRevLett.129.030503, doi:10.1103/PhysRevLett.129.030503.</p> </li> <li> <p>Yingkai Ouyang, David R. White, and Earl T. Campbell. Compilation by stochastic hamiltonian sparsification. Quantum, 4:235, 2 2020. arXiv: https://arxiv.org/abs/1910.06255. URL: https://doi.org/10.22331/q-2020-02-27-235, doi:10.22331/q-2020-02-27-235.</p> </li> <li> <p>Abhishek Rajput, Alessandro Roggero, and Nathan Wiebe. Hybridized methods for quantum simulation in the interaction picture. Quantum, 6:780, 2022. arXiv: https://arxiv.org/abs/2109.03308. doi:10.22331/q-2022-08-17-780.</p> </li> <li> <p>Matthew Hagan and Nathan Wiebe. Composite quantum simulations. arXiv: https://arxiv.org/abs/2206.06409, 2022.</p> </li> <li> <p>Oriel Kiss, Michele Grossi, and Alessandro Roggero. Importance sampling for stochastic quantum simulations. Quantum, 7:977, 4 2023. arXiv: https://arxiv.org/abs/2212.05952. URL: https://doi.org/10.22331/q-2023-04-13-977, doi:10.22331/q-2023-04-13-977.</p> </li> </ol>"},{"location":"quantum-algorithmic-primitives/hamiltonian-simulation/quantum-signal-processing-quantum-singular-value-transformation/","title":"Quantum signal processing / quantum singular value transformation","text":""},{"location":"quantum-algorithmic-primitives/hamiltonian-simulation/quantum-signal-processing-quantum-singular-value-transformation/#rough-overview-in-words","title":"Rough overview (in words)","text":"<p>Quantum signal processing (QSP) and quantum singular value transformation (QSVT) are techniques for applying polynomial transformations to block-encoded operators. These techniques can be used to implement Hamiltonian simulation, given a block-encoding of the Hamiltonian. Both approaches have optimal scaling with \\(t\\) and \\(\\epsilon\\) for time-independent Hamiltonians.</p><p>QSP was initially developed for the \\(d\\)-sparse access model [1]. Through the introduction of block-encodings and qubitization, it was made applicable in a standard form to Hamiltonians in a Pauli access model, \\(d\\)-sparse access model, or given as density matrices (where we are given access to a unitary that prepares a purification of the density matrix) [2]. QSVT was later developed as a more general and direct route to the results of QSP [3].</p><p>Hamiltonian simulation via QSP / QSVT is less well suited to time-dependent Hamiltonians, as the need to Trotterize the time-dependent evolution breaks the optimal dependence on the parameters.</p>"},{"location":"quantum-algorithmic-primitives/hamiltonian-simulation/quantum-signal-processing-quantum-singular-value-transformation/#rough-overview-in-math","title":"Rough overview (in math)","text":"<p>Access to the Hamiltonian \\(H\\) is provided by an \\((\\alpha, m, 0)\\)-block-encoding \\(U_H\\) (the case of approximate block-encodings can be treated using [3, Lemma 22]) such that </p>\\[\\begin{equation} \\left(\\bra{0}^{\\otimes m} \\otimes I \\right) U_H \\left(\\ket{0}^{\\otimes m} \\otimes I \\right) = H/\\alpha \\end{equation}\\]<p>The Hamiltonian has a spectral decomposition of \\(\\sum_\\lambda \\lambda \\ket{\\lambda} \\bra{\\lambda}\\). We seek to use \\(U_H\\) to implement an operator \\(U(t)\\) approximating </p>\\[\\begin{equation} \\nrm{ U(t) - \\sum_\\lambda e^{i \\lambda t} \\ket{\\lambda} \\bra{\\lambda}} \\leq \\epsilon. \\end{equation}\\]<p>Qubitization converts \\(U_H\\) into a more structured unitary \\(W\\) (which is also a block-encoding of the Hamiltonian). The eigenvalues of \\(W\\) are \\(e^{\\pm i \\arccos(\\lambda / \\alpha)}\\), directly related to those of \\(H\\). QSP then enables polynomial transformations to be applied to these eigenvalues, which defines the application of the polynomial to \\(W\\). This concept can be generalized via QSVT, which effectively unifies the qubitization and QSP step.</p><p>In both cases, our goal is to implement a block-encoding of \\(U(t) \\approx \\sum_\\lambda e^{i \\lambda t} \\ket{\\lambda} \\bra{\\lambda}\\), which defines Hamiltonian simulation. In QSVT we separately implement polynomials approximating \\(\\cos(\\lambda t)\\) and \\(i\\sin(\\lambda t)\\), combine them using a linear combination of block-encodings, and boost the success probability using 3-step oblivious amplitude amplification. Further details can be found in [3, 4]. Meanwhile, quantum signal processing implements \\(\\exp( i t H)\\) directly but requires an additional ancilla qubit and controlled access to a Hermitian block-encoding \\(U'_H\\), which, when implemented via Eq. \\(\\eqref{eq:genQubitiz}\\), uses both controlled \\(U_H\\) and \\(U_H^\\dagger\\) resulting in a factor of \\(\\sim 4\\) overhead [2]. Altogether these considerations suggest that the QSVT-based approach might have a slightly better complexity, particularly when controlled \\(U_H\\) is significantly more costly to implement than \\(U_H\\). If \\(U_H\\) is already Hermitian then quantum signal processing can have a lower complexity.</p>"},{"location":"quantum-algorithmic-primitives/hamiltonian-simulation/quantum-signal-processing-quantum-singular-value-transformation/#dominant-resource-cost-gatesqubits","title":"Dominant resource cost (gates/qubits)","text":"<p>Using either QSP or QSVT, block-encoding a degree-\\(k\\) polynomial \\(f(H)\\) is performed using \\(\\mathcal{O}\\left( k \\right)\\) calls to the block-encoding \\(U_H\\) [2, 3]. Hence, the degree of the polynomial approximating the \\(e^{iHt}\\) determines the complexity of Hamiltonian simulation using these techniques. As noted in [3, Corollary 60], we can rigorously bound the resources for Hamiltonian simulation via QSVT for all values of \\(t\\) as using </p>\\[\\begin{equation} \\mathcal{O}\\left( \\alpha t + \\frac{\\log(1/\\epsilon)}{\\log(e+ \\log(1/\\epsilon)/\\alpha t)} \\right) \\end{equation}\\]<p>calls to the \\((\\alpha, m, 0)\\)-block-encoding \\(U_H\\). This query complexity is optimal [5, 3], although the block-encoding can hide additional complexities, in practice. In some cases, the dependence on norm parameters can be improved by exploiting details of the simulated system, see [6, 7].</p><p>For a Pauli access model the block-encoding is implemented using the linear combination of unitaries primitives PREPARE and SELECT. For a Hamiltonian with \\(L\\) terms \\(\\alpha = \\nrm{H}_1\\), \\(m=\\mathcal{O}\\left( \\log(L) \\right)\\), and two additional qubits are required for QSVT. The overall gate complexity depends on the exact implementation of PREPARE and SELECT, which can often be tailored to the Hamiltonian of interest. In the worst case, PREPARE uses \\(\\Theta(L)\\) gates, and SELECT uses \\(\\Theta(nL)\\) gates (although these can be significantly improved by exploiting structure in the Hamiltonian, see, e.g., [8, 9]). This yields an overall worst case gate complexity of </p>\\[\\begin{equation} \\mathcal{O}\\left( nL \\left( \\nrm{H}_1 t + \\frac{\\log(1/\\epsilon)}{\\log(e+ \\log(1/\\epsilon)/\\nrm{H}_1 t)} \\right) \\right). \\end{equation}\\]<p>For a \\(d\\)-sparse access model, \\(\\alpha= d\\nrm{H}_{\\max}\\) where \\(\\nrm{H}_{\\mathrm{max}} = \\mathrm{max}_{i,j} \\lvert \\bra{i}H\\ket{j} \\rvert\\), \\(m=\\mathcal{O}\\left( \\log(d) \\right)\\), and two additional qubits are required for QSVT. The overall gate complexity depends on the cost of sparse access to elements of \\(H\\). Assuming a constant gate complexity circuit for sparse access, the overall gate complexity is </p>\\[\\begin{equation} \\mathcal{O}\\left( d\\nrm{H}_{\\max} t + \\frac{\\log(1/\\epsilon)}{\\log(e+ \\log(1/\\epsilon)/d\\nrm{H}_{\\max} t)} \\right). \\end{equation}\\]<p>The density matrix access model seeks to perform time evolution under \\(e^{i\\rho t}\\), given access to either multiple copies of \\(\\rho\\) or a unitary \\(U_\\rho\\) that prepares a purification of \\(\\rho\\). Given \\(U_\\rho\\), we can prepare a block-encoding of \\(\\rho\\) [2] (see section on block-encodings for details) with \\(\\alpha=1\\). If the gate complexity of \\(U_\\rho\\) is \\(C(U_\\rho)\\) then the overall gate complexity is </p>\\[\\begin{equation} \\mathcal{O}\\left( C(U_\\rho) \\left(t + \\frac{\\log(1/\\epsilon)}{\\log(e+ \\log(1/\\epsilon)/ t)} \\right) \\right). \\end{equation}\\]"},{"location":"quantum-algorithmic-primitives/hamiltonian-simulation/quantum-signal-processing-quantum-singular-value-transformation/#caveats","title":"Caveats","text":"<p>The method was found to perform competitively with Trotterization (and better than Taylor series) in concrete resource estimates for simulating spin chain Hamiltonians [10]. While that work had difficulty calculating the QSP phase factors, this issue has since been addressed with the development of classical algorithms for finding the phase factors [11, 12, 13, 14]. Nevertheless, this contributes a classical preprocessing cost to the algorithm.</p><p>It is currently unclear how to perform optimal time-dependent Hamiltonian simulation with these methods, without resorting to Trotterization. Some initial investigations have shown promising results using clock Hamiltonian constructions [15] or for time-periodic Hamiltonians [16, 17].</p>"},{"location":"quantum-algorithmic-primitives/hamiltonian-simulation/quantum-signal-processing-quantum-singular-value-transformation/#example-use-cases","title":"Example use cases","text":"<ul> <li>Physical systems simulation: quantum chemistry, condensed matter systems (see [10]), quantum field theories, differential equations in plasma physics (see [18]).</li> <li>Algorithms: quantum phase estimation, quantum linear system solvers, Gibbs state preparation.</li> </ul>"},{"location":"quantum-algorithmic-primitives/hamiltonian-simulation/quantum-signal-processing-quantum-singular-value-transformation/#further-reading","title":"Further reading","text":"<ul> <li>Pedagogical overviews [4, 19].</li> <li>Comparison of several Hamiltonian simulation algorithms [10].</li> </ul>"},{"location":"quantum-algorithmic-primitives/hamiltonian-simulation/quantum-signal-processing-quantum-singular-value-transformation/#bibliography","title":"Bibliography","text":"<ol> <li> <p>Guang Hao Low and Isaac L. Chuang. Optimal hamiltonian simulation by quantum signal processing. Physical Review Letters, 118(1):010501, 2017. arXiv: https://arxiv.org/abs/1606.02685. doi:10.1103/PhysRevLett.118.010501.</p> </li> <li> <p>Guang Hao Low and Isaac L. Chuang. Hamiltonian simulation by qubitization. Quantum, 3:163, 2019. arXiv: https://arxiv.org/abs/1610.06546. doi:10.22331/q-2019-07-12-163.</p> </li> <li> <p>Andr\u00e1s Gily\u00e9n, Yuan Su, Guang Hao Low, and Nathan Wiebe. Quantum singular value transformation and beyond: exponential improvements for quantum matrix arithmetics [full version]. arXiv: https://arxiv.org/abs/1806.01838, 2018.</p> </li> <li> <p>John M. Martyn, Zane M. Rossi, Andrew K. Tan, and Isaac L. Chuang. Grand unification of quantum algorithms. Physical Review X, 2(4):040203, 2021. arXiv: https://arxiv.org/abs/2105.02859. doi:10.1103/PRXQuantum.2.040203.</p> </li> <li> <p>Dominic W. Berry, Graeme Ahokas, Richard Cleve, and Barry C. Sanders. Efficient quantum algorithms for simulating sparse hamiltonians. Communications in Mathematical Physics, 270(2):359\u2013371, 2007. arXiv: https://arxiv.org/abs/quant-ph/0508139. doi:10.1007/s00220-006-0150-x.</p> </li> <li> <p>Guang Hao Low and Isaac L. Chuang. Hamiltonian simulation by uniform spectral amplification. arXiv: https://arxiv.org/abs/1707.05391, 2017.</p> </li> <li> <p>Guang Hao Low. Hamiltonian simulation with nearly optimal dependence on spectral norm. In Proceedings of the 51st ACM Symposium on the Theory of Computing (STOC), 491\u2013502. 2019. arXiv: https://arxiv.org/abs/1807.03967. doi:10.1145/3313276.3316386.</p> </li> <li> <p>Ryan Babbush, Craig Gidney, Dominic W. Berry, Nathan Wiebe, Jarrod McClean, Alexandru Paler, Austin Fowler, and Hartmut Neven. Encoding electronic spectra in quantum circuits with linear t complexity. Physical Review X, 8(4):041015, 2018. arXiv: https://arxiv.org/abs/1805.03662. doi:10.1103/PhysRevX.8.041015.</p> </li> <li> <p>Kianna Wan. Exponentially faster implementations of select(h) for fermionic hamiltonians. Quantum, 2021. arXiv: https://arxiv.org/abs/2004.04170. doi:10.22331/q-2021-01-12-380.</p> </li> <li> <p>Andrew M. Childs, Dmitri Maslov, Yunseong Nam, Neil J. Ross, and Yuan Su. Toward the first quantum simulation with quantum speedup. Proceedings of the National Academy of Sciences, 115(38):9456\u20139461, 2018. arXiv: https://arxiv.org/abs/1711.10980. doi:10.1073/pnas.1801723115.</p> </li> <li> <p>Andr\u00e1s Gily\u00e9n, Yuan Su, Guang Hao Low, and Nathan Wiebe. Quantum singular value transformation and beyond: exponential improvements for quantum matrix arithmetics. In Proceedings of the 51st ACM Symposium on the Theory of Computing (STOC), 193\u2013204. 2019. arXiv: https://arxiv.org/abs/1806.01838. doi:10.1145/3313276.3316366.</p> </li> <li> <p>Jeongwan Haah. Product decomposition of periodic functions in quantum signal processing. Quantum, 3:190, 2019. arXiv: https://arxiv.org/abs/1806.10236. doi:10.22331/q-2019-10-07-190.</p> </li> <li> <p>Yulong Dong, Xiang Meng, K. Birgitta Whaley, and Lin Lin. Efficient phase-factor evaluation in quantum signal processing. Physical Review A, 103:042419, 2021. arXiv: https://arxiv.org/abs/2002.11649. doi:10.1103/PhysRevA.103.042419.</p> </li> <li> <p>Rui Chao, Dawei Ding, Andr\u00e1s Gily\u00e9n, Cupjin Huang, and M\u00e1ri\u00f3 Szegedy. Finding angles for quantum signal processing with machine precision. arXiv: https://arxiv.org/abs/2003.02831, 2020.</p> </li> <li> <p>Jacob Watkins, Nathan Wiebe, Alessandro Roggero, and Dean Lee. Time-dependent hamiltonian simulation using discrete clock constructions. arXiv: https://arxiv.org/abs/2203.11353, 2022.</p> </li> <li> <p>Kaoru Mizuta and Keisuke Fujii. Optimal hamiltonian simulation for time-periodic systems. Quantum, 7:962, 3 2023. arXiv: https://arxiv.org/abs/2209.05048. URL: https://doi.org/10.22331/q-2023-03-28-962, doi:10.22331/q-2023-03-28-962.</p> </li> <li> <p>Kaoru Mizuta. Optimal/nearly-optimal simulation of multi-periodic time-dependent hamiltonians. arXiv: https://arxiv.org/abs/2301.06232, 2023.</p> </li> <li> <p>I. Novikau, E. A. Startsev, and I. Y. Dodin. Quantum signal processing for simulating cold plasma waves. Physical Review A, 105:062444, 6 2022. arXiv: https://arxiv.org/abs/2112.06086. URL: https://link.aps.org/doi/10.1103/PhysRevA.105.062444, doi:10.1103/PhysRevA.105.062444.</p> </li> <li> <p>Lin Lin. Lecture notes on quantum algorithms for scientific computation. arXiv: https://arxiv.org/abs/2201.08309, 2022.</p> </li> </ol>"},{"location":"quantum-algorithmic-primitives/hamiltonian-simulation/taylor-and-dyson-series-linear-combination-of-unitaries/","title":"Taylor and Dyson series (linear combination of unitaries)","text":""},{"location":"quantum-algorithmic-primitives/hamiltonian-simulation/taylor-and-dyson-series-linear-combination-of-unitaries/#rough-overview-in-words","title":"Rough overview (in words)","text":"<p>Taylor and Dyson series approaches for Hamiltonian simulation expand the time evolution operator as a Taylor series (time independent) [1] or Dyson series (time dependent) [2, 3] and use the  linear combination of unitaries (LCU) primitive to apply the terms in the expansion, followed by (robust, oblivious) amplitude amplification to boost the success probability close to unity. These methods are close to being asymptotically optimal, achieving linear scaling in time and logarithmic dependence on the error. However, they use a large number of ancilla qubits, compared to other Hamiltonian simulation algorithms.</p>"},{"location":"quantum-algorithmic-primitives/hamiltonian-simulation/taylor-and-dyson-series-linear-combination-of-unitaries/#rough-overview-in-math","title":"Rough overview (in math)","text":"<p>We focus on the time-independent case and follow the presentation in [1]. Given a Hamiltonian \\(H\\), desired evolution time \\(t\\), and error \\(\\epsilon\\), return a circuit \\(U(t)\\) made of elementary gates such that </p>\\[\\begin{align} \\nrm{ U(t) - \\mathrm{e}^{\\mathrm{i} H t} } \\le \\epsilon. \\end{align}\\]<p>In the above, we use the operator norm (the maximal singular value) to quantify the worst-case error in the simulation.</p><p>The total evolution time \\(t\\) is divided into \\(r\\) segments. In each segment we evolve under an approximation of \\(e^{iHt/r}\\). The Hamiltonian is decomposed into a linear combination of unitary operations \\(H = \\sum_{l=1}^L \\alpha_l H_l\\), where we choose \\(\\alpha_l\\) real and positive by shifting phases into \\(H_l\\), and \\(\\nrm{H_l}=1\\). This decomposition appears naturally when the Hamiltonian is given as a linear combination of Pauli products. We approximate \\(e^{iHt/r}\\) using a Taylor expansion truncated to degree \\(K\\) </p>\\[\\begin{align} e^{iHt/r} \\approx U(t/r) &amp; := \\sum_{k=0}^K \\frac{1}{k!} (iHt/r)^k \\\\ \\nonumber &amp; =\\sum_{k=0}^K \\sum_{l_1, ... l_k=1}^L \\frac{(it/r)^k}{k!} \\alpha_{l_1} ... \\alpha_{l_k} H_{l_1} ... H_{l_k}. \\end{align}\\]<p>Each segment \\(U(t/r)\\) is implemented using robust oblivious amplitude amplification. Amplitude amplification is necessary because truncating the Taylor series at degree \\(K\\) makes \\(U(t/r)\\) non-unitary. However, textbook amplitude amplification necessitates reflecting around the initial state, (as well as the \"good\" state), which would be problematic since Hamiltonian simulation requires synthesizing a unitary that works simultaneously for all input states. This can be circumvented using oblivious amplitude amplification: we are given a unitary \\(V\\) such that for any state \\(\\ket{\\psi}\\), we have \\(V \\ket{\\bar{0}_m} \\ket{\\psi} = a \\ket{\\bar{0}_m} U \\ket{\\psi} + b \\ket{(\\bar{0}_m \\psi)^\\perp}\\), for a unitary operator \\(U\\), and the goal is to amplify the state \\(\\ket{\\bar{0}_m} U \\ket{\\psi}\\) to be obtained with probability 1 (we can recognize \\(V\\) as an \\((a, m, 0)\\) unitary block-encoding of \\(U\\)). A further problem is that the above operator \\(U(t/r)\\) is non-unitary, and so deviates from the formulation of oblivious amplitude amplification [4]. The proven \"robustness\" property of oblivious amplitude amplification [1] ensures that the error induced by treating \\(U(t/r)\\) as a probabilistically implemented unitary does not accumulate.</p><p>The value of \\(K\\) controls the error in the simulation and can be chosen as </p>\\[\\begin{equation} K=\\mathcal{O}\\left( \\frac{\\log(\\nrm{H}_1 t /\\epsilon)}{ \\log\\log(\\nrm{H}_1 t / \\epsilon )} \\right)\\,, \\end{equation}\\]<p>where we define \\(\\nrm{H}_1: = \\sum_{l=1}^L \\alpha_l\\). The total time evolution is divided into \\(r = \\nrm{H}_1 t / \\ln(2)\\) segments, each of duration \\(\\ln(2) / \\nrm{H}_1\\). This ensures that a single application of robust oblivious amplitude amplification boosts the success probability of the segment to unity.</p><p>Within each segment we apply \\(U(t/r)\\) using the LCU primitive. This technique can be applied to Hamiltonians given in both the Pauli and \\(d\\)-sparse access models. For the Pauli access model, the Hamiltonian is already in the form of a linear combination of unitary operators. For the \\(d\\)-sparse case, we can use graph coloring algorithms [5, 6] to decompose the \\(d\\)-sparse Hamiltonian into a linear combination of unitaries, where each unitary is \\(1\\)-sparse and self-inverse.</p>"},{"location":"quantum-algorithmic-primitives/hamiltonian-simulation/taylor-and-dyson-series-linear-combination-of-unitaries/#dominant-resource-cost-gatesqubits","title":"Dominant resource cost (gates/qubits)","text":"<p>In addition to the \\(n\\)-qubit data register, the Taylor series approach requires a number of ancilla registers to implement the LCU technique. A register with \\(K\\) qubits is used to control the degree of the Taylor expansion, storing the value as \\(\\ket{k} = \\ket{1^{\\otimes k} 0^{\\otimes (K-k) }}\\). An additional \\(K\\) registers, each containing \\(\\lceil \\log_2(L) \\rceil\\) qubits, are used to index the possible values of each of the possible \\(H_{l_k}\\). Hence, the overall space complexity is \\(\\mathcal{O}\\left( n + K\\log(L) \\right) = \\mathcal{O}\\left( n + \\log(\\nrm{H}_1 t/\\epsilon)\\log(L) \\right)\\).</p><p>Additional ancilla qubits may be required to implement the LCU gadget (i.e. in the sparse access model) or for the reflections used in robust oblivious amplitude amplification.</p><p>As discussed above, implementing each segment requires one use of robust oblivious amplitude amplification, which makes 2 calls to the LCU circuit and 1 call to its inverse. The method incurs approximation errors from truncating the Taylor series at degree \\(K\\) and from the use of robust oblivious amplitude amplification. The resulting error per segment is bounded by \\(\\left(e \\ln{2}/(K+1) \\right)^{K+1}\\).</p><p>The cost of the LCU circuit depends on the Hamiltonian access model. For the case of the Pauli access model the LCU circuit requires two calls to a PREPARE operation that prepares the ancilla registers with the correct coefficients. This requires \\(\\mathcal{O}\\left( LK \\right)\\) gates. The LCU circuit also requires one call to a SELECT oracle, which can be implemented using \\(K\\) controlled-select\\((H)\\) operations that act as \\(\\ket{b}\\ket{l}\\ket{\\psi} \\rightarrow \\ket{b}\\ket{l} (iH_l)^b \\ket{\\psi}\\) (where \\(b \\in \\{0,1\\}\\)), and each act on a different one of the \\(K\\) different \\(\\log(L)\\)-qubit registers. These can each be implemented using \\(\\mathcal{O}\\left( L(n + \\log(L) \\right)\\) elementary gates [1]. The overall gate complexity in the Pauli access model is thus </p>\\[\\begin{align} \\mathcal{O}\\left( \\frac{\\nrm{H}_1 t L(n + \\log(L))\\log(\\nrm{H}_1 t / \\epsilon) }{\\log\\log(\\nrm{H}_1 t / \\epsilon)} \\right) = \\widetilde{\\mathcal{O}}\\left( \\nrm{H}_1 t Ln \\log\\left( \\frac{1}{\\epsilon} \\right) \\right) \\end{align}\\]<p>Using the LCU approach applied to a 1-sparse decomposition of a \\(d\\)-sparse Hamiltonian, the overall complexity is [1] </p>\\[\\begin{align} \\mathcal{O}\\left( \\frac{d^2 \\nrm{H}_{\\mathrm{max}} t n \\log^2(d^2 |H|_{\\mathrm{max}} t / \\epsilon) }{\\log\\log(d^2 \\nrm{H}_{\\mathrm{max}} t / \\epsilon)} \\right) = \\widetilde{\\mathcal{O}}\\left( d^2 \\nrm{H}_{\\mathrm{max}} t n \\log^2\\left( \\frac{1}{\\epsilon} \\right) \\right) \\end{align}\\]<p>where \\(\\nrm{H}_{\\mathrm{max}} = \\mathrm{max}_{i,j} \\lvert \\bra{i}H\\ket{j} \\rvert\\).</p><p>The extension to time-dependent Hamiltonians, through the use of a Dyson series, requires an additional \"clock\" register to store the time value and introduces a logarithmic dependence on the time derivative of the Hamiltonian [2, 3].</p>"},{"location":"quantum-algorithmic-primitives/hamiltonian-simulation/taylor-and-dyson-series-linear-combination-of-unitaries/#caveats","title":"Caveats","text":"<p>Concrete resource estimates for physical systems of interest have observed that the Taylor series approach may require more ancilla qubits and gates than product formulae or quantum signal processing approaches for Hamiltonian simulation [7]. The gate complexity of the algorithm can be reduced by exploiting anticommutativity in the Hamiltonian [8], adding a corrective operation [9], or pruning terms with small magnitudes from the expansion [10].</p>"},{"location":"quantum-algorithmic-primitives/hamiltonian-simulation/taylor-and-dyson-series-linear-combination-of-unitaries/#example-use-cases","title":"Example use cases","text":"<ul> <li>Physical systems simulation: quantum chemistry (see [11, 12, 13, 14]), condensed matter systems, quantum field theories.</li> <li>Algorithms: quantum phase estimation, quantum linear system solvers, Gibbs state preparation, quantum adiabatic algorithm.</li> <li>Hamiltonian simulation in the interaction picture [14].</li> </ul>"},{"location":"quantum-algorithmic-primitives/hamiltonian-simulation/taylor-and-dyson-series-linear-combination-of-unitaries/#further-reading","title":"Further reading","text":"<ul> <li>A comparison of several Hamiltonian simulation algorithms, including Taylor series [7].</li> <li>Video lectures on Hamiltonian simulation with Taylor series.</li> </ul>"},{"location":"quantum-algorithmic-primitives/hamiltonian-simulation/taylor-and-dyson-series-linear-combination-of-unitaries/#bibliography","title":"Bibliography","text":"<ol> <li> <p>Dominic W. Berry, Andrew M. Childs, Richard Cleve, Robin Kothari, and Rolando D. Somma. Simulating hamiltonian dynamics with a truncated taylor series. Physical Review Letters, 114(9):090502, 2015. arXiv: https://arxiv.org/abs/1412.4687. doi:10.1103/PhysRevLett.114.090502.</p> </li> <li> <p>M\u00e1ria Kieferov\u00e1, Artur Scherer, and Dominic W. Berry. Simulating the dynamics of time-dependent hamiltonians with a truncated dyson series. Physical Review A, 99:042314, 4 2019. arXiv: https://arxiv.org/abs/1805.00582. URL: https://link.aps.org/doi/10.1103/PhysRevA.99.042314, doi:10.1103/PhysRevA.99.042314.</p> </li> <li> <p>Dominic W. Berry, Andrew M. Childs, Yuan Su, Xin Wang, and Nathan Wiebe. Time-dependent hamiltonian simulation with \\(l^1\\)-norm scaling. Quantum, 4:254, 2020. arXiv: https://arxiv.org/abs/1906.07115. doi:10.22331/q-2020-04-20-254.</p> </li> <li> <p>Dominic W. Berry, Andrew M. Childs, Richard Cleve, Robin Kothari, and Rolando D. Somma. Exponential improvement in precision for simulating sparse hamiltonians. In Proceedings of the 46th ACM Symposium on the Theory of Computing (STOC), 283\u2013292. 2014. arXiv: https://arxiv.org/abs/1312.1414. doi:10.1145/2591796.2591854.</p> </li> <li> <p>Dominic W. Berry, Graeme Ahokas, Richard Cleve, and Barry C. Sanders. Efficient quantum algorithms for simulating sparse hamiltonians. Communications in Mathematical Physics, 270(2):359\u2013371, 2007. arXiv: https://arxiv.org/abs/quant-ph/0508139. doi:10.1007/s00220-006-0150-x.</p> </li> <li> <p>Andrew M. Childs and Robin Kothari. Simulating sparse hamiltonians with star decompositions. In Wim van Dam, Vivien M. Kendon, and Simone Severini, editors, Proceedings of the 5th Conference on the Theory of Quantum Computation, Communication, and Cryptography (TQC), 94\u2013103. Berlin, Heidelberg, 2011. Springer Berlin Heidelberg. arXiv: https://arxiv.org/abs/1003.3683. doi:10.1007/978-3-642-18073-6\\_8.</p> </li> <li> <p>Andrew M. Childs, Dmitri Maslov, Yunseong Nam, Neil J. Ross, and Yuan Su. Toward the first quantum simulation with quantum speedup. Proceedings of the National Academy of Sciences, 115(38):9456\u20139461, 2018. arXiv: https://arxiv.org/abs/1711.10980. doi:10.1073/pnas.1801723115.</p> </li> <li> <p>Qi Zhao and Xiao Yuan. Exploiting anticommutation in hamiltonian simulation. Quantum, 5:534, 8 2021. arXiv: https://arxiv.org/abs/2103.07988. URL: https://doi.org/10.22331/q-2021-08-31-534, doi:10.22331/q-2021-08-31-534.</p> </li> <li> <p>Leonardo Novo and Dominic W Berry. Improved hamiltonian simulation via a truncated taylor series and corrections. Quantum Information and Computation, 17(7&amp;8):623\u2013635, 2017. arXiv: https://arxiv.org/abs/1611.10033. doi:10.26421/QIC17.7-8-5.</p> </li> <li> <p>Richard Meister, Simon C. Benjamin, and Earl T. Campbell. Tailoring term truncations for electronic structure calculations using a linear combination of unitaries. Quantum, 6:637, 2 2022. arXiv: https://arxiv.org/abs/2007.11624. URL: https://doi.org/10.22331/q-2022-02-02-637, doi:10.22331/q-2022-02-02-637.</p> </li> <li> <p>Ryan Babbush, Dominic W Berry, Ian D Kivlichan, Annie Y Wei, Peter J Love, and Al\u00e1n Aspuru-Guzik. Exponentially more precise quantum simulation of fermions in second quantization. New Journal of Physics, 18(3):033032, 3 2016. arXiv: https://arxiv.org/abs/1506.01020. URL: https://dx.doi.org/10.1088/1367-2630/18/3/033032, doi:10.1088/1367-2630/18/3/033032.</p> </li> <li> <p>Ryan Babbush, Dominic W Berry, Yuval R Sanders, Ian D Kivlichan, Artur Scherer, Annie Y Wei, Peter J Love, and Al\u00e1n Aspuru-Guzik. Exponentially more precise quantum simulation of fermions in the configuration interaction representation. Quantum Science and Technology, 3(1):015006, 2017. arXiv: https://arxiv.org/abs/1506.01029. doi:10.1088/2058-9565/aa9463.</p> </li> <li> <p>Yuan Su, Dominic W Berry, Nathan Wiebe, Nicholas Rubin, and Ryan Babbush. Fault-tolerant quantum simulations of chemistry in first quantization. PRX Quantum, 2(4):040332, 2021. arXiv: https://arxiv.org/abs/2105.12767. doi:10.1103/PRXQuantum.2.040332.</p> </li> <li> <p>Guang Hao Low and Nathan Wiebe. Hamiltonian simulation in the interaction picture. arXiv: https://arxiv.org/abs/1805.00675, 2018.</p> </li> </ol>"},{"location":"quantum-algorithmic-primitives/loading-classical-data/block-encoding-dense-matrices-of-classical-data/","title":"Block-encoding dense matrices of classical data","text":""},{"location":"quantum-algorithmic-primitives/loading-classical-data/block-encoding-dense-matrices-of-classical-data/#rough-overview-in-words","title":"Rough overview (in words)","text":"<p>Many applications of quantum algorithms require access to large amounts of classical data, and in order to process this data on quantum devices, one needs coherent query access to the data. Block-encoding is a technique for importing classical data into quantum computers that provides exactly this type of coherent query access. Block-encodings work by encoding the matrices of classical data as blocks within larger matrices, which are defined such that the full encoding is a unitary operator. One way of thinking of this process is by \"brute-force\" compiling a unitary with the right structure, and then postselecting measurement outcomes to ensure the desired block of the unitary was applied. In general, block-encoding a dense matrix is not an efficient process, as one can typically expect multiplicative factors in the overhead that scale with system size (e.g., \\(\\mathcal{O}\\left( \\mathrm{poly}(N) \\right)\\)), and the process requires access to QRAM, which can be prohibitively expensive. For a general treatment not restricted to dense classical data, see the article on block-encoding.</p>"},{"location":"quantum-algorithmic-primitives/loading-classical-data/block-encoding-dense-matrices-of-classical-data/#rough-overview-in-math","title":"Rough overview (in math)","text":"<p>Given an \\(N\\times M\\) matrix \\(A\\), a block-encoding is a way of encoding the matrix \\(A\\) as a block in a larger unitary matrix: </p>\\[\\begin{equation} U_A = \\begin{pmatrix}A/\\alpha &amp; \\cdot \\\\ \\cdot &amp; \\cdot \\end{pmatrix} \\end{equation}\\]<p>We say that the unitary \\(U_A\\) is an \\((\\alpha, a, \\epsilon)\\)-block-encoding of the matrix \\(A\\in\\mathbb{C}^{N\\times M}\\) if </p>\\[\\begin{equation} \\left\\lVert A - \\alpha (\\bra{0}^{\\otimes a} \\otimes I )U_A(\\ket{0}^{\\otimes a} \\otimes I)\\right\\rVert \\leq \\epsilon, \\end{equation}\\]<p>where \\(a\\in\\mathbb{N}\\) represents the number of ancilla qubits needed, \\(\\alpha\\in\\mathbb{R}_+\\) is a normalization constant, and \\(\\epsilon\\in\\mathbb{R}_+\\) is an error parameter. Note that the definition above holds for general matrices, even though additional embedding or padding may be needed.</p><p>In this section, we focus on the loading of classical matrices of data using a pair of state preparation unitaries [1, 2, 3]. In particular, the product </p>\\[\\begin{equation} U_A=U_R^\\dagger U_L \\end{equation}\\]<p>is an \\((\\alpha,a,\\epsilon)\\)-block-encoding of \\(A\\), where \\(U_L\\) and \\(U_R\\) are unitaries that perform state preparation, \\(\\alpha\\) is a normalization constant (which can be chosen depending on application, but a convenient choice is \\(\\alpha=\\nrm{A}_F\\), the Frobenius norm of \\(A\\)), and \\(\\epsilon\\) is an error parameter that captures the error stemming from state preparation. In particular, the unitaries \\(U_L\\) and \\(U_R\\) prepare the states: </p>\\[\\begin{equation} \\label{eq:block-enc-state-prep} U_L\\ket{0}\\ket{i}=\\ket{\\psi_i}\\qquad U_R\\ket{0}\\ket{j}=\\ket{\\phi_j}, \\end{equation}\\]<p>such that \\(A_{ij}=\\braket{\\psi_i}{\\phi_j}\\). The states \\(\\ket{\\psi_i}\\) and \\(\\ket{\\phi_j}\\) encode the (normalized) rows of \\(A\\) and norms of those rows, respectively.</p><p>There are several methods of implementing the state preparation unitaries. One commonly used scheme involves constructing binary trees representing the amplitudes in the states \\(\\ket{\\psi_i}\\) and \\(\\ket{\\phi_j}\\) in Eq. \\(\\eqref{eq:block-enc-state-prep}\\), and building the state preparation unitaries out of controlled-\\(Y\\) rotations by angles defined in those binary trees. In this way, one can construct an \\(\\epsilon\\)-close approximation to the desired quantum state on \\(\\log(N)\\) qubits using \\(\\mathcal{O}\\left( N \\right)\\) qubits and \\(\\mathcal{O}\\left( \\log^2(N/\\epsilon) \\right)\\) \\(T\\)-depth. See the section on preparing states from classical data for more details. To load the data into a binary tree (for use in the state preparation step), a QRAM data structure can be employed. An improved state preparation approach was developed in [4] that quadratically improves the \\(T\\)-depth to \\(\\mathcal{O}\\left( \\log(N/\\epsilon) \\right)\\) by pre-applying all the single qubit rotations onto ancilla qubits, and then using a controlled-SWAP network to inject the ancillas appropriately.</p>"},{"location":"quantum-algorithmic-primitives/loading-classical-data/block-encoding-dense-matrices-of-classical-data/#dominant-resource-cost-gatesqubits","title":"Dominant resource cost (gates/qubits)","text":"<p>In the case of general, dense matrices, detailed resource counts and implementations of block-encodings were studied in [4]. When building a block-encoding of a dense matrix \\(A\\), one can optimize for reduced logical qubit count, \\(T\\)-depth, or \\(T\\)-count. In general, the dominant cost in terms of qubit counts comes from the state preparation step, requiring \\(\\mathcal{O}\\left( N \\right)\\) qubits. For \\(T\\)-depth, the dominant contribution comes from QRAM with a scaling that can range from \\(\\mathcal{O}\\left( \\log(N) \\right)\\) to \\(\\mathcal{O}\\left( N \\right)\\), with a tradeoff between \\(T\\)-depth and qubit count described in [5]. If we focus on \\(T\\)-gates as the primary resource, the following dominant contributions to the complexities can be achieved:</p><p>|               |  Optimized for min depth   |               Optimized for min count               | | :-\u2014\u2013\u2014--: | :-\u2014\u2013\u2014--\u2014\u2013\u2014--\u2014\u2013--: | :-\u2014\u2013\u2014--\u2014\u2013\u2014--\u2014\u2013\u2014--\u2014\u2013\u2014--\u2014\u2013\u2014-\u2013-: | | # Qubits |            \\(4 N^2\\)             |                   \\(N\\log(1/\\epsilon)\\)                   | | \\(T\\)-Depth | \\(10\\log(N)+24\\log(1/\\epsilon)\\) |         \\(8 N + 12 \\log(N) (\\log(1/\\epsilon))^2\\)         | | \\(T\\)-Count |    \\(12N^2\\log(1/\\epsilon)\\)     | \\(16N\\log(1/\\epsilon) + 12 \\log(N) (\\log(1/\\epsilon))^2\\) |</p><p>Detailed equations with accurate constants can be found in [4].</p>"},{"location":"quantum-algorithmic-primitives/loading-classical-data/block-encoding-dense-matrices-of-classical-data/#caveats","title":"Caveats","text":"<p>There are several ways of implementing block-encodings, even in the case of general matrices described above. The method is composed of two primitives: (i) state preparation and (ii) QRAM. Each of those primitives have multiple options for implementation, and one can trade one resource for another. For instance, in the state preparation step, one can use the standard method of state preparation to a fixed precision \\(\\epsilon\\), or one can pre-compute the angles required for state preparation, and implement the controlled-rotations in a parallelized way, as mentioned above. The pre-rotated state preparation method requires a \\(T\\)-depth that scales as \\(\\mathcal{O}(\\log(N/\\epsilon))\\), whereas the traditional approach scales as \\(\\mathcal{O}(\\log(N)\\log^2(1/\\epsilon))\\). Similarly, for the QRAM step there are several proposed implementations, including Select-SWAP [5] and Bucket-Brigade [6, 7], which have pros and cons based on architectural requirements. For instance, the Bucket-Brigade implementation can be more robust to noise than the Select-SWAP method, but Select-SWAP lends itself to a lower overall \\(T\\)-depth scaling.</p><p>Another important caveat is that block-encodings of dense classical data are not expected to be computationally efficient techniques. While one can tradeoff the time complexity (e.g., \\(T\\)-depth) with the number of ancilla qubits in the QRAM (such that the QRAM either requires \\(\\mathcal{O}\\left( \\log(N) \\right)\\) \\(T\\)-depth with \\(\\mathcal{O}\\left( \\mathrm{poly}(N) \\right)\\) qubits, or \\(\\mathcal{O}\\left( \\mathrm{poly}(N) \\right)\\) \\(T\\)-depth with \\(\\mathcal{O}\\left( \\log(N) \\right)\\) qubits), these are nevertheless expected to be prohibitive overhead costs for realistic problem sizes. See the section on QRAM for the caveats of using QRAM data structures. Moreover, the resource costs for block-encoding depend on norms of the matrix \\(A\\), which could scale as \\(\\mathcal{O}\\left( \\mathrm{poly}(N) \\right)\\), further nullifying any exponential speedup.</p><p>A final caveat to note is that if the matrix being block-encoded is sparse and efficiently row computable, or if the matrix enjoys some structure in the data in addition to sparsity, then more efficient block-encoding methods can be employed \u2014 see block-encoding for details.</p>"},{"location":"quantum-algorithmic-primitives/loading-classical-data/block-encoding-dense-matrices-of-classical-data/#example-use-cases","title":"Example use cases","text":"<p>In financial portfolio optimization, classical data representing average historical returns and covariance matrices for a universe of assets is needed in a quantum algorithm for optimizing a portfolio. See, for example, [8].</p>"},{"location":"quantum-algorithmic-primitives/loading-classical-data/block-encoding-dense-matrices-of-classical-data/#further-reading","title":"Further reading","text":"<ul> <li>An excellent overview of block-encodings and quantum linear algebra: [9]</li> <li>A detailed resource count of block-encoding with explicit circuits: [4]</li> <li>Select-SWAP QRAM and a tradeoff between qubit count and \\(T\\)-gates: [5]</li> </ul>"},{"location":"quantum-algorithmic-primitives/loading-classical-data/block-encoding-dense-matrices-of-classical-data/#bibliography","title":"Bibliography","text":"<ol> <li> <p>Andr\u00e1s Gily\u00e9n, Yuan Su, Guang Hao Low, and Nathan Wiebe. Quantum singular value transformation and beyond: exponential improvements for quantum matrix arithmetics [full version]. arXiv: https://arxiv.org/abs/1806.01838, 2018.</p> </li> <li> <p>Iordanis Kerenidis and Anupam Prakash. Quantum recommendation systems. In Proceedings of the 8th Innovations in Theoretical Computer Science Conference (ITCS), 49:1\u201349:21. 2017. arXiv: https://arxiv.org/abs/1603.08675. doi:10.4230/LIPIcs.ITCS.2017.49.</p> </li> <li> <p>Shantanav Chakraborty, Andr\u00e1s Gily\u00e9n, and Stacey Jeffery. The power of block-encoded matrix powers: improved regression techniques via faster hamiltonian simulation. In Proceedings of the 46th International Colloquium on Automata, Languages, and Programming (ICALP), 33:1\u201333:14. 2019. arXiv: https://arxiv.org/abs/1804.01973. doi:10.4230/LIPIcs.ICALP.2019.33.</p> </li> <li> <p>B. David Clader, Alexander M. Dalzell, Nikitas Stamatopoulos, Grant Salton, Mario Berta, and William J. Zeng. Quantum resources required to block-encode a matrix of classical data. IEEE Transactions on Quantum Engineering, 3:1\u201323, 2022. arXiv: https://arxiv.org/abs/2206.03505. doi:10.1109/TQE.2022.3231194.</p> </li> <li> <p>Guang Hao Low, Vadym Kliuchnikov, and Luke Schaeffer. Trading t-gates for dirty qubits in state preparation and unitary synthesis. arXiv: https://arxiv.org/abs/1812.00954, 2018.</p> </li> <li> <p>Vittorio Giovannetti, Seth Lloyd, and Lorenzo Maccone. Quantum random access memory. Physical Review Letters, 100(16):160501, 2008. arXiv: https://arxiv.org/abs/0708.1879. doi:10.1103/PhysRevLett.100.160501.</p> </li> <li> <p>Connor T. Hann, Gideon Lee, S.M. Girvin, and Liang Jiang. Resilience of quantum random access memory to generic noise. PRX Quantum, 2:020311, 4 2021. arXiv: https://arxiv.org/abs/2012.05340. URL: https://link.aps.org/doi/10.1103/PRXQuantum.2.020311, doi:10.1103/PRXQuantum.2.020311.</p> </li> <li> <p>Alexander M Dalzell, B David Clader, Grant Salton, Mario Berta, Cedric Yen-Yu Lin, David A Bader, Nikitas Stamatopoulos, Martin J A Schuetz, Fernando G S L Brand\u00e3o, Helmut G Katzgraber, and others. End-to-end resource analysis for quantum interior point methods and portfolio optimization. PRX Quantum, pages to appear, 2023. arXiv: https://arxiv.org/abs/2211.12489.</p> </li> <li> <p>Andr\u00e1s Gily\u00e9n, Yuan Su, Guang Hao Low, and Nathan Wiebe. Quantum singular value transformation and beyond: exponential improvements for quantum matrix arithmetics. In Proceedings of the 51st ACM Symposium on the Theory of Computing (STOC), 193\u2013204. 2019. arXiv: https://arxiv.org/abs/1806.01838. doi:10.1145/3313276.3316366.</p> </li> </ol>"},{"location":"quantum-algorithmic-primitives/loading-classical-data/introduction/","title":"Loading classical data","text":"<p>The end-to-end quantum applications covered in this document have classical inputs and classical outputs, in the sense that the problem is specified by some set of classical data, and the solution to the problem should be a different set of classical data. In some cases, the input data is relatively small, and loading it into the algorithm does not contribute significantly to the cost of the algorithm. In other cases\u2014for example, \"big data\" problems within the areas of machine learning and finance\u2014the dominant costs, both for classical and quantum algorithms, can be related to how the algorithms load and manipulate this large quantity of input data. Consequently, the availability of quantum speedups for these problems is often dependent on the ability to quickly and coherently access this data. The true cost of this access is the source of significant subtlety in many end-to-end quantum algorithms.</p>"},{"location":"quantum-algorithmic-primitives/loading-classical-data/preparing-states-from-classical-data/","title":"Preparing states from classical data","text":""},{"location":"quantum-algorithmic-primitives/loading-classical-data/preparing-states-from-classical-data/#rough-overview-in-words","title":"Rough overview (in words)","text":"<p>An important subroutine in many quantum algorithms is preparing a quantum state given a list of its amplitudes stored, for example, in a classical database.<sup>1</sup> The upshot is that \\(N\\) amplitudes, which require \\(\\mathcal{O}\\left( N \\right)\\) classical bits to write down, can be encoded in a quantum state with only \\(\\log_2(N)\\) qubits, an exponential compression in memory. However, there are caveats; for example, simple information-theoretic bounds [1] dictate that the quantum circuit that prepares the \\(\\log_2(N)\\)-qubit state must still have at least \\(\\mathcal{O}\\left( N \\right)\\) gates, so no exponential advantage in gate complexity is possible. Depending on which resource is being optimized, the best protocol for state preparation will look different and optimal state preparation methods are known for most choices of metric.</p>"},{"location":"quantum-algorithmic-primitives/loading-classical-data/preparing-states-from-classical-data/#rough-overview-in-math","title":"Rough overview (in math)","text":"<p>Let \\(x = (x_0,\\ldots,x_{N-1}) \\in \\mathbb{C}^N\\) be a vector of \\(N\\) complex numbers, and let </p>\\[\\begin{equation} \\label{eq:ket_psi_state_prep} \\ket{\\psi} = \\frac{1}{\\lVert x \\rVert}\\sum_{i=0}^{N-1} x_i \\ket{i} \\end{equation}\\]<p>be the associated normalized quantum state, where \\(\\lVert x \\rVert\\) denotes the standard Euclidean vector norm. Let \\(n=\\log_2(N)\\) denote the number of qubits of \\(\\ket{\\psi}\\). The goal is to prepare the state \\(\\ket{\\psi}\\) by applying a quantum circuit to the state \\(\\ket{0}^{\\otimes n}\\), a problem studied extensively in previous literature. A common approach, originating in [2], is to iterate through each of the \\(n\\) qubits and perform a single-qubit rotation, with the angle of rotation determined by the setting of the previous qubits. The rotation on the first qubit creates the 1-qubit state </p>\\[\\begin{equation} \\left(\\sqrt{\\sum\\nolimits_{i=0}^{N/2-1} |x_i|^2 }\\right)\\ket{0} + \\left(\\sqrt{\\sum\\nolimits_{i=N/2}^{N-1} |x_i|^2 }\\right) \\ket{1} \\end{equation}\\]<p>by performing a single-qubit rotation (about the \\(Y\\) axis) on the state \\(\\ket{0}\\) by an appropriate angle. Next, a similar kind of single-qubit rotation is performed on the second qubit, where the angle of rotation is conditioned on whether the first qubit is \\(\\ket{0}\\) or \\(\\ket{1}\\). The \\(m\\)th rotation is by one of \\(2^{m-1}\\) angles, depending on the setting of the first \\(m-1\\) qubits. Thus, in total there are \\(1+2+\\ldots+2^{n-1} = N-1\\) total angles that might be used for single-qubit rotations. This sequence of operations prepares the state \\(\\lVert x\\rVert^{-1}\\sum_{i=0}^{N-1}\\lvert x_i \\rvert \\ket{i}\\). To apply the phases, a single qubit rotation about the \\(Z\\)-axis by the appropriate angle is performed\u2014the angle depends on the setting of all \\(n\\) qubits, corresponding to the \\(N=2^n\\) different phases that might be needed. Thus, the total number of angles that define the protocol is \\(2N-1\\), exactly corresponding to the number of real parameters needed to describe the general state in Eq. \\(\\eqref{eq:ket_psi_state_prep}\\).</p> <p> </p> <p>Figure 1: Simple quantum circuit to prepare an arbitrary state \\(\\ket{\\psi}\\) with non-negative real coefficients on \\(n=3\\) qubits. The gate \\(R_y(\\theta)\\) denotes a single-qubit rotation by angle \\(\\theta\\) about the \\(Y\\) axis. The angles \\(\\theta_{s,p}\\) run from \\(s=0,1,\\ldots,n-1\\) and \\(p=0,1,\\ldots,2^s-1\\), for a total of \\(2^n-1\\) angles, which can be calculated from the amplitudes \\(x_i\\). To account for negative or complex coefficients, as many as \\(2^n\\) additional controlled \\(R_z\\) rotations would be needed. More sophisticated proposals can reduce the depth for ancilla-free constructions from \\(\\mathcal{O}\\left( 2^n \\right)\\) to \\(\\mathcal{O}\\left( 2^n/n \\right)\\) [3].</p> <p>It remains to describe how the controlled single-qubit rotations are performed when there are many control bits and different angles for each setting of the control. Here, one has many choices and the exact method will depend on how one has access to the data in \\(x\\) and what resource is being optimized. The most straightforward way is to iterate through each possible setting of the control bits and perform a multiply controlled rotation by a fixed angle for each in sequence. This approach requires \\(\\mathcal{O}\\left( N \\right)\\) gates spread over \\(\\mathcal{O}\\left( N \\right)\\) depth, as depicted in Fig. 1. When ancilla qubits are available, one can design protocols that have shallower depth (but the same total number of gates). For example, to perform the controlled rotation, one might store the \\(2N-1\\) angles needed to create the state in a quantum random access memory data structure. In this case, to perform a rotation, one need only read in the value of the angle from the QRAM into an ancilla register, then perform a rotation by the angle stored in memory. This way, one can apply the correct angle in one shot, rather than iterating through all possible angles.</p><p>Assuming one can perform arbitrary single-qubit gates to exact precision, it is possible to prepare the state \\(\\ket{\\psi}\\) exactly. However, often one must design circuits from a discrete gate set, such as Clifford gates and \\(T\\) gates, for example, when compiling into a gate sequence that can be implemented fault tolerantly. When this is the case, single-qubit rotations must be performed approximately: to approximate a single-qubit rotation to error \\(\\epsilon\\), a Clifford+\\(T\\) sequence of length \\(\\mathcal{O}\\left( \\log(1/\\epsilon) \\right)\\) must be applied [4].</p>"},{"location":"quantum-algorithmic-primitives/loading-classical-data/preparing-states-from-classical-data/#dominant-resource-cost-gatesqubits","title":"Dominant resource cost (gates/qubits)","text":"<p>In the table below, we collect several state preparation results in the model where any single-qubit gate can be performed exactly and the only multi-qubit gates allowed are CNOTs. Each result is state-of-the-art in some parameter regime. The circuit size (i.e., the total number of single-qubit and CNOT gates) and depth (i.e., the number of parallel-acting layers of gates), as well as the number of ancilla qubits (i.e. the number of qubits beyond the \\(n\\) qubits needed to hold the state \\(\\ket{\\psi}\\)) are listed.</p> Ref. Circuit size Circuit depth Ancilla qubits [3, 5] \\(\\mathcal{O}\\left( 2^n \\right)\\) \\(\\mathcal{O}\\left( \\frac{2^n}{n} \\right)\\) none [3, 5] \\(\\mathcal{O}\\left( 2^n \\right)\\) \\(\\mathcal{O}\\left( \\frac{2^n}{m+n} \\right)\\) \\(m \\in [0,\\mathcal{O}\\left( 2^n/n \\right)]\\) [3, 6, 7] \\(\\mathcal{O}\\left( 2^n \\right)\\) \\(\\mathcal{O}\\left( n \\right)\\) \\(\\mathcal{O}\\left( 2^n \\right)\\) <p>Note that the result of [5], which shows depth \\(\\mathcal{O}\\left( 2^n/(m+n) \\right)\\) using \\(m\\) ancilla qubits for \\(m \\leq \\mathcal{O}\\left( 2^n/n \\right)\\), encompasses all other results in the table (and is superior to the third row as it uses \\(\\mathcal{O}\\left( 2^n/n \\right)\\) ancilla qubits instead of \\(\\mathcal{O}\\left( 2^n \\right)\\)). We include the other results for completeness, as they are distinct constructions and can have other potential upsides.</p><p>A lower bound of \\(\\Omega(2^n)\\) is known for circuit size [1], so all of the results above are size optimal up to constant factors. Moreover, for any \\(m\\), a lower bound of \\(\\Omega(\\max(n,2^n/(n+m)))\\) is known for the circuit depth [3], so all of the results above are also optimal in circuit depth, up to constant factors.</p><p>For approximate state preparation in a discrete gate set such as \\(\\{H,S,T,\\mathrm{CNOT}\\}\\), the state \\(\\ket{\\psi}\\) is prepared up to \\(\\epsilon\\) error, measured by the \\(\\ell_2\\)-norm, and the circuit size and depth will depend on \\(\\epsilon\\). In this case, we have the following table of results.</p> Ref. Circuit size Circuit depth Ancilla qubits [3] \\(\\mathcal{O}\\left( 2^n \\log(2^n/\\epsilon) \\right)\\) \\(\\mathcal{O}\\left( \\frac{2^n \\log(2^n/\\epsilon)}{n} \\right)\\) none [3] \\(\\mathcal{O}\\left( 2^n \\log(2^n/\\epsilon) \\right)\\) \\(\\mathcal{O}\\left( \\frac{2^n\\log(2^n/\\epsilon)}{m+n} \\right)\\) \\(m \\in [0,\\mathcal{O}\\left( \\frac{2^n}{n \\log(n)} \\right)]\\) [7] \\(\\mathcal{O}\\left( 2^n\\log(n/\\epsilon) \\right)\\) \\(\\mathcal{O}\\left( n +\\log(1/\\epsilon) \\right)\\) \\(\\mathcal{O}\\left( 2^n \\right)\\) <p>If the state \\(\\ket{\\psi}\\) is sparse, meaning that only \\(d\\) of the \\(N\\) amplitudes are nonzero, then more efficient state preparation methods are known. In particular, [6] gave a circuit of depth \\(\\mathcal{O}\\left( \\log(nd) \\right)\\) that uses only \\(\\mathcal{O}\\left( nd\\log(d) \\right)\\) ancilla qubits, a great improvement over the general case when \\(d \\ll N\\).</p><p>In some fault-tolerant implementation schemes, such as lattice surgery using surface codes, Clifford gates can be performed cheaply, while \\(T\\) gates require the expensive process of magic state distillation. While \\(\\Omega(2^n\\log(1/\\epsilon)/\\log(n))\\) total gates are necessary to approximately create \\(\\ket{\\psi}\\) [8, Eq. 4.85] (matching upper bounds from [7] up to \\(\\mathrm{polylog}(n)\\) factors), [9] noted that it is possible for most of these to be Clifford gates. The number of \\(T\\) gates can be reduced to \\(\\sqrt{2^n}\\log(2^n/\\epsilon)\\) using \\(\\sqrt{2^n}\\log(1/\\epsilon)\\) ancillas (in fact, there is a smooth tradeoff between the \\(T\\) count and the number of ancillas). Furthermore, these ancillas can be dirty, meaning they can be initialized into any quantum state, so long as they are returned to this (potentially unknown) state at the end of the procedure.</p><p>All of the above constructions are \"garbage-free\" state preparation protocols, because they prepare the state \\(\\ket{\\psi}\\) exactly and all ancilla qubits are returned to their initial state. However, in some applications, it is allowable to leave the ancilla register entangled with the data as long as the coefficients are correct. That is, one prepares the state </p>\\[\\begin{equation} \\frac{1}{\\lVert x\\rVert}\\sum_{i=0}^{N-1} x_i \\ket{i} \\otimes \\ket{\\mathrm{garbage}_i}\\,. \\end{equation}\\]<p>In this setting, [10, Sec. IIID], en route to giving better algorithms for the electronic structure problem, gave a construction that approximately prepares the state above using only \\(\\mathcal{O}\\left( 2^n+\\log(1/\\epsilon) \\right)\\) \\(T\\) gates and \\(\\mathcal{O}\\left( \\log(N) \\right)\\) ancilla qubits, albeit still requiring \\(\\mathcal{O}\\left( N\\log(1/\\epsilon) \\right)\\) Clifford gates and \\(\\mathcal{O}\\left( \\log(N/\\epsilon) \\right)\\) ancillas. In [10] it is presented with \\(\\mathcal{O}\\left( N \\right)\\) depth but could be improved to \\(\\mathcal{O}\\left( \\log(N) \\right)\\) depth at the expense of additional ancillas, using log-depth constructions for QRAM. This method can also make use of the spacetime tradeoffs mentioned above, as discussed in [9, 11].</p>"},{"location":"quantum-algorithmic-primitives/loading-classical-data/preparing-states-from-classical-data/#caveats","title":"Caveats","text":"<ul> <li>Classical pre-processing: computing the circuits for preparing \\(\\ket{\\psi}\\) given the list of \\(N\\) coefficients \\(x\\) can be a non-negligible classical cost. For example, computing each of the \\(\\mathcal{O}\\left( N \\right)\\) single-qubit rotation angles requires computing sums and evaluating trigonometric functions, which can be done to precision \\(\\epsilon\\) in \\(\\mathrm{polylog}(1/\\epsilon)\\) classical time. Moreover, computing Clifford+\\(T\\) gate sequences that approximate given rotation angles to error \\(\\epsilon\\) likewise requires \\(\\mathrm{polylog}(1/\\epsilon)\\) classical time [4]. The total classical work scales as \\(O(N\\mathrm{polylog}(1/\\epsilon))\\), although this cost can be parallelized.</li> <li>Coherent arithmetic: to avoid some of the classical pre-processing, one might try to perform the arithmetic coherently. This might be unavoidable if the entries of \\(x\\) arrive in an online fashion and rotation angles and other quantities need to be computed after superpositions have been created. Formally, the scaling of coherent arithmetic is mild, generally requiring just \\(\\mathrm{polylog}(N,1/\\epsilon)\\) number of gates and ancilla qubits, but in practice this is likely to be expensive (e.g., known methods for coherently computing \\(\\arcsin(\\cdot)\\) to nine bits of precision use order-\\(10^4\\) Toffoli gates and more than 100 ancilla qubits [12]). See [13] for a general black-box approach that avoids coherent arithmetic.</li> <li>Too many ancilla qubits: achieving depths that scale logarithmically with \\(N\\) requires \\(\\mathcal{O}\\left( N \\right)\\) ancilla qubits, which limits the size of \\(N\\) that might be practical. This could be mitigated if it is possible to develop a large-scale hardware element specialized for performing the sort of circuits that arise in these protocols, similar to a quantum random access memory.</li> <li>Long-range gates: achieving \\(\\mathrm{polylog}(N)\\) depth for state preparation requires \\(\\mathcal{O}\\left( N \\right)\\) ancilla qubits and \\(\\mathcal{O}\\left( N \\right)\\) gates, many of which act in parallel and on far-separated qubits. If spatial locality were imposed, it would likely be difficult to avoid \\(\\mathcal{O}\\left( N \\right)\\) overhead in depth.</li> <li>Dequantization: Consider the task of drawing samples from the same probability distribution induced by measuring \\(\\ket{\\psi}\\) in the computational basis in time \\(\\mathrm{polylog}(N)\\) time. Preparing \\(\\ket{\\psi}\\) as described is a quantum method of doing so, but the same can be done classically by first constructing a certain classical data structure and assuming access to classical RAM [14]. In some machine learning applications, this idea leads to classical algorithms that effectively dequantize quantum algorithms that utilize the state preparation primitive [15, 16].</li> </ul>"},{"location":"quantum-algorithmic-primitives/loading-classical-data/preparing-states-from-classical-data/#example-use-cases","title":"Example use cases","text":"<ul> <li>Hamiltonian simulation via linear combination of unitaries (LCU) requires a PREPARE step where a state is prepared with certain classically computed coefficients. Relatedly, the same PREPARE gadget is used to construct block-encodings of such Hamiltonians. However, in this application, state preparation with garbage is generally allowable.</li> <li>In certain quantum machine learning protocols, classical data (e.g., image pixel values) are encoded into a quantum state via the so-called \"amplitude encoding,\" where \\(N\\) classical features are stored in a quantum state of \\(\\log_2(N)\\) qubits [17]. Following the preparation of the amplitude encoded data, the state is processed with the goal of, for example, classifying the image.</li> <li>Creating a block-encoding of a matrix of classical data is performed using state preparation as a subroutine (more precisely, block-encoding classical data requires controlled state preparation). The block-encoding is then useful in a variety of contexts, for example in quantum interior point methods.</li> </ul>"},{"location":"quantum-algorithmic-primitives/loading-classical-data/preparing-states-from-classical-data/#further-reading","title":"Further reading","text":"<ul> <li>When the amplitudes \\(x_i\\) correspond to an efficiently computable function \\(f(i)\\), the complexity of state preparation can be reduced. In this case, the oracle access to \\(x_i\\) can be replaced by a reversible computation of \\(f(i)\\), up to \\(t\\) bits of precision, using coherent arithmetic \\(\\ket{i}\\ket{0^t} \\rightarrow \\ket{i}\\ket{f(i)}\\) [12, 18, 19]. The value of \\(f(i)\\) can be transduced into the amplitude using the methods of [20, 13, 21, 22], and the success probability boosted to unity using quantum amplitude amplification. There is an alternative method [23], based on quantum singular value transformation (QSVT) that circumvents the need for the coherent evaluation of \\(f(i)\\) by implementing a low-cost block-encoding of \\(\\sin(i)\\), and then using QSVT to apply \\(f(\\arcsin(\\cdot))\\) to this block-encoding. The complexity of both of these approaches depends on an \"L2-norm filling-fraction\\\" \\(\\mathcal{F}_f^{[N]} := \\nrm{f(i)}_2 / (\\sqrt{N} |f(i)|_{\\mathrm{max}})\\) as \\(\\mathcal{O}(1/\\mathcal{F}_f^{[N]})\\) (see [23] for more detail). There is also an approach [24] based on the adiabatic algorithm which has a worse dependence on \\(\\mathcal{F}_f^{[N]}\\). For efficiently integrable probability distributions, one can use the approach of [2], which has complexity independent of \\(\\mathcal{F}_f^{[N]}\\). However, this approach requires coherent arithmetic to reversibly evaluate the integral of the desired function (when applied to functions for which an analytic expression for the integral is not available, this can nullify the quadratic speedup in quantum Monte Carlo estimation [25]). There also exist methods specialized for certain target states, such as Gaussians [26, 27].</li> <li>A related problem asks to synthesize an arbitrary \\(2^n \\times 2^n\\) unitary. Without ancillas, this requires depth and size \\(\\mathcal{O}\\left( 4^n \\right)\\), for which there are upper [28] and lower [29] bounds that match up to constant factors. With ancillas, it is an open question whether or not the depth can be reduced to \\(\\mathrm{poly}(n)\\); this is related to the \"unitary synthesis problem\" from the list of open problems in [30], and it has been studied in several works, e.g., [3, 31, 5]. A depth lower bound of \\(\\Omega(n + 4^n/(m+n))\\) is known for \\(m\\) ancilla qubits [3], but the shallowest upper bound is depth \\(\\mathcal{O}\\left( n2^{n/2} \\right)\\), using \\(m=\\mathcal{O}\\left( 4^n/n \\right)\\) ancilla qubits [5].</li> </ul>"},{"location":"quantum-algorithmic-primitives/loading-classical-data/preparing-states-from-classical-data/#bibliography","title":"Bibliography","text":"<ol> <li> <p>Martin Plesch and \u010caslav Brukner. Quantum-state preparation with universal gate decompositions. Physical Review A, 83:032302, 3 2011. arXiv: https://arxiv.org/abs/1003.5760. URL: https://link.aps.org/doi/10.1103/PhysRevA.83.032302, doi:10.1103/PhysRevA.83.032302.</p> </li> <li> <p>Lov Grover and Terry Rudolph. Creating superpositions that correspond to efficiently integrable probability distributions. arXiv: https://arxiv.org/abs/quant-ph/0208112, 2002.</p> </li> <li> <p>Xiaoming Sun, Guojing Tian, Shuai Yang, Pei Yuan, and Shengyu Zhang. Asymptotically optimal circuit depth for quantum state preparation and general unitary synthesis. IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems, pages 1\u20131, 2023. arXiv: https://arxiv.org/abs/2108.06150. doi:10.1109/TCAD.2023.3244885.</p> </li> <li> <p>Neil J Ross and Peter Selinger. Optimal ancilla-free clifford+ t approximation of z-rotations. arXiv: https://arxiv.org/abs/1403.2975, 2014.</p> </li> <li> <p>Pei Yuan and Shengyu Zhang. Optimal (controlled) quantum state preparation and improved unitary synthesis by quantum circuits with any number of ancillary qubits. Quantum, 7:956, 3 2023. arXiv: https://arxiv.org/abs/2202.11302. URL: https://doi.org/10.22331/q-2023-03-20-956, doi:10.22331/q-2023-03-20-956.</p> </li> <li> <p>Xiao-Ming Zhang, Tongyang Li, and Xiao Yuan. Quantum state preparation with optimal circuit depth: implementations and applications. Physical Review Letters, 129:230504, 11 2022. arXiv: https://arxiv.org/abs/2201.11495. URL: https://link.aps.org/doi/10.1103/PhysRevLett.129.230504, doi:10.1103/PhysRevLett.129.230504.</p> </li> <li> <p>Kaiwen Gui, Alexander M Dalzell, Alessandro Achille, Martin Suchara, and Frederic T Chong. Spacetime-efficient low-depth quantum state preparation with applications. arXiv: https://arxiv.org/abs/2303.02131, 2023.</p> </li> <li> <p>Michael A. Nielsen and Isaac L. Chuang. Quantum computation and quantum information. Cambridge University Press, 2000. doi:10.1017/CBO9780511976667.</p> </li> <li> <p>Guang Hao Low, Vadym Kliuchnikov, and Luke Schaeffer. Trading t-gates for dirty qubits in state preparation and unitary synthesis. arXiv: https://arxiv.org/abs/1812.00954, 2018.</p> </li> <li> <p>Ryan Babbush, Craig Gidney, Dominic W. Berry, Nathan Wiebe, Jarrod McClean, Alexandru Paler, Austin Fowler, and Hartmut Neven. Encoding electronic spectra in quantum circuits with linear t complexity. Physical Review X, 8(4):041015, 2018. arXiv: https://arxiv.org/abs/1805.03662. doi:10.1103/PhysRevX.8.041015.</p> </li> <li> <p>Dominic W. Berry, Craig Gidney, Mario Motta, Jarrod R. McClean, and Ryan Babbush. Qubitization of arbitrary basis quantum chemistry leveraging sparsity and low rank factorization. Quantum, 3:208, 12 2019. arXiv: https://arxiv.org/abs/1902.02134. URL: https://doi.org/10.22331/q-2019-12-02-208, doi:10.22331/q-2019-12-02-208.</p> </li> <li> <p>Thomas H\u00e4ner, Martin Roetteler, and Krysta M Svore. Optimizing quantum circuits for arithmetic. arXiv: https://arxiv.org/abs/1805.12445, 2018.</p> </li> <li> <p>Yuval R. Sanders, Guang Hao Low, Artur Scherer, and Dominic W. Berry. Black-box quantum state preparation without arithmetic. Physical Review Letters, 122:020502, 1 2019. arXiv: https://arxiv.org/abs/1807.03206. URL: https://link.aps.org/doi/10.1103/PhysRevLett.122.020502, doi:10.1103/PhysRevLett.122.020502.</p> </li> <li> <p>Shantanav Chakraborty, Andr\u00e1s Gily\u00e9n, and Stacey Jeffery. The power of block-encoded matrix powers: improved regression techniques via faster hamiltonian simulation. In Proceedings of the 46th International Colloquium on Automata, Languages, and Programming (ICALP), 33:1\u201333:14. 2019. arXiv: https://arxiv.org/abs/1804.01973. doi:10.4230/LIPIcs.ICALP.2019.33.</p> </li> <li> <p>Ewin Tang. A quantum-inspired classical algorithm for recommendation systems. In Proceedings of the 51st ACM Symposium on the Theory of Computing (STOC), 217\u2013228. 2019. arXiv: https://arxiv.org/abs/1807.04271. doi:10.1145/3313276.3316310.</p> </li> <li> <p>Ewin Tang. Quantum principal component analysis only achieves an exponential speedup because of its state preparation assumptions. Physical Review Letters, 127(6):060503, 2021. arXiv: https://arxiv.org/abs/1811.00414. doi:10.1103/PhysRevLett.127.060503.</p> </li> <li> <p>Maria Schuld and Francesco Petruccione. Machine learning with quantum computers. Springer, 2021. doi:10.1007/978-3-030-83098-4.</p> </li> <li> <p>Mihir K Bhaskar, Stuart Hadfield, Anargyros Papageorgiou, and Iasonas Petras. Quantum algorithms and circuits for scientific computing. Quantum Information and Computation, 2016. arXiv: https://arxiv.org/abs/1511.08253. doi:10.26421/QIC16.3-4-2.</p> </li> <li> <p>Edgard Mu\u00f1oz-Coreas and Himanshu Thapliyal. T-count and qubit optimized quantum circuit design of the non-restoring square root algorithm. ACM Journal on Emerging Technologies in Computing Systems, 14(3):1\u201315, 2018. arXiv: https://arxiv.org/abs/1712.08254. doi:https://doi.org/10.1145/3264816.</p> </li> <li> <p>Lov K Grover. Synthesis of quantum superpositions by quantum computation. Physical Review Letters, 85(6):1334, 2000. doi:10.1103/PhysRevLett.85.1334.</p> </li> <li> <p>Shengbin Wang, Zhimin Wang, Guolong Cui, Shangshang Shi, Ruimin Shang, Lixin Fan, Wendong Li, Zhiqiang Wei, and Yongjian Gu. Fast black-box quantum state preparation based on linear combination of unitaries. Quantum Information Processing, 20(8):1\u201314, 2021. arXiv: https://arxiv.org/abs/2105.06230. doi:https://doi.org/10.1007/s11128-021-03203-z.</p> </li> <li> <p>Johannes Bausch. Fast black-box quantum state preparation. Quantum, 2022. arXiv: https://arxiv.org/abs/2009.10709. doi:https://doi.org/10.22331/q-2022-08-04-773.</p> </li> <li> <p>Sam McArdle, Andr\u00e1s Gily\u00e9n, and Mario Berta. Quantum state preparation without coherent arithmetic. arXiv: https://arxiv.org/abs/2210.14892, 2022.</p> </li> <li> <p>Arthur G Rattew and B\u00e1lint Koczor. Preparing arbitrary continuous functions in quantum registers with logarithmic complexity. arXiv: https://arxiv.org/abs/2205.00519, 2022.</p> </li> <li> <p>Steven Herbert. No quantum speedup with grover\u2013rudolph state preparation for quantum monte carlo integration. Physical Review E, 103:063302, 6 2021. arXiv: https://arxiv.org/abs/2101.02240. URL: https://link.aps.org/doi/10.1103/PhysRevE.103.063302, doi:10.1103/PhysRevE.103.063302.</p> </li> <li> <p>Alexei Kitaev and William A Webb. Wavefunction preparation and resampling using a quantum computer. arXiv: https://arxiv.org/abs/0801.0342, 2008.</p> </li> <li> <p>Arthur G. Rattew, Yue Sun, Pierre Minssen, and Marco Pistoia. The efficient preparation of normal distributions in quantum registers. Quantum, 5:609, 12 2021. arXiv: https://arxiv.org/abs/2009.06601. URL: https://doi.org/10.22331/q-2021-12-23-609, doi:10.22331/q-2021-12-23-609.</p> </li> <li> <p>M. Mottonen and J. J. Vartiainen. Decompositions of general quantum gates. arXiv: https://arxiv.org/abs/quant-ph/0504100, 2005.</p> </li> <li> <p>Vivek V. Shende, Igor L. Markov, and Stephen S. Bullock. Minimal universal two-qubit controlled-not-based circuits. Physical Review A, 69:062321, 6 2004. arXiv: https://arxiv.org/abs/quant-ph/0308033. URL: https://link.aps.org/doi/10.1103/PhysRevA.69.062321, doi:10.1103/PhysRevA.69.062321.</p> </li> <li> <p>Scott Aaronson. Open problems related to quantum query complexity. ACM Transactions on Quantum Computing, 12 2021. arXiv: https://arxiv.org/abs/2109.06917. URL: https://doi.org/10.1145/3488559, doi:10.1145/3488559.</p> </li> <li> <p>Gregory Rosenthal. Query and depth upper bounds for quantum unitaries via grover search. arXiv: https://arxiv.org/abs/2111.07992, 2021.</p> </li> </ol> <ol> <li> <p>When the amplitudes are given by some well-behaved function, rather than being arbitrarily chosen, different (related) protocols are used, see Further reading below.\u00a0\u21a9</p> </li> </ol>"},{"location":"quantum-algorithmic-primitives/loading-classical-data/quantum-random-access-memory/","title":"Quantum random access memory","text":""},{"location":"quantum-algorithmic-primitives/loading-classical-data/quantum-random-access-memory/#rough-overview-in-words","title":"Rough overview (in words)","text":"<p>Quantum random access memory (QRAM) is a construction that enables coherent access to classical data, such that multiple different elements in a classical database can be read in superposition. The ability to rapidly access large, unstructured classical data sets in this way is crucial to the speedups of certain quantum algorithms (for example, quantum machine learning based on quantum linear algebra). QRAM is commonly invoked in such cases as a way to circumvent data-input bottlenecks [1], i.e. situations where loading input data could limit the end-to-end runtime of an algorithm. It remains an open question, however, whether a large-scale QRAM will ever be practical, casting doubt on quantum speedups that rely on QRAM. Note that, while here we focus on the more common use case of loading classical data with QRAM, certain QRAM architectures can be adapted to also load quantum data.</p>"},{"location":"quantum-algorithmic-primitives/loading-classical-data/quantum-random-access-memory/#rough-overview-in-math","title":"Rough overview (in math)","text":"<p>Consider a length-\\(N\\), unstructured classical data vector \\(x\\), and denote the \\(i^\\mathrm{th}\\) entry as \\(x_i\\). Let the number of bits of \\(x_i\\) be denoted by \\(d\\) and let \\(D = 2^d\\). Given an input quantum state \\(\\ket{\\psi} = \\sum_{i =0}^{N-1}\\sum_{j=0}^{D-1}\\alpha_{ij} \\ket{i}_A \\ket{j}_B\\), QRAM is defined [2] as a unitary operation \\(Q\\) with the action, </p>\\[\\begin{equation} Q\\ket{\\psi} = Q\\sum_{i =0}^{N-1}\\sum_{j=0}^{D-1}\\alpha_{ij} \\ket{i}_A \\ket{j}_B = \\sum_{i =0}^{N-1}\\sum_{j=0}^{D-1}\\alpha_{ij} \\ket{i}_A \\ket{j \\oplus x_i}_B. \\label{eq:QRAM_definition} \\end{equation}\\]<p>Here, \\(A\\) is a \\(\\log_2(N)\\)-qubit register, and \\(B\\) is a \\(d\\)-qubit register. Note that the unitary \\(Q\\) can also be understood as an oracle (or black box) providing access to \\(x\\), as \\(Q(\\sum_i \\alpha_i \\ket{i}\\ket{0}) = \\sum_i \\alpha_i \\ket{i}\\ket{x_i}\\).</p><p>Let \\(T_Q\\) denote the time it takes to implement the operation \\(Q\\), where \\(T_Q\\) can be measured in circuit depth, total gate cost, \\(T\\)-gate cost, etc., depending on the context. Algorithms that rely on QRAM to claim exponential speedups over their classical counterparts frequently assume that \\(T_Q = \\mathrm{polylog} (N)\\).</p>"},{"location":"quantum-algorithmic-primitives/loading-classical-data/quantum-random-access-memory/#dominant-resource-cost-gatesqubits","title":"Dominant resource cost (gates/qubits)","text":"<p>The QRAM operation \\(Q\\) can be implemented as a quantum circuit that uses \\(\\mathcal{O}\\left( N \\right)\\) ancillary qubits and \\(\\mathcal{O}\\left( N \\right)\\) gates. Assuming gates acting on disjoint qubits can be parallelized, the depth of the circuit is only \\(T_Q = \\mathcal{O}\\left( \\log(N) \\right)\\). Explicit circuits can be found in, e.g., [3, 4]. The number of ancillary qubits can be reduced at the price of increased circuit depth; circuits implementing \\(Q\\) can be constructed using \\(\\mathcal{O}\\left( N/M \\right)\\) ancillary qubits and depth \\(\\mathcal{O}\\left( M\\log(N) \\right)\\), where \\(M \\in [1, N]\\), see examples in [5, 6, 3, 4] (the setting of \\(M=N/\\log(N)\\) is sometimes referred to as \"QROM\\\"\u2014see terminology caveats below\u2014and its fault-tolerant cost of implementation is well established [7]).</p><p>Note that the above resource costs neglect the dependence on \\(d\\) for simplicity, since different constructions yield different \\(d\\) dependence. For example, the \\(d\\) bits of a data element can be queried in series, requiring \\(\\mathcal{O}\\left( N \\right)\\) ancillary qubits with \\(T_Q = \\mathcal{O}\\left( d\\log(N) \\right)\\) (improvement to \\(T_Q = \\mathcal{O}\\left( d+\\log(N) \\right)\\) is possible for certain QRAM architectures [8]). Alternatively, the \\(d\\) bits can be accessed in parallel, with \\(T_Q = \\mathcal{O}\\left( \\log(N) \\right)\\), but at the price of \\(\\mathcal{O}\\left( Nd \\right)\\) ancillary qubits.</p>"},{"location":"quantum-algorithmic-primitives/loading-classical-data/quantum-random-access-memory/#caveats","title":"Caveats","text":"<p>The main concern for QRAM's practicality is the large hardware overhead that is necessary to realize fast queries \\(T_Q = \\mathcal{O}\\left( \\log(N) \\right)\\). This cost is likely to be prohibitive for big-data applications where \\(N\\) can be millions or billions. This cost will be magnified by additional overhead associated with error correction and fault tolerance [3], especially given that circuits implementing \\(Q\\) are composed of \\(\\mathcal{O}\\left( N \\right)\\) non-Clifford gates. Indeed, the fact that \\(\\mathcal{O}\\left( N \\right)\\) non-Clifford gates are required, together with the assumption that magic state distillation is expensive to run in a massively parallel fashion, has led some to argue that \\(T_Q = \\mathcal{O}\\left( \\log(N) \\right)\\) is not realistic in a fault-tolerant setting. It is possible that alternative approaches to fault tolerance tailored to QRAM could help alleviate this large hardware overhead.</p><p>The fault-tolerance overhead may be reduced for the so-called bucket-brigade QRAM (BBQRAM) [2, 9, 4]. BBQRAM can be understood as a family of circuits implementing \\(Q\\) that are intrinsically resilient to noise. More precisely, [4] shows that if \\(\\epsilon\\) is the per-gate error rate, BBQRAM circuits can implement \\(Q\\) with leading-order fidelity \\(F \\sim 1- \\epsilon\\, \\mathrm{polylog}(N)\\), while generic circuits implementing \\(Q\\) have leading-order fidelity \\(F \\sim 1- \\epsilon\\, \\mathcal{O}\\left( N \\right)\\). Nevertheless, some amount of error correction will almost certainly be required even for BBQRAM circuits.</p><p>Some terminology caveats:</p><ul> <li>The unitary \\(Q\\) is referred to by some as Quantum Read-Only Memory (QROM) [7], reflecting the fact that \\(Q\\) corresponds only to reading data. Some algorithms also require the ability to write to the vector \\(x\\) duration a computation, but the writing of classical data need not be implemented via a quantum circuit.</li> <li>The term QRAM is used by different authors to refer to the unitary \\(Q\\), families of circuits that implement \\(Q\\), or quantum hardware that runs said circuits.</li> <li>Some use the term QRAM to refer exclusively to the case \\(N\\gg 1\\) and \\(T_Q = \\mathrm{polylog} (N)\\), where the implementation challenges for QRAM are most pronounced.</li> <li>The terms QRAM and QROM are sometimes synonymous with the cases of \\(T_Q = \\mathrm{polylog}(N)\\) and \\(T_Q = \\mathrm{poly}(N)\\), respectively, even though \\(T_Q\\) is unrelated to the distinction between reading and writing. The term QROAM has also been used to describe intermediate circuits that trade off depth and width [6].</li> </ul><p>Elsewhere in this document, we follow the convention described in the final two bullet points above: usage of the term QRAM, unless specified otherwise, refers to the ability to implement \\(Q\\) at cost \\(\\mathrm{polylog}(N)\\).</p>"},{"location":"quantum-algorithmic-primitives/loading-classical-data/quantum-random-access-memory/#example-use-cases","title":"Example use cases","text":"<ul> <li>Quantum linear algebra. QRAM can be used as an oracle implementation for linear algebra algorithms operating on unstructured data (e.g., by acting as a subroutine in a block-encoding), with applications in machine learning, finance, etc. For example, the quantum recommendation systems algorithm [10] (now dequantized) uses QRAM as a subroutine to efficiently encode rows of an input data matrix in the amplitudes of quantum states (see Appendix A of [10] for details).</li> <li>Hamiltonian simulation, quantum chemistry, condensed matter physics. In the linear combination of unitaries query model, QRAM can be used as a subroutine for \"PREPARE\" oracles that encode coefficients of the simulated Hamiltonian into the amplitudes of quantum states [7]. These use cases typically consider the hybrid QROM/QRAM constructions with \\(\\mathcal{O}\\left( K \\log(N) \\right)\\) ancillary qubits and depth \\(\\mathcal{O}\\left( N/K \\right)\\) (with \\(K\\) a parameter to be optimized), because the amount of data (and thus the size of \\(N\\)) scales only polynomially with the system size.</li> <li>Grover's search. QRAM can be used as an oracle implementation for Grover's oracle in the context of an unstructured database search, see Chapter 4 of [11]. This sort of Grover's search appears for example in quantum algorithms that utilize dynamic programming to give polynomial speedups for combinatorial optimization problems like the traveling salesman problem [12]. However, it has been argued that a quantum computer running Grover's algorithm with a QRAM oracle would not provide a speedup over a classical computer with comparable hardware resources [13].</li> <li>Topological data analysis (TDA). A small QRAM (i.e., not exponentially larger than the main quantum data register) is used in some quantum algorithms for TDA [14, 15] in order to load the positions of the data points for computing whether simplices are present in the complex at a given length scale.</li> </ul>"},{"location":"quantum-algorithmic-primitives/loading-classical-data/quantum-random-access-memory/#further-reading","title":"Further reading","text":"<ul> <li>Reference [16] focuses on various fundamental and practical concerns for large-scale QRAM, while also providing a comprehensive survey of the field.</li> <li>Reference [17] provides an overview of practical concerns facing QRAM in the context of big-data applications (though the discussions of noise resilience there and in [9] are somewhat outdated, cf. [4]).</li> </ul>"},{"location":"quantum-algorithmic-primitives/loading-classical-data/quantum-random-access-memory/#bibliography","title":"Bibliography","text":"<ol> <li> <p>Scott Aaronson. Read the fine print. Nature Physics, 11(4):291\u2013293, 2015. URL: https://scottaaronson.com/papers/qml.pdf, doi:10.1038/nphys3272.</p> </li> <li> <p>Vittorio Giovannetti, Seth Lloyd, and Lorenzo Maccone. Quantum random access memory. Physical Review Letters, 100(16):160501, 2008. arXiv: https://arxiv.org/abs/0708.1879. doi:10.1103/PhysRevLett.100.160501.</p> </li> <li> <p>Olivia Di Matteo, Vlad Gheorghiu, and Michele Mosca. Fault-tolerant resource estimation of quantum random-access memories. IEEE Transactions on Quantum Engineering, 1:1\u201313, 2020. arXiv: https://arxiv.org/abs/1902.01329. doi:10.1109/TQE.2020.2965803.</p> </li> <li> <p>Connor T. Hann, Gideon Lee, S.M. Girvin, and Liang Jiang. Resilience of quantum random access memory to generic noise. PRX Quantum, 2:020311, 4 2021. arXiv: https://arxiv.org/abs/2012.05340. URL: https://link.aps.org/doi/10.1103/PRXQuantum.2.020311, doi:10.1103/PRXQuantum.2.020311.</p> </li> <li> <p>Guang Hao Low, Vadym Kliuchnikov, and Luke Schaeffer. Trading t-gates for dirty qubits in state preparation and unitary synthesis. arXiv: https://arxiv.org/abs/1812.00954, 2018.</p> </li> <li> <p>Dominic W. Berry, Craig Gidney, Mario Motta, Jarrod R. McClean, and Ryan Babbush. Qubitization of arbitrary basis quantum chemistry leveraging sparsity and low rank factorization. Quantum, 3:208, 12 2019. arXiv: https://arxiv.org/abs/1902.02134. URL: https://doi.org/10.22331/q-2019-12-02-208, doi:10.22331/q-2019-12-02-208.</p> </li> <li> <p>Ryan Babbush, Craig Gidney, Dominic W. Berry, Nathan Wiebe, Jarrod McClean, Alexandru Paler, Austin Fowler, and Hartmut Neven. Encoding electronic spectra in quantum circuits with linear t complexity. Physical Review X, 8(4):041015, 2018. arXiv: https://arxiv.org/abs/1805.03662. doi:10.1103/PhysRevX.8.041015.</p> </li> <li> <p>Zhao-Yun Chen, Cheng Xue, Tai-Ping Sun, Huan-Yu Liu, Xi-Ning Zhuang, Meng-Han Dou, Tian-Rui Zou, Yuan Fang, Yu-Chun Wu, and Guo-Ping Guo. An efficient and error-resilient protocol for quantum random access memory with generalized data size. arXiv: https://arxiv.org/abs/2303.05207, 2023.</p> </li> <li> <p>Srinivasan Arunachalam, Vlad Gheorghiu, Tomas Jochym-O'Connor, Michele Mosca, and Priyaa Varshinee Srinivasan. On the robustness of bucket brigade quantum ram. New Journal of Physics, 17(12):123010, 2015. arXiv: https://arxiv.org/abs/1502.03450. doi:10.1088/1367-2630/17/12/123010.</p> </li> <li> <p>Iordanis Kerenidis and Anupam Prakash. Quantum recommendation systems. In Proceedings of the 8th Innovations in Theoretical Computer Science Conference (ITCS), 49:1\u201349:21. 2017. arXiv: https://arxiv.org/abs/1603.08675. doi:10.4230/LIPIcs.ITCS.2017.49.</p> </li> <li> <p>Michael A. Nielsen and Isaac L. Chuang. Quantum computation and quantum information. Cambridge University Press, 2000. doi:10.1017/CBO9780511976667.</p> </li> <li> <p>Andris Ambainis, Kaspars Balodis, J\u0101nis Iraids, Martins Kokainis, Kri\u0161j\u0101nis Pr\u016bsis, and Jevg\u0113nijs Vihrovs. Quantum speedups for exponential-time dynamic programming algorithms. In Proceedings of the 30th ACM-SIAM Symposium on Discrete Algorithms (SODA), 1783\u20131793. SIAM, 2019. arXiv: https://arxiv.org/abs/2104.14384. doi:10.1137/1.9781611975482.107.</p> </li> <li> <p>Damian S Steiger and Matthias Troyer. Racing in parallel: quantum versus classical. In APS March Meeting Abstracts, volume 2016, H44\u2013010. 2016. See related talk video.</p> </li> <li> <p>Seth Lloyd, Silvano Garnerone, and Paolo Zanardi. Quantum algorithms for topological and geometric analysis of data. Nature Communications, 7(1):1\u20137, 2016. arXiv: https://arxiv.org/abs/1408.3106. doi:https://doi.org/10.1038/ncomms10138.</p> </li> <li> <p>Sam McArdle, Andr\u00e1s Gily\u00e9n, and Mario Berta. A streamlined quantum algorithm for topological data analysis with exponentially fewer qubits. arXiv: https://arxiv.org/abs/2209.12887, 2022.</p> </li> <li> <p>Samuel Jaques and Arthur G Rattew. Qram: a survey and critique. arXiv: https://arxiv.org/abs/2305.10310, 2023.</p> </li> <li> <p>Carlo Ciliberto, Mark Herbster, Alessandro Davide Ialongo, Massimiliano Pontil, Andrea Rocchetto, Simone Severini, and Leonard Wossnig. Quantum machine learning: a classical perspective. Proceedings of the Royal Society A, 474(2209):20170551, 2018. arXiv: https://arxiv.org/abs/1707.08561. doi:https://doi.org/10.1098/rspa.2017.0551.</p> </li> </ol>"},{"location":"quantum-algorithmic-primitives/quantum-linear-algebra/block-encodings/","title":"Block-encodings","text":""},{"location":"quantum-algorithmic-primitives/quantum-linear-algebra/block-encodings/#rough-overview-in-words","title":"Rough overview (in words)","text":"<p>In a quantum algorithm, the quantum gates that are applied to quantum states are necessarily unitary operators. However, one often needs to apply a linear transformation to some encoded data that is not represented by a unitary operator, and furthermore one generally needs coherent access to these non-unitary transformations. How can we encode such a non-unitary transformation within a unitary operator? Block-encoding is one method of providing exactly this kind of coherent access to generic linear operators. Block-encoding works by embedding the desired linear operator as a suitably normalized block within a larger unitary matrix, such that the full encoding is a unitary operator, and the desired linear operator is given by restricting the unitary to an easily recognizable subspace. To be useful for quantum algorithms, this block-encoding unitary must also be realized by some specific quantum circuit acting on the main register and additional ancilla qubits.</p><p>Block-encodings are ubiquitous within quantum algorithms, but they have both benefits and drawbacks. They are easy to work with, since one can efficiently perform manipulations of block-encodings, such as taking products or convex combinations. On the other hand, this improved working efficiency comes at the cost of having more limited access. For example, if a matrix is stored in classical random access memory, the matrix entries can be explicitly accessed with a single query to the memory, whereas if one only has access to a block-encoding of the matrix, estimating a matrix entry to precision \\(\\varepsilon\\) requires \\(\\mathcal{O}\\left( 1/\\varepsilon \\right)\\) uses of the block-encoding unitary in general (by utilizing an amplitude estimation subroutine).</p><p>Block-encodings also provide a layer of abstraction that assists in the design and analysis of quantum algorithms. One can simply assume access to a block-encoding and count the number times it is applied. To run the algorithm, it is necessary to choose a method for implementing the block-encoding. There are many ways of constructing block-encodings that could be suited to the structure of the input. For instance, there are efficient block-encoding strategies for density matrices, positive operator-valued measures (POVMs), Gram matrices, sparse-access matrices, matrices that are stored in quantum data structures, structured matrices, and operators given as a linear combination of unitaries (with a known implementation). We discuss these constructions below. For unstructured, dense matrices, the strategy for Gram matrices can be instantiated using state-preparation and quantum random access memory (QRAM) as subroutines. For more details on a particular block-encoding scheme for loading matrices of classical data, see block-encoding matrices of classical data.</p>"},{"location":"quantum-algorithmic-primitives/quantum-linear-algebra/block-encodings/#rough-overview-in-math","title":"Rough overview (in math)","text":"<p>Our goal is to build a unitary operator that gives coherent access to an \\(M\\times M\\) matrix \\(A\\) (we will later relax the assumption that \\(A\\) is square), with normalization \\(\\alpha \\geq \\nrm{A}\\), where \\(\\nrm{A}\\) denotes the spectral norm of \\(A\\). As the name suggests, block-encoding is a way of encoding the matrix \\(A\\) as a block in a larger unitary matrix: </p>\\[\\begin{aligned} &amp;\\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ket{0}^{\\otimes a}\\ket{0}^{\\otimes a}_\\perp\\\\ U_A=&amp;\\begin{aligned} \\ket{0}^{\\otimes a}\\\\ \\ket{0}^{\\otimes a}_\\perp \\end{aligned}\\begin{pmatrix} A/\\alpha &amp; \\cdot \\\\ \\cdot &amp; \\cdot \\end{pmatrix} \\end{aligned}\\]<p>More precisely, we say that the unitary \\(U_A\\) is an \\((\\alpha, a, \\epsilon)\\)-block-encoding of the matrix \\(A\\in\\mathbb{C}^{M\\times M}\\) if </p>\\[\\begin{equation} \\label{eq:BEDef} \\left\\lVert A - \\alpha (\\bra{0}^{\\otimes a} \\otimes I )U_A(\\ket{0}^{\\otimes a} \\otimes I)\\right\\rVert \\leq \\epsilon, \\end{equation}\\]<p>where \\(a\\in\\mathbb{N}\\) is the number of ancilla qubits used for embedding the block-encoded operator, and \\(\\alpha,\\epsilon\\in\\mathbb{R}_+\\) define the normalization and error, respectively. Note that \\(\\alpha\\geq \\nrm{A}-\\epsilon\\) is necessary for \\(U_A\\) to be unitary. The definition above can be extended for general matrices, though additional embedding or padding may be needed (e.g., to make the matrix square).</p><p>Once a block-encoding is constructed, it can be used in a quantum algorithm to apply the matrix \\(A\\) to a quantum state by applying the unitary \\(U_A\\) to the larger quantum system. The application of the block-encoding can be thought of as a probabilistic application of \\(A\\): applying \\(U_A\\) to \\(\\ket{0}^{\\otimes a}\\ket{\\psi}\\) and postselecting on the first register being in the state \\(\\ket{0}^{\\otimes a}\\) gives an output state proportional to \\(A\\ket{\\psi}\\) in the second register.</p><p>There are several ways of implementing block-encodings based on the choice of matrix \\(A\\) [1, Section 4.2]:<sup>1</sup></p><ul> <li>Unitary matrices are \\((1,0,0)\\)-block-encodings of themselves. Controlled unitaries (e.g. \\(\\mathrm{CNOT}\\)) are essentially \\((1,1,0)\\)-block-encodings of the controlled operation.</li> <li>Given an \\(s\\)-qubit density matrix \\(\\rho\\) and an \\((a+s)\\)-qubit unitary \\(G\\) that prepares a purification of \\(\\rho\\) as \\(G\\ket{0}^{\\otimes a}\\ket{0}^{\\otimes s}=\\ket{\\rho}\\) (s.t. \\(\\text{tr}_a \\ket{\\rho}\\!\\bra{\\rho}=\\rho\\), where \\(\\text{tr}_a\\) denotes trace over the first register), then the operator [2]  \\[\\begin{equation} (G^\\dagger\\otimes I_s)(I_a\\otimes \\mathrm{SWAP}_s)(G\\otimes I_s) \\end{equation}\\] <p>is a \\((1, a+s, 0)\\)-block-encoding of the density matrix \\(\\rho\\), where \\(I_x\\) denotes the identity operator on a register with \\(x\\) qubits, and \\(\\mathrm{SWAP}_s\\) denotes the operation that swaps two \\(s\\)-qubit registers [1, Lemma 45]. - Similarly, one can construct block-encodings of POVM operators, given access to a unitary that implements the POVM [3]. Specifically, if \\(U\\) is a unitary that implements the POVM \\(M\\) to precision \\(\\epsilon\\) such that, for all \\(s\\)-qubit density operators \\(\\rho\\) we have </p> \\[\\begin{equation} \\left |\\mathrm{Tr}(\\rho M) -\\mathrm{Tr}\\left [U(\\ket{0}\\!\\bra{0}^{\\otimes a}\\otimes\\rho)U^\\dagger (\\ket{0}\\!\\bra{0}\\otimes I_{a+s-1}))\\right ] \\right |\\leq \\epsilon, \\end{equation}\\] <p>then \\((I_1\\otimes U^\\dagger)(\\mathrm{CNOT}\\otimes I_{a+s-1})(I_1\\otimes U)\\) is a \\((1,1+a,\\epsilon)\\)-block-encoding of \\(M\\) [1, Lemma 46]. - One can also implement a block-encoding of a Gram matrix using a pair of state-preparation unitaries \\(U_L\\) and \\(U_R\\). In particular, the product </p> \\[\\begin{equation} U_A=U_L^\\dagger U_R \\end{equation}\\] <p>is a \\((1,a,0)\\)-block-encoding of the Gram matrix \\(A\\) whose entries are \\(A_{ij}=\\braket{\\psi_i}{\\phi_j}\\), where [1, Lemma 47] </p> \\[\\begin{equation} U_L\\ket{0}^{\\otimes a}\\ket{i}=\\ket{\\psi_i},\\qquad U_R\\ket{0}^{\\otimes a}\\ket{j}=\\ket{\\phi_j}. \\end{equation}\\] </li> <li>One can generalize the above strategy from Gram matrices to arbitrary matrices to produce \\((\\alpha, a, \\epsilon)\\)-block-encodings of general matrices \\(A\\), where again \\(\\alpha\\geq\\nrm{A}\\). See Block-encoding classical data for details.</li> <li>Sparse-access matrices: Given a matrix \\(A\\in\\mathbb{C}^{2^w \\times 2^w}\\) that is \\(s_r\\)-row sparse and \\(s_c\\)-column sparse (meaning each row/column has at most \\(s_r\\) or \\(s_c\\) nonzero entries), then, defining \\(\\nrm{A}_{\\mathrm{max}} = \\max_{i,j} |A_{ij}|\\), one can create a \\((\\sqrt{s_rs_c}\\nrm{A}_{\\mathrm{max}},w+3,\\epsilon)\\)-block-encoding of \\(A\\) using oracles \\(O_r\\), \\(O_c\\), and \\(O_A\\), defined below [1, Lemma 48]:  \\[\\begin{align} &amp; O_r:\\ket{i}\\ket{k}\\mapsto \\ket{i}\\ket{r_{ik}}, &amp; \\forall i\\in [2^w]-1, k\\in [s_r] \\\\   &amp; O_c:\\ket{\\ell}\\ket{j}\\mapsto \\ket{c_{\\ell j}}\\ket{j}, &amp; \\forall \\ell\\in [s_c], j\\in [2^w]-1 \\\\   &amp; O_A:\\ket{i}\\ket{j}\\ket{0}^{\\otimes b}\\mapsto \\ket{i}\\ket{j}\\ket{A_{ij}}, &amp; \\forall i,j\\in [2^w]-1 \\end{align}\\] <p>In the above, \\(r_{ij}\\) is the index of the \\(j\\)-th nonzero entry in the \\(i\\)-th row of \\(A\\) (or \\(j+2^w\\) if there are less than \\(i\\) nonzero entries), and \\(c_{ij}\\) is the index of the \\(i\\)-th nonzero entry in the \\(j\\)-th column of \\(A\\) (or \\(i+2^w\\) if there are less than \\(j\\) nonzero entries), and \\(\\ket{A_{ij}}\\) is a \\(b\\)-bit binary encoding of the matrix element \\(A_{ij}\\). To build the block-encoding, one needs one query to each of \\(O_r\\) and \\(O_c\\), and two queries of \\(O_A\\)\u2014see [1, Lemma 48] and the more recent [4] for implementation details. If, in addition to being sparse, the matrix also enjoys some additional structure, e.g., there are only a few distinct values that the matrix elements can take, the complexity can be further improved, c.f. [5, 6]. Finally, note that the sparsity dependence can be essentially quadratically improved to \\((\\max(s_r.s_c))^{\\frac{1}{2}+o(1)}\\) using advanced Hamiltonian simulation techniques [7, Theorem 2] combined with taking the logarithm of unitaries [1, Corollary 71], however the resulting subroutine may be impractical and comes with a worse precision dependence. - For matrices given as a linear combination of unitary operators (LCU), we can block-encode the matrix using the LCU technique [8]. We provide a full description in the LCU section, and only give a brief outline here. For \\(A = \\sum_{i=1}^L c_i V_i\\) with \\(V_i\\) unitary, we define the oracles \\(\\mathrm{PREPARE}\\) (acting on \\(\\lceil \\log_2(L)\\rceil\\) ancilla qubits) and \\(\\mathrm{SELECT}\\) (acting on the ancilla and register qubits), and implement a \\((\\sum_i |c_i|, \\lceil \\log_2(L)\\rceil, 0)\\)-block-encoding of \\(A\\), using \\(U := \\mathrm{PREPARE}^\\dag \\cdot \\mathrm{SELECT} \\cdot \\mathrm{PREPARE}\\). The Hamiltonians of physical systems can often be written as a linear combination of a moderate number of Pauli operators, leading to a prevalence of this technique in quantum algorithms for chemistry [9, 10] and condensed matter physics [9, 11, 12].</p> </li> </ul><p>In addition to the definition of block-encoding in \\(\\eqref{eq:BEDef}\\), one can also define an asymmetric version as follows: </p>\\[\\begin{equation} \\left\\lVert A - \\alpha (\\bra{0}^{\\otimes a} \\otimes I )U_A(\\ket{0}^{\\otimes b} \\otimes I)\\right\\rVert \\leq \\epsilon, \\end{equation}\\]<p>where \\(a\\) may not equal \\(b\\). In this case, \\(U_A\\) can be considered to be an \\((\\alpha, (a,b), \\epsilon)\\)- or an \\((\\alpha, \\max(a,b), \\epsilon)\\)-block-encoding of \\(A\\). This can be useful for block-encoding a non-square matrix.</p>"},{"location":"quantum-algorithmic-primitives/quantum-linear-algebra/block-encodings/#dominant-resource-cost-gatesqubits","title":"Dominant resource cost (gates/qubits)","text":"<p>The complexity of block-encoding an operator depends on the type of data or operator being encoded and any underlying assumptions. For instance, unitaries are naturally block-encodings of themselves, and hence their resource requirements depend entirely on their circuit-level implementation without any additional overhead for being a \"block-encoding.\" By contrast, approaches that make use of state-preparation and QRAM to implement the block-encoding tend to have larger complexities, as those two subroutines typically dominate the resource requirements. For example, the best-known circuits that implement block-encoding matrices of classical data for general, dense \\(N\\times N\\) matrices use \\(\\mathcal{O}\\left( N\\log(1/\\epsilon) \\right)\\) qubits to achieve minimum \\(T\\)-gate count (which also scales as \\(\\mathcal{O}\\left( N \\log(1/\\epsilon) \\right)\\)), or a larger \\(\\mathcal{O}\\left( N^2 \\right)\\) number of qubits to achieve minimum \\(T\\)-gate depth (which scales as \\(\\mathcal{O}\\left( \\log(N)+\\log(1/\\epsilon) \\right)\\) [13]. In the sparse-access model, one can use \\(\\mathcal{O}\\left( w+\\log^{2.5}(s_rs_c/\\epsilon) \\right)\\) one- and two-qubit gates, and \\(\\mathcal{O}\\left( b+ \\log^{2.5}(s_rs_c/\\epsilon) \\right)\\) ancilla qubits [1], in addition to the calls to the matrix entry \\(O_A\\) and sparse access oracles \\(O_r\\) and \\(O_c\\), which must be implemented either by computing matrix entries \"on-the-fly\" or by using a QRAM primitive. Assuming appropriate binary representations of the numbers \\(A_{ij}\\), the exponents of the above logarithms can be reduced to \\(1\\) using the techniques of [4] (see also [9, Section III.D] and [14, Supplementary Material VII.A.2]).</p><p>The value of block-encodings is not that it is always cheap to implement them (as it depends on the relevant cost metric and the data access model); rather, the concept of block-encodings is powerful because it allows a practitioner of quantum algorithms to study and optimize the block-encoding construction independently of how it is used within the larger algorithm.</p>"},{"location":"quantum-algorithmic-primitives/quantum-linear-algebra/block-encodings/#caveats","title":"Caveats","text":"<p>A block-encoded matrix \\(A\\) must have norm \\(\\|A\\|\\leq 1\\), or otherwise the matrix must first be normalized, and one must take care to keep track of normalization throughout the computation. In the definition of block-encodings shown above, the parameter \\(\\alpha\\) plays the role of normalizing \\(A\\). Note that often the above constructions are suboptimal in the sense that \\(\\alpha\\gg \\|A\\|\\), which can lead to increased complexity.</p><p>For a given desired block-encoding, there can be several independent, yet equally valid implementations, and one can sometimes optimize for various resources when building the block-encoding. For example, many block-encoding strategies require a step in which some classical data is loaded into QRAM, but there are several ways of performing this data-loading step.</p><p>When using a block-encoding as part of a larger quantum algorithm, it is important to ensure that the overhead introduced by implementing a block-encoding will not outweigh any potential quantum speedups, as block-encoding can be very resource intensive.</p><p>The use of \\(\\ket{0}^{\\otimes a}\\) as the \"signal\" state is just one convention\u2014we can use any \"signal\" state, given a unitary to prepare it [2]. One can also consider a more general definition known as \"projected unitary encodings\" which allows using an arbitrary subspace, rather than just a state-indexed block [1].</p>"},{"location":"quantum-algorithmic-primitives/quantum-linear-algebra/block-encodings/#example-use-cases","title":"Example use cases","text":"<p>Block-encodings are ubiquitous in quantum algorithms, and they prevail in quantum algorithms that need coherent access to some linear operator or a method of implementing a non-unitary transformation on quantum data. Some specific examples:</p><ul> <li>We can manipulate block-encoded operators\u2014for example, take convex or linear combinations, products, tensor products, and other transformations of an input operator.</li> <li>The combination of qubitization with quantum signal processing, or quantum singular value transformation can be used to realize algorithms by applying polynomial transformations to block-encoded matrices. Prominent examples are Hamiltonian simulation via qubitization, and matrix (pseudo) inversion [1, Theorem 41] that can be used for solving large linear systems of equations [15] or more generally least-squares regression problems [16].</li> <li>Block-encoding can be used to provide coherent access to classical data in a quantum algorithm; for example, loading classical data into a quantum interior point method for portfolio optimization [17].</li> </ul>"},{"location":"quantum-algorithmic-primitives/quantum-linear-algebra/block-encodings/#further-reading","title":"Further reading","text":"<p>Reference [16] provides an instructive overview of the concept of block-encoding and showcases its power in several applications related to (generalized) regression problems. Meanwhile, [1] is a comprehensive collection of technical results about block-encodings and quantum linear algebra more generally.</p>"},{"location":"quantum-algorithmic-primitives/quantum-linear-algebra/block-encodings/#bibliography","title":"Bibliography","text":"<ol> <li> <p>Andr\u00e1s Gily\u00e9n, Yuan Su, Guang Hao Low, and Nathan Wiebe. Quantum singular value transformation and beyond: exponential improvements for quantum matrix arithmetics. In Proceedings of the 51st ACM Symposium on the Theory of Computing (STOC), 193\u2013204. 2019. arXiv: https://arxiv.org/abs/1806.01838. doi:10.1145/3313276.3316366.</p> </li> <li> <p>Guang Hao Low and Isaac L. Chuang. Hamiltonian simulation by qubitization. Quantum, 3:163, 2019. arXiv: https://arxiv.org/abs/1610.06546. doi:10.22331/q-2019-07-12-163.</p> </li> <li> <p>Joran van Apeldoorn and Andr\u00e1s Gily\u00e9n. Improvements in quantum sdp-solving with applications. In Proceedings of the 46th International Colloquium on Automata, Languages, and Programming (ICALP), 99:1\u201399:15. 2019. arXiv: https://arxiv.org/abs/1804.05058. doi:10.4230/LIPIcs.ICALP.2019.99.</p> </li> <li> <p>Yuval R. Sanders, Guang Hao Low, Artur Scherer, and Dominic W. Berry. Black-box quantum state preparation without arithmetic. Physical Review Letters, 122:020502, 1 2019. arXiv: https://arxiv.org/abs/1807.03206. URL: https://link.aps.org/doi/10.1103/PhysRevLett.122.020502, doi:10.1103/PhysRevLett.122.020502.</p> </li> <li> <p>Christoph S\u00fcnderhauf, Earl Campbell, and Joan Camps. Block-encoding structured matrices for data input in quantum computing. arXiv: https://arxiv.org/abs/2302.10949, 2023.</p> </li> <li> <p>Daan Camps, Lin Lin, Roel Van Beeumen, and Chao Yang. Explicit quantum circuits for block encodings of certain sparse matrices. arXiv: https://arxiv.org/abs/2203.10236, 2023.</p> </li> <li> <p>Guang Hao Low. Hamiltonian simulation with nearly optimal dependence on spectral norm. In Proceedings of the 51st ACM Symposium on the Theory of Computing (STOC), 491\u2013502. 2019. arXiv: https://arxiv.org/abs/1807.03967. doi:10.1145/3313276.3316386.</p> </li> <li> <p>Andrew M. Childs and Nathan Wiebe. Hamiltonian simulation using linear combinations of unitary operations. Quantum Information and Computation, 12(11&amp;12):901\u2013924, 2012. arXiv: https://arxiv.org/abs/1202.5822. doi:10.26421/QIC12.11-12.</p> </li> <li> <p>Ryan Babbush, Craig Gidney, Dominic W. Berry, Nathan Wiebe, Jarrod McClean, Alexandru Paler, Austin Fowler, and Hartmut Neven. Encoding electronic spectra in quantum circuits with linear t complexity. Physical Review X, 8(4):041015, 2018. arXiv: https://arxiv.org/abs/1805.03662. doi:10.1103/PhysRevX.8.041015.</p> </li> <li> <p>Dominic W. Berry, Craig Gidney, Mario Motta, Jarrod R. McClean, and Ryan Babbush. Qubitization of arbitrary basis quantum chemistry leveraging sparsity and low rank factorization. Quantum, 3:208, 12 2019. arXiv: https://arxiv.org/abs/1902.02134. URL: https://doi.org/10.22331/q-2019-12-02-208, doi:10.22331/q-2019-12-02-208.</p> </li> <li> <p>Andrew M. Childs, Dmitri Maslov, Yunseong Nam, Neil J. Ross, and Yuan Su. Toward the first quantum simulation with quantum speedup. Proceedings of the National Academy of Sciences, 115(38):9456\u20139461, 2018. arXiv: https://arxiv.org/abs/1711.10980. doi:10.1073/pnas.1801723115.</p> </li> <li> <p>Kianna Wan. Exponentially faster implementations of select(h) for fermionic hamiltonians. Quantum, 2021. arXiv: https://arxiv.org/abs/2004.04170. doi:10.22331/q-2021-01-12-380.</p> </li> <li> <p>B. David Clader, Alexander M. Dalzell, Nikitas Stamatopoulos, Grant Salton, Mario Berta, and William J. Zeng. Quantum resources required to block-encode a matrix of classical data. IEEE Transactions on Quantum Engineering, 3:1\u201323, 2022. arXiv: https://arxiv.org/abs/2206.03505. doi:10.1109/TQE.2022.3231194.</p> </li> <li> <p>Vera von Burg, Guang Hao Low, Thomas H\u00e4ner, Damian S. Steiger, Markus Reiher, Martin Roetteler, and Matthias Troyer. Quantum computing enhanced computational catalysis. Physical Review Research, 3(3):033055, 2021. arXiv: https://arxiv.org/abs/2007.14460. doi:10.1103/PhysRevResearch.3.033055.</p> </li> <li> <p>Aram W. Harrow, Avinatan Hassidim, and Seth Lloyd. Quantum algorithm for linear systems of equations. Physical Review Letters, 103(15):150502, 2009. arXiv: https://arxiv.org/abs/0811.3171. doi:10.1103/PhysRevLett.103.150502.</p> </li> <li> <p>Shantanav Chakraborty, Andr\u00e1s Gily\u00e9n, and Stacey Jeffery. The power of block-encoded matrix powers: improved regression techniques via faster hamiltonian simulation. In Proceedings of the 46th International Colloquium on Automata, Languages, and Programming (ICALP), 33:1\u201333:14. 2019. arXiv: https://arxiv.org/abs/1804.01973. doi:10.4230/LIPIcs.ICALP.2019.33.</p> </li> <li> <p>Alexander M Dalzell, B David Clader, Grant Salton, Mario Berta, Cedric Yen-Yu Lin, David A Bader, Nikitas Stamatopoulos, Martin J A Schuetz, Fernando G S L Brand\u00e3o, Helmut G Katzgraber, and others. End-to-end resource analysis for quantum interior point methods and portfolio optimization. PRX Quantum, pages to appear, 2023. arXiv: https://arxiv.org/abs/2211.12489.</p> </li> </ol> <ol> <li> <p>References to locations in [1] typically refer to the longer arXiv version, rather than the STOC version.\u00a0\u21a9</p> </li> </ol>"},{"location":"quantum-algorithmic-primitives/quantum-linear-algebra/introduction/","title":"Quantum linear algebra","text":"<p>At a high level of abstraction, quantum computers compose unitary matrices, and do so with classically unparalleled efficiency. This hints at quantum speedups for linear algebra tasks. However, often one needs to work with large non-unitary matrices; thus, for performing general linear algebra tasks we often wish to embed certain non-unitary matrices into unitary matrices represented by efficient quantum circuits, and then apply them to quantum states, take their sums or products, or implement more general matrix functions. These tasks are collectively referred to as \"quantum linear algebra,\" the building blocks of which are discussed in this section.</p><p>The techniques described in this section evolved over the past decades and converged to the presented unified framework within several distinct research threads. Block-encodings emerged as a natural approach for embedding non-unitary matrices into quantum circuits, inspired by approaches based on purification, dilation,<sup>1</sup> and postselection. Quantum signal processing (QSP) was discovered as a byproduct of the characterization of simple single-qubit pulse sequences used in nuclear magnetic resonance [1], for synthesizing polynomial transformations applicable to a \"signal parameter\" encoded as a matrix element of a single-qubit rotation matrix. Meanwhile, it was extensively studied how matrix functions could be synthesized using the linear combinations of unitaries technique on matrix exponentials implemented by Hamiltonian simulation [2, 3, 4], or Chebyshev polynomials of operators implemented via quantum walk techniques [5, 6, 7]. Such matrix exponentials or Chebyshev polynomials can be implemented, e.g., via qubitization of a block-encoded operator. In parallel to progress on advanced amplitude amplification [8, 9] techniques, it was recognized [10, 11] that QSP can be \"lifted\" for applying polynomial transformations to the eigenvalues of quantum walk operators (such as those implemented by qubitization), and thus for implementing a rich family of matrix functions, immediately yielding an optimal algorithm for time-independent Hamiltonian simulation. The concepts of qubitization and QSP were later generalized and unified into the framework of quantum singular value transformation [12], providing generalizations and more efficient implementations of a number of existing quantum algorithms and leading to the discovery of several new algorithms.</p>"},{"location":"quantum-algorithmic-primitives/quantum-linear-algebra/introduction/#bibliography","title":"Bibliography","text":"<ol> <li> <p>Guang Hao Low, Theodore J. Yoder, and Isaac L. Chuang. Methodology of resonant equiangular composite quantum gates. Physical Review X, 6(4):041067, 2016. arXiv: https://arxiv.org/abs/1603.03996. doi:10.1103/PhysRevX.6.041067.</p> </li> <li> <p>Andrew M. Childs and Nathan Wiebe. Hamiltonian simulation using linear combinations of unitary operations. Quantum Information and Computation, 12(11&amp;12):901\u2013924, 2012. arXiv: https://arxiv.org/abs/1202.5822. doi:10.26421/QIC12.11-12.</p> </li> <li> <p>Joran van Apeldoorn, Andr\u00e1s Gily\u00e9n, Sander Gribling, and Ronald de Wolf. Quantum sdp-solvers: better upper and lower bounds. Quantum, 4:230, 2020. Earlier version in FOCS'17. arXiv: https://arxiv.org/abs/1705.01843. doi:10.22331/q-2020-02-14-230.</p> </li> <li> <p>Shantanav Chakraborty, Andr\u00e1s Gily\u00e9n, and Stacey Jeffery. The power of block-encoded matrix powers: improved regression techniques via faster hamiltonian simulation. In Proceedings of the 46th International Colloquium on Automata, Languages, and Programming (ICALP), 33:1\u201333:14. 2019. arXiv: https://arxiv.org/abs/1804.01973. doi:10.4230/LIPIcs.ICALP.2019.33.</p> </li> <li> <p>Dominic W. Berry, Andrew M. Childs, Richard Cleve, Robin Kothari, and Rolando D. Somma. Exponential improvement in precision for simulating sparse hamiltonians. In Proceedings of the 46th ACM Symposium on the Theory of Computing (STOC), 283\u2013292. 2014. arXiv: https://arxiv.org/abs/1312.1414. doi:10.1145/2591796.2591854.</p> </li> <li> <p>Dominic W. Berry, Andrew M. Childs, and Robin Kothari. Hamiltonian simulation with nearly optimal dependence on all parameters. In Proceedings of the 56th IEEE Symposium on Foundations of Computer Science (FOCS), 792\u2013809. 2015. arXiv: https://arxiv.org/abs/1501.01715. doi:10.1109/FOCS.2015.54.</p> </li> <li> <p>Andrew M. Childs, Robin Kothari, and Rolando D. Somma. Quantum algorithm for systems of linear equations with exponentially improved dependence on precision. SIAM Journal on Computing, 46(6):1920\u20131950, 2017. arXiv: https://arxiv.org/abs/1511.02306. doi:10.1137/16M1087072.</p> </li> <li> <p>Lov K. Grover. Fixed-point quantum search. Physical Review Letters, 95(15):150501, 2005. arXiv: https://arxiv.org/abs/quant-ph/0503205. doi:10.1103/PhysRevLett.95.150501.</p> </li> <li> <p>Theodore J. Yoder, Guang Hao Low, and Isaac L. Chuang. Fixed-point quantum search with an optimal number of queries. Physical Review Letters, 113(21):210501, 2014. arXiv: https://arxiv.org/abs/1409.3305. doi:10.1103/PhysRevLett.113.210501.</p> </li> <li> <p>Guang Hao Low and Isaac L. Chuang. Optimal hamiltonian simulation by quantum signal processing. Physical Review Letters, 118(1):010501, 2017. arXiv: https://arxiv.org/abs/1606.02685. doi:10.1103/PhysRevLett.118.010501.</p> </li> <li> <p>Guang Hao Low and Isaac L. Chuang. Hamiltonian simulation by qubitization. Quantum, 3:163, 2019. arXiv: https://arxiv.org/abs/1610.06546. doi:10.22331/q-2019-07-12-163.</p> </li> <li> <p>Andr\u00e1s Gily\u00e9n, Yuan Su, Guang Hao Low, and Nathan Wiebe. Quantum singular value transformation and beyond: exponential improvements for quantum matrix arithmetics. In Proceedings of the 51st ACM Symposium on the Theory of Computing (STOC), 193\u2013204. 2019. arXiv: https://arxiv.org/abs/1806.01838. doi:10.1145/3313276.3316366.</p> </li> <li> <p>Michael M. Wolf. Quantum channels &amp; operations: guided tour. 2012. https://mediatum.ub.tum.de/download/1701036/1701036.pdf, accessed: 2023-09-30. URL: https://mediatum.ub.tum.de/download/1701036/1701036.pdf.</p> </li> <li> <p>Mark M. Wilde. Quantum Information Theory. Cambridge University Press, 2nd edition, 2017. arXiv: https://arxiv.org/abs/1106.1445. doi:10.1017/9781316809976.</p> </li> </ol> <ol> <li> <p>That is, representing an incoherent state or operation as a coherent one with the help of an ancillary system\u2014see for example Stinespring representation [13] or Stinespring dilation [14].\u00a0\u21a9</p> </li> </ol>"},{"location":"quantum-algorithmic-primitives/quantum-linear-algebra/manipulating-block-encodings/","title":"Manipulating block-encodings","text":""},{"location":"quantum-algorithmic-primitives/quantum-linear-algebra/manipulating-block-encodings/#rough-overview-in-words","title":"Rough overview (in words)","text":"<p>Given one or more block-encodings, we often want to form a single block-encoding of a product, tensor product, or linear combination of the individual block-encoded operators. This can be achieved as outlined below, using additional ancilla qubits.</p>"},{"location":"quantum-algorithmic-primitives/quantum-linear-algebra/manipulating-block-encodings/#rough-overview-in-maths-and-resource-cost","title":"Rough overview (in maths) and resource cost","text":"<p>We will consider the case of two operators \\(A\\) and \\(B\\), with straightforward generalizations to additional operators [1]. We are given an \\((\\alpha, a, \\epsilon_a)\\)-block-encoding \\(U_A\\) of \\(A\\), and a \\((\\beta, b, \\epsilon_b)\\)-block-encoding \\(U_B\\) of \\(B\\). Operators \\(A\\) and \\(B\\) act on system qubits \\(s\\).</p>"},{"location":"quantum-algorithmic-primitives/quantum-linear-algebra/manipulating-block-encodings/#products","title":"Products:","text":"<p>The operation \\(U_{AB} := (I_b \\otimes U_A)(U_B \\otimes I_a )\\) is an \\((\\alpha \\beta, a+b, \\alpha \\epsilon_b + \\beta \\epsilon_a)\\)-block-encoding of \\(AB\\) [1, Lemma 53], where \\(I_x\\) denotes the identity operator on \\(x\\) qubits (see Fig. 1). For example, if \\(a=b\\), this construction uses twice as many ancilla qubits for block-encoding the product compared to the block-encoding of the individual matrices. In fact we can assume without loss of generality that \\(a=b\\) (by taking the max of the two) and improve the construction using the circuit in Fig. 2.</p><p> <p>Figure 1: Implementing the block-encoding \\(U_{AB}\\) of \\(AB\\) that acts on \\(s\\) qubits. The cost is \\(a+b\\) ancilla qubits, and 1 call to each of \\(U_A\\), \\(U_B\\). </p> </p><p> <p>Figure 2: Implementing the block-encoding \\(U_{AB}\\) of \\(AB\\) for the case where both \\(U_A\\) and \\(U_B\\) act on \\(a\\) ancilla qubits. The controlled gate is an \\(a\\)-controlled generalized Toffoli gate.</p> </p>"},{"location":"quantum-algorithmic-primitives/quantum-linear-algebra/manipulating-block-encodings/#tensor-products","title":"Tensor products:","text":"<p>The operation \\(U_{A \\otimes B} := (U_A \\otimes U_B)\\) is an \\((\\alpha \\beta, a+b, \\alpha \\epsilon_b + \\beta \\epsilon_a)\\)-block-encoding of the operator \\(A \\otimes B\\).</p><p> <p>Figure 3: Implementing the block-encoding \\(U_{A \\otimes B}\\) of \\(A \\otimes B\\) that acts on \\(2s\\) qubits. The cost is \\(a+b\\) ancilla qubits, and 1 call to each of \\(U_A\\), \\(U_B\\).</p> </p>"},{"location":"quantum-algorithmic-primitives/quantum-linear-algebra/manipulating-block-encodings/#linear-combinations","title":"Linear combinations:","text":"<p>Linear combinations of block-encodings can be viewed as a generalization of the linear combination of unitaries (LCU) trick [2]. We wish to implement a block-encoding of \\(\\sum_{i=0}^{L-1} c_i A_i\\), where \\(c_i \\in \\mathbb{R}\\) (the LCU trick can also be extended to complex coefficients) and define \\(\\lambda := \\sum_{i=0}^{L-1} |c_i|\\). We consider \\(L\\) block-encodings \\(U_i\\) that are \\((1, m, \\epsilon_i)\\)-block-encodings of \\(A_i\\). We note that in cases where the block-encodings have different \\(\\alpha_i\\) or \\(m_i\\) values, the former can be absorbed into the \\(c_i\\) values and the latter can be taken as \\(m = \\max_i m_i\\).</p><p>We first define an operator \\(\\mathrm{PREPARE}\\) by the following action on \\(\\ket{0^{\\lceil \\log_2(L)\\rceil}}\\) </p>\\[\\begin{equation} \\mathrm{PREPARE} \\ket{0^{\\lceil \\log_2(L)\\rceil }} = \\frac{1}{\\sqrt{\\lambda}} \\sum_j \\sqrt{|c_j|} \\ket{j} \\end{equation}\\]<p>that prepares a weighted superposition on an ancilla register, such that the amplitudes are proportional to the square roots of the absolute values of the desired coefficients. We also define<sup>1</sup> </p>\\[\\begin{equation} \\mathrm{SELECT} = \\sum_{j=0}^{L-1} \\ketbra{j}{j} \\otimes \\mathrm{sign}(c_j) U_j. \\end{equation}\\]<p>We then have the following result: </p>\\[\\begin{align} \\label{Eq:LCU} \\left(\\bra{0^{\\lceil \\log_2(L)\\rceil}} \\otimes I \\right) \\mathrm{PREPARE}^\\dag \\cdot \\mathrm{SELECT} \\cdot \\mathrm{PREPARE} \\left( \\ket{0^{\\lceil \\log_2(L)\\rceil}} \\otimes I \\right) &amp; = \\frac{1}{\\lambda} \\sum_{i=0}^{L-1} c_i U_i \\end{align}\\]<p>i.e. \\(U_{\\mathrm{LC}} := \\mathrm{PREPARE}^\\dag \\cdot \\mathrm{SELECT} \\cdot \\mathrm{PREPARE}\\) is a \\((\\lambda, \\lceil \\log_2(L)\\rceil, 0)\\)-block-encoding of the LCU \\(\\sum_i c_i U_i\\). This is the standard LCU trick [2], and it does not require \\(U_i\\) to be block-encodings (or we can view them as \\((1, 0, 0)\\)-block-encodings of themselves). This technique can be used in Hamiltonian simulation, or to instantiate a block-encoding.</p><p>If, as specified above, \\(U_i\\) are block-encodings of \\(\\tilde{A}_i\\) (which approximate \\(A_i\\)), we also have the following result: </p>\\[\\begin{equation} \\left\\lVert\\left( \\sum_i c_i A_i \\right) - \\lambda \\left(\\bra{0^{m+\\lceil \\log_2(L)\\rceil}} \\otimes I \\right) U_{\\mathrm{LC}} \\left(\\ket{0^{m + \\lceil \\log_2(L)\\rceil}} \\otimes I \\right) \\right\\rVert \\leq \\sum_i |c_i|\\epsilon_i. \\end{equation}\\]<p>Hence, \\(U_{\\mathrm{LC}}\\) is a \\((\\lambda, \\lceil \\log_2(L)\\rceil + m, \\lambda \\max_i \\epsilon_i)\\) block-encoding of \\(\\sum_i c_i A_i\\).</p> <p> </p> <p>Figure 4: Implementing the block-encoding \\(U_{\\mathrm{LC}}\\) of \\(\\sum_i c_i A_i\\) that acts on \\(s\\) qubits. We require \\(\\lceil \\log_2(L)\\rceil + m\\) ancilla qubits. The regular LCU circuit is obtained by omitting the register \\(\\ket{0^m}\\) and the requirement that \\(U_i\\) are block-encodings. The complexity of \\(\\mathrm{PREPARE}\\) depends on the coefficients \\(c_i\\) but is \\(\\Theta(L)\\) in the worst case (using no additional ancilla qubits) [3]. We can also define \\(\\mathrm{PREPARE}\\) that leads to entanglement with a garbage register \\(\\mathrm{PREPARE} \\ket{0^{\\lceil \\log_2(L)\\rceil}} \\ket{0^g} = \\lambda^{-0.5} \\sum_i \\sqrt{|c_i|} \\ket{i} \\ket{G_i}\\), which can be seen to satisfy the relations required to implement the linear combination, Eq. \\(\\eqref{Eq:LCU}\\). It can sometimes (e.g., [4]) be cheaper to implement this garbage-entangled \\(\\mathrm{PREPARE}\\), see preparing states from classical data. The cost of \\(\\mathrm{SELECT}\\) depends on the form of \\(U_i\\), but in the worst case requires \\(\\Theta(L)\\) primitive gates and \\(\\Theta(L)\\) calls to \\(\\ketbra{0}{0} \\otimes I + \\ketbra{1}{1} \\otimes U_i\\) [5, 4], although this can be improved in some relevant special cases (e.g., [6]).   </p>"},{"location":"quantum-algorithmic-primitives/quantum-linear-algebra/manipulating-block-encodings/#caveats","title":"Caveats","text":"<p>Performing linear algebraic manipulations of block-encodings using these primitives can quickly increase the ancilla count of the algorithm and worsen the normalization factor of the block-encoding. Amplifying a subnormalized block-encoding is possible, but costly, requiring an amount of time scaling roughly linearly in the amplification factor, see [7, 1]. Given a single block-encoded operator \\(A\\), the above primitives can be used to implement a block-encoding of a polynomial in \\(A\\). However, this can be achieved with much lower overhead using quantum singular value transformation.</p>"},{"location":"quantum-algorithmic-primitives/quantum-linear-algebra/manipulating-block-encodings/#example-use-cases","title":"Example use cases","text":"<ul> <li>Linear combination of block-encodings are used to obtain mixed-parity functions in QSVT required for Hamiltonian simulation.</li> <li>LCU trick used for: Hamiltonian simulation, or to instantiate block-encodings of chemistry or condensed matter physics Hamiltonians (see, e.g., [4, 6]).</li> </ul>"},{"location":"quantum-algorithmic-primitives/quantum-linear-algebra/manipulating-block-encodings/#further-reading","title":"Further reading","text":"<ul> <li>References [8, Section 3.3] and [9, Section 7.3] contain a comprehensive discussion of manipulating block-encodings, including proofs of many of the results stated above.</li> </ul>"},{"location":"quantum-algorithmic-primitives/quantum-linear-algebra/manipulating-block-encodings/#bibliography","title":"Bibliography","text":"<ol> <li> <p>Andr\u00e1s Gily\u00e9n, Yuan Su, Guang Hao Low, and Nathan Wiebe. Quantum singular value transformation and beyond: exponential improvements for quantum matrix arithmetics. In Proceedings of the 51st ACM Symposium on the Theory of Computing (STOC), 193\u2013204. 2019. arXiv: https://arxiv.org/abs/1806.01838. doi:10.1145/3313276.3316366.</p> </li> <li> <p>Andrew M. Childs and Nathan Wiebe. Hamiltonian simulation using linear combinations of unitary operations. Quantum Information and Computation, 12(11&amp;12):901\u2013924, 2012. arXiv: https://arxiv.org/abs/1202.5822. doi:10.26421/QIC12.11-12.</p> </li> <li> <p>Martin Plesch and \u010caslav Brukner. Quantum-state preparation with universal gate decompositions. Physical Review A, 83:032302, 3 2011. arXiv: https://arxiv.org/abs/1003.5760. URL: https://link.aps.org/doi/10.1103/PhysRevA.83.032302, doi:10.1103/PhysRevA.83.032302.</p> </li> <li> <p>Ryan Babbush, Craig Gidney, Dominic W. Berry, Nathan Wiebe, Jarrod McClean, Alexandru Paler, Austin Fowler, and Hartmut Neven. Encoding electronic spectra in quantum circuits with linear t complexity. Physical Review X, 8(4):041015, 2018. arXiv: https://arxiv.org/abs/1805.03662. doi:10.1103/PhysRevX.8.041015.</p> </li> <li> <p>Andrew M. Childs, Dmitri Maslov, Yunseong Nam, Neil J. Ross, and Yuan Su. Toward the first quantum simulation with quantum speedup. Proceedings of the National Academy of Sciences, 115(38):9456\u20139461, 2018. arXiv: https://arxiv.org/abs/1711.10980. doi:10.1073/pnas.1801723115.</p> </li> <li> <p>Kianna Wan. Exponentially faster implementations of select(h) for fermionic hamiltonians. Quantum, 2021. arXiv: https://arxiv.org/abs/2004.04170. doi:10.22331/q-2021-01-12-380.</p> </li> <li> <p>Guang Hao Low and Isaac L. Chuang. Hamiltonian simulation by uniform spectral amplification. arXiv: https://arxiv.org/abs/1707.05391, 2017.</p> </li> <li> <p>Andr\u00e1s Gily\u00e9n. Quantum Singular Value Transformation &amp; Its Algorithmic Applications. PhD thesis, University of Amsterdam, 2019. URL: https://hdl.handle.net/11245.1/20e9733e-6014-402d-afa9-20f3cc4a0568.</p> </li> <li> <p>Lin Lin. Lecture notes on quantum algorithms for scientific computation. arXiv: https://arxiv.org/abs/2201.08309, 2022.</p> </li> </ol> <ol> <li> <p>To be precise for \\(j\\notin\\{0,1,\\ldots,L-1\\}\\) we define \\(\\mathrm{sign}(c_j) U_j:=I\\).\u00a0\u21a9</p> </li> </ol>"},{"location":"quantum-algorithmic-primitives/quantum-linear-algebra/quantum-signal-processing/","title":"Quantum signal processing","text":""},{"location":"quantum-algorithmic-primitives/quantum-linear-algebra/quantum-signal-processing/#rough-overview-in-words","title":"Rough overview (in words)","text":"<p>Quantum signal processing (QSP) [1] describes a method for nonlinear transformations of a signal parameter encoded in a single-qubit gate, using a structured sequence that interleaves the \"signal gate\" with fixed parametrized \"modulation\" gates. The technique was originally motivated by the desire to characterize pulse sequences used in nuclear magnetic resonance [1]. Remarkably, it has been shown [1, 2] that there is a rich family of polynomial transformations that are in one-to-one correspondence with appropriate modulation sequences, moreover given such a polynomial one can efficiently compute the corresponding modulation parameters.</p><p>Even more remarkably, this analysis holds not just for single-qubit \"signal gates\" but can be extended for multiqubit operators that act like single-qubit rotations when restricted to appropriate two-dimensional subspaces [3]. This insight enables the implementation of block-encodings of polynomials of Hermitian/normal matrices when used in conjunction with qubitization. The two-step process of qubitization</p><ul> <li>QSP can be unified and generalized through quantum singular value transformation (QSVT).</li> </ul>"},{"location":"quantum-algorithmic-primitives/quantum-linear-algebra/quantum-signal-processing/#rough-overview-in-math","title":"Rough overview (in math)","text":"<p>We follow the \"Wx convention\" of QSP [4, 5]. We define the single-qubit signal operator </p>\\[\\begin{equation} W(x) := \\begin{pmatrix} x &amp; i \\sqrt{1-x^2} \\\\ i \\sqrt{1-x^2} &amp; x \\end{pmatrix} = e^{i \\arccos(x) X} \\end{equation}\\]<p>which is a single-qubit \\(X\\) rotation. We can verify that </p>\\[\\begin{align} W(x)^2 &amp; = \\begin{pmatrix} 2x^2 - 1 &amp; \\cdot \\\\ \\cdot &amp; \\cdot \\end{pmatrix}, \\\\ W(x)^3 &amp; = \\begin{pmatrix} 4x^3 - 3x &amp; \\cdot \\\\ \\cdot &amp; \\cdot \\end{pmatrix}, \\\\ &amp; \\vdots \\\\ W(x)^n &amp; = \\begin{pmatrix} T_n(x) &amp; \\cdot \\\\ \\cdot &amp; \\cdot \\end{pmatrix}, \\\\ \\end{align}\\]<p>where \\(T_n(x)\\) is the \\(n\\)-th Chebyshev polynomial of the first kind, showcasing that even a simple sequence of the signal unitaries can implement a rich family of polynomials of the signal \\(x\\).</p><p>More complex behavior is obtained by interleaving \\(W(x)\\) with parametrized single-qubit \\(Z\\) rotations \\(e^{i \\phi_j Z}\\). We define a QSP sequence </p>\\[\\begin{equation} U_{\\mathrm{QSP}}(\\Phi) := e^{i \\phi_0 Z} \\prod_{j=1}^d W(x) e^{i \\phi_j Z}. \\end{equation}\\]<p>where \\(\\Phi\\) denotes the vector of angles \\((\\phi_0,\\phi_1,\\ldots,\\phi_d)\\). The QSP sequence implements the following unitary </p>\\[\\begin{equation} \\label{eq:UQSP(Phi)} U_{\\mathrm{QSP}}(\\Phi) = \\begin{pmatrix} P(x) &amp; i Q(x) \\sqrt{1-x^2} \\\\ i Q^*(x) \\sqrt{1-x^2} &amp; P^*(x) \\end{pmatrix} \\end{equation}\\]<p>where \\(P(x), Q(x)\\) are complex polynomials obeying a number of constraints (see below), and \\(P^*(x)\\), \\(Q^*(x)\\) denote their complex conjugates.</p>"},{"location":"quantum-algorithmic-primitives/quantum-linear-algebra/quantum-signal-processing/#dominant-resource-cost-gatesqubits","title":"Dominant resource cost (gates/qubits)","text":"<p>A QSP circuit that implements a degree \\(d\\) polynomial in the signal parameter requires \\(d\\) uses of \\(W(x)\\) and \\(d+1\\) fixed angle \\(Z\\) rotations. There are efficient classical algorithms to determine the angles for a given target polynomial, either using high-precision arithmetic with \\(\\sim d\\log(d)\\) bits of precision [2] (or more [4]\u2014though this can be mitigated using heuristic techniques [6]) or in some regimes using more efficient optimization-based algorithms [7]. Although these procedures are efficient in theory, in practice it may still be nontrivial to find the angles. Nevertheless, researchers reportedly computed angle sequences corresponding to various degree \\(d = \\mathcal{O}\\left( 10^4 \\right)\\) polynomials.</p>"},{"location":"quantum-algorithmic-primitives/quantum-linear-algebra/quantum-signal-processing/#caveats","title":"Caveats","text":"<p>As discussed above, not all polynomials can be implemented by a QSP sequence. Implementable polynomials must obey a number of constraints, which can be somewhat restrictive. For the standard QSP circuit \\(U_{\\mathrm{QSP}}(\\Phi)\\) given above, the achievable polynomials pairs \\(P(x), Q(x) \\in \\mathbb{C}\\) can be characterized by the following three conditions:</p><ul> <li>\\(\\mathrm{Deg}(P) \\leq d\\), \\(\\mathrm{Deg}(Q) \\leq d-1\\).</li> <li>\\(\\mathrm{Parity}(P) = \\mathrm{Parity}(d)\\), \\(\\mathrm{Parity}(Q) = \\mathrm{Parity}(d-1)\\).</li> <li>\\(\\forall~x \\in [-1, 1]: |P(x)|^2 + (1-x^2) |Q(x)|^2 = 1\\) (required for Eq. \\(\\eqref{eq:UQSP(Phi)}\\) to be unitary).</li> </ul><p>This last requirement can be particularly limiting. A useful way to circumvent this for real functions is to encode the polynomial in the matrix element \\(\\bra{+} U_{\\mathrm{QSP}}(\\Phi) \\ket{+}\\) rather than in \\(\\bra{0} U_{\\mathrm{QSP}}(\\Phi) \\ket{0}\\), where \\(\\ket{+} = \\smash{(\\ket{0}+\\ket{1})/\\sqrt{2}}\\). This matrix element evaluates to </p>\\[\\begin{equation} \\bra{+} U_{\\mathrm{QSP}}(\\Phi) \\ket{+} = \\operatorname{Re}[P(x)] + i\\sqrt{1-\\smash{x^2}} \\operatorname{Re}[Q(x)]\\,. \\end{equation}\\]<p>Given a real target polynomial \\(f(x)\\) with parity equal to \\(\\mathrm{Parity}(d)\\), we can guarantee that the matrix element evaluates to \\(f(x)\\) by choosing \\(\\operatorname{Re}[P(x)] = f(x)\\) and \\(\\operatorname{Re}[Q(x)] = 0\\). The third condition above then reduces to \\(1-f(x)^2 = \\lvert \\operatorname{Im}[P(x)]\\rvert^2 + (1-x^2)\\lvert \\operatorname{Im}[Q(x)]\\rvert^2\\). By [4, Lemma 6], there exist choices for \\(\\operatorname{Im}[P(x)]\\) and \\(\\operatorname{Im}[Q(x)]\\) that satisfy this identity as well as the first two conditions above, provided \\(|f(x)| \\leq 1~\\forall~x \\in [-1, 1]\\). In summary, we may implement any real polynomial \\(f(x)\\) satisfying the requirements [4, Corollary 10]:</p><ul> <li>\\(\\mathrm{Deg}(f) = d\\).</li> <li>\\(\\mathrm{Parity}(f) = \\mathrm{Parity}(d)\\).</li> <li>\\(\\forall~x \\in [-1, 1]: |f(x)| \\leq 1\\).</li> </ul><p>There are several related conventions considered in the literature for the explicit form of the single qubit operators used in QSP; a thorough discussion is given in [5, Appendix A]. One common form that links closely to qubitization and QSVT is the reflection convention, which replaces \\(W(x)\\) by the reflection </p>\\[\\begin{equation} \\label{eq:QSPR} R(x) = \\begin{pmatrix} x &amp; \\sqrt{1-x^2} \\\\ \\sqrt{1-x^2} &amp; -x \\end{pmatrix} \\,, \\end{equation}\\]<p>and adjusts the parameters \\(\\{ \\phi_j \\}\\) accordingly [4].</p>"},{"location":"quantum-algorithmic-primitives/quantum-linear-algebra/quantum-signal-processing/#example-use-cases","title":"Example use cases","text":"<ul> <li>Functions of Hermitian/normal matrices, in conjunction with qubitization, including for Hamiltonian simulation.</li> <li>Functions of general matrices via quantum singular value transformation (QSVT).</li> <li>Reference [8] applied QSP to beyond-Heisenberg-limit calibration of two-qubit gates in a superconducting system.</li> </ul>"},{"location":"quantum-algorithmic-primitives/quantum-linear-algebra/quantum-signal-processing/#further-reading","title":"Further reading","text":"<ul> <li>A pedagogical discussion of QSP [5].</li> <li>Detailed proofs of the key results of QSP [1, 4].</li> <li>Lecture notes on QSP [9, Sec. 7.6].</li> </ul>"},{"location":"quantum-algorithmic-primitives/quantum-linear-algebra/quantum-signal-processing/#bibliography","title":"Bibliography","text":"<ol> <li> <p>Guang Hao Low, Theodore J. Yoder, and Isaac L. Chuang. Methodology of resonant equiangular composite quantum gates. Physical Review X, 6(4):041067, 2016. arXiv: https://arxiv.org/abs/1603.03996. doi:10.1103/PhysRevX.6.041067.</p> </li> <li> <p>Jeongwan Haah. Product decomposition of periodic functions in quantum signal processing. Quantum, 3:190, 2019. arXiv: https://arxiv.org/abs/1806.10236. doi:10.22331/q-2019-10-07-190.</p> </li> <li> <p>Guang Hao Low and Isaac L. Chuang. Optimal hamiltonian simulation by quantum signal processing. Physical Review Letters, 118(1):010501, 2017. arXiv: https://arxiv.org/abs/1606.02685. doi:10.1103/PhysRevLett.118.010501.</p> </li> <li> <p>Andr\u00e1s Gily\u00e9n, Yuan Su, Guang Hao Low, and Nathan Wiebe. Quantum singular value transformation and beyond: exponential improvements for quantum matrix arithmetics. In Proceedings of the 51st ACM Symposium on the Theory of Computing (STOC), 193\u2013204. 2019. arXiv: https://arxiv.org/abs/1806.01838. doi:10.1145/3313276.3316366.</p> </li> <li> <p>John M. Martyn, Zane M. Rossi, Andrew K. Tan, and Isaac L. Chuang. Grand unification of quantum algorithms. Physical Review X, 2(4):040203, 2021. arXiv: https://arxiv.org/abs/2105.02859. doi:10.1103/PRXQuantum.2.040203.</p> </li> <li> <p>Rui Chao, Dawei Ding, Andr\u00e1s Gily\u00e9n, Cupjin Huang, and M\u00e1ri\u00f3 Szegedy. Finding angles for quantum signal processing with machine precision. arXiv: https://arxiv.org/abs/2003.02831, 2020.</p> </li> <li> <p>Yulong Dong, Xiang Meng, K. Birgitta Whaley, and Lin Lin. Efficient phase-factor evaluation in quantum signal processing. Physical Review A, 103:042419, 2021. arXiv: https://arxiv.org/abs/2002.11649. doi:10.1103/PhysRevA.103.042419.</p> </li> <li> <p>Yulong Dong, Jonathan Gross, and Murphy Yuezhen Niu. Beyond heisenberg limit quantum metrology through quantum signal processing. arXiv: https://arxiv.org/abs/2209.11207, 2022.</p> </li> <li> <p>Lin Lin. Lecture notes on quantum algorithms for scientific computation. arXiv: https://arxiv.org/abs/2201.08309, 2022.</p> </li> </ol>"},{"location":"quantum-algorithmic-primitives/quantum-linear-algebra/quantum-singular-value-transformation/","title":"Quantum singular value transformation","text":""},{"location":"quantum-algorithmic-primitives/quantum-linear-algebra/quantum-singular-value-transformation/#rough-overview-in-words","title":"Rough overview (in words)","text":"<p>Quantum singular value transformation (QSVT) can be viewed as both a unification and generalization of qubitization and quantum signal processing. Given a block-encoding \\(U_A\\) of a general matrix \\(A\\), QSVT enables the transformation of the singular values of \\(A\\) by a polynomial \\(f(\\cdot)\\). In QSVT there is one-to-one correspondence between the desired polynomial transformation and its quantum circuit implementation whose parameters can be found by efficient classical algorithms.</p><p>It transpires that a number of existing quantum algorithms have simple and (near-)optimal implementations via the QSVT framework, including but not limited to: Hamiltonian simulation [1, 2, 3], amplitude amplification and estimation [3, 4], quantum linear systems solving [3, 5], Gibbs sampling [3], algorithms for topological data analysis [6, 7, 8], and quantum phase estimation [5, 9].</p>"},{"location":"quantum-algorithmic-primitives/quantum-linear-algebra/quantum-singular-value-transformation/#rough-overview-in-math","title":"Rough overview (in math)","text":"<p>We are given a \\((1, m, 0)\\)-block-encoding \\(U_A\\) of operator \\(A\\) (for simplicity we will restrict our presentation to square matrices \\(A\\), noting there is a straightforward generalization to non-square \\(A\\) [3]) such that </p>\\[\\begin{equation} A= \\left(\\bra{0^m} \\otimes I \\right) U_A \\left( \\ket{0^m} \\otimes I \\right) \\end{equation}\\]<p>where \\(\\ket{0^m}\\) denotes \\(\\ket{0}^{\\otimes m}\\). The matrix \\(A\\) has a singular value decomposition (SVD) </p>\\[\\begin{equation} A = \\sum_i \\sigma_i \\ketbra{w_i}{v_i}. \\end{equation}\\]<p>QSVT provides a method for implementing </p>\\[\\begin{equation} f^{(SV)}(A):=\\left\\{\\begin{array}{rcl} \\sum_i f(\\sigma_i) \\ketbra{w_i}{v_i} &amp; &amp; \\text{if $f$ is odd, and} \\\\ \\sum_i f(\\sigma_i) \\ketbra{v_i}{v_i} &amp; &amp; \\text{if $f$ is even,}\\end{array}\\right. \\end{equation}\\]<p>for certain definite-parity polynomials \\(f\\colon [-1,1] \\rightarrow \\mathbb{C}\\) such that \\(|f(x)| \\leq 1~\\forall~x \\in [-1,1]\\). Crucially, QSVT does not require us to know the SVD in advance; the transformation is carried out automatically by following an SVD-agnostic procedure outlined below. Note that \\(f^{(SV)}(A)\\) only coincides with the matrix function \\(f(A)\\) for Hermitian \\(A\\) (see Caveats). In the Hermitian case, we can also obtain block-encodings of mixed-parity or complex functions by taking linear combinations of block-encodings\u2014see [10] for examples.</p><p>By considering \\(U_A \\ket{0^m} \\ket{v_i}\\) and \\(U_A^\\dagger \\ket{0^m}\\ket{w_i}\\) one can show that (see [11] for a step-by-step derivation) \\(U_A\\) and \\(U_A^\\dagger\\) act as linear maps between the 2D subspaces \\(S_i:=\\mathrm{Span}\\{\\ket{0^m}\\ket{v_i},\\ket{\\perp_i}\\} \\rightarrow S_i':=\\mathrm{Span}\\{\\ket{0^m}\\ket{w_i},\\ket{\\perp_i'}\\}\\), and \\(U_A\\)'s transition matrix between these bases is </p>\\[ \\begin{aligned}\\label{eq:SVD2D} \\ket{0^m} \\ket{v_i}\\ \\ \\ \\ \\ \\ \\ \\ \\  \\   \\ket{\\perp_i}\\ \\ \\ \\ \\ \\ \\\\ \\begin{gathered}\\ket{0^m} \\ket{w_i}\\\\ \\ket{\\perp_i'}\\end{gathered} \\begin{pmatrix} \\sigma_i &amp; \\sqrt{1-\\sigma_i^2} \\\\ \\sqrt{1-\\sigma_i^2}&amp; -\\sigma_i \\end{pmatrix} \\end{aligned} \\]<p>where both \\(\\ket{\\perp_i}, \\ket{\\perp_i'}\\) are orthogonal to \\(\\ket{0^m}\\) (but not necessarily to each other).<sup>1</sup> One can show that \\(S_i\\) is invariant under the operation \\(W := Z_{\\ket{0^m}} U_A^\\dag Z_{\\ket{0^m}} U_A\\) (with \\(Z_{\\ket{0^m}} = (2\\ketbra{0^m}{0^m} - I)\\)) having matrix </p>\\[\\begin{equation} \\left(\\begin{array}{cc} \\sigma_i &amp; \\sqrt{1-\\sigma_i^2} \\\\ - \\sqrt{1-\\sigma_i^2} &amp; \\sigma_i \\end{array}\\right)^{\\!\\!2} \\end{equation}\\]<p>when restricted onto the 2D subspace \\(S_i\\). An additional application of \\(Z_{\\ket{0^m}} U_A\\) maps back into the \\(S_i'\\) subspace. By analogy with qubitization, repeated applications of \\(W\\) applies a Chebyshev polynomial to each of the singular values of \\(A\\). In analogy with quantum signal processing, by lifting the \\(Z_{\\ket{0^m}}\\) reflection operation to a (controlled) rotation \\(e^{i\\phi_j Z_{\\ket{0^m}}}\\) we can impose polynomial transformations of the singular values of \\(A\\), which then induces the claimed polynomial transformation of \\(A\\). It is typically convenient to use an additional ancilla qubit to implement \\(e^{i\\phi_j Z_{\\ket{0^m}}}\\).</p><p>We define a QSVT circuit as the unitary sequence </p>\\[\\begin{equation} U_\\Phi:=\\left\\{\\begin{array}{rcl} \\underset{\\phantom{\\sum}}{ e^{i\\phi_1 Z_{\\ket{0^m}}}U_A} \\prod_{j=1}^{(d-1)/2}\\left(e^{i\\phi_{2j} Z_{\\ket{0^m}}} U_A^\\dagger e^{i\\phi_{2j+1} Z_{\\ket{0^m}}} U_A\\right) &amp; &amp; \\text{if }d\\text{ is odd, and} \\\\ \\prod_{j=1}^{d/2}\\left(e^{i\\phi_{2j-1} Z_{\\ket{0^m}}} U_A^\\dagger e^{i\\phi_{2j} Z_{\\ket{0^m}}} U_A \\right) &amp; &amp; \\text{if }d\\text{ is even,}\\end{array}\\right. \\end{equation}\\]<p>where \\(\\Phi = (\\phi_1,\\phi_2,\\ldots,\\phi_d)\\). We have that </p>\\[\\begin{align} (\\bra{0^m} \\otimes I) U_\\Phi (\\ket{0^m} \\otimes I) =P^{(SV)}(A) = \\left\\{\\begin{array}{rl} &amp; \\sum_i P(\\sigma_i) \\ketbra{w_i}{v_i}, \\text{ for odd $d$, and} \\\\ &amp; \\sum_i P(\\sigma_i) \\ketbra{v_i}{v_i}, \\text{ for even $d$,}\\end{array}\\right. \\end{align}\\]<p>i.e., the unitary \\(U_\\Phi\\) is a block-encoding of \\(P^{(SV)}(A)\\), were \\(P\\) is the same polynomial that appears in quantum signal processing because the 2D matrix of \\(\\eqref{eq:SVD2D}\\) has the same form as the analogous 2D matrix in \\(\\eqref{eq:QSPR}\\). We note that the constraints on the polynomials typically preclude direct implementation of the desired function as outlined above. By exploiting that \\(-\\Phi\\) implements \\(P^*\\), we can use the circuit shown in Fig. 1 to implement a block-encoding of</p>\\[\\begin{equation} P_{\\Re}(A) = (\\bra{+} \\otimes \\bra{0^m} \\otimes I) (\\ketbra{0}{0} \\otimes U_\\Phi + \\ketbra{1}{1} \\otimes U_{-\\Phi}) (\\ket{+} \\otimes \\ket{0^m} \\otimes I) \\end{equation}\\]<p>for any definite-parity polynomial \\(P_{\\Re}\\colon [-1,1]\\rightarrow [-1,1]\\) by appropriately choosing \\(\\Phi\\) to implement a complex polynomial that fulfills the QSP conditions and then taking linear combinations of \\(U_{\\Phi}, U_{-\\Phi}\\) to give a block-encoding of \\(P_{\\Re}(A)\\) [3, 5, 10].</p><p> <p>Figure 1: The QSVT circuit \\(U_\\Phi\\) which transforms a block-encoding \\(U_A\\) of \\(A\\) into a block-encoding of \\(f(A)\\) for definite-parity \\(f: [-1,1]\\rightarrow [-1,1]\\) polynomial of degree \\(d\\). As discussed in the main text, the angles \\(\\{\\phi_i\\}\\) can be calculated using efficient classical algorithms.</p> </p>"},{"location":"quantum-algorithmic-primitives/quantum-linear-algebra/quantum-singular-value-transformation/#dominant-resource-cost-gatesqubits","title":"Dominant resource cost (gates/qubits)","text":"<p>Given a degree-\\(d\\) even-parity polynomial \\(f\\colon [-1,1]\\rightarrow [-1,1]\\) and a \\((1,m,0)\\)-block-encoding \\(U_A\\) of \\(A\\), one can implement a block-encoding of \\(f(A)\\) using \\(d/2\\) calls to \\(U_A\\), \\(d/2\\) calls to \\(U_A^\\dagger\\), \\(2d\\) \\(m\\)-controlled Toffoli gates, and \\(d\\) single-qubit \\(Z\\) rotations (as shown in Fig. 1). Implementing a degree \\(d+1\\) odd polynomial additionally requires another call to \\(U_A\\), another two \\(m\\)-controlled Toffoli gate, and another single-qubit \\(Z\\) rotation. The QSVT circuit implements a \\((1, m+1, 0)\\)-block-encoding of \\(f(A)\\).</p><p>If \\(U_A\\) is imperfect (i.e., it is a \\((1, m, \\epsilon)\\)-block-encoding of \\(A\\)), then [3, Lemma 22] shows that the error in \\(f(A)\\) is bounded by \\(4d\\sqrt{\\epsilon}\\); that is, QSVT implements a \\((1, m+1, 4d\\sqrt{\\epsilon})\\)-block-encoding of \\(f(A)\\). Moreover, if the norm of \\(A\\) is bounded away from \\(1\\), e.g., \\(\\nrm{A}\\leq 1/2\\), then the perturbation bound can be improved to \\(\\mathcal{O}\\left( d\\epsilon \\right)\\) [3, Lemma 23].</p><p>Given an initial state \\(\\ket{\\psi}\\), the success probability of implementing \\(f(A) \\ket{\\psi}\\) is given by \\(|\\bra{\\psi} f(A)^\\dag f(A) \\ket{\\psi}|^2\\).</p>"},{"location":"quantum-algorithmic-primitives/quantum-linear-algebra/quantum-singular-value-transformation/#caveats","title":"Caveats","text":"<p>Since the output must be subnormalized to ensure the existence of a unitary block-encoding of \\(f(A)\\), \\(f\\) must satisfy \\(|f(x)| \\leq 1~\\forall~x \\in [-1,1]\\)</p><p>As noted above, \\(f^{(SV)}(A)\\) is only guaranteed to coincide with the matrix function \\(f(A)\\) for Hermitian \\(A\\). As an example, choosing \\(f(x) = x^2\\) we have \\(f^{(SV)}(A) = \\sum_i \\sigma_i^2 \\ketbra{v_i} {v_i}=A^\\dagger A\\) whereas \\(A^2 = \\sum_{i,j} \\sigma_i \\sigma_j \\ket{w_i}\\braket{v_i}{ w_j}\\bra{v_j}\\). As discussed above, for the Hermitian case we can implement a block-encoding of a mixed-parity function \\(f\\) by taking linear combinations of block-encodings of its even/odd parts. However, in the general case when \\(\\ket{w_i}\\) and \\(\\ket{v_i}\\) do not coincide, it does not seem to be possible to remove the parity constraint, as the odd \\(\\sum_i f_{\\mathrm{odd}}(\\sigma_i) \\ketbra{w_i}{v_i}\\) and even \\(\\sum_i f_{\\mathrm{even}}(\\sigma_i) \\ketbra{v_i}{v_i}\\) singular value transforms potentially map to different subspaces.</p><p>As discussed for quantum signal processing, while formally efficient classical algorithms have been developed for computing the angle sequence \\(\\Phi\\), these either require very high accuracy arithmetics [3, 12], or use alternative methods with only partially proven guarantees [10, 13]. Nevertheless, these approaches have enabled the computation of angle sequences for polynomials of degree up to \\(\\sim10^4\\).</p><p>As noted above, if \\(f(A)\\) has small singular values, then preparing the a quantum sate \\(f(A)\\ket{\\psi}\\) might require many repeated uses of its block-encoding, thus the normalization factor of \\(f\\) plays a crucial role in efficiency.</p><p>In many applications, one seeks to apply a function that is not a polynomial (e.g., \\(e^x\\), \\(e^{ix}\\), \\(\\mathrm{erf}(x)\\)). In such cases, one needs to first approximate the desired function by a polynomial (incurring an approximation error \\(\\epsilon\\)) in order to apply QSVT.</p>"},{"location":"quantum-algorithmic-primitives/quantum-linear-algebra/quantum-singular-value-transformation/#example-use-cases","title":"Example use cases","text":"<ul> <li>Linear equation solving: apply a polynomial approximation of \\(\\frac{1}{x}\\) to a block-encoding of \\(A^\\dagger\\) to get an approximate block-encoding of the pseudoinverse \\(A^+\\).</li> <li>Hamiltonian simulation: apply polynomial approximations of \\(\\sin(x)\\) and \\(\\cos(x)\\) to a block-encoding of a Hamiltonian \\(H\\) and combine them with linear combination of unitaries and amplitude amplification to obtain a block-encoding of \\(e^{iHt}\\).</li> <li>Fixed-point amplitude amplification [14]: construct a polynomial that maps values in the domain \\([a_{\\min},1]\\) to the range \\([1-\\delta,1]\\), and apply this polynomial to a state-preparation unitary that prepares the desired state with amplitude \\(a\\). The result is amplification of the amplitude to at least \\(1-\\delta\\) as long as \\(a &gt; a_{\\min}\\).</li> <li>For additional applications see [3, 9, 5, 15, 16].</li> </ul>"},{"location":"quantum-algorithmic-primitives/quantum-linear-algebra/quantum-singular-value-transformation/#further-reading","title":"Further reading","text":"<ul> <li>The QSVT framework was introduced in [3] and is also discussed in detail in [17].</li> <li>A pedagogical tutorial of the QSVT framework is given in [5, 11].</li> <li>A streamlined derivation of QSVT is presented in [18].</li> </ul>"},{"location":"quantum-algorithmic-primitives/quantum-linear-algebra/quantum-singular-value-transformation/#bibliography","title":"Bibliography","text":"<ol> <li> <p>Guang Hao Low and Isaac L. Chuang. Optimal hamiltonian simulation by quantum signal processing. Physical Review Letters, 118(1):010501, 2017. arXiv: https://arxiv.org/abs/1606.02685. doi:10.1103/PhysRevLett.118.010501.</p> </li> <li> <p>Guang Hao Low and Isaac L. Chuang. Hamiltonian simulation by qubitization. Quantum, 3:163, 2019. arXiv: https://arxiv.org/abs/1610.06546. doi:10.22331/q-2019-07-12-163.</p> </li> <li> <p>Andr\u00e1s Gily\u00e9n, Yuan Su, Guang Hao Low, and Nathan Wiebe. Quantum singular value transformation and beyond: exponential improvements for quantum matrix arithmetics. In Proceedings of the 51st ACM Symposium on the Theory of Computing (STOC), 193\u2013204. 2019. arXiv: https://arxiv.org/abs/1806.01838. doi:10.1145/3313276.3316366.</p> </li> <li> <p>Patrick Rall and Bryce Fuller. Amplitude estimation from quantum signal processing. Quantum, 7:937, 3 2023. arXiv: https://arxiv.org/abs/2207.08628. URL: https://doi.org/10.22331/q-2023-03-02-937, doi:10.22331/q-2023-03-02-937.</p> </li> <li> <p>John M. Martyn, Zane M. Rossi, Andrew K. Tan, and Isaac L. Chuang. Grand unification of quantum algorithms. Physical Review X, 2(4):040203, 2021. arXiv: https://arxiv.org/abs/2105.02859. doi:10.1103/PRXQuantum.2.040203.</p> </li> <li> <p>Ryu Hayakawa. Quantum algorithm for persistent betti numbers and topological data analysis. Quantum, 6:873, 12 2022. arXiv: https://arxiv.org/abs/2111.00433. URL: https://doi.org/10.22331/q-2022-12-07-873, doi:10.22331/q-2022-12-07-873.</p> </li> <li> <p>Sam McArdle, Andr\u00e1s Gily\u00e9n, and Mario Berta. A streamlined quantum algorithm for topological data analysis with exponentially fewer qubits. arXiv: https://arxiv.org/abs/2209.12887, 2022.</p> </li> <li> <p>Dominic W Berry, Yuan Su, Casper Gyurik, Robbie King, Joao Basso, Alexander Del Toro Barba, Abhishek Rajput, Nathan Wiebe, Vedran Dunjko, and Ryan Babbush. Quantifying quantum advantage in topological data analysis. arXiv: https://arxiv.org/abs/2209.13581, 2022.</p> </li> <li> <p>Patrick Rall. Faster coherent quantum algorithms for phase, energy, and amplitude estimation. Quantum, 5:566, 10 2021. arXiv: https://arxiv.org/abs/2103.09717. URL: https://doi.org/10.22331/q-2021-10-19-566, doi:10.22331/q-2021-10-19-566.</p> </li> <li> <p>Yulong Dong, Xiang Meng, K. Birgitta Whaley, and Lin Lin. Efficient phase-factor evaluation in quantum signal processing. Physical Review A, 103:042419, 2021. arXiv: https://arxiv.org/abs/2002.11649. doi:10.1103/PhysRevA.103.042419.</p> </li> <li> <p>Lin Lin. Lecture notes on quantum algorithms for scientific computation. arXiv: https://arxiv.org/abs/2201.08309, 2022.</p> </li> <li> <p>Jeongwan Haah. Product decomposition of periodic functions in quantum signal processing. Quantum, 3:190, 2019. arXiv: https://arxiv.org/abs/1806.10236. doi:10.22331/q-2019-10-07-190.</p> </li> <li> <p>Rui Chao, Dawei Ding, Andr\u00e1s Gily\u00e9n, Cupjin Huang, and M\u00e1ri\u00f3 Szegedy. Finding angles for quantum signal processing with machine precision. arXiv: https://arxiv.org/abs/2003.02831, 2020.</p> </li> <li> <p>Theodore J. Yoder, Guang Hao Low, and Isaac L. Chuang. Fixed-point quantum search with an optimal number of queries. Physical Review Letters, 113(21):210501, 2014. arXiv: https://arxiv.org/abs/1409.3305. doi:10.1103/PhysRevLett.113.210501.</p> </li> <li> <p>Lin Lin and Yu Tong. Optimal polynomial based quantum eigenstate filtering with application to solving quantum linear systems. Quantum, 4:361, 2020. arXiv: https://arxiv.org/abs/1910.14596. doi:10.22331/q-2020-11-11-361.</p> </li> <li> <p>Lin Lin and Yu Tong. Near-optimal ground state preparation. Quantum, 4:372, 2020. arXiv: https://arxiv.org/abs/2002.12508. doi:10.22331/q-2020-12-14-372.</p> </li> <li> <p>Andr\u00e1s Gily\u00e9n. Quantum Singular Value Transformation &amp; Its Algorithmic Applications. PhD thesis, University of Amsterdam, 2019. URL: https://hdl.handle.net/11245.1/20e9733e-6014-402d-afa9-20f3cc4a0568.</p> </li> <li> <p>Ewin Tang and Kevin Tian. A cs guide to the quantum singular value transformation. arXiv: https://arxiv.org/abs/2302.14324, 2023.</p> </li> </ol> <ol> <li> <p>If \\(\\sigma_i=1\\), then there is no need for \\(\\ket{\\perp_i}, \\ket{\\perp_i'}\\), and the subspaces \\(S_i\\), \\(S_i'\\) become one dimensional.\u00a0\u21a9</p> </li> </ol>"},{"location":"quantum-algorithmic-primitives/quantum-linear-algebra/qubitization/","title":"Qubitization","text":""},{"location":"quantum-algorithmic-primitives/quantum-linear-algebra/qubitization/#rough-overview-in-words","title":"Rough overview (in words)","text":"<p>Qubitization has the following motivation: we are given a block-encoding \\(U_A\\) of a Hermitian operator \\(A\\), and we wish to manipulate \\(A\\)\u2014e.g., implement \\(A^2\\), or more generally some function \\(f(A)\\) [1]. However, the eigenvalues of \\(U_A\\) are typically unrelated to those of \\(A\\), and plain repeated applications of \\(U_A\\) do not in general produce the desired behavior. Qubitization converts the block-encoding \\(U_A\\) into a unitary operator \\(W\\) (sometimes called a qubiterate or a qubitized quantum walk operator) having the following guaranteed advantageous properties:</p><ol> <li>\\(W\\) is a block-encoding of the operator \\(A\\).</li> <li>The spectrum of \\(W\\) has a nice relation to the spectrum of \\(A\\).</li> <li>Repeated applications of \\(W\\) leads to structured behavior that can be cleanly analyzed.</li> </ol><p>This combination of features means that qubitization can be used for applying polynomial transformations to the spectrum of \\(A\\). For example, repeated application of \\(W\\) implements Chebyshev polynomials of \\(A\\), while other polynomials can also be implemented by using quantum signal processing [2, 1, 3].</p><p>The key observation is that a qubitization unitary \\(W\\) has eigenvalues and eigenvectors that relate in a nice way to those of \\(A\\). Thus one can also perform quantum phase estimation on \\(W\\) to learn these quantities [4, 5], providing a potentially cheaper alternative to such tasks compared to approaches based on explicit Hamiltonian simulation for implementing \\(U=e^{iAt}\\).</p>"},{"location":"quantum-algorithmic-primitives/quantum-linear-algebra/qubitization/#rough-overview-in-math","title":"Rough overview (in math)","text":"<p>We are given a \\((1, m, 0)\\)-block-encoding \\(U_A\\) of Hermitian \\(A\\) such that </p>\\[\\begin{equation} A= \\left(\\bra{0^m} \\otimes I \\right) U_A \\left(\\ket{0^m} \\otimes I \\right)\\Longleftrightarrow U_A = \\left(\\begin{array}{cc} A &amp; \\cdot \\\\ \\cdot &amp; \\cdot \\end{array}\\right)\\,, \\end{equation}\\]<p>where \\(\\ket{0^m}\\) denotes \\(\\ket{0}^{\\otimes m}\\). First we will assume \\(U_A\\) is also Hermitian (implying \\(U_A^2 = I\\), where \\(I\\) is the identity matrix). Let \\(A\\) have spectral decomposition \\(A = \\sum_\\lambda \\lambda \\ketbra{\\lambda}{\\lambda}\\). An application of \\(U_A\\) to an eigenstate \\(\\ket{\\lambda}\\) of \\(A\\) gives </p>\\[\\begin{equation} U_A \\ket{0^m} \\ket{\\lambda} = \\lambda \\ket{0^m} \\ket{\\lambda} + \\sqrt{1-\\lambda^2} \\ket{\\perp_{0^m, \\lambda}}, \\end{equation}\\]<p>where \\(\\ket{\\perp_{0^m, \\lambda}}\\) is a state perpendicular to \\(\\ket{0^m}\\).<sup>1</sup> Noting \\(U_A^2=I\\) reveals that the 2D subspace \\(S_\\lambda\\) spanned by \\(\\{ \\ket{0^m}\\ket{\\lambda}, \\ket{\\perp_{0^m, \\lambda}} \\}\\) is invariant under the action of \\(U_A\\). \\(U_A\\) restricted onto \\(S_\\lambda\\) can be described by the matrix </p>\\[ \\begin{aligned} \\ket{0^m}\\ket{\\lambda}\\ \\ \\ \\ \\  \\  \\   \\ket{\\perp_{0^m, \\lambda}}\\ \\ \\ \\\\ \\begin{gathered}\\ket{0^m}\\ket{\\lambda}\\\\ \\ket{\\perp_{0^m, \\lambda}}\\end{gathered} \\begin{pmatrix} \\lambda &amp; \\sqrt{1-\\lambda^2} \\\\ \\sqrt{1-\\lambda^2} &amp; -\\lambda \\end{pmatrix} \\end{aligned} \\]<p>which is a 2D reflection with eigenvalues \\(\\pm 1\\). Clearly, repeated application of (self-inverse) \\(U_A\\) can have limited effect on any input state. Qubitization uses a reflection \\(Z_{\\ket{0^m}} = (2\\ketbra{0^m}{0^m} - I)\\) to transform \\(U_A\\) into a Grover-like operator \\(W = Z_{\\ket{0^m}} U_A\\) which has the following matrix when restricted onto the invariant subspace \\(S_\\lambda\\) in the \\(\\{ \\ket{0^m}\\ket{\\lambda}, \\ket{\\perp_{0^m, \\lambda}} \\}\\) basis </p>\\[\\begin{equation} _{ \\{ \\ket{0^m}\\ket{\\lambda}, \\ket{\\perp_{0^m, \\lambda}} \\} } = \\left(\\begin{array}{cc} 1 &amp; 0 \\\\ 0 &amp; -1 \\end{array}\\right) \\left(\\begin{array}{cc} \\lambda &amp; \\sqrt{1-\\lambda^2} \\\\ \\sqrt{1-\\lambda^2} &amp; -\\lambda \\end{array}\\right) = \\left(\\begin{array}{cc} \\lambda &amp; \\sqrt{1-\\lambda^2} \\\\ - \\sqrt{1-\\lambda^2} &amp; \\lambda \\end{array}\\right), \\end{equation}\\]<p>showing that \\(W\\) is still a \\((1, m, 0)\\)-block-encoding of \\(A\\). This has the form of a \\(Y\\)-axis rotation </p>\\[\\begin{equation} _{ \\{ \\ket{0^m}\\ket{\\lambda}, \\ket{\\perp_{0^m, \\lambda}} \\} }=\\left(\\begin{array}{cc} \\cos(\\theta_\\lambda) &amp; \\sin(\\theta_\\lambda) \\\\ -\\sin(\\theta_\\lambda) &amp; \\cos(\\theta_\\lambda) \\end{array}\\right), \\end{equation}\\]<p>where \\(\\theta_\\lambda = \\arccos(\\lambda)\\). Therefore, \\(W\\) has eigenvalues \\(e^{\\pm i \\arccos(\\lambda)}\\) with respective eigenvectors \\(\\left(\\ket{0^m} \\ket{\\lambda} \\pm i \\ket{\\perp_{0^m, \\lambda}} \\right)/\\sqrt{2}\\), which can be accessed using quantum phase estimation.</p><p>Furthermore, we can see that on the span of the subspaces \\(S_\\lambda\\) repeated application of \\(W\\) acts as </p>\\[\\begin{align} W^d &amp; = \\bigoplus_\\lambda \\left(\\begin{array}{cc} \\cos(d\\theta_\\lambda) &amp; \\sin(d\\theta_\\lambda) \\\\ -\\sin(d\\theta_\\lambda) &amp; \\cos(d\\theta_\\lambda) \\end{array}\\right) \\\\ &amp; = \\bigoplus_\\lambda\\left(\\begin{array}{cc} T_d(\\lambda) &amp; \\sqrt{1-\\lambda^2} U_{d-1}(\\lambda) \\\\ -\\sqrt{1-\\lambda^2} U_{d-1}(\\lambda) &amp; T_d(\\lambda) \\end{array}\\right) \\\\ &amp; = \\left(\\begin{array}{cc} T_d(A) &amp; \\cdot \\\\ \\cdot &amp; \\cdot \\end{array}\\right), \\end{align}\\]<p>where \\(T_d(\\cdot)\\) and \\(U_d(\\cdot)\\) are degree-\\(d\\) Chebyshev polynomials of the first and second kind, respectively. Therefore, \\(W^d\\) applies the polynomial transformation \\(T_d\\) to each eigenvalue of \\(A\\) thereby implementing \\(T_d(A)\\).</p>"},{"location":"quantum-algorithmic-primitives/quantum-linear-algebra/qubitization/#dominant-resource-cost-gatesqubits","title":"Dominant resource cost (gates/qubits)","text":"<p>The resource cost of qubitization is inherited from the cost of the block-encoding. Given a Hermitian \\((\\alpha, m, 0)\\)-block-encoding \\(U_A\\), the qubitization operator \\(W\\) is a (non-Hermitian) \\((\\alpha, m, 0)\\)-block-encoding, and it uses no additional qubits. The operation \\(Z_{\\ket{0^m}} = (2\\ketbra{0^m}{0^m} - I)\\) can be implemented (up to global phase) with an \\(m\\)-qubit controlled \\(Z\\) gate, equivalent to an \\(m\\)-qubit Toffoli up to single-qubit gates. An example qubitization circuit is shown below in Fig. 1 for \\(m=3\\). Implementing a block-encoding of a degree-\\(d\\) Chebyshev polynomial applied to \\(A\\) requires \\(d\\) calls to \\(U_A\\) and \\(Z_{\\ket{0^m}}\\).</p><p> <p>Figure 1: An example qubitization circuit using the Hermitian \\((1,3,0)\\)-block-encoding \\(U_A\\).</p> </p><p>If the block-encoding \\(U_A\\) is not Hermitian, qubitization can be achieved using the construction of [1, Lemma 10] that uses one additional qubit and one call to controlled \\(U_A\\) and controlled \\(U_A^\\dag\\) to implement the Hermitian block-encoding </p>\\[\\begin{align} \\label{eq:genQubitiz} U'_A:=((HX)\\otimes I)(\\ketbra{0}{0}\\otimes U_A+\\ketbra{1}{1}\\otimes U_A^\\dagger)(H\\otimes I). \\end{align}\\]<p>An alternative to qubitization is based on quantum singular value transformation that uses the sequence \\(Z_{\\ket{0^m}} U_A^\\dag Z_{\\ket{0^m}} U_A\\), analogous to the earlier \\(W^2\\), acting as </p>\\[\\begin{equation} \\nonumber \\left(\\begin{array}{cc} \\lambda &amp; \\sqrt{1-\\lambda^2} \\\\ -\\sqrt{1-\\lambda^2} &amp; \\lambda \\end{array}\\right)^{\\!\\!2} \\end{equation}\\]<p>on a 2D subspace analogous to \\(S_\\lambda\\). The approach can be extended to odd-degree polynomials with a single additional application of \\(Z_{\\ket{0^m}} U_A\\) [3]. The advantage of this approach is that it does not require \\(U_A\\) to be Hermitian, thus there is no need for an additional qubit or calls to controlled \\(U_A^{\\pm 1}\\). This approach may be referred to as \"quantum eigenvalue transformation\" [6, 7] as this is a special case of quantum singular value transformation just applied to Hermitian \\(A\\).</p>"},{"location":"quantum-algorithmic-primitives/quantum-linear-algebra/qubitization/#caveats","title":"Caveats","text":"<p>The original formulation of qubitization [1] discussed above requires a Hermitian or normal block-encoded matrix \\(A\\). The concept can be extended to general (non-square) matrices via quantum singular value transformation, providing a significant generalization, however in some cases quantum signal processing and its generalized versions [8, 9] can exploit additional structure that comes for example from the extra symmetries of Hermitian block-encodings, leading to potential constant factor savings.<sup>2</sup></p>"},{"location":"quantum-algorithmic-primitives/quantum-linear-algebra/qubitization/#example-use-cases","title":"Example use cases","text":"<ul> <li>Some quantum algorithms in quantum chemistry that compute energies perform phase estimation on a qubitization operator \\(W\\) implemented via calls to a block-encoding of the electronic structure Hamiltonian. This avoids the approximation error incurred when performing phase estimation on \\(e^{iHt}\\), implemented via Hamiltonian simulation [4, 5].</li> <li>Qubitization acts as a precursor to quantum singular value transformation, which extends the concept to general matrices and unifies it with quantum signal processing.</li> </ul>"},{"location":"quantum-algorithmic-primitives/quantum-linear-algebra/qubitization/#further-reading","title":"Further reading","text":"<ul> <li>Original introduction of qubitization [1] and quantum singular value transformation [3].</li> <li>A pedagogical overview of quantum signal processing, its lifting to quantum singular value transformation, and their applications [10].</li> <li>Reference [6, Chapters 7 &amp; 8] provides an accessible derivation of qubitization and quantum singular value transformation.</li> </ul>"},{"location":"quantum-algorithmic-primitives/quantum-linear-algebra/qubitization/#bibliography","title":"Bibliography","text":"<ol> <li> <p>Guang Hao Low and Isaac L. Chuang. Hamiltonian simulation by qubitization. Quantum, 3:163, 2019. arXiv: https://arxiv.org/abs/1610.06546. doi:10.22331/q-2019-07-12-163.</p> </li> <li> <p>Guang Hao Low and Isaac L. Chuang. Optimal hamiltonian simulation by quantum signal processing. Physical Review Letters, 118(1):010501, 2017. arXiv: https://arxiv.org/abs/1606.02685. doi:10.1103/PhysRevLett.118.010501.</p> </li> <li> <p>Andr\u00e1s Gily\u00e9n, Yuan Su, Guang Hao Low, and Nathan Wiebe. Quantum singular value transformation and beyond: exponential improvements for quantum matrix arithmetics. In Proceedings of the 51st ACM Symposium on the Theory of Computing (STOC), 193\u2013204. 2019. arXiv: https://arxiv.org/abs/1806.01838. doi:10.1145/3313276.3316366.</p> </li> <li> <p>David Poulin, Alexei Kitaev, Damian S. Steiger, Matthew B. Hastings, and Matthias Troyer. Quantum algorithm for spectral measurement with a lower gate count. Physical Review Letters, 121:010501, 7 2018. arXiv: https://arxiv.org/abs/1711.11025. URL: https://link.aps.org/doi/10.1103/PhysRevLett.121.010501, doi:10.1103/PhysRevLett.121.010501.</p> </li> <li> <p>Dominic W. Berry, M\u00e1ria Kieferov\u00e1, Artur Scherer, Yuval R. Sanders, Guang Hao Low, Nathan Wiebe, Craig Gidney, and Ryan Babbush. Improved techniques for preparing eigenstates of fermionic hamiltonians. npj Quantum Information, 4(1):22, 5 2018. arXiv: https://arxiv.org/abs/1711.10460. URL: https://doi.org/10.1038/s41534-018-0071-5, doi:10.1038/s41534-018-0071-5.</p> </li> <li> <p>Lin Lin. Lecture notes on quantum algorithms for scientific computation. arXiv: https://arxiv.org/abs/2201.08309, 2022.</p> </li> <li> <p>Sam McArdle, Andr\u00e1s Gily\u00e9n, and Mario Berta. Quantum state preparation without coherent arithmetic. arXiv: https://arxiv.org/abs/2210.14892, 2022.</p> </li> <li> <p>Jeongwan Haah. Product decomposition of periodic functions in quantum signal processing. Quantum, 3:190, 2019. arXiv: https://arxiv.org/abs/1806.10236. doi:10.22331/q-2019-10-07-190.</p> </li> <li> <p>Rui Chao, Dawei Ding, Andr\u00e1s Gily\u00e9n, Cupjin Huang, and M\u00e1ri\u00f3 Szegedy. Finding angles for quantum signal processing with machine precision. arXiv: https://arxiv.org/abs/2003.02831, 2020.</p> </li> <li> <p>John M. Martyn, Zane M. Rossi, Andrew K. Tan, and Isaac L. Chuang. Grand unification of quantum algorithms. Physical Review X, 2(4):040203, 2021. arXiv: https://arxiv.org/abs/2105.02859. doi:10.1103/PRXQuantum.2.040203.</p> </li> </ol> <ol> <li> <p>If \\(\\lambda=\\pm 1\\), then there is no need for \\(\\ket{\\perp_{0^m, \\lambda}}\\), and the subspace \\(S_\\lambda\\) becomes one dimensional.\u00a0\u21a9</p> </li> <li> <p>Consider for example Hamiltonian simulation, where QSVT separately implements \\(\\sin(t H)\\) and \\(\\cos(t H)\\) using a block-encoding \\(U_H\\) of the Hamiltonian \\(H\\), and applies a 3-step oblivious amplification procedure on top of linear combination of unitaries to implement \\(\\exp( i t H)\\) [3]. Meanwhile, quantum signal processing implements \\(\\exp( i t H)\\) directly but requires an additional ancilla qubit and controlled access to a Hermitian block-encoding \\(U'_H\\), which, when implemented via Eq. [eq:genQubitiz], uses both controlled \\(U_H\\) and \\(U_H^\\dagger\\) resulting in a factor of \\(\\sim 4\\) overhead. Altogether these considerations suggest that the QSVT-based approach might have a slightly better constant factor overhead, particularly when controlled \\(U_H\\) is significantly more costly to implement than \\(U_H\\). If \\(U_H\\) is already Hermitian then quantum signal processing can have an improved complexity.\u00a0\u21a9</p> </li> </ol>"}]}